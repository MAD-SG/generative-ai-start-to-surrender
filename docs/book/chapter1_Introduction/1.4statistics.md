# 统计学简介

## 1.  抽样 sampling

### 1.1 抽样 (Sampling in Statistics)数学和统计定义

- 抽样是从一个总体 (Population) 中选取一个子集 (Sample) 的过程。
- 假设总体是集合 $\mathcal{P}$，其大小为 $N$，抽样选取的样本集合记为 $\mathcal{S} \subset \mathcal{P}$，样本大小为 $n$，其中 $n \ll N$。
**核心目标**
- **统计推断** ：通过研究样本 $\mathcal{S}$，估计总体 $\mathcal{P}$ 的参数（如均值、方差、分布等）。

- **核心问题** ：如何保证样本具有代表性，以减少总体与样本之间的误差。
**数学方法**
- 随机抽样：样本是从总体中独立且等概率地抽取的，每个元素被抽取的概率为 $\frac{1}{N}$。
- 分层抽样：总体分为若干子集，分别从每个子集中按比例抽取样本。
- 样本均值：$ \bar{x} = \frac{1}{n} \sum_{i=1}^n x_i$

样本均值是总体均值的无偏估计。

### 1.2 **统计依据**

- **大数定律** ：样本量 $n$ 越大，样本均值 $\bar{x}$ 趋近于总体均值 $\mu$。

- **中心极限定理** ：当样本量足够大时，样本均值 $\bar{x}$ 的分布接近正态分布。

    **应用示例**

    1. **调查研究** ：从城市中的居民中随机抽取 1000 人，调查他们的收入分布。

    2. **机器学习** ：从一个大规模数据集中选取子集，用于训练模型。

### 1.3 和 **采样 (Signal Sampling in Mathematics)** 的区别

- 采样是从一个连续信号 $f(t)$ 中，按照一定规则在离散点 $\{t_n\}$ 上取值，形成离散信号 $f[n]$ 的过程。
- 离散化的信号表示为：

$$
 f[n] = f(t_n), \quad t_n = nT, \quad n \in \mathbb{Z}
$$


其中 $T$ 是采样间隔，$1/T$ 是采样频率。

核心区别

- **抽样** ：研究离散总体的子集，推断总体特性。
- **采样** ：将连续信号离散化，为数字处理或分析做准备。
**操作对象**
- **抽样** ：离散总体（有限集合）。
- **采样** ：连续信号（时间域或空间域函数）。
**理论依据**

| 特性 | 抽样 | 采样 |
| --- | --- | --- |
| 基础理论 | 大数定律、中心极限定理 | 奈奎斯特采样定理、插值理论 |
| 样本代表性 | 随机性和覆盖性是关键 | 采样频率决定是否能够还原信号 |
**数学公式** | 特性 | 抽样公式 | 采样公式 |
| --- | --- | --- |
| 均值估计 | $\bar{x}=\frac{1}{n}\sum_{i=1}^n x_i$ | $f[n]=f(tn),t_n = nT$ |
| 误差范围 | 标准误差：$text{SE} = \frac{\sigma}{\sqrt{n}}$​ | 采样误差：由混叠频率引起 |

## 2. 大数定律 (LLN)

在大数定律中，**样本平均值** 的定义为：$ \bar{X}_n = \frac{1}{n} \sum_{i=1}^n X_i$,
其中 $X_1, X_2, \dots, X_n$ 是独立同分布的随机变量，具有期望值 $\mu = \mathbb{E}[X_i]$ 和有限方差 $\sigma^2 = \mathrm{Var}(X_i)$。

**大数定律的结论：**

$$
 \bar{X}_n \xrightarrow{\text{a.s.}} \mu, \quad \text{或者} \quad \mathbb{P}(|\bar{X}_n - \mu| > \epsilon) \to 0 \; (\forall \epsilon > 0, \; n \to \infty).
$$


**大数定律的关键点：**

- 它研究的是 $\bar{X}_n$ 的长期行为（随着 $n \to \infty$）。
- 它不涉及样本平均值的概率分布或波动性，只强调$\bar{X}_n$会逐渐接近 $\mu$。

## 3 中央极限定理 (CLT)

在中央极限定理中，考虑的也是**样本平均值** ：$\bar{X}_n = \frac{1}{n} \sum_{i=1}^n X_i$.

但这里进一步研究了$\bar{X}_n$ 的波动性或概率分布的行为。

**标准化形式：**

我们构造一个标准化的随机变量 $Z_n$，用来衡量 $\bar{X}_n$ 偏离期望值的程度：

$$Z_n = \frac{\sqrt{n}(\bar{X}_n - \mu)}{\sigma}.$$


**CLT 的结论：**
当 $n \to \infty$，标准化的变量 $Z_n$ 的分布收敛于标准正态分布：$Z_n \xrightarrow{d} N(0, 1)$。

这说明：

- **样本平均值** 在 $n$ 足够大时的分布会趋于正态分布，且中心是 $\mu$，标准差是 $\frac{\sigma}{\sqrt{n}}$。

- 样本平均值 $\bar{X}_n$ 的分布近似为：

$$
 \bar{X}_n \sim N\left(\mu, \frac{\sigma^2}{n}\right).
$$


## 4. 中心极限定理和大数定律两个平均值的核心差异

**差异的核心：**

- **LLN 的平均值** ：关注 $\bar{X}_n$ 是否在 $n \to \infty$ 时收敛到一个固定值 $\mu$。
- **CLT 的平均值** ：关注 $\bar{X}_n$ 在有限 $n 时的概率分布行为（波动性）。

**用数学公式表示：**

1. **LLN**  描述：

$$
 \bar{X}_n \xrightarrow{\text{a.s.}} \mu \quad \text{（收敛到期望值 \(\mu\)）}.
$$


1. **CLT**  描述：

$$
 \sqrt{n}(\bar{X}_n - \mu) \xrightarrow{d} N(0, \sigma^2) \quad \text{（描述标准化偏差的分布行为）}.
$$


**公式差异总结：**

- 在 LLN 中，强调的是：

$$
 \bar{X}_n \approx \mu \quad (\text{当 } n \to \infty).
$$


即，随着 $n$ 增加，样本平均值$\bar{X}_n$ 越来越接近期望值 $\mu$。

- 在 CLT 中，强调的是：

$$
 \bar{X}_n \sim N\left(\mu, \frac{\sigma^2}{n}\right),
$$


即，样本平均值在有限 $n$ 时服从正态分布，方差 $\sigma^2 / n$ 会随着 $n$ 增大逐渐减小，但存在波动性。

**直观解释两者差异：**

- **LLN** ：告诉我们，当 $n$ 越来越大时，$\bar{X}_n$ 最终会无限接近于期望值 $\mu$（值越来越稳定）。
- **CLT** ：告诉我们，对于有限的 $n$，$\bar{X}_n$ 仍然有波动，并且这种波动遵循正态分布，且波动范围随 $n$ 增大而减小（$\sim \frac{1}{\sqrt{n}}$）。
**例子**

假如你测量某机器零件的长度，单个零件的长度是随机变量 $X$:

- **大数定律** ：如果你测量 $n$ 个零件，计算它们的平均长度 $\bar{X}_n$，当 $n$ 足够大时，这个平均值会无限接近于零件的真实平均长度（期望值 $\mu$）。
- **中央极限定理** ：如果 $n$ 不是无限大（比如 $n = 100$)),那么平均长度 $\bar{X}_n$ 会在某个范围内波动，且这种波动的概率分布是正态分布。

**总结：LLN 和 CLT 的平均值差异**

1. **LLN**  研究的是 $\bar{X}_n$ 是否稳定并最终收敛到 $\mu$，强调长期收敛性。

2. **CLT**  研究的是 $\bar{X}_n$ 的分布如何演变为正态分布，强调分布形状和波动性。

用更直观的比喻：

- **LLN**  就像你测量很多次，逐渐逼近“真实值”。

- **CLT**  告诉你在有限次测量时，这个“逼近值”有多大的波动范围，以及波动的概率分布是什么样的。

## 5. change of variable

随机变量分布的 **Change of Variable** （变量变换）是概率论中一个重要的公式，用于描述当随机变量通过某种函数进行变换时，其概率密度如何变化。

**公式推导** 假设我们有一个随机变量 $z$，其概率密度为 $p_Z(z)$，并定义了一个可逆变换 $z = f(x)$，其逆变换为 $x = f^{-1}(z)$。目标是求变换后随机变量 $x$ 的概率密度 $p_X(x)$。

**Change of Variable 定理** 当 $z = f(x)$ 且变换 $f(x)$ 可逆时，变换后的概率密度 $p_X(x)$ 可以通过以下公式计算：$
 p_X(x) = p_Z(f(x)) \cdot \left| \det \left( \frac{\partial f(x)}{\partial x} \right) \right|
$

- $p_Z(f(x))$：是原始变量 $z$ 的概率密度函数值。

- $\frac{\partial f(x)}{\partial x}$：是变换 $f(x)$ 的雅可比矩阵（Jacobian Matrix）。

- $\det \left( \frac{\partial f(x)}{\partial x} \right)$：是雅可比矩阵的行列式，表示变换对概率密度的缩放程度。

- $\left| \cdot \right|$：是行列式的绝对值，因为概率密度需要非负。

**直观理解**

1. **变换带来的密度变化** ：
如果变换 $f(x)$ 压缩了某一区域的体积（即行列式小于 1），则该区域的概率密度会增加；反之，如果体积扩大，则概率密度会减小。

2. **概率保持不变** ：
随机变量的总概率始终为 1，因此变换只改变密度的分布形式，而不改变总体积。

**一维情况** 在一维情况下（即 $z$ 和 $x$ 是标量），雅可比矩阵 $\frac{\partial f(x)}{\partial x}$ 退化为导数 $f'(x)$，公式简化为：$
 p_X(x) = p_Z(f(x)) \cdot \left| f'(x) \right|
$

例如：

- 如果 $z \sim \mathcal{N}(0, 1)$ 且 $z = f(x) = 2x + 3$，则：
$
 p_X(x) = \mathcal{N}(f(x) \mid 0, 1) \cdot \left| f'(x) \right| = \mathcal{N}(2x + 3 \mid 0, 1) \cdot 2
$

**多维情况** 在多维情况下（即 $z$ 和 $x$ 是向量），需要使用雅可比矩阵。雅可比矩阵定义为：$
 J_f(x) = \frac{\partial f(x)}{\partial x} =
\begin{bmatrix}
\frac{\partial f_1}{\partial x_1} & \cdots & \frac{\partial f_1}{\partial x_n} \\
\vdots & \ddots & \vdots \\
\frac{\partial f_m}{\partial x_1} & \cdots & \frac{\partial f_m}{\partial x_n}
\end{bmatrix}
$

多维情况下，公式为：$p_X(x) = p_Z(f(x)) \cdot \left| \det J_f(x) \right|$

## 6. 随机变量和分布

表示一个随机变量的分布通常使用以下几种方式：

### 6.1 概率密度函数(PDF, Probability Density Function)

- 如果随机变量是连续型随机变量(如正态分布),其分布可以用概率密度函数 $f_X(x)$ 表示。

- 例如，对于正态分布:

$$
 X \sim \mathcal{N}(\mu, \sigma^2)
$$


或

$$
 f_X(x) = \frac{1}{\sqrt{2\pi\sigma^2}} e^{-\frac{(x-\mu)^2}{2\sigma^2}}
$$


表示 $X$ 服从均值为 $\mu$、方差为 $\sigma^2$ 的正态分布。

### 6.2. 概率质量函数(PMF, Probability Mass Function)

- 如果随机变量是离散型随机变量，其分布用概率质量函数 $$P(X = x)$$ 表示。


- 例如，对于一个离散型变量 $X$ 的伯努利分布：

$$
 P(X = x) = p^x (1-p)^{1-x}, \quad x \in \{0, 1\}
$$


### 6.3. **累积分布函数(CDF, Cumulative Distribution Function)

- 累积分布函数表示随机变量小于等于某个值的概率：

$$
 F_X(x) = P(X \leq x)
$$


- 它适用于连续型和离散型随机变量。

### 6.4. **分布符号表示**

- 在简化场景中，可以直接用符号 $\sim$ 表示随机变量的分布类型。例如：
  - $X \sim \mathcal{N}(\mu, \sigma^2)$：正态分布。
  - $X \sim \text{Bernoulli}(p)$：伯努利分布。
  - $X \sim \text{Uniform}(a, b)$：均匀分布。

或者更进一步, 可以表示为：$\mathcal{N}(\mathbf{X}; \mu, \Sigma)$,
$\mathcal{N}$ 是 "Normal"（正态分布）的首字母，用于表明分布的类型。
这是一种记号惯例，用来简洁地表示多元正态分布:

- 第一部分 $\mathbf{X}$ 是随机变量。

- 第二部分 $0$ 和 $\mathbf{I}$ 分别表示均值向量和协方差矩阵。

### 6.5. **联合分布与条件分布**

- 如果有多个随机变量，可以用联合分布或条件分布来描述它们的关系：
  - 联合分布：$P(X, Y)$ 或 $f_{X, Y}(x, y)$。

  - 条件分布：$P(X | Y)$ 表示在 $Y$ 已知的条件下，$X$ 的分布。

## 7. Markov链

**Markov链** （Markov Chain）是一个满足 **Markov性** （或称为“无后效性”）的随机过程。简单来说，Markov性指的是：未来的状态只与当前的状态有关，而与过去的状态无关。

### 7.1 Markov链的数学定义

设 $X_t$ 表示一个随机过程在时间 $t$ 时的状态。如果对于任意的 $t$ 和状态序列 $x_0, x_1, \ldots, x_t$，满足条件：

$$
 P(X_{t+1} = x_{t+1} \mid X_t = x_t, X_{t-1} = x_{t-1}, \ldots, X_0 = x_0) = P(X_{t+1} = x_{t+1} \mid X_t = x_t)
$$


即，给定当前状态 $X_t$，未来状态 $X_{t+1}$ 的分布与过去的状态 $X_{t-1}, X_{t-2}, \ldots$ 无关，那么这个随机过程就是一个**Markov过程** 。如果状态空间是离散的，并且时间也是离散的，这个过程称为**离散时间Markov链** （Discrete-Time Markov Chain, DTMC）。

### 7.2 Markov链的要素

1. **状态空间**  ($S$)
Markov链可以处于的所有可能状态的集合。状态空间可以是有限的，也可以是无限的。

2. **转移概率**
从当前状态转移到下一个状态的概率。通常用 ****转移概率**
从当前状态转移到下一个状态的概率。通常用 转移概率矩阵 $P$**  表示：$
 P_{ij} = P(X_{t+1} = j \mid X_t = i)
$
这里 $P_{ij}$ 表示从状态 $i$ 转移到状态 $j$ 的概率。

3. **初始状态分布**
指随机过程在 $t = 0$ 时各个状态的概率分布，记为 $\pi_0$。

---

### 7.3 Markov链的性质

1. **无后效性（Markov性）** ：未来的状态只依赖于当前状态，与过去状态无关。

2. **状态转移的概率分布固定** ：转移概率矩阵 $P$ 通常是时间不变的。

3. **n步转移概率** ：经过 $n$ 步从状态 $i$ 转移到状态 $j$ 的概率可用矩阵幂表示：

$$
 P^{(n)}_{ij} = P(X_{t+n} = j \mid X_t = i)
$$


### 7.3 典型应用

- **自然语言处理** ：如语言模型中用Markov链预测下一个词。

- **金融建模** ：股票价格或经济指标的动态建模。

- **网络分析** ：如PageRank算法，用Markov链分析网页跳转。

- **生物信息学** ：基因序列分析。

### 7.4 不同形式的Markov链

Markov链中的“**状态转移的概率分布固定** ”并不是一个必须条件，而是针对**齐次Markov链** （Homogeneous Markov Chain）的假设。实际上，Markov链也有以下情况：

**1. 齐次Markov链（Homogeneous Markov Chain）** 这是最常见的情况，转移概率矩阵 $P$ **不随时间变化** ，即对于任意时间 $t$：$
 P(X_{t+1} = j \mid X_t = i) = P_{ij}, \quad \text{(恒定)}。
$

这种假设简化了分析，且在很多实际问题中是合理的，比如PageRank算法、天气模型等。

**2. 非齐次Markov链（Non-Homogeneous Markov Chain）** 在一些场景下，转移概率可能**随时间变化** ，即：$
 P(X_{t+1} = j \mid X_t = i) = P_{ij}^{(t)}， \quad \text{(随 \( t \) 变化)}。
$
这意味着状态从 $i$ 转移到 $j$ 的概率依赖于时间 $t$。这种情况通常用于以下情景：

- **季节性变化** ：比如天气模型，夏季的天气转移概率不同于冬季。

- **动态系统** ：比如金融市场，其状态转移可能随时间或外部事件调整。

**3. 其他扩展形式**
除了以上两种，还可以有更复杂的Markov链形式：

1. **半Markov过程（Semi-Markov Process）** ：允许在每个状态停留的时间不是固定的，也不是指数分布。

2. **高阶Markov链（Higher-Order Markov Chain）** ：未来状态依赖于多个历史状态（不仅是上一个状态），如：

$$
 P(X_{t+1} \mid X_t, X_{t-1}, \ldots, X_{t-k})。
$$


## 8 Monte Carlo estimate

**Monte Carlo estimate**  是一种利用随机抽样方法来近似计算复杂问题的数值解的统计技术。它广泛应用于数学、物理、金融、工程等领域，尤其是那些解析解难以获得的问题。

---

### 8.1 基本原理

Monte Carlo 方法基于以下核心思想：

1. 使用随机数生成一系列样本。

2. 根据这些样本，计算一个函数或系统的平均值。

3. 使用大数定律和中心极限定理，来确保通过大量随机样本的平均值可以逼近真实值。

简单来说，Monte Carlo 方法通过多次模拟和统计分析，来估计某些复杂问题的解。

---

### 8.2 Monte Carlo estimate 的步骤

以估计积分 $\int_a^b f(x) dx$ 为例：

1. 在区间 $[a, b]$ 内生成 $N$ 个随机样本 $x_1, x_2, \ldots, x_N$。

2. 计算 $f(x)$ 的值在这些样本点上的平均值：$ \text{平均值} = \frac{1}{N} \sum_{i=1}^N f(x_i)$

3. 用以下公式估计积分值：$\int_a^b f(x) dx \approx (b-a) \cdot \text{平均值}$

对于多维积分、概率分布计算或复杂物理系统模拟，Monte Carlo 方法可以通过类似的方式进行扩展。

### 8.3 Monte Carlo estimate 的典型应用

1. **计算复杂积分**:  用于解决传统数值积分方法难以处理的高维积分问题。

2. **模拟随机过程**:  模拟股票价格路径（如 Black-Scholes 模型）、粒子运动、队列排队等问题。

3. **概率估计**:  估计事件发生的概率，例如在统计物理中模拟系统的状态分布。

4. **优化问题**:  在机器学习中，用 Monte Carlo 方法优化参数或模型性能。

### 8.4 优点与缺点

#### 8.4.1 优点

- **通用性强**:  可以应用于高维、复杂的问题。

- **易于实现**:  不依赖问题的具体形式，只需要生成随机样本并计算平均值。

- **渐进收敛：**  随着样本数量增加，估计值会逐渐收敛到真实值。

#### 8.4.2 缺点

- **效率较低：**  收敛速度较慢，通常需要大量样本来达到高精度。

- **依赖随机数质量：**  生成高质量的随机样本对结果至关重要。

- **高维问题的样本效率低：**  高维问题中的“维度灾难”会显著增加所需样本数量。

### 8.5 直观例子

**Monte Carlo estimate**  是一种利用随机抽样方法来近似计算复杂问题的数值解的统计技术。它广泛应用于数学、物理、金融、工程等领域，尤其是那些解析解难以获得的问题。

## 9.Entropy,KL divergence,ELBO

### 9.1 熵(Entropy)

熵衡量分布的平均不确定性。
**积分形式** 对于连续分布 $p(x)$，熵的积分形式为：

$$
 H(X) = -\int p(x) \log p(x) \, dx
$$


**期望形式** 熵也可以表示为随机变量 $X$ 的信息量的期望：

$$
 H(X) = -\mathbb{E}_{X \sim p(x)}[\log p(X)]
$$


其中 $\mathbb{E}_{X \sim p(x)}$ 表示关于分布 $p(x)$ 的期望。

### 9.2KL散度（KL Divergence

KL散度衡量两个分布之间的差异。
**积分形式** 对于连续分布 $p(x)$ 和 $q(x)$，KL散度的积分形式为：

$$
 D_{\text{KL}}(P \| Q) = \int p(x) \log \frac{p(x)}{q(x)} \, dx
$$


**期望形式** KL散度可以写为关于分布 $p(x)$ 的对数比值的期望：

$$
 D_{\text{KL}}(P \| Q) = \mathbb{E}_{X \sim p(x)} \left[ \log \frac{p(X)}{q(X)} \right]
$$


### 9.3. 证据下界（Evidence Lower Bound, ELBO)

ELBO 是在变分推断中用来优化后验分布的目标函数。

**积分形式**
ELBO 的积分形式为：

$$
 \mathcal{L}(q) = \int q(z) \log p(\mathcal{D} \mid z) \, dz - \int q(z) \log \frac{q(z)}{p(z)} \, dz
$$


**期望形式** 将积分形式改写为关于 $$q(z)$$ 的期望，得到：


$$
 \mathcal{L}(q) = \mathbb{E}_{z \sim q(z)}[\log p(\mathcal{D} \mid z)] - D_{\text{KL}}(q(z) \| p(z))
$$


**分解为对数似然**
边际对数似然可以分解为 ELBO 和 KL 散度：

$$
 \log p(\mathcal{D}) = \mathcal{L}(q) + D_{\text{KL}}(q(z) \| p(z \mid \mathcal{D}))
$$


其中：

$$\mathcal{L}(q) = \mathbb{E}_{z \sim q(z)}[\log p(\mathcal{D}, z) - \log q(z)]$$


**总结**

| 概念 | 积分形式 | 期望形式 |
| --- | --- | --- |
| 熵 $H(X)$ | $-\int p(x) \log p(x)$ | $-\mathbb{E}_{X \sim p(x)}[\log p(X)]$ |
| KL散度 ${\text{KL}}(P \| Q)$ | $\int p(x) \log \frac{p(x)}{q(x)} \, dx$ | $\mathbb{E}_{X \sim p(x)} \left[ \log \frac{p(X)}{q(X)} \right]$
| ELBO $\mathcal{L}(q)$ | $\int q(z) \log p(\mathcal{D} \mid z) \, dz - \int q(z) \log \frac{q(z)}{p(z)}$ | $\mathbb{E}_{z \sim q(z)}[\log p(\mathcal{D} \mid z)] - D_{\text{KL}}(q(z) \| p(z)) $ |

#### 9.3.1 ELBO {#ELBO}

---
证明

$$
 \mathcal{L}(x, \theta, q) = \log p_\theta(x) - D_{\text{KL}}(q_\phi(z|x) \| p_\theta(z|x)).\\
=\mathbb{E}_{z \sim q_\phi} [\log p_\theta(x, z)] + H(q_\phi).
$$


推导步骤

1. **KL 散度定义** ：
由 KL 散度的定义：

$$
 D_{\text{KL}}(q_\phi(z|x) \| p_\theta(z|x)) = \mathbb{E}_{z \sim q_\phi} \left[ \log \frac{q_\phi(z|x)}{p_\theta(z|x)} \right].
$$


将其代入公式：

$$
 \mathcal{L}(x, \theta, q) = \log p_\theta(x) - \mathbb{E}_{z \sim q_\phi} \left[ \log \frac{q_\phi(z|x)}{p_\theta(z|x)} \right].
$$


2. **贝叶斯公式替换 $p_\theta(z|x)$** :

根据贝叶斯公式：

$$
 p_\theta(z|x) = \frac{p_\theta(x, z)}{p_\theta(x)}.
$$


将其代入：

$$
 \mathcal{L}(x, \theta, q) = \log p_\theta(x) - \mathbb{E}_{z \sim q_\phi} \left[ \log \frac{q_\phi(z|x)}{p_\theta(x, z) / p_\theta(x)} \right].
$$


简化分母中的分数：

$$
 \mathcal{L}(x, \theta, q) = \log p_\theta(x) - \mathbb{E}_{z \sim q_\phi} \left[ \log \left( q_\phi(z|x) \cdot \frac{p_\theta(x)}{p_\theta(x, z)} \right) \right].
$$


3. **分解对数项** ：
展开对数项：

$$
 \mathcal{L}(x, \theta, q) = \log p_\theta(x) - \mathbb{E}_{z \sim q_\phi} \left[ \log q_\phi(z|x) + \log p_\theta(x) - \log p_\theta(x, z) \right].
$$


将期望展开：

$$
 \mathcal{L}(x, \theta, q) = \log p_\theta(x) - \mathbb{E}_{z \sim q_\phi} [\log q_\phi(z|x)] - \mathbb{E}_{z \sim q_\phi} [\log p_\theta(x)] + \mathbb{E}_{z \sim q_\phi} [\log p_\theta(x, z)].
$$


注意到 $\log p_\theta(x)$ 是常数，可以提到期望外部：

$$
 \mathcal{L}(x, \theta, q) = \mathbb{E}_{z \sim q_\phi} [\log p_\theta(x, z)] - \mathbb{E}_{z \sim q_\phi} [\log q_\phi(z|x)].
$$


4. **熵的定义替换** ：

根据熵的定义：

$$
 H(q_\phi) = -\mathbb{E}_{z \sim q_\phi} [\log q_\phi(z|x)].
$$


将其代入：

$$
 \mathcal{L}(x, \theta, q) = \mathbb{E}_{z \sim q_\phi} [\log p_\theta(x, z)] + H(q_\phi).
$$


---

## Reference

[1] [Book: Deep Learning, Ian Goodfellow, Yoshua Bengio, Aaron Courville](https://github.com/janishar/mit-deep-learning-book-pdf/blob/master/complete-book-pdf/Ian%20Goodfellow%2C%20Yoshua%20Bengio%2C%20Aaron%20Courville%20-%20Deep%20Learning%20(2017%2C%20MIT).pdf)
