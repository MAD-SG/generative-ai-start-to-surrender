# 能量模型：理论与应用全景解读

---

## **引言**
能量模型（Energy-Based Models, EBMs）是机器学习领域的一类重要生成模型，其核心思想是通过能量函数隐式定义数据分布。与显式建模概率密度的模型（如标准化流、VAE）不同，能量模型通过“能量值”衡量样本的合理性，低能量对应高概率区域。这种灵活性使其在图像生成、多模态学习、科学计算等任务中展现出独特优势。
本文将系统解析能量模型的**数学基础**、**核心流派**、**扩展方法**及其与主流生成模型（如GAN、扩散模型）的联系，并探讨其未来发展方向。

---

## 1. 能量模型的基础理论

### 1.1. 定义与数学形式

能量模型通过能量函数 $E_\theta(x)$ 隐式定义概率分布：

$$
P_\theta(x) = \frac{e^{-E_\theta(x)}}{Z(\theta)}, \quad Z(\theta) = \int e^{-E_\theta(x)} dx
$$

- **能量函数 $E_\theta(x)$**：衡量样本 $x$ 的“不合理性”，通常由神经网络参数化。
- **归一化因子 $Z(\theta)$**：确保概率积分为1，但在高维空间中难以直接计算。

类比物理系统

- 物理势能：在物理学中，势能越低的状态越稳定（如小球在谷底）。
- 能量模型：能量函数E(x) 扮演类似势能的角色，低能量区域对应数据分布的高概率区域（即真实数据集中出现可能性大的样本）。

能量函数本质是一个评分函数：

- 对合理的样本（如训练数据）赋予低能量值;
- 对不合理的样本（如噪声、异常值）赋予高能量值。

示例：

- 在图像生成任务中，清晰的图片能量低，模糊或混乱的图片能量高;
- 在文本生成中，语法正确的句子能量低，语义矛盾的句子能量高。

这里大家可能会有困惑，虽然定义了一个能量，但是这个能量到底怎么使用？使用能量模型有两个核心要解决的问题，一个是学习出能量函数和目标数据分布一致，另外一个是从能量函数中采样出数据，这是能量模型的核心挑战。后续我们会讲到怎么学习能量函数，又怎么从能量函数中采样。直观上讲，假设我们有了一个能量函数，那采样意味着我们按照能量函数给出的分布概率进行采样。

### 1.2. 核心假设与条件

- **低能量对应高概率**：真实数据样本位于能量函数的低能区域。
- **数学条件**：
  - **可积性**：保证 $Z(\theta)$ 存在（积分收敛）。
  - **可微分性**：能量函数需对输入 $x$ 和参数 $\theta$ 可导，以支持梯度优化。
- **训练假设**：
  - **对比学习**：通过区分真实样本（低能量）与噪声样本（高能量）优化能量函数。
  - **采样可行性**：依赖高效采样方法（如MCMC）生成负样本。

## 2. 能量模型的核心挑战

### 2.1. 估计真实数据分布 $p_{\text{data}}(x)$

直接计算归一化因子 $Z(\theta)$ 不可行，需绕过显式积分：

- **对比散度（CD）**：用少量MCMC步骤生成负样本，对比优化能量函数（如受限玻尔兹曼机）。
- **分数匹配（Score Matching）**：直接匹配数据分布的梯度 $\nabla_x \log p_{\text{data}}(x)$（即能量函数的负梯度）。
- **对抗训练**：将生成器作为采样器，判别器作为能量函数（如EBGAN）。

### 2.2. 高效采样

从 $P_\theta(x) \propto e^{-E_\theta(x)}$ 中采样需探索低能量区域：

- **马尔可夫链蒙特卡洛（MCMC）**：
  - **Langevin动力学**：通过梯度下降与噪声扰动迭代采样：

$$
x_{t+1} = x_t - \eta \nabla_x E_\theta(x_t) + \sqrt{2\eta} \epsilon_t, \quad \epsilon_t \sim \mathcal{N}(0, I)
$$

- **Gibbs采样**：适用于具有局部依赖性的模型（如玻尔兹曼机）。
- **隐式生成器**：如GAN的生成器直接学习从简单分布到数据分布的映射。
- **扩散模型**：在去噪过程中结合能量梯度引导采样。

采样时一般都需要能量函数的梯度，这个梯度我们也叫做"score function", 是一个向量场，表示能量变化的方向和强度。

- 预测能量函数的模型， 模型输出一个标量值, 我们叫 "EBM", energy-based model
- 直接预测score function 的模型, 模型输出为一个向量场, 我们叫做 "SBM", score based model

## 3. 能量模型的主流流派

### 3.1. Contrastive Divergence

- **核心**：正常迭代模型，需要计算$\theta$ 的梯度，那我们是不是可以直接计算出 $p_\theta(x)$ 的梯度, 然后按照梯度方向去更新梯度。 根据这个方法我们就得到了对比散度（CD）方法。

- **代表模型**：受限玻尔兹曼机（RBM）、Deep Belief Networks。
- **特点**：训练稳定，但MCMC采样效率低。

### 3.2. 分数匹配

- **核心**： 直接计算两个分布之间的距离会比较难，但是计算两个分布的梯度的差异会容易一些。同时利用分部积分，可以绕过原始分布的梯度计算。这就是所谓的 **score matching** 方法。这里的‘score’ 就是梯度。

$$
 J(\theta) = \frac{1}{2} \mathbb{E}_{p(x)} \left[ \| \nabla_x \log q_\theta(x) - \nabla_x \log p(x) \|^2 \right].
$$

它等价于优化

$$
 \min_\theta\mathbb{E}_{p(x)} \left[ \text{trace} \left( \nabla_x^2 \log q_\theta(x) \right) + \frac{1}{2} \| \nabla_x \log q_\theta(x) \|^2 \right].
$$

因为二阶导的计算通常比较复杂，因此在这个方向上会有不同的实践方法，常见的有sliced score matching 和 denosing score matching

- **代表模型**：常见的score matching 有 sliced score matching和denosing score matching
- **特点**：生成质量高，但计算成本大。

### 3.3. 对抗训练派

- **核心**：判别器作为能量函数，生成器作为采样器。
- **代表模型**：EBGAN、BEGAN。
- **特点**：生成高效，但易模式崩溃。

### 3.4. 结构化能量模型

- **核心**：引入领域知识（如图结构、物理约束）设计能量函数。
- **代表模型**：GraphEBM（分子生成）、CRF（条件随机场）。
- **特点**：可解释性强，泛化性弱。

---

## 4.能量模型的扩展方法

### 4.1. 条件能量模型

通过条件变量 $c$（如文本、标签）建模条件分布 $p(x \mid c)$：

- **能量函数**：$E_\theta(x, c)$，概率分布为

$$
p(x \mid c) = \frac{e^{-E_\theta(x, c)}}{Z(c)}, \quad Z(c) = \int e^{-E_\theta(x, c)} dx
$$

- **应用场景**：文本到图像生成、可控生成（如DALL·E 2）。

### 4.2. 隐变量能量模型

引入隐变量 $z$ 建模联合分布 $p(x, z)$，提升表达能力：

- **变分能量模型（VAE-EBM）**：结合VAE的变分推断与能量函数约束。

$$
\log p(x) \geq \mathbb{E}_{q(z|x)} \left[ -E_\theta(x, z) - \log q(z|x) \right] - \log Z
$$

- **对抗式隐变量EBMs**：生成器 $G(z)$ 生成样本，能量函数 $E_\theta(x)$ 判别合理性。

### 4.3. 能量引导的扩散模型

在扩散过程中显式引入能量函数 $E_\theta(x, c)$，增强生成可控性：

- **采样公式**：

$$
x_{t-1} = \text{Denoise}(x_t) - \eta \nabla_x E_\theta(x_t, c)
$$

- **应用**：分子生成、艺术品风格迁移。

---

## 5. 能量模型与其他生成模型的关系

### 5.1. VAE：隐变量能量模型的变分实现

VAE通过隐变量 $z$ 建模联合分布 $p(x, z)$，其ELBO目标等价于能量函数的变分优化：

$$
\text{ELBO} = \mathbb{E}_{q(z|x)}[\log p(x|z)] - \text{KL}(q(z|x) \| p(z))
$$

### 5.2. GAN：对抗式能量模型

- **EBGAN**：判别器 $D(x)$ 作为能量函数，生成器 $G(z)$ 最小化 $E(G(z))$。
- **能量视角**：GAN的对抗训练隐式优化能量分布。

### 5.3. 扩散模型：动态能量模型

- **分数匹配等价性**：扩散模型学习分数函数 $\nabla_x \log p(x)$，即能量梯度 $-\nabla_x E(x)$。
- **Langevin动力学**：扩散采样过程与能量模型的MCMC方法一致。

### 5.4. 标准化流：显式归一化的特例

标准化流通过可逆变换显式保证 $Z=1$，其能量函数为 $E(x) = -\log p(x)$，但生成机制（确定性映射）与传统EBMs不同。

---

## 6.挑战与未来方向

### 6.1. 核心挑战

- **训练稳定性**：隐变量与条件变量的联合优化易导致模式崩溃。
- **采样效率**：高维数据下MCMC收敛缓慢。
- **可解释性**：隐变量的物理意义不明确。

### 6.2. 未来趋势

- **高效采样算法**：扩散蒸馏、快速MCMC变体。
- **多模态统一建模**：跨文本、图像、语音的能量函数设计。
- **与大型模型结合**：利用LLMs提供条件信号或隐变量先验。
- **科学计算深化**：分子动力学、材料设计中的能量模型应用。
