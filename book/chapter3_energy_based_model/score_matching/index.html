
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../cd/">
      
      
        <link rel="next" href="../../chapter6_VAE/vae_introduction/">
      
      
      <link rel="icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.49">
    
    
      
        <title>Score Matching - Generative AI: From Start to Surrender</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.6f8fc17f.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../stylesheets/extra.css">
    
      <link rel="stylesheet" href="https://unpkg.com/katex@0/dist/katex.min.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      
  


  
  

<script id="__analytics">function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config",""),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script>
  
    <script>"undefined"!=typeof __md_analytics&&__md_analytics()</script>
  

    
    
    
   <link href="../../../assets/stylesheets/glightbox.min.css" rel="stylesheet"/><style>
    html.glightbox-open { overflow: initial; height: 100%; }
    .gslide-title { margin-top: 0px; user-select: text; }
    .gslide-desc { color: #666; user-select: text; }
    .gslide-image img { background: white; }
    .gscrollbar-fixer { padding-right: 15px; }
    .gdesc-inner { font-size: 0.75rem; }
    body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color);}
    body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color);}
    body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color);}</style> <script src="../../../assets/javascripts/glightbox.min.js"></script></head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#score-matching" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="Generative AI: From Start to Surrender" class="md-header__button md-logo" aria-label="Generative AI: From Start to Surrender" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Generative AI: From Start to Surrender
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Score Matching
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h4v-1.9H7c-1.71 0-3.1-1.39-3.1-3.1M8 13h8v-2H8zm9-6h-4v1.9h4c1.71 0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4a5 5 0 0 0 5-5 5 5 0 0 0-5-5"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="black" data-md-color-accent="indigo"  aria-label="Switch to system preference"  type="radio" name="__palette" id="__palette_2">
    
      <label class="md-header__button md-icon" title="Switch to system preference" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5M7 15a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="Share" aria-label="Share" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../.." class="md-tabs__link">
        
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../chapter1_Introduction/1.1terminology/" class="md-tabs__link">
          
  
    
  
  Introduction

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../chapter2_generation_theory/mle/" class="md-tabs__link">
          
  
    
  
  Generation Theory

        </a>
      </li>
    
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../introduction/" class="md-tabs__link">
          
  
    
  
  Energy Based Models

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../chapter6_VAE/vae_introduction/" class="md-tabs__link">
          
  
    
  
  VAE

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../chapter5_GAN/3.1from_gan_to_stylegan/paper/" class="md-tabs__link">
          
  
    
  
  GANs

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../chapter7_diffusion/ddpm/" class="md-tabs__link">
          
  
    
  
  Diffusion Models

        </a>
      </li>
    
  

    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../chapter9_flow_matching/introduction/" class="md-tabs__link">
          
  
    
  
  Flow Matching

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../chapter11_hybrid_sota_models/hybrid_methods/" class="md-tabs__link">
          
  
    
  
  Hybrid SOTA Models

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../chapter12_applications/diffusion_anomaly_detection/" class="md-tabs__link">
          
  
    
  
  Application

        </a>
      </li>
    
  

    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


  

<nav class="md-nav md-nav--primary md-nav--lifted md-nav--integrated" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="Generative AI: From Start to Surrender" class="md-nav__button md-logo" aria-label="Generative AI: From Start to Surrender" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Generative AI: From Start to Surrender
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Introduction
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Introduction
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter1_Introduction/1.1terminology/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Terms
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter1_Introduction/1.2fourier_transform/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Fourier Transform
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter1_Introduction/1.3signal_processing/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Signal Processing
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter1_Introduction/1.4statistics/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Statistics
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter1_Introduction/tutorials/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Tutorials
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Generation Theory
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Generation Theory
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter2_generation_theory/mle/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Maximal Likelihood
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter2_generation_theory/manifold_hypothesis/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Manifold Hypothesis
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter2_generation_theory/generative_model_category/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Generative Model Category
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" checked>
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Energy Based Models
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Energy Based Models
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../introduction/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../score_function/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Score Functions
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../sampling/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Sampling Methods
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../cd/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Contrastive Divergence
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Score Matching
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Score Matching
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#1-explicit-score-matching" class="md-nav__link">
    <span class="md-ellipsis">
      1. Explicit Score-Matching
    </span>
  </a>
  
    <nav class="md-nav" aria-label="1. Explicit Score-Matching">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#11-esm" class="md-nav__link">
    <span class="md-ellipsis">
      1.1 显式分数匹配（ESM）的直观思想
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#12-step-1kde" class="md-nav__link">
    <span class="md-ellipsis">
      1.2 Step 1：用核密度估计（KDE）近似数据分布
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#13-step-2-kde" class="md-nav__link">
    <span class="md-ellipsis">
      1.3 Step 2：计算 KDE 的梯度
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#14-step-3" class="md-nav__link">
    <span class="md-ellipsis">
      1.4 Step 3：训练模型拟合梯度
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#15" class="md-nav__link">
    <span class="md-ellipsis">
      1.5 为什么需要改进？
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#16" class="md-nav__link">
    <span class="md-ellipsis">
      1.6 改进方案
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#17" class="md-nav__link">
    <span class="md-ellipsis">
      1.7 总结与适用场景
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#18" class="md-nav__link">
    <span class="md-ellipsis">
      1.8 实验
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-implicit-score-matching" class="md-nav__link">
    <span class="md-ellipsis">
      2. Implicit Score Matching
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2. Implicit Score Matching">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#21-fisher" class="md-nav__link">
    <span class="md-ellipsis">
      2.1 从Fisher散度到隐式分数匹配的推导
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#22-1-fisher" class="md-nav__link">
    <span class="md-ellipsis">
      2.2 1. 定义Fisher散度
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#23-2" class="md-nav__link">
    <span class="md-ellipsis">
      2.3 2. 展开平方项
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#24-3-t_2" class="md-nav__link">
    <span class="md-ellipsis">
      2.4 3. 处理交叉项 $ T_2 $
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#25-4-fisher" class="md-nav__link">
    <span class="md-ellipsis">
      2.5 4. 重组Fisher散度
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#26-5" class="md-nav__link">
    <span class="md-ellipsis">
      2.6 5. 标准化目标函数
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#27-6" class="md-nav__link">
    <span class="md-ellipsis">
      2.7 6. 隐式性分析
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#28-experiment" class="md-nav__link">
    <span class="md-ellipsis">
      2.8 experiment
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-siced-score-matching" class="md-nav__link">
    <span class="md-ellipsis">
      3. Siced score matching
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4-statement" class="md-nav__link">
    <span class="md-ellipsis">
      4. Statement
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5-coordinatelevel-proof" class="md-nav__link">
    <span class="md-ellipsis">
      5. Coordinate‐Level Proof
    </span>
  </a>
  
    <nav class="md-nav" aria-label="5. Coordinate‐Level Proof">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#51-4-summary" class="md-nav__link">
    <span class="md-ellipsis">
      5.1 4. Summary
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#52" class="md-nav__link">
    <span class="md-ellipsis">
      5.2 对比其他方法
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#53-experiment" class="md-nav__link">
    <span class="md-ellipsis">
      5.3 experiment
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#6-denoising-score-matching" class="md-nav__link">
    <span class="md-ellipsis">
      6. Denoising Score Matching
    </span>
  </a>
  
    <nav class="md-nav" aria-label="6. Denoising Score Matching">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#61-1-intuition-why-add-noise" class="md-nav__link">
    <span class="md-ellipsis">
      6.1 1. Intuition: Why Add Noise?
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#62-2-derivation-connecting-noise-to-the-score" class="md-nav__link">
    <span class="md-ellipsis">
      6.2 2. Derivation: Connecting Noise to the Score
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#63-3-training-process-step-by-step" class="md-nav__link">
    <span class="md-ellipsis">
      6.3 3. Training Process: Step-by-Step
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#64-4-sampling-with-langevin-dynamics" class="md-nav__link">
    <span class="md-ellipsis">
      6.4 4. Sampling with Langevin Dynamics
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#65-5-multi-scale-noise-training" class="md-nav__link">
    <span class="md-ellipsis">
      6.5 5. Multi-Scale Noise Training
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#66-6-continuous-noise-levels" class="md-nav__link">
    <span class="md-ellipsis">
      6.6 6. Continuous Noise Levels
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#67-7-why-does-dsm-work-a-unified-view" class="md-nav__link">
    <span class="md-ellipsis">
      6.7 7. Why Does DSM Work? A Unified View
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#68-conclusion" class="md-nav__link">
    <span class="md-ellipsis">
      6.8 Conclusion
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    VAE
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            VAE
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter6_VAE/vae_introduction/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter6_VAE/vq_vae/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    VA-VAE
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_6" >
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    GANs
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            GANs
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter5_GAN/3.1from_gan_to_stylegan/paper/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    From GAN to StyleGAN
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_6_2" >
        
          
          <label class="md-nav__link" for="__nav_6_2" id="__nav_6_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    StyleGAN Variants
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_6_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_2">
            <span class="md-nav__icon md-icon"></span>
            StyleGAN Variants
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter5_GAN/3.3stylegan/paper/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    StyleGAN
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter5_GAN/3.4stylegan2/paper/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    StyleGAN2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter5_GAN/3.5stylegan3/paper/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    StyleGAN3
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter5_GAN/3.6styleganT/paper/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    StyleGAN-T
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter5_GAN/3.7R3Gan/paper/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    R3GAN
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter5_GAN/vq_gan/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    VQ-GAN
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_7" >
        
          
          <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Diffusion Models
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            Diffusion Models
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_7_1" >
        
          
          <label class="md-nav__link" for="__nav_7_1" id="__nav_7_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Discrete Diffusion
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_7_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_1">
            <span class="md-nav__icon md-icon"></span>
            Discrete Diffusion
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter7_diffusion/ddpm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DDPM
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter7_diffusion/ldm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    LDM
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter7_diffusion/ldm_handson/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    LDM Handson
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter7_diffusion/diffusion_model_varients/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Diffusion Model Varients
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter7_diffusion/general_diffusion_model/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    General Diffusion Model
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_7_2" >
        
          
          <label class="md-nav__link" for="__nav_7_2" id="__nav_7_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    SDE Diffusion
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_7_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_2">
            <span class="md-nav__icon md-icon"></span>
            SDE Diffusion
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter7_diffusion/introduction_sde/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    SDE Fundamentals
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter7_diffusion/from_ddpm_2_sde/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    SDE for DDPM
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter7_diffusion/score_based_sde/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Score Based SDE
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter7_diffusion/probability_flow_ode/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Probability Flow ODE
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter7_diffusion/sde_diffusion_speedup/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    SDE Diffusion Speedup
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter7_diffusion/sde_diffusion_unified_representation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Scaling and Scheduling
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_7_3" >
        
          
          <label class="md-nav__link" for="__nav_7_3" id="__nav_7_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Diffusion Network
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_7_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_3">
            <span class="md-nav__icon md-icon"></span>
            Diffusion Network
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter7_diffusion/DiT/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DiT
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_7_4" >
        
          
          <label class="md-nav__link" for="__nav_7_4" id="__nav_7_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Diffusion Solver
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_7_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_4">
            <span class="md-nav__icon md-icon"></span>
            Diffusion Solver
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter7_diffusion/diffusion_solver/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DPM Solver
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_7_5" >
        
          
          <label class="md-nav__link" for="__nav_7_5" id="__nav_7_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Conditional Diffusion
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_7_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_5">
            <span class="md-nav__icon md-icon"></span>
            Conditional Diffusion
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter7_diffusion/controlnet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ControlNet
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter7_diffusion/sde_diffusion_guidance/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    SDE Diffusion Guidance
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_8" >
        
          
          <label class="md-nav__link" for="__nav_8" id="__nav_8_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Flow Matching
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_8">
            <span class="md-nav__icon md-icon"></span>
            Flow Matching
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter9_flow_matching/introduction/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter9_flow_matching/probability_with_velocity_field/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Probability Path and Velocity Fields
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter9_flow_matching/flow_matching_theory/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Flow Matching Theorem
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter9_flow_matching/affine_conditional_flows/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Affine Conditional Flow
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter9_flow_matching/optimal_transport_flow/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Optimal Transport Flow
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter9_flow_matching/comparison_with_flow_ode/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Comparison with Diffusion Flow ODE
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_9" >
        
          
          <label class="md-nav__link" for="__nav_9" id="__nav_9_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Hybrid SOTA Models
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_9">
            <span class="md-nav__icon md-icon"></span>
            Hybrid SOTA Models
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter11_hybrid_sota_models/hybrid_methods/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hybrid Methods
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter11_hybrid_sota_models/sota_closed_models/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Closed Models
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_9_3" >
        
          
          <label class="md-nav__link" for="__nav_9_3" id="__nav_9_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Open Models
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_9_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_9_3">
            <span class="md-nav__icon md-icon"></span>
            Open Models
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter11_hybrid_sota_models/sota_open_models/dalle_series/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Dalle Series
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_9_3_2" >
        
          
          <label class="md-nav__link" for="__nav_9_3_2" id="__nav_9_3_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Stable Diffusion Series
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_9_3_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_9_3_2">
            <span class="md-nav__icon md-icon"></span>
            Stable Diffusion Series
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter11_hybrid_sota_models/sota_open_models/stable_diffusion_series/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Overview
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter11_hybrid_sota_models/sota_open_models/stable_diffusion_xl/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Stable Diffusion XL
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter11_hybrid_sota_models/sota_open_models/stable_diffusion_3_reading/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Stable Diffusion 3
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter11_hybrid_sota_models/sota_open_models/stable_diffusion_3_5_reading/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Stable Diffusion 3.5
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter11_hybrid_sota_models/sota_open_models/flux1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Flux.1
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter11_hybrid_sota_models/trends_future/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Future Trends
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_10" >
        
          
          <label class="md-nav__link" for="__nav_10" id="__nav_10_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Application
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_10_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_10">
            <span class="md-nav__icon md-icon"></span>
            Application
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_10_1" >
        
          
          <label class="md-nav__link" for="__nav_10_1" id="__nav_10_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Anomaly Detection
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_10_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_10_1">
            <span class="md-nav__icon md-icon"></span>
            Anomaly Detection
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter12_applications/diffusion_anomaly_detection/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Diffuson Anomaly Detection
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter12_applications/deepfake_detection/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Deepfake Detection
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="score-matching">Score matching<a class="headerlink" href="#score-matching" title="Permanent link">&para;</a></h1>
<p>Score Matching 是一种估计概率分布的密度模型的方法，最早由 Aapo Hyvärinen 在 2005 年提出。它的主要目标是通过直接拟合数据的概率密度梯度（也称为 score function）来避免对归一化因子（partition function）的显式计算。以下是对 Score Matching 方法的总结：</p>
<p><strong>核心思想</strong></p>
<ul>
<li>
<p>设 <span class="arithmatex">\(p(x)\)</span> 是数据的真实分布，模型分布为 <span class="arithmatex">\(q_\theta(x)\)</span>。</p>
</li>
<li>
<p>Score Matching 的目标是使模型的 score function <span class="arithmatex">\(\nabla_x \log q_\theta(x)\)</span> 尽可能接近数据分布的 score function <span class="arithmatex">\(\nabla_x \log p(x)\)</span></p>
</li>
<li>
<p>换句话说，优化目标是最小化以下目标函数：</p>
</li>
</ul>
<div class="arithmatex">\[
 J(\theta) = \frac{1}{2} \mathbb{E}_{p(x)} \left[ \| \nabla_x \log q_\theta(x) - \nabla_x \log p(x) \|^2 \right].
\]</div>
<p>总体来说，在EBM和SBM (energy based model and score based model) 中,score matching 都可以使用。在EBM中，函数是一个标量，表示能量，能量低的地方表示概率高，稳定区域。在SBM中，函数是一个向量，表示 score function，score 表示能量或者密度变化的剧烈程度和方向，随着score 的负方向，会到达能量低的区域。score matching 在这两种模型中都有自然的扩展，即可以拟合非常复杂的density function或者其score function。</p>
<p>对于score matching, 它也有不同的实现方法。</p>
<ul>
<li>explicite score matching</li>
<li>sliced score matching</li>
<li>denosing score matching</li>
</ul>
<h2 id="1-explicit-score-matching">1. Explicit Score-Matching<a class="headerlink" href="#1-explicit-score-matching" title="Permanent link">&para;</a></h2>
<h3 id="11-esm">1.1 显式分数匹配（ESM）的直观思想<a class="headerlink" href="#11-esm" title="Permanent link">&para;</a></h3>
<p>ESM 的核心目标是训练一个模型 $ s_\theta(x) $，使其预测的梯度尽可能接近真实的 score function。为此，ESM 直接定义一个损失函数：</p>
<div class="arithmatex">\[
\mathcal{L}(\theta) = \mathbb{E}_{x \sim p(x)} \left[ \| s_\theta(x) - \nabla_x \log p(x) \|^2 \right]
\]</div>
<p>但问题在于：<strong>真实分布 <span class="arithmatex">\(p(x)\)</span> 未知</strong>，因此无法直接计算真实的梯度。
<strong>解决方案</strong>：先用 <strong>核密度估计（KDE）</strong> 近似 <span class="arithmatex">\(p(x)\)</span>，再用 KDE 的结果训练模型。</p>
<hr />
<h3 id="12-step-1kde">1.2 <strong>Step 1：用核密度估计（KDE）近似数据分布</strong><a class="headerlink" href="#12-step-1kde" title="Permanent link">&para;</a></h3>
<p>KDE 是一种非参数方法，通过数据点周围的“平滑小山丘”（核函数）叠加来估计分布。例如，对于数据点 $ {x_1, x_2, ..., x_N} $，KDE 的公式为：</p>
<div class="arithmatex">\[
\hat{p}(x) = \frac{1}{N} \sum_{i=1}^N K_h(x - x_i)
\]</div>
<p>其中 $ K_h $ 是核函数（如高斯核），$ h $ 是控制平滑度的带宽参数。</p>
<p><strong>高斯核的直观解释</strong>：每个数据点 $ x_i $ 周围生成一个钟形曲线，所有曲线叠加形成整体分布。</p>
<hr />
<h3 id="13-step-2-kde">1.3 <strong>Step 2：计算 KDE 的梯度</strong><a class="headerlink" href="#13-step-2-kde" title="Permanent link">&para;</a></h3>
<p>为了得到 score function，需计算 $ \nabla_x \log \hat{p}(x) $。以高斯核为例：</p>
<ol>
<li>计算梯度的分子部分：</li>
</ol>
<div class="arithmatex">\[
\nabla_x \hat{p}(x) = \frac{1}{N} \sum_{i=1}^N K_h(x - x_i) \cdot \left(-\frac{x - x_i}{h^2}\right)
\]</div>
<ol>
<li>计算梯度：</li>
</ol>
<div class="arithmatex">\[
\nabla_x \log \hat{p}(x) = \frac{\nabla_x \hat{p}(x)}{\hat{p}(x)}
\]</div>
<p><strong>物理意义</strong>：梯度方向指向周围数据点的加权平均位置。</p>
<h3 id="14-step-3">1.4 <strong>Step 3：训练模型拟合梯度</strong><a class="headerlink" href="#14-step-3" title="Permanent link">&para;</a></h3>
<p>定义一个模型（如神经网络） $ s_\theta(x) $，输入数据点 $ x $，输出预测的梯度。损失函数为：</p>
<div class="arithmatex">\[
\mathcal{L}(\theta) \approx \frac{1}{N} \sum_{i=1}^N \| s_\theta(x_i) - \nabla_x \log \hat{p}(x_i) \|^2
\]</div>
<p><strong>训练过程</strong>：</p>
<ol>
<li>对每个数据点 $ x_i $，用 KDE 计算其梯度 $ \nabla_x \log \hat{p}(x_i) $。</li>
<li>用梯度下降法优化模型参数 $ \theta $，使预测值逼近 KDE 的梯度。</li>
</ol>
<h3 id="15">1.5 <strong>为什么需要改进？</strong><a class="headerlink" href="#15" title="Permanent link">&para;</a></h3>
<p>尽管方法直观，但存在两个主要问题：</p>
<ol>
<li><strong>维度灾难</strong>：KDE 在高维数据中效果差（计算量大且估计不准）。</li>
<li><strong>计算效率</strong>：每个点的梯度计算需遍历所有数据，复杂度为 $ O(N) $。</li>
</ol>
<h3 id="16">1.6 <strong>改进方案</strong><a class="headerlink" href="#16" title="Permanent link">&para;</a></h3>
<ol>
<li>
<p><strong>去噪分数匹配（DSM）</strong>：
   直接向数据添加噪声（如高斯噪声），利用噪声分布的已知梯度间接训练模型，避免显式计算 $ p(x) $。</p>
</li>
<li>
<p><strong>降维预处理</strong>：
   对高维数据使用 PCA 或自编码器降维，再在低维空间应用 KDE。</p>
</li>
<li>
<p><strong>Mini-batch 优化</strong>：
   每次随机采样部分数据计算梯度，减少计算量。</p>
</li>
</ol>
<h3 id="17">1.7 <strong>总结与适用场景</strong><a class="headerlink" href="#17" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>适用场景</strong>：低维数据分布估计、生成模型预训练、小规模数据分析。</li>
<li><strong>优势</strong>：无需假设数据分布形式，直接通过数据学习梯度。</li>
<li><strong>局限性</strong>：高维数据效果受限，需结合 DSM 或降维技术。</li>
</ul>
<p>通过 KDE 与显式分数匹配的结合，我们能够从有限的数据中“感知”概率分布的变化方向，为后续生成模型或异常检测任务奠定基础。尽管存在挑战，这一方法在低维场景中仍是一个简洁而强大的工具。</p>
<h3 id="18">1.8 实验<a class="headerlink" href="#18" title="Permanent link">&para;</a></h3>
<p>我们用一个二维的混合高斯分布进行实验。</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-0-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-0-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-0-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-0-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-0-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-0-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-0-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-0-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-0-10">10</a></span>
<span class="normal"><a href="#__codelineno-0-11">11</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="k">def</span> <span class="nf">generate_data</span><span class="p">(</span><span class="n">num_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a>    <span class="c1"># 生成两个高斯分布的混合数据</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a>    <span class="n">mean1</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>    <span class="n">cov1</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]</span>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a>    <span class="n">data1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mean1</span><span class="p">,</span> <span class="n">cov1</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">//</span><span class="mi">2</span><span class="p">)</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a>    <span class="n">mean2</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">]</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a>    <span class="n">cov2</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]</span>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a>    <span class="n">data2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mean2</span><span class="p">,</span> <span class="n">cov2</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">//</span><span class="mi">2</span><span class="p">)</span>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a>    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">data1</span><span class="p">,</span> <span class="n">data2</span><span class="p">])</span>
</code></pre></div></td></tr></table></div>
<p>根据以上的混合高斯分布生成的数据。
<a class="glightbox" href="../../../images/image-25.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="alt text" src="../../../images/image-25.png" /></a>
然后我们进行KDE，然后利用KDE去估计梯度。最后得到预测结果和真实梯度的可视化。</p>
<p><a class="glightbox" href="../../../images/image-27.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="alt text" src="../../../images/image-27.png" /></a></p>
<p>可以看到最终在高概率区域，分布是比较相似的，但是在低概率区域，分布相差较大。这个原因主要是因为低概率区域的数据量较少，KDE 估计的梯度可能会受到大量噪声的影响。 同时模型学出来的分布比KDE和原始分布更加接近。</p>
<h2 id="2-implicit-score-matching">2. Implicit Score Matching<a class="headerlink" href="#2-implicit-score-matching" title="Permanent link">&para;</a></h2>
<h3 id="21-fisher">2.1 从Fisher散度到隐式分数匹配的推导<a class="headerlink" href="#21-fisher" title="Permanent link">&para;</a></h3>
<h3 id="22-1-fisher">2.2 1. 定义Fisher散度<a class="headerlink" href="#22-1-fisher" title="Permanent link">&para;</a></h3>
<p>Fisher散度衡量两个概率分布 $ p(\mathbf{x}) $ 和 $ q(\mathbf{x}; \theta) $ 的分数差异：</p>
<div class="arithmatex">\[
D_F(p \parallel q) = \mathbb{E}_{p(\mathbf{x})} \left[ \| \nabla_{\mathbf{x}} \log p(\mathbf{x}) - \nabla_{\mathbf{x}} \log q(\mathbf{x}; \theta) \|^2 \right].
\]</div>
<h3 id="23-2">2.3 2. 展开平方项<a class="headerlink" href="#23-2" title="Permanent link">&para;</a></h3>
<p>将平方项展开为三部分：</p>
<div class="arithmatex">\[
D_F = \underbrace{\mathbb{E}_{p} \left[ \| \nabla \log p \|^2 \right]}_{T_1} - 2 \underbrace{\mathbb{E}_{p} \left[ (\nabla \log p)^\top (\nabla \log q) \right]}_{T_2} + \underbrace{\mathbb{E}_{p} \left[ \| \nabla \log q \|^2 \right]}_{T_3}.
\]</div>
<h3 id="24-3-t_2">2.4 3. 处理交叉项 $ T_2 $<a class="headerlink" href="#24-3-t_2" title="Permanent link">&para;</a></h3>
<p>交叉项</p>
<div class="arithmatex">\[ T_2 = -2 \mathbb{E}_{p} \left[ (\nabla \log p)^\top (\nabla \log q) \right] \]</div>
<p>包含未知的 <span class="arithmatex">\(\nabla \log p\)</span>，需通过分部积分消除依赖。</p>
<h4 id="241">2.4.1 分量为标量的推导<a class="headerlink" href="#241" title="Permanent link">&para;</a></h4>
<p>对每个维度 $ x_i $ 单独处理：</p>
<div class="arithmatex">\[
T_2 = -2 \sum_{i=1}^d \mathbb{E}_{p} \left[ \partial_i \log p \cdot \partial_i \log q \right].
\]</div>
<p>应用分部积分公式：</p>
<div class="arithmatex">\[
\int p(\mathbf{x}) \partial_i \log p \cdot \partial_i \log q \, d\mathbf{x} = -\int p(\mathbf{x}) \partial_i^2 \log q \, d\mathbf{x}.
\]</div>
<p><strong>关键假设</strong>：概率密度在边界处衰减至零，即：</p>
<div class="arithmatex">\[
\left. p(\mathbf{x}) \partial_i \log q \right|_{x_i \to \pm\infty} = 0.
\]</div>
<h4 id="242">2.4.2 合并所有维度<a class="headerlink" href="#242" title="Permanent link">&para;</a></h4>
<p>对每个分量积分后求和：</p>
<div class="arithmatex">\[
T_2 = 2 \sum_{i=1}^d \mathbb{E}_{p} \left[ \partial_i^2 \log q \right] = 2 \mathbb{E}_{p} \left[ \text{tr}(\nabla_{\mathbf{x}}^2 \log q) \right],
\]</div>
<p>其中 <span class="arithmatex">\(\text{tr}(\nabla_{\mathbf{x}}^2 \log q)\)</span> 表示Hessian矩阵的迹。</p>
<h3 id="25-4-fisher">2.5 4. 重组Fisher散度<a class="headerlink" href="#25-4-fisher" title="Permanent link">&para;</a></h3>
<p>将 <span class="arithmatex">\(T_1, T_2, T_3\)</span> 代入原式：</p>
<div class="arithmatex">\[
D_F = \mathbb{E}_{p} \left[ \| \nabla \log p \|^2 \right] + \mathbb{E}_{p} \left[ \| \nabla \log q \|^2 + 2 \, \text{tr}(\nabla^2 \log q) \right].
\]</div>
<p>忽略常数项 <span class="arithmatex">\(\mathbb{E}_{p} \left[ \| \nabla \log p \|^2 \right]\)</span>，优化目标简化为：</p>
<div class="arithmatex">\[
\min_{\theta} \mathbb{E}_{p} \left[ \| \nabla \log q \|^2 + 2 \, \text{tr}(\nabla^2 \log q) \right].
\]</div>
<h3 id="26-5">2.6 5. 标准化目标函数<a class="headerlink" href="#26-5" title="Permanent link">&para;</a></h3>
<p>引入缩放因子 <span class="arithmatex">\(\frac{1}{2}\)</span>，得到隐式分数匹配目标函数：</p>
<div class="arithmatex">\[
J(\theta) = \mathbb{E}_{p(\mathbf{x})} \left[ \frac{1}{2} \| \nabla_{\mathbf{x}} \log q(\mathbf{x}; \theta) \|^2 + \text{tr}(\nabla_{\mathbf{x}}^2 \log q(\mathbf{x}; \theta)) \right].
\]</div>
<h3 id="27-6">2.7 6. 隐式性分析<a class="headerlink" href="#27-6" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>显式匹配项</strong>：<span class="arithmatex">\(\frac{1}{2} \| \nabla \log q \|^2\)</span> 直接约束分数模长。</li>
<li><strong>隐式正则项</strong>：<span class="arithmatex">\(\text{tr}(\nabla^2 \log q)\)</span> 通过二阶导数隐式约束分数方向，避免依赖 <span class="arithmatex">\(\nabla \log p\)</span>。</li>
</ul>
<hr />
<h4 id="271-7">2.7.1 7. 最终形式<a class="headerlink" href="#271-7" title="Permanent link">&para;</a></h4>
<p>隐式分数匹配的目标函数为：</p>
<div class="arithmatex">\[
\boxed{J(\theta) = \mathbb{E}_{p(\mathbf{x})} \left[ \frac{1}{2} \| \nabla_{\mathbf{x}} \log q(\mathbf{x}; \theta) \|^2 + \text{tr}(\nabla_{\mathbf{x}}^2 \log q(\mathbf{x}; \theta)) \right]}.
\]</div>
<p>当然如果我们只关注score function 本身，而不需要知道原始的density function 或者说energy function, 那么问题就简化了，就不涉及到二阶导了。</p>
<p>Let <span class="arithmatex">\(s_\theta(x) = \nabla_{\mathbf{x}} \log q(\mathbf{x}; \theta)\)</span> be score function.</p>
<p>The implicit score matching loss can be approximated by Monte Carlo:</p>
<div class="arithmatex">\[
J_{\text{ISM}}(\theta) \approx \frac{1}{M} \sum_{m=1}^{M} \sum_{i} \left( \partial_i \mathbf{s}_{\theta}(\mathbf{x}^{(m)}) + \frac{1}{2} \| \mathbf{s}_{\theta}(\mathbf{x}^{(m)}) \|^2 \right),
\]</div>
<p>where <span class="arithmatex">\(\partial_i \mathbf{s}_{\theta}(\mathbf{x}^{(m)}) = \frac{\partial}{\partial x_i} [\mathbf{s}_{\theta}(\mathbf{x})]_i = \frac{\partial^2}{\partial x_i^2} \log p(\mathbf{x})\)</span>. If the model for the score function is realized by a deep neural network, the trace operator can be difficult to compute, hence making the implicit score matching not scalable [40].</p>
<p><strong>Refenrence</strong></p>
<ul>
<li>Aapo Hyv¨arinen. Estimation of non-normalized statistical models by score matching. Journal
of Machine Learning Research (JMLR), 6(24):695–709, 2005. <a href="https://jmlr.org/papers/volume6/">https://jmlr.org/papers/volume6/</a>
hyvarinen05a/hyvarinen05a.pdf</li>
</ul>
<h3 id="28-experiment">2.8 experiment<a class="headerlink" href="#28-experiment" title="Permanent link">&para;</a></h3>
<p>We use a mixture of guassian distribution for testing. But the results is not good.</p>
<p><a class="glightbox" href="../../../images/image-29.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="alt text" src="../../../images/image-29.png" /></a>
<a class="glightbox" href="../../../images/image-28.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="pred" src="../../../images/image-28.png" /></a></p>
<p>It turns out that the derivative maganitude is near 0, but the trace is almost - 0.0004.</p>
<ul>
<li>optimizatioin 1
add regularization of <span class="arithmatex">\(E_x p_\theta(x)\)</span>.
Still not work, almost constant
<a class="glightbox" href="../../../images/image-30.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="alt text" src="../../../images/image-30.png" /></a></li>
<li>optimization 2
output energy function not the <span class="arithmatex">\(p_\theta\)</span>, that is without a exponention.</li>
</ul>
<h2 id="3-siced-score-matching">3. Siced score matching<a class="headerlink" href="#3-siced-score-matching" title="Permanent link">&para;</a></h2>
<ul>
<li>optimization3
Finally, it is because that the network used ReLU, which is not enough for modeling the complex density function. Here we
change to Swish function instead. Now the iteration is much more stable and output the correct estimation of the ground truth density function (un-normalized)</li>
</ul>
<p><a class="glightbox" href="../../../images/image-31.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="alt text" src="../../../images/image-31.png" /></a></p>
<h4 id="31">3.1 <strong>核心思想</strong><a class="headerlink" href="#31" title="Permanent link">&para;</a></h4>
<p><strong>Sliced Score Matching（切片分数匹配）</strong> 是一种用于高效估计数据分布梯度（score function）的方法，主要针对高维数据场景设计。其核心创新在于通过<strong>随机投影技术</strong>降低计算复杂度，避免直接计算高维Jacobian矩阵的迹（Trace），从而解决传统Implicit Score Matching的可扩展性问题。</p>
<p>直观的说，就是在任何的投影空间，两个function 能够近似，那么原本的两个function 也必然近似。这是一种比较重要的思想，可以在其他的问题中借鉴。同样的还有，如果两个function 的梯度处处相等，那么这两个function 也相等（差一个constant), 这些都是一种转化问题的技巧，值得学习。</p>
<h4 id="32">3.2 <strong>数学定义</strong><a class="headerlink" href="#32" title="Permanent link">&para;</a></h4>
<p><strong>1. Fisher 散度的定义</strong>
Fisher 散度衡量真实分布 <span class="arithmatex">\(p(x)\)</span> 与模型分布 <span class="arithmatex">\(q_\theta(x)\)</span> 的 score function 之间的差异：</p>
<div class="arithmatex">\[
\mathcal{D}_{\text{Fisher}}(p \| q_\theta) = \mathbb{E}_{p(x)} \left[ \| \nabla_x \log p(x) - \nabla_x \log q_\theta(x) \|^2 \right].
\]</div>
<p>最小化 Fisher 散度等价于让模型 score <span class="arithmatex">\(\nabla_x \log q_\theta(x)\)</span> 逼近真实 score <span class="arithmatex">\(\nabla_x \log p(x)\)</span>。</p>
<p>通过 Stein 恒等式，ISM 将 Fisher 散度转化为以下目标函数：</p>
<div class="arithmatex">\[
J_{\text{ISM}}(\theta) = \mathbb{E}_{p(x)} \left[ \operatorname{Tr}(\nabla_x \mathbf{s}_\theta(x)) + \frac{1}{2} \| \mathbf{s}_\theta(x) \|^2 \right],
\]</div>
<p>其中 <span class="arithmatex">\(\mathbf{s}_\theta(x)\)</span> 是模型预测的 score function。</p>
<p><strong>关键等式</strong>：当 <span class="arithmatex">\(\mathbf{s}_\theta(x) = \nabla_x \log p_\theta(x)\)</span> 时，ISM 损失达到最小值，此时 <span class="arithmatex">\(\mathcal{D}_{\text{Fisher}} = 0\)</span>。</p>
<p><strong>3. Sliced Score Matching 的动机</strong>
ISM 的瓶颈在于计算 Jacobian 矩阵的迹 <span class="arithmatex">\(\operatorname{Tr}(\nabla_x \mathbf{s}_\theta(x))\)</span>，其复杂度为 <span class="arithmatex">\(O(d^2)\)</span>（<span class="arithmatex">\(d\)</span> 为数据维度）。
<strong>核心思想</strong>：利用随机投影技术将迹的计算复杂度降至 <span class="arithmatex">\(O(d)\)</span>。</p>
<p><strong>4. 随机投影近似迹</strong></p>
<p>根据 Hutchinson 迹估计器，任意矩阵 <span class="arithmatex">\(A \in \mathbb{R}^{d \times d}\)</span> 的迹可表示为：</p>
<div class="arithmatex">\[
\operatorname{Tr}(A) = \mathbb{E}_{\mathbf{v} \sim \mathcal{N}(0, I)} \left[ \mathbf{v}^\top A \mathbf{v} \right],
\]</div>
<p>其中 $ \mathbf{v} $ 为标准正态分布的随机向量。
将此技术应用于 ISM 的迹项：</p>
<div class="arithmatex">\[
\operatorname{Tr}(\nabla_x \mathbf{s}_\theta(x)) = \mathbb{E}_{\mathbf{v}} \left[ \mathbf{v}^\top \nabla_x \mathbf{s}_\theta(x) \mathbf{v} \right].
\]</div>
<p><strong>5. Sliced Score Matching 的目标函数</strong></p>
<p>将 ISM 的迹项替换为随机投影近似，得到 SSM 的目标函数：</p>
<div class="arithmatex">\[
J_{\text{SSM}}(\theta) = \mathbb{E}_{p(x)} \mathbb{E}_{\mathbf{v}} \left[ \mathbf{v}^\top \nabla_x \mathbf{s}_\theta(x) \mathbf{v} + \frac{1}{2} \| \mathbf{s}_\theta(x) \|^2 \right].
\]</div>
<p><strong>蒙特卡洛近似</strong>：通过采样少量投影方向 $ {\mathbf{v}<em k="1">k}</em>^K $ 估计期望值：</p>
<div class="arithmatex">\[
J_{\text{SSM}}(\theta) \approx \frac{1}{N} \sum_{i=1}^N \left[ \frac{1}{K} \sum_{k=1}^K \mathbf{v}_k^\top \nabla_x \mathbf{s}_\theta(x_i) \mathbf{v}_k + \frac{1}{2} \| \mathbf{s}_\theta(x_i) \|^2 \right].
\]</div>
<p><strong>6. 等价性证明</strong></p>
<p>当投影方向数量 $K \to \infty $ 时，SSM 与 ISM 的目标函数等价：</p>
<div class="arithmatex">\[
\lim_{K \to \infty} J_{\text{SSM}}(\theta) = J_{\text{ISM}}(\theta).
\]</div>
<p>因此，SSM 是 ISM 的高效近似，且在优化过程中等价于最小化 Fisher 散度。</p>
<p><strong>7. 总结</strong></p>
<ul>
<li><strong>从 Fisher 散度到 SSM</strong> 的推导路径：</li>
</ul>
<div class="arithmatex">\[
\mathcal{D}_{\text{Fisher}} \xrightarrow{\text{Stein 恒等式}} J_{\text{ISM}} \xrightarrow{\text{随机投影近似}} J_{\text{SSM}}.
\]</div>
<ul>
<li><strong>SSM 的优势</strong>：将计算复杂度从 <span class="arithmatex">\(O(d^2)\)</span> 降低至 <span class="arithmatex">\(O(Kd)\)</span>，适用于高维数据（如图像、文本）。</li>
<li>
<p><strong>适用场景</strong>：生成模型（如扩散模型）、无需显式概率密度的梯度估计。</p>
</li>
<li>
<p><strong>基础公式</strong>
与传统Implicit Score Matching的损失函数类似，但引入随机投影向量 $ \mathbf{v} $：</p>
</li>
</ul>
<div class="arithmatex">\[
J_{\text{SSM}}(\theta) = \mathbb{E}_{p(\mathbf{x})} \mathbb{E}_{\mathbf{v} \sim \mathcal{N}(0,I)} \left[ \mathbf{v}^\top \nabla_{\mathbf{x}} \mathbf{s}_\theta(\mathbf{x}) \mathbf{v} + \frac{1}{2} \| \mathbf{s}_\theta(\mathbf{x}) \|^2 \right],
\]</div>
<p>其中：</p>
<ul>
<li>
<p><span class="arithmatex">\(\mathbf{v}\)</span> 是服从标准正态分布的随机向量。</p>
</li>
<li>
<p><span class="arithmatex">\(\mathbf{v}^\top \nabla_{\mathbf{x}} \mathbf{s}_\theta(\mathbf{x}) \mathbf{v}\)</span> 表示Jacobian矩阵在随机方向 <span class="arithmatex">\(\mathbf{v}\)</span> 上的投影。</p>
</li>
<li>
<p><strong>关键简化</strong>
   通过随机投影，将计算全Jacobian矩阵的迹 <span class="arithmatex">\(\operatorname{Tr}(\nabla_{\mathbf{x}}\mathbf{s}_\theta(\mathbf{x}))\)</span> 转化为：</p>
</li>
</ul>
<div class="arithmatex">\[
\operatorname{Tr}(\nabla_{\mathbf{x}}\mathbf{s}_\theta(\mathbf{x})) = \mathbb{E}_{\mathbf{v}} \left[ \mathbf{v}^\top \nabla_{\mathbf{x}} \mathbf{s}_\theta(\mathbf{x}) \mathbf{v} \right].
\]</div>
<h4 id="33-complexity-analysis">3.3 Complexity Analysis<a class="headerlink" href="#33-complexity-analysis" title="Permanent link">&para;</a></h4>
<p>Consider the case</p>
<div class="arithmatex">\[
\operatorname{Tr}(\nabla_{x} \nabla_x \log p_\theta (x) )) = \mathbb{E}_{\mathbf{v}} \left[ \mathbf{v}^\top \nabla_{x} \nabla_x \log p_\theta(x) \mathbf{v} \right].
\]</div>
<h5 id="331-gradient-computation">3.3.1 Gradient Computation<a class="headerlink" href="#331-gradient-computation" title="Permanent link">&para;</a></h5>
<p>For a scalar function <span class="arithmatex">\(f: \mathbb{R}^n \to \mathbb{R}\)</span>, <strong>reverse-mode AD</strong> (backpropagation) computes all partial derivatives <span class="arithmatex">\(\frac{\partial f}{\partial x_1}, \ldots, \frac{\partial f}{\partial x_n}\)</span> in a single backward pass. Its cost is on the same order as one or two forward evaluations of <span class="arithmatex">\(f\)</span>. We denote this by <span class="arithmatex">\(\mathbf{C}_\nabla\)</span>. Thus:</p>
<div class="arithmatex">\[
\text{Cost of computing } \nabla f(x) \;\approx\; O(\mathbf{C}_\nabla).
\]</div>
<p><strong>Key note</strong>: Requesting a single partial <span class="arithmatex">\(\frac{\partial f}{\partial x[i]}\)</span> doesn’t save much computation in practice; the backward pass still traverses the entire graph.</p>
<h5 id="332-hessian-trace-computation">3.3.2 Hessian Trace Computation<a class="headerlink" href="#332-hessian-trace-computation" title="Permanent link">&para;</a></h5>
<p>The Hessian <span class="arithmatex">\(\nabla^2 f(x)\)</span> is an <span class="arithmatex">\(n \times n\)</span> matrix. Its trace is</p>
<div class="arithmatex">\[
\mathrm{trace}(\nabla^2 f(x)) \;=\; \sum_{i=1}^n \frac{\partial^2 f}{\partial x_i^2}.
\]</div>
<p>A standard AD procedure to get each diagonal entry <span class="arithmatex">\(\frac{\partial^2 f}{\partial x_i^2}\)</span> involves one <strong>forward-mode</strong> pass (perturbing only <span class="arithmatex">\(x_i\)</span>) plus one <strong>reverse-mode</strong> pass. Doing this for all <span class="arithmatex">\(n\)</span> coordinates requires roughly <span class="arithmatex">\(n\)</span> times the gradient cost:</p>
<div class="arithmatex">\[
\text{Cost of computing } \mathrm{trace}(\nabla^2 f) \;\approx\; O\bigl(n \times \mathbf{C}_\nabla\bigr).
\]</div>
<h5 id="333-hessian-vector-product-computation">3.3.3 Hessian Vector Product Computation<a class="headerlink" href="#333-hessian-vector-product-computation" title="Permanent link">&para;</a></h5>
<p>To calculate the <span class="arithmatex">\(v^TH\cdot v\)</span>, we have</p>
<ol>
<li>Calculate <span class="arithmatex">\(\nabla f(x)\)</span> from the backward and keep the graph</li>
<li>Calculate the product <span class="arithmatex">\(\nabla f(x) v\)</span>, which is a scalar, and then do another backward to get its derivative <span class="arithmatex">\(\nabla \bigl[\nabla f(x)\cdot v\bigr]\)</span></li>
<li>Calcualte <span class="arithmatex">\(v^T \nabla \bigl[\nabla f(x)\cdot v\bigr]\)</span> which can be ignored compared with the computation with the first two steps</li>
</ol>
<p>Hence, totally, the computation of <span class="arithmatex">\(v^TH\cdot v\)</span> is around <span class="arithmatex">\(2\times \mathbf{C}_\nabla\)</span>.</p>
<p>Below is a <strong>coordinate‐level proof</strong> that</p>
<div class="arithmatex">\[
\nabla \bigl[\nabla f(x)\cdot v\bigr]
\;=\;
\nabla^2 f(x)\,v,
\]</div>
<p>which justifies the standard PyTorch implementation for the Hessian–vector product:</p>
<hr />
<h2 id="4-statement">4. Statement<a class="headerlink" href="#4-statement" title="Permanent link">&para;</a></h2>
<p>Let <span class="arithmatex">\(f:\mathbb{R}^n \to \mathbb{R}\)</span> be twice continuously differentiable, and let <span class="arithmatex">\(v \in \mathbb{R}^n\)</span>. Define the scalar function</p>
<div class="arithmatex">\[
g(x)\;=\;\nabla f(x)\,\cdot\,v \;=\; \sum_{i=1}^n \frac{\partial f}{\partial x_i}(x)\,v_i.
\]</div>
<p>Then</p>
<div class="arithmatex">\[
\nabla g(x)
\;=\;
\nabla^2 f(x)\,v.
\]</div>
<p>In other words, if <span class="arithmatex">\(H = \nabla^2 f(x)\)</span> is the Hessian of <span class="arithmatex">\(f\)</span> at <span class="arithmatex">\(x\)</span>, then</p>
<div class="arithmatex">\[
\frac{\partial}{\partial x_j} \bigl[\nabla f(x)\cdot v\bigr]
\;=\;
\bigl(H\,v\bigr)_j
\quad
\text{for each }j=1,\dots,n.
\]</div>
<hr />
<h2 id="5-coordinatelevel-proof">5. Coordinate‐Level Proof<a class="headerlink" href="#5-coordinatelevel-proof" title="Permanent link">&para;</a></h2>
<ol>
<li><strong>Expand the definition of <span class="arithmatex">\(g(x)\)</span></strong>:</li>
</ol>
<div class="arithmatex">\[
g(x)\;=\;  \nabla f(x)\,\cdot\,v  \;=\;  \sum_{i=1}^n  \frac{\partial f}{\partial x_i}(x)\,v_i.
\]</div>
<ol>
<li><strong>Compute the partial derivative w.r.t. <span class="arithmatex">\(x_j\)</span></strong>:</li>
</ol>
<div class="arithmatex">\[
\frac{\partial g}{\partial x_j}(x)
\;=\;
\frac{\partial}{\partial x_j}
\Bigl[\,
  \sum_{i=1}^n
  \frac{\partial f}{\partial x_i}(x)\,v_i
\Bigr].
\]</div>
<ol>
<li><strong>Bring the partial derivative inside the sum</strong> (assuming sufficient smoothness of <span class="arithmatex">\(f\)</span>):</li>
</ol>
<div class="arithmatex">\[
\frac{\partial g}{\partial x_j}(x)\;=\;\sum_{i=1}^n v_i\,\frac{\partial}{\partial x_j} \Bigl(\frac{\partial f}{\partial x_i}(x)\Bigr).
\]</div>
<ol>
<li><strong>Recognize the second partial derivative</strong>:</li>
</ol>
<div class="arithmatex">\[
\frac{\partial}{\partial x_j}\Bigl(\frac{\partial f}{\partial x_i}(x)\Bigr)\;=\;   \frac{\partial^2 f}{\partial x_j \,\partial x_i}(x).
\]</div>
<p>If <span class="arithmatex">\(f\)</span> is <span class="arithmatex">\(C^2\)</span> and the Hessian is symmetric, <span class="arithmatex">\(\partial^2 f/\partial x_j \partial x_i = \partial^2 f/\partial x_i \partial x_j\)</span>. Then</p>
<div class="arithmatex">\[
\frac{\partial g}{\partial x_j}(x) \;=\;\sum_{i=1}^nv_i\,\frac{\partial^2 f}{\partial x_i \,\partial x_j}(x).
\]</div>
<ol>
<li><strong>Interpret as the <span class="arithmatex">\(j\)</span>-th component of <span class="arithmatex">\(H\,v\)</span></strong>:</li>
<li>The matrix <span class="arithmatex">\(H = \bigl[\frac{\partial^2 f}{\partial x_i \,\partial x_j}(x)\bigr]\)</span> is <span class="arithmatex">\(n\times n\)</span>.</li>
<li>
<p>The product <span class="arithmatex">\((H\,v)_j\)</span> is</p>
<div class="arithmatex">\[
(H\,v)_j
\;=\;
\sum_{i=1}^n
\frac{\partial^2 f}{\partial x_j\,\partial x_i}(x)\;v_i,
\]</div>
<p>which, by symmetry of second derivatives, equals
 <span class="arithmatex">\(\sum_{i=1}^n v_i \,\frac{\partial^2 f}{\partial x_i\,\partial x_j}(x)\)</span>.</p>
</li>
</ol>
<p>Therefore,</p>
<div class="arithmatex">\[
\frac{\partial g}{\partial x_j}(x)
\;=\;
(H\,v)_j,
\quad
\forall\,j.
\]</div>
<p>Hence, <span class="arithmatex">\(\nabla g(x) = H\,v = \nabla^2 f(x)\,v\)</span>.</p>
<h3 id="51-4-summary">5.1 4. Summary<a class="headerlink" href="#51-4-summary" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>Full Gradient</strong>: One reverse-mode pass yields <span class="arithmatex">\(\nabla f(x)\)</span> at cost <span class="arithmatex">\(\mathbf{C}_\nabla\)</span>.</li>
<li><strong>Hessian Trace</strong>: Exact computation requires about <span class="arithmatex">\(n+1\)</span> times that cost.</li>
<li><strong>Hessin vector product</strong>: Requires about <span class="arithmatex">\(2\)</span> times of the cost of gradient.</li>
<li><strong>Single Partial vs. Full Gradient</strong>: In reverse-mode AD for scalar outputs, both cost nearly the same. that is <code>grad(f,x)</code> has almost the same complexity of <code>grad(f,x[i])</code>.</li>
</ul>
<p>See the code here</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-1-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-1-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-1-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-1-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-1-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-1-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-1-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-1-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-1-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-1-10">10</a></span>
<span class="normal"><a href="#__codelineno-1-11">11</a></span>
<span class="normal"><a href="#__codelineno-1-12">12</a></span>
<span class="normal"><a href="#__codelineno-1-13">13</a></span>
<span class="normal"><a href="#__codelineno-1-14">14</a></span>
<span class="normal"><a href="#__codelineno-1-15">15</a></span>
<span class="normal"><a href="#__codelineno-1-16">16</a></span>
<span class="normal"><a href="#__codelineno-1-17">17</a></span>
<span class="normal"><a href="#__codelineno-1-18">18</a></span>
<span class="normal"><a href="#__codelineno-1-19">19</a></span>
<span class="normal"><a href="#__codelineno-1-20">20</a></span>
<span class="normal"><a href="#__codelineno-1-21">21</a></span>
<span class="normal"><a href="#__codelineno-1-22">22</a></span>
<span class="normal"><a href="#__codelineno-1-23">23</a></span>
<span class="normal"><a href="#__codelineno-1-24">24</a></span>
<span class="normal"><a href="#__codelineno-1-25">25</a></span>
<span class="normal"><a href="#__codelineno-1-26">26</a></span>
<span class="normal"><a href="#__codelineno-1-27">27</a></span>
<span class="normal"><a href="#__codelineno-1-28">28</a></span>
<span class="normal"><a href="#__codelineno-1-29">29</a></span>
<span class="normal"><a href="#__codelineno-1-30">30</a></span>
<span class="normal"><a href="#__codelineno-1-31">31</a></span>
<span class="normal"><a href="#__codelineno-1-32">32</a></span>
<span class="normal"><a href="#__codelineno-1-33">33</a></span>
<span class="normal"><a href="#__codelineno-1-34">34</a></span>
<span class="normal"><a href="#__codelineno-1-35">35</a></span>
<span class="normal"><a href="#__codelineno-1-36">36</a></span>
<span class="normal"><a href="#__codelineno-1-37">37</a></span>
<span class="normal"><a href="#__codelineno-1-38">38</a></span>
<span class="normal"><a href="#__codelineno-1-39">39</a></span>
<span class="normal"><a href="#__codelineno-1-40">40</a></span>
<span class="normal"><a href="#__codelineno-1-41">41</a></span>
<span class="normal"><a href="#__codelineno-1-42">42</a></span>
<span class="normal"><a href="#__codelineno-1-43">43</a></span>
<span class="normal"><a href="#__codelineno-1-44">44</a></span>
<span class="normal"><a href="#__codelineno-1-45">45</a></span>
<span class="normal"><a href="#__codelineno-1-46">46</a></span>
<span class="normal"><a href="#__codelineno-1-47">47</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-1-1" name="__codelineno-1-1"></a><span class="k">def</span> <span class="nf">gradient</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<a id="__codelineno-1-2" name="__codelineno-1-2"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-1-3" name="__codelineno-1-3"></a><span class="sd">    Compute the gradient of the scalar function f w.r.t. x.</span>
<a id="__codelineno-1-4" name="__codelineno-1-4"></a>
<a id="__codelineno-1-5" name="__codelineno-1-5"></a><span class="sd">    f: a scalar PyTorch tensor (the output of some function of x)</span>
<a id="__codelineno-1-6" name="__codelineno-1-6"></a><span class="sd">    x: a PyTorch tensor of shape (n,) with requires_grad=True</span>
<a id="__codelineno-1-7" name="__codelineno-1-7"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-1-8" name="__codelineno-1-8"></a>    <span class="c1"># create_graph=True allows further differentiation</span>
<a id="__codelineno-1-9" name="__codelineno-1-9"></a>    <span class="n">grad_f</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">create_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<a id="__codelineno-1-10" name="__codelineno-1-10"></a>    <span class="k">return</span> <span class="n">grad_f</span>
<a id="__codelineno-1-11" name="__codelineno-1-11"></a>
<a id="__codelineno-1-12" name="__codelineno-1-12"></a><span class="k">def</span> <span class="nf">hessian_trace</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<a id="__codelineno-1-13" name="__codelineno-1-13"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-1-14" name="__codelineno-1-14"></a><span class="sd">    Compute the trace of the Hessian of the scalar function f w.r.t. x.</span>
<a id="__codelineno-1-15" name="__codelineno-1-15"></a><span class="sd">    i.e., sum(d^2 f / d x_i^2).</span>
<a id="__codelineno-1-16" name="__codelineno-1-16"></a>
<a id="__codelineno-1-17" name="__codelineno-1-17"></a><span class="sd">    f: scalar value (output of some function of x)</span>
<a id="__codelineno-1-18" name="__codelineno-1-18"></a><span class="sd">    x: torch.tensor shape (n,), requires_grad=True</span>
<a id="__codelineno-1-19" name="__codelineno-1-19"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-1-20" name="__codelineno-1-20"></a>    <span class="c1"># First get the gradient. We need create_graph=True so we can differentiate again.</span>
<a id="__codelineno-1-21" name="__codelineno-1-21"></a>    <span class="n">grad_f</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">create_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<a id="__codelineno-1-22" name="__codelineno-1-22"></a>
<a id="__codelineno-1-23" name="__codelineno-1-23"></a>    <span class="c1"># Sum of second derivatives w.r.t each x[i]</span>
<a id="__codelineno-1-24" name="__codelineno-1-24"></a>    <span class="c1"># We&#39;ll accumulate each d(grad_f[i]) / d x[i].</span>
<a id="__codelineno-1-25" name="__codelineno-1-25"></a>    <span class="n">trace_val</span> <span class="o">=</span> <span class="mf">0.0</span>
<a id="__codelineno-1-26" name="__codelineno-1-26"></a>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">numel</span><span class="p">()):</span>
<a id="__codelineno-1-27" name="__codelineno-1-27"></a>        <span class="c1"># grad of grad_f[i] w.r.t x gives a vector; we take [i] component</span>
<a id="__codelineno-1-28" name="__codelineno-1-28"></a>        <span class="n">second_deriv_i</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">grad_f</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">x</span><span class="p">,</span> <span class="n">retain_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="n">i</span><span class="p">]</span>
<a id="__codelineno-1-29" name="__codelineno-1-29"></a>        <span class="n">trace_val</span> <span class="o">+=</span> <span class="n">second_deriv_i</span>
<a id="__codelineno-1-30" name="__codelineno-1-30"></a>
<a id="__codelineno-1-31" name="__codelineno-1-31"></a>    <span class="k">return</span> <span class="n">trace_val</span>
<a id="__codelineno-1-32" name="__codelineno-1-32"></a>
<a id="__codelineno-1-33" name="__codelineno-1-33"></a><span class="k">def</span> <span class="nf">hvp</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
<a id="__codelineno-1-34" name="__codelineno-1-34"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-1-35" name="__codelineno-1-35"></a><span class="sd">    Compute Hessian-vector product H * v, where H = ∇^2 f(x).</span>
<a id="__codelineno-1-36" name="__codelineno-1-36"></a><span class="sd">    f: 标量，网络/函数对 x 的输出</span>
<a id="__codelineno-1-37" name="__codelineno-1-37"></a><span class="sd">    x: 参数或输入向量 (requires_grad=True)</span>
<a id="__codelineno-1-38" name="__codelineno-1-38"></a><span class="sd">    v: 一个和 x 形状相同的向量，用作方向</span>
<a id="__codelineno-1-39" name="__codelineno-1-39"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-1-40" name="__codelineno-1-40"></a>    <span class="c1"># 第一步：求一阶梯度，保留计算图</span>
<a id="__codelineno-1-41" name="__codelineno-1-41"></a>    <span class="n">grad_f</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">create_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<a id="__codelineno-1-42" name="__codelineno-1-42"></a>    <span class="c1"># grad_f 是和 x 同 shape 的张量</span>
<a id="__codelineno-1-43" name="__codelineno-1-43"></a>
<a id="__codelineno-1-44" name="__codelineno-1-44"></a>    <span class="c1"># 第二步：对 (grad_f 和 v 的内积) 再求一次梯度</span>
<a id="__codelineno-1-45" name="__codelineno-1-45"></a>    <span class="c1"># 这相当于对 g(x)^T * v 做一次 backprop，得出 H*v</span>
<a id="__codelineno-1-46" name="__codelineno-1-46"></a>    <span class="n">hv</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">grad_f</span> <span class="o">@</span> <span class="n">v</span><span class="p">,</span> <span class="n">x</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<a id="__codelineno-1-47" name="__codelineno-1-47"></a>    <span class="k">return</span> <span class="n">hv</span>
</code></pre></div></td></tr></table></div>
<p><strong>References</strong></p>
<ul>
<li>A. Griewank &amp; A. Walther, <em>Evaluating Derivatives.</em></li>
<li>B. A. Pearlmutter, <em>Fast Exact Multiplication by the Hessian,</em> 1994.</li>
<li>Hutchinson, <em>A Stochastic Estimator of the Trace,</em> 1990.</li>
</ul>
<h3 id="52">5.2 <strong>对比其他方法</strong><a class="headerlink" href="#52" title="Permanent link">&para;</a></h3>
<table>
<thead>
<tr>
<th><strong>方法</strong></th>
<th><strong>计算复杂度</strong></th>
<th><strong>主要挑战</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>Explicit Score Matching</td>
<td><span class="arithmatex">\(O(d)\)</span></td>
<td>依赖真实score function，通常未知</td>
</tr>
<tr>
<td>Implicit Score Matching</td>
<td><span class="arithmatex">\(O(d^2)\)</span></td>
<td>计算Jacobian迹的高复杂度</td>
</tr>
<tr>
<td>Sliced Score Matching</td>
<td><span class="arithmatex">\(O(d)\)</span></td>
<td>需平衡投影方向数量与估计精度</td>
</tr>
</tbody>
</table>
<hr />
<h4 id="521">5.2.1 <strong>代码实现（伪代码）</strong><a class="headerlink" href="#521" title="Permanent link">&para;</a></h4>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-2-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-2-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-2-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-2-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-2-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-2-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-2-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-2-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-2-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-2-10">10</a></span>
<span class="normal"><a href="#__codelineno-2-11">11</a></span>
<span class="normal"><a href="#__codelineno-2-12">12</a></span>
<span class="normal"><a href="#__codelineno-2-13">13</a></span>
<span class="normal"><a href="#__codelineno-2-14">14</a></span>
<span class="normal"><a href="#__codelineno-2-15">15</a></span>
<span class="normal"><a href="#__codelineno-2-16">16</a></span>
<span class="normal"><a href="#__codelineno-2-17">17</a></span>
<span class="normal"><a href="#__codelineno-2-18">18</a></span>
<span class="normal"><a href="#__codelineno-2-19">19</a></span>
<span class="normal"><a href="#__codelineno-2-20">20</a></span>
<span class="normal"><a href="#__codelineno-2-21">21</a></span>
<span class="normal"><a href="#__codelineno-2-22">22</a></span>
<span class="normal"><a href="#__codelineno-2-23">23</a></span>
<span class="normal"><a href="#__codelineno-2-24">24</a></span>
<span class="normal"><a href="#__codelineno-2-25">25</a></span>
<span class="normal"><a href="#__codelineno-2-26">26</a></span>
<span class="normal"><a href="#__codelineno-2-27">27</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-2-1" name="__codelineno-2-1"></a><span class="kn">import</span> <span class="nn">torch</span>
<a id="__codelineno-2-2" name="__codelineno-2-2"></a>
<a id="__codelineno-2-3" name="__codelineno-2-3"></a><span class="k">def</span> <span class="nf">sliced_score_matching_loss</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">num_projections</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
<a id="__codelineno-2-4" name="__codelineno-2-4"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-2-5" name="__codelineno-2-5"></a><span class="sd">    model: 预测score function的神经网络</span>
<a id="__codelineno-2-6" name="__codelineno-2-6"></a><span class="sd">    data: 输入数据样本</span>
<a id="__codelineno-2-7" name="__codelineno-2-7"></a><span class="sd">    num_projections: 随机投影方向的数量</span>
<a id="__codelineno-2-8" name="__codelineno-2-8"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-2-9" name="__codelineno-2-9"></a>    <span class="n">scores</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>  <span class="c1"># 模型预测的score [batch_size, d]</span>
<a id="__codelineno-2-10" name="__codelineno-2-10"></a>    <span class="n">loss</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">scores</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>  <span class="c1"># 1/2 ||s_θ(x)||^2</span>
<a id="__codelineno-2-11" name="__codelineno-2-11"></a>
<a id="__codelineno-2-12" name="__codelineno-2-12"></a>    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_projections</span><span class="p">):</span>
<a id="__codelineno-2-13" name="__codelineno-2-13"></a>        <span class="n">v</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>  <span class="c1"># 随机投影向量 [batch_size, d]</span>
<a id="__codelineno-2-14" name="__codelineno-2-14"></a>        <span class="n">v</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-2-15" name="__codelineno-2-15"></a>
<a id="__codelineno-2-16" name="__codelineno-2-16"></a>        <span class="c1"># 计算 v^T ∇s_θ(x) v</span>
<a id="__codelineno-2-17" name="__codelineno-2-17"></a>        <span class="n">v_scores</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">v</span> <span class="o">*</span> <span class="n">scores</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># [batch_size]</span>
<a id="__codelineno-2-18" name="__codelineno-2-18"></a>        <span class="n">jvp</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span>
<a id="__codelineno-2-19" name="__codelineno-2-19"></a>            <span class="n">outputs</span><span class="o">=</span><span class="n">v_scores</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">data</span><span class="p">,</span>
<a id="__codelineno-2-20" name="__codelineno-2-20"></a>            <span class="n">grad_outputs</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">v_scores</span><span class="p">),</span>
<a id="__codelineno-2-21" name="__codelineno-2-21"></a>            <span class="n">create_graph</span><span class="o">=</span><span class="kc">True</span>
<a id="__codelineno-2-22" name="__codelineno-2-22"></a>        <span class="p">)[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># ∇(v^T s_θ(x)) = v^T ∇s_θ(x)</span>
<a id="__codelineno-2-23" name="__codelineno-2-23"></a>        <span class="n">trace_estimate</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">v</span> <span class="o">*</span> <span class="n">jvp</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># v^T ∇s_θ(x) v</span>
<a id="__codelineno-2-24" name="__codelineno-2-24"></a>
<a id="__codelineno-2-25" name="__codelineno-2-25"></a>        <span class="n">loss</span> <span class="o">+=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">trace_estimate</span><span class="p">)</span> <span class="o">/</span> <span class="n">num_projections</span>
<a id="__codelineno-2-26" name="__codelineno-2-26"></a>
<a id="__codelineno-2-27" name="__codelineno-2-27"></a>    <span class="k">return</span> <span class="n">loss</span>
</code></pre></div></td></tr></table></div>
<h3 id="53-experiment">5.3 experiment<a class="headerlink" href="#53-experiment" title="Permanent link">&para;</a></h3>
<p>We also tried with the mixture og gaussian distribution, it performs well.</p>
<p><a class="glightbox" href="../../../images/image-32.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="alt text" src="../../../images/image-32.png" /></a></p>
<p>See notebook on  <strong>experiment/implicit_score_matching.ipynb</strong>.</p>
<h2 id="6-denoising-score-matching">6. Denoising Score Matching<a class="headerlink" href="#6-denoising-score-matching" title="Permanent link">&para;</a></h2>
<p>Generative models aim to learn the underlying distribution of data, allowing us to generate new samples. <strong>Denoising Score Matching (DSM)</strong> is a powerful technique in this domain, leveraging noise to simplify training. In this blog, we'll break down DSM's intuition, math, training, and sampling, and extend it to multi-scale and continuous noise settings. We’ll emphasize <em>why</em> each step matters and <em>how</em> the pieces connect.</p>
<h3 id="61-1-intuition-why-add-noise">6.1 1. Intuition: Why Add Noise?<a class="headerlink" href="#61-1-intuition-why-add-noise" title="Permanent link">&para;</a></h3>
<h4 id="611-what-is-a-score">6.1.1 What is a "Score"?<a class="headerlink" href="#611-what-is-a-score" title="Permanent link">&para;</a></h4>
<p>The <strong>score</strong> of a probability distribution <span class="arithmatex">\(p(x)\)</span> is its gradient of the log-density:</p>
<div class="arithmatex">\[ \nabla_x \log p(x)\]</div>
<p>Imagine you’re hiking on a landscape where valleys represent regions of high data density (e.g., realistic images). The score tells you the direction to move <em>uphill</em> toward higher density (i.e., toward realistic data).</p>
<h4 id="612-why-traditional-score-matching-fails">6.1.2 Why Traditional Score Matching Fails<a class="headerlink" href="#612-why-traditional-score-matching-fails" title="Permanent link">&para;</a></h4>
<p>For high-dimensional data (e.g., images), most of the space is empty—data lies on a thin "manifold." Traditional score matching struggles because:</p>
<ol>
<li><strong>Computational cost</strong>: Estimating gradients in high dimensions is expensive.</li>
<li><strong>Sparse signals</strong>: The score is undefined or noisy in empty regions far from the data manifold.</li>
</ol>
<h4 id="613-the-noise-solution">6.1.3 The Noise Solution<a class="headerlink" href="#613-the-noise-solution" title="Permanent link">&para;</a></h4>
<p>By adding Gaussian noise to data points, we "smooth" the distribution, filling empty regions with a blurry haze of noisy data. This makes the score easier to estimate everywhere. Think of it like turning a spiky mountain range into rolling hills—easier to navigate!</p>
<p><strong>Key Insight</strong>:
Instead of learning <span class="arithmatex">\(\nabla_x \log p(x)\)</span> directly (hard!), learn to <em>denoise</em> perturbed data. The denoising direction aligns with the score of the <em>noise-augmented</em> distribution.</p>
<h3 id="62-2-derivation-connecting-noise-to-the-score">6.2 2. Derivation: Connecting Noise to the Score<a class="headerlink" href="#62-2-derivation-connecting-noise-to-the-score" title="Permanent link">&para;</a></h3>
<h4 id="621-step-1-define-the-noisy-distribution">6.2.1 Step 1: Define the Noisy Distribution<a class="headerlink" href="#621-step-1-define-the-noisy-distribution" title="Permanent link">&para;</a></h4>
<p>Corrupt a data point <span class="arithmatex">\(x\)</span> with Gaussian noise:</p>
<div class="arithmatex">\[ \tilde{x} = x + \epsilon, \quad \epsilon \sim \mathcal{N}(0, \sigma^2 I) \]</div>
<p>The conditional distribution is:</p>
<div class="arithmatex">\[ q(\tilde{x}|x) = \mathcal{N}(x, \sigma^2 I) \]</div>
<p>thus,</p>
<div class="arithmatex">\[
q_\sigma(\tilde{\mathbf{x}}) = \int q(\tilde{\mathbf{x}} \mid \mathbf{x}) p_{\text{data}}(\mathbf{x}) \, d\mathbf{x},
\]</div>
<p>where <span class="arithmatex">\(q(\tilde{\mathbf{x}} \mid \mathbf{x}) = \mathcal{N}(\tilde{\mathbf{x}}; \mathbf{x}, \sigma^2 \mathbf{I})\)</span> is a Gaussian distribution centered at <span class="arithmatex">\(\mathbf{x}\)</span> with variance <span class="arithmatex">\(\sigma^2\)</span>. This represents a <strong>convolution</strong> of <span class="arithmatex">\(p_{\text{data}}(\mathbf{x})\)</span> with a Gaussian kernel.</p>
<h4 id="622-1-small-noise-sigma-to-0">6.2.2 1. Small Noise <span class="arithmatex">\(\sigma \to 0\)</span><a class="headerlink" href="#622-1-small-noise-sigma-to-0" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>Behavior of <span class="arithmatex">\(q(\tilde{\mathbf{x}} \mid \mathbf{x})\)</span>:</strong></li>
</ul>
<p>The Gaussian becomes a Dirac delta function:</p>
<div class="arithmatex">\[
q_\sigma(\tilde{\mathbf{x}} \mid \mathbf{x}) \to \delta(\tilde{\mathbf{x}} - \mathbf{x}).
\]</div>
<ul>
<li><strong>Effect on <span class="arithmatex">\(q(\tilde{\mathbf{x}})\)</span>:</strong></li>
</ul>
<p>The integral simplifies to <span class="arithmatex">\(p_{\text{data}}(\tilde{\mathbf{x}})\)</span>, preserving the original distribution:</p>
<div class="arithmatex">\[
q_\sigma(\tilde{\mathbf{x}}) \approx p_{\text{data}}(\tilde{\mathbf{x}}).
\]</div>
<ul>
<li><strong>Interpretation:</strong> Minimal blurring; the perturbed distribution matches the original data distribution.</li>
</ul>
<h4 id="623-2-moderate-noise-sigma-0">6.2.3 2. Moderate Noise <span class="arithmatex">\(\sigma &gt; 0\)</span><a class="headerlink" href="#623-2-moderate-noise-sigma-0" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p><strong>Behavior of <span class="arithmatex">\(q(\tilde{\mathbf{x}} \mid \mathbf{x})\)</span>:</strong>
  The Gaussian acts as a smoothing kernel with width proportional to <span class="arithmatex">\(\sigma\)</span>.</p>
</li>
<li>
<p><strong>Effect on <span class="arithmatex">\(q(\tilde{\mathbf{x}})\)</span>:</strong>
  The convolution introduces controlled blurring, creating a smoothed version of <span class="arithmatex">\(p_{\text{data}}(\mathbf{x})\)</span>. Fine details are averaged, but the global structure remains recognizable.</p>
</li>
<li>
<p><strong>Interpretation:</strong> Useful for regularization or generating "softened" data samples.</p>
</li>
</ul>
<h4 id="624-3-large-noise-sigma-to-infty">6.2.4 3. Large Noise <span class="arithmatex">\(\sigma \to \infty\)</span><a class="headerlink" href="#624-3-large-noise-sigma-to-infty" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p><strong>Behavior of <span class="arithmatex">\(q_\sigma(\tilde{\mathbf{x}} \mid \mathbf{x})\)</span>:</strong>
  The Gaussian becomes extremely wide and flat, approximating a uniform distribution over the domain.</p>
</li>
<li>
<p><strong>Effect on <span class="arithmatex">\(q_\sigma(\tilde{\mathbf{x}})\)</span>:</strong></p>
</li>
</ul>
<p>The integral averages <span class="arithmatex">\(p_{\text{data}}(\mathbf{x})\)</span> over a large region, erasing fine structure. If <span class="arithmatex">\(p_{\text{data}}(\mathbf{x})\)</span> is bounded, <span class="arithmatex">\(q(\tilde{\mathbf{x}})\)</span> approaches a uniform distribution; otherwise, it becomes a broad Gaussian.</p>
<ul>
<li><strong>Interpretation:</strong> Severe distortion; the original distribution is lost.</li>
</ul>
<h4 id="625-step-2-score-of-the-noisy-distribution">6.2.5 Step 2: Score of the Noisy Distribution<a class="headerlink" href="#625-step-2-score-of-the-noisy-distribution" title="Permanent link">&para;</a></h4>
<p>The score of <span class="arithmatex">\(q(\tilde{x}|x)\)</span> is:</p>
<div class="arithmatex">\[\nabla_{\tilde{x}} \log q(\tilde{x}|x) = \frac{x - \tilde{x}}{\sigma^2}\]</div>
<p><strong>Why?</strong></p>
<p>For a Gaussian <span class="arithmatex">\(\mathcal{N}(x, \sigma^2 I)\)</span>, the gradient of the log-density with respect to <span class="arithmatex">\(\tilde{x}\)</span> points toward the mean <span class="arithmatex">\(x\)</span>. The term <span class="arithmatex">\((x - \tilde{x})/\sigma^2\)</span> is the "denoising direction" that corrects <span class="arithmatex">\(\tilde{x}\)</span> back to <span class="arithmatex">\(x\)</span>.</p>
<h4 id="626-step-3-the-dsm-objective">6.2.6 Step 3: The DSM Objective<a class="headerlink" href="#626-step-3-the-dsm-objective" title="Permanent link">&para;</a></h4>
<p>Train a model <span class="arithmatex">\(s_\theta(\tilde{x})\)</span> to match this score:</p>
<div class="arithmatex">\[ J(\theta) = \mathbb{E}_{q(\tilde{x},x)}\left[ \| s_\theta(\tilde{x}) - \frac{x - \tilde{x}}{\sigma^2} \|^2 \right] \]</div>
<p><strong>Why This Works</strong>:</p>
<p>Minimizing this loss forces <span class="arithmatex">\(s_\theta(\tilde{x})\)</span> to approximate <span class="arithmatex">\(\nabla_{\tilde{x}} \log q(\tilde{x})\)</span>, the score of the <em>marginal</em> noisy distribution <span class="arithmatex">\(q(\tilde{x}) = \int q(\tilde{x}|x)p_{\text{data}}(x)dx\)</span>,  which has been proved in the above section.
As illustrated above, this is equivalent to learning the score of the <em>true</em> data distribution <span class="arithmatex">\(p_{\text{data}}(x)\)</span> as <span class="arithmatex">\(\sigma \to 0\)</span>.</p>
<h3 id="63-3-training-process-step-by-step">6.3 3. Training Process: Step-by-Step<a class="headerlink" href="#63-3-training-process-step-by-step" title="Permanent link">&para;</a></h3>
<h4 id="631-step-1-add-noise-to-data">6.3.1 Step 1: Add Noise to Data<a class="headerlink" href="#631-step-1-add-noise-to-data" title="Permanent link">&para;</a></h4>
<p>For each clean data point <span class="arithmatex">\(x\)</span>, generate a noisy version:</p>
<div class="arithmatex">\[ \tilde{x} = x + \epsilon, \quad \epsilon \sim \mathcal{N}(0, \sigma^2 I) \]</div>
<p><strong>Why Add Noise?</strong></p>
<ul>
<li>Creates "easier" training examples by spreading data into empty regions.</li>
<li>Teaches the model to handle perturbations, improving robustness.</li>
</ul>
<h4 id="632-step-2-compute-the-loss">6.3.2 Step 2: Compute the Loss<a class="headerlink" href="#632-step-2-compute-the-loss" title="Permanent link">&para;</a></h4>
<p>The DSM loss simplifies to:</p>
<div class="arithmatex">\[ \mathcal{L} = \frac{1}{N} \sum_{i=1}^N \| s_\theta(\tilde{x}_i) - \frac{x_i - \tilde{x}_i}{\sigma^2} \|^2 \]</div>
<p><strong>Interpretation</strong>:</p>
<p>The model learns to predict the vector <span class="arithmatex">\((x_i - \tilde{x}_i)/\sigma^2\)</span>, which points from the noisy sample <span class="arithmatex">\(\tilde{x}_i\)</span> back to the clean <span class="arithmatex">\(x_i\)</span>. This is equivalent to estimating the score of the noisy distribution.</p>
<h4 id="633-step-3-gradient-descent">6.3.3 Step 3: Gradient Descent<a class="headerlink" href="#633-step-3-gradient-descent" title="Permanent link">&para;</a></h4>
<p>Update model parameters <span class="arithmatex">\(\theta\)</span> to minimize <span class="arithmatex">\(\mathcal{L}\)</span>.</p>
<p><a class="glightbox" href="../../../images/image-33.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="progress of denoising" src="../../../images/image-33.png" /></a></p>
<p><strong>Practical Tip</strong>:</p>
<p>Scale the loss by $ \sigma^2 $ to balance learning across noise levels (critical for multi-scale training).</p>
<p><strong>多尺度 sigmas (σ schedules)</strong></p>
<ul>
<li>
<p>为了增强模型的鲁棒性，可以为噪声设置一系列值，从较小的噪声到较大的噪声，形成一个<strong>噪声尺度</strong> 。</p>
</li>
<li>
<p><strong>公式</strong> : 通常构造一个对数间隔的序列，例如：</p>
</li>
</ul>
<div class="arithmatex">\[
\sigma_i = \sigma_{\text{min}} \times \left(\frac{\sigma_{\text{max}}}{\sigma_{\text{min}}}\right)^{i / (N-1)}
\]</div>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span></pre></div></td><td class="code"><div><pre><span></span><code>- `σ_min`: 最小噪声强度。

- `σ_max`: 最大噪声强度。

- `N`: 噪声尺度的数量。
</code></pre></div></td></tr></table></div>
<ul>
<li><strong>常用设置</strong> :</li>
<li>
<p>对于图像数据，<code>σ_min</code> 通常是 <code>0.01</code> 或 <code>0.05</code>。</p>
</li>
<li>
<p><code>σ_max</code> 通常取 <code>0.5</code> 或 <code>1.0</code>。</p>
</li>
<li>
<p><code>N</code> 的典型值为 <code>10</code> 到 <code>50</code>。</p>
</li>
<li>
<p><strong>优点</strong> : 多尺度噪声更适合复杂分布，可以建模从低噪声到高噪声的各种情况。</p>
</li>
<li>
<p><strong>缺点</strong> : 训练和实现更复杂，需要动态调整噪声水平。</p>
</li>
</ul>
<h3 id="64-4-sampling-with-langevin-dynamics">6.4 4. Sampling with Langevin Dynamics<a class="headerlink" href="#64-4-sampling-with-langevin-dynamics" title="Permanent link">&para;</a></h3>
<p>Once trained, we use <strong>Langevin dynamics</strong> to generate samples by "walking" along the learned score.</p>
<h4 id="641-the-update-rule">6.4.1 The Update Rule<a class="headerlink" href="#641-the-update-rule" title="Permanent link">&para;</a></h4>
<div class="arithmatex">\[ x_{t+1} = x_t + \epsilon \cdot s_\theta(x_t) + \sqrt{2\epsilon} \cdot z_t, \quad z_t \sim \mathcal{N}(0, I)\]</div>
<p><strong>Breaking It Down</strong>:</p>
<ol>
<li><strong>Score term <span class="arithmatex">\(\epsilon \cdot s_\theta(x_t)\)</span></strong>: Guides <span class="arithmatex">\(x_t\)</span> toward high-density regions (denoising).</li>
<li><strong>Noise term <span class="arithmatex">\(\sqrt{2\epsilon} \cdot z_t\)</span></strong>: Adds randomness to escape local minima and explore the distribution.</li>
</ol>
<p><strong>Why This Works</strong>:
Langevin dynamics is a Markov Chain Monte Carlo (MCMC) method that uses the score to perform gradient ascent on <span class="arithmatex">\(\log p(x)\)</span>. The noise ensures ergodicity, allowing the chain to converge to the true distribution.</p>
<h4 id="642-analogy">6.4.2 Analogy<a class="headerlink" href="#642-analogy" title="Permanent link">&para;</a></h4>
<p>Imagine rolling a marble on a bumpy surface (the data landscape). The score tilts the surface to guide the marble toward valleys (data points), while the noise gives it occasional kicks to explore new areas.</p>
<h3 id="65-5-multi-scale-noise-training">6.5 5. Multi-Scale Noise Training<a class="headerlink" href="#65-5-multi-scale-noise-training" title="Permanent link">&para;</a></h3>
<h4 id="651-why-multiple-noise-scales">6.5.1 Why Multiple Noise Scales?<a class="headerlink" href="#651-why-multiple-noise-scales" title="Permanent link">&para;</a></h4>
<p><strong>Key Challenges in Training SBMs/EBMs</strong></p>
<ul>
<li><strong>Undefined Score Function Off the Data Manifold</strong> : Under the manifold hypothesis, data resides on a low-dimensional manifold embedded in a high-dimensional ambient space. The score function $ \nabla_x \log p(x) $, which requires gradients to be defined everywhere in the ambient space, becomes ill-defined outside the manifold.</li>
</ul>
<p><strong>Problem</strong>: Score estimation fails in regions irrelevant to the data, destabilizing training and generation.</p>
<p><strong>Implication</strong>: Score estimation fails in regions irrelevant to the data, destabilizing training and generation.</p>
<ul>
<li><strong>Sparse Data in Low-Density Regions</strong></li>
</ul>
<p><strong>Problem</strong>: Real-world datasets often lack sufficient samples in low-density areas (e.g., transitions between classes or rare features). This sparsity makes it difficult to reliably estimate the score function in these regions.</p>
<p><strong>Implication</strong>: Poor score approximation leads to artifacts, mode collapse, or unrealistic interpolations.</p>
<ul>
<li><strong>Degradation of Mixing Distribution Coefficients</strong></li>
</ul>
<p><strong>Problem</strong>: In near-zero density regions (e.g., far from the manifold), the coefficients (weights) of the mixing distribution—used to model complex data—vanish or become negligible.</p>
<p><strong>Implication</strong>: The model loses expressive power in these regions, exacerbating mode collapse and limiting diversity in generated samples.</p>
<p>We use multi-scale noise pertubation could help address these challenges.</p>
<p>Real-world data (e.g., images) has structure at multiple resolutions:</p>
<ul>
<li><strong>Low noise (small <span class="arithmatex">\(\sigma\)</span>)</strong>: Captures fine details (e.g., textures).</li>
<li><strong>High noise (large <span class="arithmatex">\(\sigma\)</span>)</strong>: Captures coarse structure (e.g., shapes).</li>
</ul>
<p>Training with a single <span class="arithmatex">\(\sigma\)</span> limits the model’s ability to generalize across scales.</p>
<h4 id="652-training-process">6.5.2 Training Process<a class="headerlink" href="#652-training-process" title="Permanent link">&para;</a></h4>
<ol>
<li><strong>Noise Sampling</strong>: For each batch, randomly pick <span class="arithmatex">\(\sigma_i\)</span> from a set <span class="arithmatex">\(\{\sigma_1, ..., \sigma_L\}\)</span>.</li>
<li><strong>Loss Adjustment</strong>: Scale the loss by <span class="arithmatex">\(\sigma_i^2\)</span> to prevent larger <span class="arithmatex">\(\sigma\)</span> from dominating:</li>
</ol>
<div class="arithmatex">\[ \mathcal{L} = \frac{1}{L} \sum_{i=1}^L \mathbb{E}\left[ \sigma_i^2 \| s_\theta(\tilde{x}, \sigma_i) - \frac{x - \tilde{x}}{\sigma_i^2} \|^2 \right] \]</div>
<h4 id="653-sampling">6.5.3 Sampling<a class="headerlink" href="#653-sampling" title="Permanent link">&para;</a></h4>
<p>Use a decreasing sequence <span class="arithmatex">\(\sigma_1 &gt; \sigma_2 &gt; ... &gt; \sigma_L\)</span> during Langevin dynamics:</p>
<ol>
<li>Start with high noise to capture coarse structure.</li>
<li>Gradually reduce noise to refine details.</li>
</ol>
<p><strong>Analogy</strong>:
Like sketching a painting—first outline shapes (high noise), then add details (low noise).</p>
<h3 id="66-6-continuous-noise-levels">6.6 6. Continuous Noise Levels<a class="headerlink" href="#66-6-continuous-noise-levels" title="Permanent link">&para;</a></h3>
<h4 id="661-why-go-continuous">6.6.1 Why Go Continuous?<a class="headerlink" href="#661-why-go-continuous" title="Permanent link">&para;</a></h4>
<p>Discrete noise scales are rigid and computationally costly for large <span class="arithmatex">\(L\)</span>. A continuous approach:</p>
<ul>
<li>Smoothly interpolates between noise levels.</li>
<li>Connects to differential equations for efficient sampling.</li>
</ul>
<h4 id="662-training">6.6.2 Training<a class="headerlink" href="#662-training" title="Permanent link">&para;</a></h4>
<ol>
<li>
<p><strong>Noise Sampling</strong>: Sample <span class="arithmatex">\(t \sim \mathcal{U}(0,1)\)</span>, compute <span class="arithmatex">\(\sigma(t)\)</span> (e.g., <span class="arithmatex">\(\sigma(t) = \sigma_{\text{min}} + t(\sigma_{\text{max}} - \sigma_{\text{min}})\)</span>).</p>
</li>
<li>
<p><strong>Condition the Model</strong>: Feed <span class="arithmatex">\(t\)</span> to <span class="arithmatex">\(s_\theta\)</span> via time embeddings (e.g., sinusoidal features).</p>
</li>
</ol>
<h4 id="663-sampling-with-stochastic-differential-equations-sdes">6.6.3 Sampling with Stochastic Differential Equations (SDEs)<a class="headerlink" href="#663-sampling-with-stochastic-differential-equations-sdes" title="Permanent link">&para;</a></h4>
<p>The continuous noise process can be described as an SDE:</p>
<div class="arithmatex">\[ dx = s_\theta(x, t) dt + \sqrt{2\sigma(t)} dw \]</div>
<p><strong>Intuition</strong>:
This generalizes Langevin dynamics to infinitesimal steps. The term <span class="arithmatex">\(s_\theta(x,t)dt\)</span> is the deterministic drift (denoising), and <span class="arithmatex">\(\sqrt{2\sigma(t)}dw\)</span> is stochastic diffusion (noise).</p>
<p><strong>Solving the SDE</strong>:
Use numerical solvers like Euler-Maruyama:</p>
<div class="arithmatex">\[ x_{t+1} = x_t + s_\theta(x_t, t) \Delta t + \sqrt{2\sigma(t) \Delta t} \, z_t \]</div>
<p>This is equivalent to Langevin dynamics with time-dependent noise.</p>
<h3 id="67-7-why-does-dsm-work-a-unified-view">6.7 7. Why Does DSM Work? A Unified View<a class="headerlink" href="#67-7-why-does-dsm-work-a-unified-view" title="Permanent link">&para;</a></h3>
<ol>
<li><strong>Avoids Density Estimation</strong>: Models gradients instead of <span class="arithmatex">\(p(x)\)</span>, bypassing normalization constraints.</li>
<li><strong>Exploits Noise</strong>: Smoothens the data manifold, making score estimation tractable.</li>
<li><strong>Connects to Diffusion Models</strong>: DSM is the backbone of diffusion models (e.g., DDPM, Score-SDE), where noise addition/removal is formalized across timesteps.</li>
</ol>
<p><strong>Comparison to GANs/VAEs</strong>:</p>
<ul>
<li><strong>No adversarial training</strong>: More stable than GANs.</li>
<li><strong>No latent space bottlenecks</strong>: Richer expressivity than VAEs.</li>
</ul>
<h3 id="68-conclusion">6.8 Conclusion<a class="headerlink" href="#68-conclusion" title="Permanent link">&para;</a></h3>
<p>Denoising Score Matching elegantly bridges noise and geometry to learn data distributions. By progressively corrupting and denoising data, it captures multi-scale structure and enables efficient sampling via SDEs. This framework powers cutting-edge generative models, offering flexibility, stability, and scalability.</p>
<p><strong>Further Reading</strong>:</p>
<ul>
<li><a href="https://www.jmlr.org/papers/volume6/hyvarinen05a/hyvarinen05a.pdf">Score Matching</a> (Hyvärinen, 2005)</li>
<li><a href="https://www.iro.umontreal.ca/~vincentp/Publications/denoising_score_matching_AISTATS2011.pdf">Denoising Score Matching</a> (Vincent, 2011)</li>
<li><a href="https://arxiv.org/abs/2011.13456">Score-Based SDEs</a> (Song et al., 2021)</li>
<li><a href="https://arxiv.org/pdf/1907.05600">Generative Modeling by Estimating Gradients of the Data Distribution</a> (YangSong, 2019)</li>
</ul>









  



<!-- 段落注释系统
<div class="comments-container annotation-container">
  <div class="comments-header">
    <h2 id="__annotations" class="comments-title">
      <span class="comments-icon">🔍</span>
      段落注释
      <span class="comments-subtitle">您可以高亮并评论任何文本!</span>
    </h2>
    <div class="comments-divider"></div>
  </div>

  <div class="comments-wrapper">
    <div class="hypothesis-instructions">
      <p><strong>如何使用段落注释功能：</strong></p>
      <ol>
        <li>点击右上角的 <img src="https://hypothes.is/assets/images/logo.png" alt="Hypothesis" style="height: 16px; vertical-align: middle;"> 图标打开侧边栏</li>
        <li>选择任意文本段落即可高亮并添加注释</li>
        <li>您还可以对其他人的注释进行回复</li>
      </ol>
    </div>
  </div>
</div> -->

<!-- 加载  -->
<script type="application/json" class="js-hypothesis-config">
{
  "openSidebar": false,
  "showHighlights": true,
  "theme": "clean"
}
</script>
<script async src="https://hypothes.is/embed.js"></script>

<!-- Hypothesis 样式美化 -->
<style>
  /* 修改高亮效果为下划线和聊天泡泡 */
  .hypothesis-highlight {
    background-color: transparent !important; /* 移除高亮背景 */
    text-decoration: underline !important;
    text-decoration-color: #4285f4 !important;
    text-decoration-thickness: 2px !important;
    text-decoration-style: wavy !important;
    position: relative !important;
    cursor: pointer !important;
    border-bottom: none !important; /* 移除之前的边框 */
    box-shadow: none !important; /* 移除之前的阴影 */
  }

  .hypothesis-highlight::after {
    content: "💬" !important;
    position: absolute !important;
    display: inline-block !important;
    font-size: 14px !important;
    top: -10px !important;
    right: -5px !important;
    opacity: 0.7 !important;
    transition: opacity 0.3s ease !important;
  }

  .hypothesis-highlight:hover {
    background-color: rgba(66, 133, 244, 0.08) !important; /* 鼠标悬停时的轻微背景 */
  }

  .hypothesis-highlight:hover::after {
    opacity: 1 !important;
    transform: scale(1.2) !important;
  }

  /* 美化 Hypothesis 侧边栏 */
  hypothesis-sidebar {
    font-family: var(--md-text-font-family, -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Open Sans", "Helvetica Neue", sans-serif) !important;
    box-shadow: -2px 0 10px rgba(0, 0, 0, 0.1) !important;
  }

  /* 美化卡片样式 */
  .hypothesis-annotation-card {
    border-radius: 8px !important;
    box-shadow: 0 2px 5px rgba(0, 0, 0, 0.05) !important;
    transition: transform 0.2s ease, box-shadow 0.2s ease !important;
    overflow: hidden !important;
  }

  .hypothesis-annotation-card:hover {
    transform: translateY(-2px) !important;
    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1) !important;
  }

  /* 美化 Hypothesis 按钮 */
  .hypothesis-button {
    border-radius: 4px !important;
    transition: background-color 0.2s ease !important;
  }

  /* 美化标签样式 */
  .hypothesis-tag {
    border-radius: 12px !important;
    padding: 2px 8px !important;
    font-size: 12px !important;
    background-color: rgba(0, 0, 0, 0.05) !important;
    color: #606060 !important;
  }

  /* 美化工具栏 */
  .hypothesis-toolbar {
    background: linear-gradient(to right, #f5f5f5, #ffffff) !important;
    border-bottom: 1px solid rgba(0, 0, 0, 0.1) !important;
  }

  /* 美化注释面板header */
  .hypothesis-annotation-header {
    padding: 10px !important;
    background-color: #f9f9f9 !important;
  }

  /* 美化注释内容 */
  .hypothesis-annotation-body {
    font-size: 14px !important;
    line-height: 1.6 !important;
    color: #333 !important;
  }

  /* 美化用户名 */
  .hypothesis-user {
    font-weight: 600 !important;
    color: #3f51b5 !important;
  }

  /* 美化时间戳 */
  .hypothesis-timestamp {
    font-size: 12px !important;
    color: #757575 !important;
  }

  /* 美化输入框 */
  .hypothesis-input {
    border-radius: 4px !important;
    border: 1px solid #e0e0e0 !important;
    transition: border-color 0.2s ease, box-shadow 0.2s ease !important;
  }

  .hypothesis-input:focus {
    border-color: #4dabf7 !important;
    box-shadow: 0 0 0 2px rgba(77, 171, 247, 0.2) !important;
    outline: none !important;
  }
</style>

<!-- 页面评论系统 -->
<div class="comments-container utterances-container">
  <div class="comments-header">
    <h2 id="__comments" class="comments-title">
      <span class="comments-icon">💬</span>
      Comments
      <span class="comments-subtitle">Share your thoughts!</span>
    </h2>
    <div class="comments-divider"></div>
  </div>

  <div class="comments-wrapper">
    <script src="https://utteranc.es/client.js"
            repo="MAD-SG/generative-ai-start-to-surrender"
            issue-term="pathname"
            label="comment"
            theme="preferred-color-scheme"
            crossorigin="anonymous"
            async>
    </script>
  </div>
</div>

<style>
  .comments-container {
    margin: 2.5rem auto;
    padding: 1.5rem;
    background: var(--md-code-bg-color, rgba(0, 0, 0, 0.05));
    border-radius: 8px;
    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.05);
    transition: transform 0.3s ease, box-shadow 0.3s ease;
    width: 100%;
    max-width: 100%;
    box-sizing: border-box;
  }

  .annotation-container {
    margin-bottom: 1rem;
    background: rgba(255, 255, 240, 0.5);
    border-left: 4px solid #ffeb3b;
  }

  .utterances-container {
    background: rgba(240, 248, 255, 0.5);
    border-left: 4px solid #2196f3;
  }

  .comments-container:hover {
    transform: translateY(-2px);
    box-shadow: 0 6px 12px rgba(0, 0, 0, 0.1);
  }

  .comments-header {
    margin-bottom: 1.5rem;
  }

  .comments-title {
    font-weight: 600;
    display: flex;
    align-items: center;
    gap: 0.5rem;
    margin-top: 0;
    margin-bottom: 0.75rem;
    color: var(--md-primary-fg-color, #2196f3);
    flex-wrap: wrap;
  }

  .annotation-container .comments-title {
    color: #f57c00;
  }

  .comments-icon {
    font-size: 1.4em;
  }

  .comments-subtitle {
    font-size: 0.7em;
    font-weight: 400;
    opacity: 0.8;
    margin-left: 1rem;
  }

  .comments-divider {
    height: 3px;
    background: linear-gradient(90deg,
      var(--md-primary-fg-color, #2196f3) 0%,
      rgba(255, 255, 255, 0) 100%);
    border-radius: 3px;
    margin-bottom: 1rem;
    width: 100%;
  }

  .annotation-container .comments-divider {
    background: linear-gradient(90deg,
      #f57c00 0%,
      rgba(255, 255, 255, 0) 100%);
  }

  .comments-wrapper {
    position: relative;
    min-height: 150px;
    width: 100%;
  }

  .hypothesis-instructions {
    padding: 1rem;
    background-color: rgba(255, 255, 255, 0.5);
    border-radius: 6px;
    margin-bottom: 1rem;
  }

  .hypothesis-instructions p {
    margin-top: 0;
    font-weight: 500;
  }

  .hypothesis-instructions ol {
    margin-bottom: 0;
    padding-left: 1.5rem;
  }

  .hypothesis-instructions li {
    margin-bottom: 0.5rem;
  }

  .hypothesis-instructions li:last-child {
    margin-bottom: 0;
  }

  /* 确保utterances的iframe填充可用宽度 */
  .utterances-container .comments-wrapper iframe {
    border-radius: 6px;
    width: 100% !important;
    max-width: 100% !important;
  }

  /* 动画效果 */
  @keyframes fadeInUp {
    from {
      opacity: 0;
      transform: translate3d(0, 20px, 0);
    }
    to {
      opacity: 1;
      transform: translate3d(0, 0, 0);
    }
  }

  .comments-wrapper {
    animation: fadeInUp 0.6s ease forwards;
  }

  /* 响应式设计 - 小屏幕调整 */
  @media (max-width: 768px) {
    .comments-container {
      padding: 1rem;
      margin: 1.5rem auto;
    }

    .comments-title {
      font-size: 1.3rem;
    }

    .comments-subtitle {
      display: block;
      width: 100%;
      margin-left: 0;
      margin-top: 0.3rem;
    }
  }
</style>
                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer" >
        
          
          <a href="../cd/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Contrastive Divergence">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                Contrastive Divergence
              </div>
            </div>
          </a>
        
        
          
          <a href="../../chapter6_VAE/vae_introduction/" class="md-footer__link md-footer__link--next" aria-label="Next: Introduction">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                Introduction
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
</div>
      
        <div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://mad-sg.github.io/generative-ai-start-to-surrender/" target="_blank" rel="noopener" title="mad-sg.github.io" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://hub.docker.com/r/squidfunk/mkdocs-material/" target="_blank" rel="noopener" title="hub.docker.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M349.9 236.3h-66.1v-59.4h66.1zm0-204.3h-66.1v60.7h66.1zm78.2 144.8H362v59.4h66.1zm-156.3-72.1h-66.1v60.1h66.1zm78.1 0h-66.1v60.1h66.1zm276.8 100c-14.4-9.7-47.6-13.2-73.1-8.4-3.3-24-16.7-44.9-41.1-63.7l-14-9.3-9.3 14c-18.4 27.8-23.4 73.6-3.7 103.8-8.7 4.7-25.8 11.1-48.4 10.7H2.4c-8.7 50.8 5.8 116.8 44 162.1 37.1 43.9 92.7 66.2 165.4 66.2 157.4 0 273.9-72.5 328.4-204.2 21.4.4 67.6.1 91.3-45.2 1.5-2.5 6.6-13.2 8.5-17.1zm-511.1-27.9h-66v59.4h66.1v-59.4zm78.1 0h-66.1v59.4h66.1zm78.1 0h-66.1v59.4h66.1zm-78.1-72.1h-66.1v60.1h66.1z"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://pypi.org/project/mkdocs-material/" target="_blank" rel="noopener" title="pypi.org" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.8 200.5c-7.7-30.9-22.3-54.2-53.4-54.2h-40.1v47.4c0 36.8-31.2 67.8-66.8 67.8H172.7c-29.2 0-53.4 25-53.4 54.3v101.8c0 29 25.2 46 53.4 54.3 33.8 9.9 66.3 11.7 106.8 0 26.9-7.8 53.4-23.5 53.4-54.3v-40.7H226.2v-13.6h160.2c31.1 0 42.6-21.7 53.4-54.2 11.2-33.5 10.7-65.7 0-108.6M286.2 404c11.1 0 20.1 9.1 20.1 20.3 0 11.3-9 20.4-20.1 20.4-11 0-20.1-9.2-20.1-20.4.1-11.3 9.1-20.3 20.1-20.3M167.8 248.1h106.8c29.7 0 53.4-24.5 53.4-54.3V91.9c0-29-24.4-50.7-53.4-55.6-35.8-5.9-74.7-5.6-106.8.1-45.2 8-53.4 24.7-53.4 55.6v40.7h106.9v13.6h-147c-31.1 0-58.3 18.7-66.8 54.2-9.8 40.7-10.2 66.1 0 108.6 7.6 31.6 25.7 54.2 56.8 54.2H101v-48.8c0-35.3 30.5-66.4 66.8-66.4m-6.7-142.6c-11.1 0-20.1-9.1-20.1-20.3.1-11.3 9-20.4 20.1-20.4 11 0 20.1 9.2 20.1 20.4s-9 20.3-20.1 20.3"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://bsky.app/profile/squidfunk.bsky.social" target="_blank" rel="noopener" title="bsky.app" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M111.8 62.2C170.2 105.9 233 194.7 256 242.4c23-47.6 85.8-136.4 144.2-180.2 42.1-31.6 110.3-56 110.3 21.8 0 15.5-8.9 130.5-14.1 149.2-18.2 64.8-84.4 81.4-143.3 71.3C456 322 482.2 380 425.6 438c-107.4 110.2-154.3-27.6-166.3-62.9-1.7-4.9-2.6-7.8-3.3-7.8s-1.6 3-3.3 7.8c-12 35.3-59 173.1-166.3 62.9-56.5-58-30.4-116 72.5-133.5C100 314.6 33.8 298 15.7 233.1 10.4 214.4 1.5 99.4 1.5 83.9c0-77.8 68.2-53.4 110.3-21.8z"/></svg>
    </a>
  
    
    
      
    
    
    
      
      
    
    <a href="https://fosstodon.org/@squidfunk" target="_blank" rel="noopener me" title="fosstodon.org" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M433 179.11c0-97.2-63.71-125.7-63.71-125.7-62.52-28.7-228.56-28.4-290.48 0 0 0-63.72 28.5-63.72 125.7 0 115.7-6.6 259.4 105.63 289.1 40.51 10.7 75.32 13 103.33 11.4 50.81-2.8 79.32-18.1 79.32-18.1l-1.7-36.9s-36.31 11.4-77.12 10.1c-40.41-1.4-83-4.4-89.63-54a102.5 102.5 0 0 1-.9-13.9c85.63 20.9 158.65 9.1 178.75 6.7 56.12-6.7 105-41.3 111.23-72.9 9.8-49.8 9-121.5 9-121.5m-75.12 125.2h-46.63v-114.2c0-49.7-64-51.6-64 6.9v62.5h-46.33V197c0-58.5-64-56.6-64-6.9v114.2H90.19c0-122.1-5.2-147.9 18.41-175 25.9-28.9 79.82-30.8 103.83 6.1l11.6 19.5 11.6-19.5c24.11-37.1 78.12-34.8 103.83-6.1 23.71 27.3 18.4 53 18.4 175z"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://x.com/squidfunk" target="_blank" rel="noopener" title="x.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8l164.9-188.5L26.8 48h145.6l100.5 132.9zm-24.8 373.8h39.1L151.1 88h-42z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../../..", "features": ["navigation.tabs", "toc.integrate", "content.code.copy", "content.code.select", "content.code.annotate", "content.tabs.link", "content.footnote.tooltips", "content.tooltips", "navigation.tracking", "search.highlight", "search.share", "search.suggest", "toc.follow", "announce.dismiss", "content.action.edit", "content.action.view", "content.code.annotate", "navigation.footer", "navigation.indexes", "navigation.sections", "navigation.tabs", "navigation.top", "navigation.expand", "search.share", "search.suggest"], "search": "../../../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../../assets/javascripts/bundle.88dd0f4e.min.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/core-js/3.26.1/minified.min.js"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
        <script src="../../../javascripts/mathjax.js"></script>
      
    
  <script id="init-glightbox">const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});
document$.subscribe(() => { lightbox.reload() });
</script></body>
</html>