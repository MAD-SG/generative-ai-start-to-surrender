
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../../../chapter6_VAE/vq_vae/">
      
      
        <link rel="next" href="../../3.3stylegan/paper/">
      
      
      <link rel="icon" href="../../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.50">
    
    
      
        <title>From GAN to StyleGAN - Generative AI: From Start to Surrender</title>
      
    
    
      <link rel="stylesheet" href="../../../../assets/stylesheets/main.a40c8224.min.css">
      
        
        <link rel="stylesheet" href="../../../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../../stylesheets/extra.css">
    
      <link rel="stylesheet" href="https://unpkg.com/katex@0/dist/katex.min.css">
    
    <script>__md_scope=new URL("../../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      
  


  
  

<script id="__analytics">function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config",""),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script>
  
    <script>"undefined"!=typeof __md_analytics&&__md_analytics()</script>
  

    
    
    
   <link href="../../../../assets/stylesheets/glightbox.min.css" rel="stylesheet"/><style>
    html.glightbox-open { overflow: initial; height: 100%; }
    .gslide-title { margin-top: 0px; user-select: text; }
    .gslide-desc { color: #666; user-select: text; }
    .gslide-image img { background: white; }
    .gscrollbar-fixer { padding-right: 15px; }
    .gdesc-inner { font-size: 0.75rem; }
    body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color);}
    body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color);}
    body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color);}</style> <script src="../../../../assets/javascripts/glightbox.min.js"></script></head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#from-gan-to-pggan-some-base-gan-model-introduction" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../../.." title="Generative AI: From Start to Surrender" class="md-header__button md-logo" aria-label="Generative AI: From Start to Surrender" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Generative AI: From Start to Surrender
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              From GAN to StyleGAN
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h4v-1.9H7c-1.71 0-3.1-1.39-3.1-3.1M8 13h8v-2H8zm9-6h-4v1.9h4c1.71 0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4a5 5 0 0 0 5-5 5 5 0 0 0-5-5"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="black" data-md-color-accent="indigo"  aria-label="Switch to system preference"  type="radio" name="__palette" id="__palette_2">
    
      <label class="md-header__button md-icon" title="Switch to system preference" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5M7 15a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="Share" aria-label="Share" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../../.." class="md-tabs__link">
        
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../chapter1_Introduction/1.1terminology/" class="md-tabs__link">
          
  
    
  
  Introduction

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../chapter2_generation_theory/5.1MLE/" class="md-tabs__link">
          
  
    
  
  Generation Theory

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../chapter3_energy_based_model/introduction/" class="md-tabs__link">
          
  
    
  
  Energy Based Models

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../chapter6_VAE/2.1introduction/" class="md-tabs__link">
          
  
    
  
  VAE

        </a>
      </li>
    
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="./" class="md-tabs__link">
          
  
    
  
  GANs

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../chapter7_diffusion/ddpm/" class="md-tabs__link">
          
  
    
  
  Diffusion Models

        </a>
      </li>
    
  

    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../chapter9_flow_matching/introduction/" class="md-tabs__link">
          
  
    
  
  Flow Matching

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../chapter11_hybrid_sota_models/hybrid_methods/" class="md-tabs__link">
          
  
    
  
  Hybrid SOTA Models

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


  

<nav class="md-nav md-nav--primary md-nav--lifted md-nav--integrated" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../.." title="Generative AI: From Start to Surrender" class="md-nav__button md-logo" aria-label="Generative AI: From Start to Surrender" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Generative AI: From Start to Surrender
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Introduction
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Introduction
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../chapter1_Introduction/1.1terminology/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Terms
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../chapter1_Introduction/1.2fourier_transform/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Fourier Transform
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../chapter1_Introduction/1.3signal_processing/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Signal Processing
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../chapter1_Introduction/1.4statistics/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Statistics
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../chapter1_Introduction/tutorials/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Tutorials
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Generation Theory
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Generation Theory
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../chapter2_generation_theory/5.1MLE/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Maximal Likelihood
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../chapter2_generation_theory/manifold_hypothesis/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Manifold Hypothesis
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Energy Based Models
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Energy Based Models
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../chapter3_energy_based_model/introduction/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../chapter3_energy_based_model/score_function/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Score Functions
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../chapter3_energy_based_model/sampling/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Sampling Methods
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../chapter3_energy_based_model/cd/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Contrastive Divergence
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../chapter3_energy_based_model/score_matching/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Score Matching
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    VAE
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            VAE
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../chapter6_VAE/2.1introduction/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../chapter6_VAE/vq_vae/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    VA-VAE
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" checked>
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="">
            
  
  <span class="md-ellipsis">
    GANs
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            GANs
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    From GAN to StyleGAN
  </span>
  

      </a>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_6_2" >
        
          
          <label class="md-nav__link" for="__nav_6_2" id="__nav_6_2_label" tabindex="">
            
  
  <span class="md-ellipsis">
    StyleGAN Variants
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_6_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_2">
            <span class="md-nav__icon md-icon"></span>
            StyleGAN Variants
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../3.3stylegan/paper/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    StyleGAN
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../3.4stylegan2/paper/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    StyleGAN2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../3.5stylegan3/paper/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    StyleGAN3
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../3.6styleganT/paper/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    StyleGAN-T
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../3.7R3Gan/paper/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    R3GAN
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../vq_gan/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    VQ-GAN
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_7" >
        
          
          <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Diffusion Models
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            Diffusion Models
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_7_1" >
        
          
          <label class="md-nav__link" for="__nav_7_1" id="__nav_7_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Discrete Diffusion
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_7_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_1">
            <span class="md-nav__icon md-icon"></span>
            Discrete Diffusion
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../chapter7_diffusion/ddpm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DDPM
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_7_2" >
        
          
          <label class="md-nav__link" for="__nav_7_2" id="__nav_7_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Continuous Diffusion
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_7_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_2">
            <span class="md-nav__icon md-icon"></span>
            Continuous Diffusion
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../chapter7_diffusion/introduction_sde/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    SDE Fundamentals
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../chapter7_diffusion/SDE4_DDPM_DSM/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    SDE for DDPM
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../chapter7_diffusion/probability_flow_ode/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Probability Flow ODE
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_8" >
        
          
          <label class="md-nav__link" for="__nav_8" id="__nav_8_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Flow Matching
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_8">
            <span class="md-nav__icon md-icon"></span>
            Flow Matching
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../chapter9_flow_matching/introduction/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../chapter9_flow_matching/probability_with_velocity_field/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Probability Path and Velocity Fields
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../chapter9_flow_matching/flow_matching_theory/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Flow Matching Theorem
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_9" >
        
          
          <label class="md-nav__link" for="__nav_9" id="__nav_9_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Hybrid SOTA Models
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_9">
            <span class="md-nav__icon md-icon"></span>
            Hybrid SOTA Models
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../chapter11_hybrid_sota_models/hybrid_methods/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hybrid Methods
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../chapter11_hybrid_sota_models/sota_closed_models/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Closed Models
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../chapter11_hybrid_sota_models/sota_open_models/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Open Models
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../chapter11_hybrid_sota_models/trends_future/" class="md-nav__link">
        
  
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 2 1 21h22M12 6l7.53 13H4.47M11 10v4h2v-4m-2 6v2h2v-2"/></svg>
  
  <span class="md-ellipsis">
    Future Trends
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="from-gan-to-pggan-some-base-gan-model-introduction">From GAN to PGGAN: Some Base GAN model Introduction<a class="headerlink" href="#from-gan-to-pggan-some-base-gan-model-introduction" title="Permanent link">&para;</a></h1>
<h1 id="1-2014gan-generative-adversarial-networks">1. [2014]GAN : <a href="https://arxiv.org/abs/1406.2661">Generative Adversarial Networks</a><a class="headerlink" href="#1-2014gan-generative-adversarial-networks" title="Permanent link">&para;</a></h1>
<p>GANs (Generative Adversarial Networks) are based on an adversarial process framework. In this framework, there are two networks that work in opposition: a generator and a discriminator. This can be compared to a scenario where one team (generator) tries to produce counterfeit items without being detected, while the other team (discriminator) acts like law enforcement trying to detect the fakes.
Overall Introduction</p>
<ul>
<li>
<p>Base model structure
  <a class="glightbox" href="https://hackmd.io/_uploads/BkDsNVoDyx.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="image" src="https://hackmd.io/_uploads/BkDsNVoDyx.png" /></a>
<em>Image Source: <a href="https://semiengineering.com/knowledge_centers/artificial-intelligence/neural-networks/generative-adversarial-network-gan/">Semi Engineering - GAN Knowledge Center</a></em></p>
</li>
<li>
<p>The model works through two independent learning models: a Generative Model and a Discriminative Model, which learn through adversarial training to produce high-quality outputs.</p>
<ul>
<li>Generative Model,short as <span class="arithmatex">\(G\)</span>：</li>
<li>Takes random noise <span class="arithmatex">\(z\)</span> as input -&gt; Generates images <span class="arithmatex">\(G(z)\)</span></li>
<li>Aims to create images that look real enough to fool <span class="arithmatex">\(D\)</span></li>
<li>Discriminative Model, short as <span class="arithmatex">\(D\)</span>,is a binary classifier:</li>
<li>Takes an image x as input -&gt; Output <span class="arithmatex">\(D(x)\)</span>, representing the probability that <span class="arithmatex">\(x\)</span> is a real image<ul>
<li><span class="arithmatex">\(D(x)=1\)</span> means 100% confidence it's real</li>
<li><span class="arithmatex">\(D(x)=0\)</span> means it's definitely fake</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Adversarial training: The optimization process is a minimax game, with the goal of reaching Nash equilibrium</p>
</li>
<li>
<p>The generator tries to minimize the probability of the discriminator detecting fake samples
    The discriminator tries to maximize its ability to distinguish between real and fake samples</p>
</li>
</ul>
<h2 id="11-loss-function">1.1 <strong>Loss function</strong>:<a class="headerlink" href="#11-loss-function" title="Permanent link">&para;</a></h2>
<p><span class="arithmatex">\(<span class="arithmatex">\(V(D,G) = \underset{D}{\max} {\underbrace{\mathbb{E}_{x \sim p_{data}(x)}[\log D(x)] + \mathbb{E}_{z \sim p_z(z)}[\log(1-D(G(z)))]}_{\text{Discriminator Loss}:L_D}} +\underset{G}{\min} {\underbrace{\mathbb{E}_{z \sim p_z(z)}[\log(1-D(G(z)))]}_{\text{Generator Loss: }L_G}}\)</span>\)</span></p>
<p>Where:
  - <span class="arithmatex">\(p_{data}(x)\)</span> is the real data distribution
  - <span class="arithmatex">\(p_z(z)\)</span> is the noise distribution
  - <span class="arithmatex">\(G(z)\)</span> is generator mapping from noise to synthetic data
  - <span class="arithmatex">\(D(x)\)</span> is the discriminator's estimate of the probability that <span class="arithmatex">\(x\)</span> is real</p>
<p>overall training process:
  <a class="glightbox" href="https://hackmd.io/_uploads/S1ROHEiwke.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="image" src="https://hackmd.io/_uploads/S1ROHEiwke.png" /></a>
<em>Image Source: Goodfellow et al., "Generative Adversarial Networks" (2014) arXiv:1406.2661</em></p>
<ul>
<li>
<p>In GAN training, we iterate the Discriminator (<span class="arithmatex">\(D\)</span>) <span class="arithmatex">\(K\)</span> times before updating the Generator (<span class="arithmatex">\(G\)</span>) once：</p>
</li>
<li>
<p>because we need <span class="arithmatex">\(D\)</span> to be powerful enough to provide accurate feedback for <span class="arithmatex">\(G's\)</span> improvement</p>
</li>
<li>This iterative strategy helps maintain training stability and prevent mode collapse, although K needs to be carefully balanced <ul>
<li>too large and G can't learn effectively, too small and D's feedback becomes unreliable.</li>
</ul>
</li>
</ul>
<h2 id="12-base-model-structure">1.2 Base model structure<a class="headerlink" href="#12-base-model-structure" title="Permanent link">&para;</a></h2>
<p>Code reference: https://github.com/eriklindernoren/PyTorch-GAN/blob/master/implementations/gan/gan.py</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-0-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-0-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-0-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-0-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-0-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-0-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-0-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-0-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-0-10">10</a></span>
<span class="normal"><a href="#__codelineno-0-11">11</a></span>
<span class="normal"><a href="#__codelineno-0-12">12</a></span>
<span class="normal"><a href="#__codelineno-0-13">13</a></span>
<span class="normal"><a href="#__codelineno-0-14">14</a></span>
<span class="normal"><a href="#__codelineno-0-15">15</a></span>
<span class="normal"><a href="#__codelineno-0-16">16</a></span>
<span class="normal"><a href="#__codelineno-0-17">17</a></span>
<span class="normal"><a href="#__codelineno-0-18">18</a></span>
<span class="normal"><a href="#__codelineno-0-19">19</a></span>
<span class="normal"><a href="#__codelineno-0-20">20</a></span>
<span class="normal"><a href="#__codelineno-0-21">21</a></span>
<span class="normal"><a href="#__codelineno-0-22">22</a></span>
<span class="normal"><a href="#__codelineno-0-23">23</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="k">class</span> <span class="nc">Generator</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a>        <span class="nb">super</span><span class="p">(</span><span class="n">Generator</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a>        <span class="k">def</span> <span class="nf">block</span><span class="p">(</span><span class="n">in_feat</span><span class="p">,</span> <span class="n">out_feat</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a>            <span class="n">layers</span> <span class="o">=</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_feat</span><span class="p">,</span> <span class="n">out_feat</span><span class="p">)]</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a>            <span class="k">if</span> <span class="n">normalize</span><span class="p">:</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a>                <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">out_feat</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">))</span>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a>            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a>            <span class="k">return</span> <span class="n">layers</span>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a>
<a id="__codelineno-0-12" name="__codelineno-0-12"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
<a id="__codelineno-0-13" name="__codelineno-0-13"></a>            <span class="o">*</span><span class="n">block</span><span class="p">(</span><span class="n">opt</span><span class="o">.</span><span class="n">latent_dim</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
<a id="__codelineno-0-14" name="__codelineno-0-14"></a>            <span class="o">*</span><span class="n">block</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span>
<a id="__codelineno-0-15" name="__codelineno-0-15"></a>            <span class="o">*</span><span class="n">block</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">512</span><span class="p">),</span>
<a id="__codelineno-0-16" name="__codelineno-0-16"></a>            <span class="o">*</span><span class="n">block</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">1024</span><span class="p">),</span>
<a id="__codelineno-0-17" name="__codelineno-0-17"></a>            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">img_shape</span><span class="p">))),</span>
<a id="__codelineno-0-18" name="__codelineno-0-18"></a>            <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">()</span>
<a id="__codelineno-0-19" name="__codelineno-0-19"></a>        <span class="p">)</span>
<a id="__codelineno-0-20" name="__codelineno-0-20"></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
<a id="__codelineno-0-21" name="__codelineno-0-21"></a>        <span class="n">img</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
<a id="__codelineno-0-22" name="__codelineno-0-22"></a>        <span class="n">img</span> <span class="o">=</span> <span class="n">img</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">*</span><span class="n">img_shape</span><span class="p">)</span>
<a id="__codelineno-0-23" name="__codelineno-0-23"></a>        <span class="k">return</span> <span class="n">img</span>
</code></pre></div></td></tr></table></div>
<p><div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-1-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-1-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-1-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-1-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-1-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-1-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-1-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-1-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-1-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-1-10">10</a></span>
<span class="normal"><a href="#__codelineno-1-11">11</a></span>
<span class="normal"><a href="#__codelineno-1-12">12</a></span>
<span class="normal"><a href="#__codelineno-1-13">13</a></span>
<span class="normal"><a href="#__codelineno-1-14">14</a></span>
<span class="normal"><a href="#__codelineno-1-15">15</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-1-1" name="__codelineno-1-1"></a><span class="k">class</span> <span class="nc">Discriminator</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<a id="__codelineno-1-2" name="__codelineno-1-2"></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<a id="__codelineno-1-3" name="__codelineno-1-3"></a>        <span class="nb">super</span><span class="p">(</span><span class="n">Discriminator</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-1-4" name="__codelineno-1-4"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
<a id="__codelineno-1-5" name="__codelineno-1-5"></a>            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">img_shape</span><span class="p">)),</span> <span class="mi">512</span><span class="p">),</span>
<a id="__codelineno-1-6" name="__codelineno-1-6"></a>            <span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<a id="__codelineno-1-7" name="__codelineno-1-7"></a>            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span>
<a id="__codelineno-1-8" name="__codelineno-1-8"></a>            <span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<a id="__codelineno-1-9" name="__codelineno-1-9"></a>            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
<a id="__codelineno-1-10" name="__codelineno-1-10"></a>            <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">(),</span>
<a id="__codelineno-1-11" name="__codelineno-1-11"></a>        <span class="p">)</span>
<a id="__codelineno-1-12" name="__codelineno-1-12"></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
<a id="__codelineno-1-13" name="__codelineno-1-13"></a>        <span class="n">img_flat</span> <span class="o">=</span> <span class="n">img</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-1-14" name="__codelineno-1-14"></a>        <span class="n">validity</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">img_flat</span><span class="p">)</span>
<a id="__codelineno-1-15" name="__codelineno-1-15"></a>        <span class="k">return</span> <span class="n">validity</span>
</code></pre></div></td></tr></table></div>
<strong>Training process and images generated:</strong></p>
<p><a class="glightbox" href="https://hackmd.io/_uploads/HJX7I4jDyl.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="image" src="https://hackmd.io/_uploads/HJX7I4jDyl.png" /></a>
<em>Image Source: Goodfellow et al., "Generative Adversarial Networks" (2014) arXiv:1406.2661</em></p>
<ul>
<li>Real data distribution <span class="arithmatex">\(p_{data}\)</span>(Black dotted line)</li>
<li>Generator distribution <span class="arithmatex">\(p_g\)</span>(Green solid line )</li>
<li>Discriminator output <span class="arithmatex">\(D\)</span>(Blue dashed line)</li>
<li>Noise space where <span class="arithmatex">\(z\)</span> is sampled (Lower horizontal line)</li>
<li>Data space <span class="arithmatex">\(x\)</span>(Upper horizontal line)</li>
<li>Generator G's mapping from  <span class="arithmatex">\(z\)</span> to  <span class="arithmatex">\(x\)</span> (Arrows connecting lines)</li>
</ul>
<p>From the picture, we can see the training Evolution (from a to d):</p>
<ul>
<li>
<p>Initial Stage:</p>
</li>
<li>
<p>The generated distribution  <span class="arithmatex">\(p_g\)</span> (green) differs significantly from the real distribution <span class="arithmatex">\(p_{data}\)</span> (black)</p>
</li>
<li>
<p>Discriminator <span class="arithmatex">\(D\)</span>  (blue) attempts to distinguish samples, but performs unstably</p>
</li>
<li>
<p>Discriminator Training: <span class="arithmatex">\(D\)</span> is trained to reach optimal solution: <span class="arithmatex">\(D^*(x) = \frac{p_{data}(x)}{p_{data}(x) + p_g(x)}\)</span></p>
</li>
<li>
<p>Generator Update:  <span class="arithmatex">\(G\)</span> updates based on gradients from <span class="arithmatex">\(D\)</span></p>
</li>
<li>
<p>Final Convergence: When <span class="arithmatex">\(G\)</span> and <span class="arithmatex">\(D\)</span> have sufficient capacity（ <span class="arithmatex">\(p_{data} =p_g\)</span>), they reach Nash equilibrium</p>
</li>
</ul>
<p><a class="glightbox" href="https://hackmd.io/_uploads/HJn4UVswye.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="image" src="https://hackmd.io/_uploads/HJn4UVswye.png" /></a>
<em>Image Source: Goodfellow et al., "Generative Adversarial Networks" (2014) arXiv:1406.2661</em></p>
<h1 id="2-2014cgan-conditional-generative-adversarial-nets">2. [2014]<a href="https://arxiv.org/abs/1411.1784">cGAN: Conditional Generative Adversarial Nets</a><a class="headerlink" href="#2-2014cgan-conditional-generative-adversarial-nets" title="Permanent link">&para;</a></h1>
<h2 id="21-overall-introduction">2.1 Overall Introduction:<a class="headerlink" href="#21-overall-introduction" title="Permanent link">&para;</a></h2>
<p>Conditional generation
Traditional GANs produce samples from random noise but <strong>can't control the output features</strong>, as they are <strong>unsupervised learning</strong>.</p>
<p>While conditional GANs (cGANs) <strong>incorporate conditional information into both the generator and discriminator, enabling control over the output properties</strong>. This is achieved through a semi-supervised approach.</p>
<p>The cGAN paper only shows its generated results on the MNIST dataset, where simply concatenating label embeddings might have limited impact. However, the core idea of "guiding the generation process with conditional information" proposed by cGAN has significantly influenced subsequent generative models. </p>
<ul>
<li>For example, models like DALL-E and Stable Diffusion, although utilizing different architectures like Diffusion, have adopted the principle of conditional generation: they use text embeddings as conditional information to control image generation.</li>
</ul>
<h2 id="22-base-model-structure">2.2 Base model structure<a class="headerlink" href="#22-base-model-structure" title="Permanent link">&para;</a></h2>
<p><a class="glightbox" href="https://hackmd.io/_uploads/Hy6cONjwkx.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="image" src="https://hackmd.io/_uploads/Hy6cONjwkx.png" /></a>
<em>Source: Mirza et al., "Conditional Generative Adversarial Nets" (2014) arXiv:1411.1784</em></p>
<p>How to combine the condition into input:</p>
<ul>
<li>
<p>First convert categorical labels into continuous vector representations using nn.Embedding</p>
</li>
<li>
<p><code>self.label_emb = nn.Embedding(opt.n_classes, opt.n_classes)</code></p>
</li>
<li>
<p>Then concatenates torch.cat label embeddings(y) with noise vectors(z) along dimension -1: </p>
</li>
<li>
<p><code>gen_input = torch.cat((self.label_emb(labels), noise), -1)</code></p>
</li>
<li>
<p>Uses this concatenated vector as input to generate images through multiple network layers</p>
</li>
</ul>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-2-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-2-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-2-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-2-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-2-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-2-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-2-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-2-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-2-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-2-10">10</a></span>
<span class="normal"><a href="#__codelineno-2-11">11</a></span>
<span class="normal"><a href="#__codelineno-2-12">12</a></span>
<span class="normal"><a href="#__codelineno-2-13">13</a></span>
<span class="normal"><a href="#__codelineno-2-14">14</a></span>
<span class="normal"><a href="#__codelineno-2-15">15</a></span>
<span class="normal"><a href="#__codelineno-2-16">16</a></span>
<span class="normal"><a href="#__codelineno-2-17">17</a></span>
<span class="normal"><a href="#__codelineno-2-18">18</a></span>
<span class="normal"><a href="#__codelineno-2-19">19</a></span>
<span class="normal"><a href="#__codelineno-2-20">20</a></span>
<span class="normal"><a href="#__codelineno-2-21">21</a></span>
<span class="normal"><a href="#__codelineno-2-22">22</a></span>
<span class="normal"><a href="#__codelineno-2-23">23</a></span>
<span class="normal"><a href="#__codelineno-2-24">24</a></span>
<span class="normal"><a href="#__codelineno-2-25">25</a></span>
<span class="normal"><a href="#__codelineno-2-26">26</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-2-1" name="__codelineno-2-1"></a><span class="k">class</span> <span class="nc">Generator</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<a id="__codelineno-2-2" name="__codelineno-2-2"></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<a id="__codelineno-2-3" name="__codelineno-2-3"></a>        <span class="nb">super</span><span class="p">(</span><span class="n">Generator</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-2-4" name="__codelineno-2-4"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">label_emb</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">opt</span><span class="o">.</span><span class="n">n_classes</span><span class="p">,</span> <span class="n">opt</span><span class="o">.</span><span class="n">n_classes</span><span class="p">)</span>
<a id="__codelineno-2-5" name="__codelineno-2-5"></a>        <span class="k">def</span> <span class="nf">block</span><span class="p">(</span><span class="n">in_feat</span><span class="p">,</span> <span class="n">out_feat</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<a id="__codelineno-2-6" name="__codelineno-2-6"></a>            <span class="n">layers</span> <span class="o">=</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_feat</span><span class="p">,</span> <span class="n">out_feat</span><span class="p">)]</span>
<a id="__codelineno-2-7" name="__codelineno-2-7"></a>            <span class="k">if</span> <span class="n">normalize</span><span class="p">:</span>
<a id="__codelineno-2-8" name="__codelineno-2-8"></a>                <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">out_feat</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">))</span>
<a id="__codelineno-2-9" name="__codelineno-2-9"></a>            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
<a id="__codelineno-2-10" name="__codelineno-2-10"></a>            <span class="k">return</span> <span class="n">layers</span>
<a id="__codelineno-2-11" name="__codelineno-2-11"></a>
<a id="__codelineno-2-12" name="__codelineno-2-12"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
<a id="__codelineno-2-13" name="__codelineno-2-13"></a>            <span class="o">*</span><span class="n">block</span><span class="p">(</span><span class="n">opt</span><span class="o">.</span><span class="n">latent_dim</span> <span class="o">+</span> <span class="n">opt</span><span class="o">.</span><span class="n">n_classes</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
<a id="__codelineno-2-14" name="__codelineno-2-14"></a>            <span class="o">*</span><span class="n">block</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span>
<a id="__codelineno-2-15" name="__codelineno-2-15"></a>            <span class="o">*</span><span class="n">block</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">512</span><span class="p">),</span>
<a id="__codelineno-2-16" name="__codelineno-2-16"></a>            <span class="o">*</span><span class="n">block</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">1024</span><span class="p">),</span>
<a id="__codelineno-2-17" name="__codelineno-2-17"></a>            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">img_shape</span><span class="p">))),</span>
<a id="__codelineno-2-18" name="__codelineno-2-18"></a>            <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">()</span>
<a id="__codelineno-2-19" name="__codelineno-2-19"></a>        <span class="p">)</span>
<a id="__codelineno-2-20" name="__codelineno-2-20"></a>
<a id="__codelineno-2-21" name="__codelineno-2-21"></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">noise</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
<a id="__codelineno-2-22" name="__codelineno-2-22"></a>        <span class="c1"># Concatenate label embedding and image to produce input</span>
<a id="__codelineno-2-23" name="__codelineno-2-23"></a>        <span class="n">gen_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">label_emb</span><span class="p">(</span><span class="n">labels</span><span class="p">),</span> <span class="n">noise</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-2-24" name="__codelineno-2-24"></a>        <span class="n">img</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">gen_input</span><span class="p">)</span>
<a id="__codelineno-2-25" name="__codelineno-2-25"></a>        <span class="n">img</span> <span class="o">=</span> <span class="n">img</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">*</span><span class="n">img_shape</span><span class="p">)</span>
<a id="__codelineno-2-26" name="__codelineno-2-26"></a>        <span class="k">return</span> <span class="n">img</span>
</code></pre></div></td></tr></table></div>
<p>IN Discriminator:</p>
<ul>
<li>
<p>Flattens input images: </p>
<ul>
<li><code>img.view(img.size(0), -1)</code></li>
</ul>
</li>
<li>
<p>Similarly, processes labels through embedding: <code>self.label_embedding(labels)</code></p>
</li>
<li>
<p>Concatenates flattened images and label embeddings:</p>
<ul>
<li><code>d_in = torch.cat((img.view(img.size(0), -1), self.label_embedding(labels)), -1)</code></li>
</ul>
</li>
<li>
<p>Passes concatenated vector through discriminator network for real/fake classification</p>
</li>
</ul>
<p><div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-3-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-3-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-3-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-3-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-3-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-3-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-3-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-3-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-3-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-3-10">10</a></span>
<span class="normal"><a href="#__codelineno-3-11">11</a></span>
<span class="normal"><a href="#__codelineno-3-12">12</a></span>
<span class="normal"><a href="#__codelineno-3-13">13</a></span>
<span class="normal"><a href="#__codelineno-3-14">14</a></span>
<span class="normal"><a href="#__codelineno-3-15">15</a></span>
<span class="normal"><a href="#__codelineno-3-16">16</a></span>
<span class="normal"><a href="#__codelineno-3-17">17</a></span>
<span class="normal"><a href="#__codelineno-3-18">18</a></span>
<span class="normal"><a href="#__codelineno-3-19">19</a></span>
<span class="normal"><a href="#__codelineno-3-20">20</a></span>
<span class="normal"><a href="#__codelineno-3-21">21</a></span>
<span class="normal"><a href="#__codelineno-3-22">22</a></span>
<span class="normal"><a href="#__codelineno-3-23">23</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-3-1" name="__codelineno-3-1"></a><span class="k">class</span> <span class="nc">Discriminator</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<a id="__codelineno-3-2" name="__codelineno-3-2"></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<a id="__codelineno-3-3" name="__codelineno-3-3"></a>        <span class="nb">super</span><span class="p">(</span><span class="n">Discriminator</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-3-4" name="__codelineno-3-4"></a>
<a id="__codelineno-3-5" name="__codelineno-3-5"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">label_embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">opt</span><span class="o">.</span><span class="n">n_classes</span><span class="p">,</span> <span class="n">opt</span><span class="o">.</span><span class="n">n_classes</span><span class="p">)</span>
<a id="__codelineno-3-6" name="__codelineno-3-6"></a>
<a id="__codelineno-3-7" name="__codelineno-3-7"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
<a id="__codelineno-3-8" name="__codelineno-3-8"></a>            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">opt</span><span class="o">.</span><span class="n">n_classes</span> <span class="o">+</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">img_shape</span><span class="p">)),</span> <span class="mi">512</span><span class="p">),</span>
<a id="__codelineno-3-9" name="__codelineno-3-9"></a>            <span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<a id="__codelineno-3-10" name="__codelineno-3-10"></a>            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">),</span>
<a id="__codelineno-3-11" name="__codelineno-3-11"></a>            <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.4</span><span class="p">),</span>
<a id="__codelineno-3-12" name="__codelineno-3-12"></a>            <span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<a id="__codelineno-3-13" name="__codelineno-3-13"></a>            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">),</span>
<a id="__codelineno-3-14" name="__codelineno-3-14"></a>            <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.4</span><span class="p">),</span>
<a id="__codelineno-3-15" name="__codelineno-3-15"></a>            <span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<a id="__codelineno-3-16" name="__codelineno-3-16"></a>            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
<a id="__codelineno-3-17" name="__codelineno-3-17"></a>        <span class="p">)</span>
<a id="__codelineno-3-18" name="__codelineno-3-18"></a>
<a id="__codelineno-3-19" name="__codelineno-3-19"></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
<a id="__codelineno-3-20" name="__codelineno-3-20"></a>        <span class="c1"># Concatenate label embedding and image to produce input</span>
<a id="__codelineno-3-21" name="__codelineno-3-21"></a>        <span class="n">d_in</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">img</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">label_embedding</span><span class="p">(</span><span class="n">labels</span><span class="p">)),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-3-22" name="__codelineno-3-22"></a>        <span class="n">validity</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">d_in</span><span class="p">)</span>
<a id="__codelineno-3-23" name="__codelineno-3-23"></a>        <span class="k">return</span> <span class="n">validity</span>
</code></pre></div></td></tr></table></div>
Actually, it's still a Binary Classification Task. The output of cGAN discriminator still maintains GAN's binary output (real/fake). </p>
<ul>
<li>Doesn't explicitly verify condition-image matching</li>
<li>Output is a single scalar through Sigmoid/BCELoss or MSELoss</li>
</ul>
<p>For example, an input condition: number "7". If the generator generates an image that looks like "3". Although the discriminator will not directly point out "this is not 7", because the label of "7" in the training data has never been paired with the image of "3". So this wrong match will be identified as "generated" by the discriminator.</p>
<h2 id="23-loss-function">2.3 Loss function<a class="headerlink" href="#23-loss-function" title="Permanent link">&para;</a></h2>
<div class="arithmatex">\[\min_{G} \max_{D} V(D,G) = \mathbb{E}_{x \sim p_{data}(x)}[\log D(x|y)] + \mathbb{E}_{z \sim p_z(z)}[\log(1 - D(G(z|y)))]\]</div>
<p>Where: <span class="arithmatex">\(\mathbb{E}\)</span>: Expected value (expectation) <span class="arithmatex">\(\mathbb{E}_{x \sim p_{data}(x)}[\log D(x|y)]\)</span> : </p>
<ul>
<li>
<p><span class="arithmatex">\(x \sim p_{data(x)}\)</span>:  <span class="arithmatex">\(x\)</span>sampled from real data distribution</p>
</li>
<li>
<p><span class="arithmatex">\(D(x|y)\)</span>: Discriminator's output for real data  <span class="arithmatex">\(x\)</span> given condition  <span class="arithmatex">\(y\)</span></p>
</li>
<li>
<p><span class="arithmatex">\(E[\log D(x|y)]\)</span> - Discriminator's ability to identify real samples</p>
</li>
</ul>
<p><span class="arithmatex">\(\mathbb{E}_{z \sim p_z(z)}[\log(1 - D(G(z|y)))]\)</span> : </p>
<ul>
<li>
<p><span class="arithmatex">\(z \sim p_z(z)\)</span> z sampled from noise distribution</p>
</li>
<li>
<p><span class="arithmatex">\(G(z|y)\)</span>: Generator's output from noise z given condition y</p>
</li>
<li>
<p><span class="arithmatex">\(E[log(1 - D(G(z|y)))]\)</span> - Discriminator's ability to identify fake samples</p>
</li>
</ul>
<p><div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-4-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-4-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-4-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-4-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-4-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-4-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-4-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-4-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-4-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-4-10">10</a></span>
<span class="normal"><a href="#__codelineno-4-11">11</a></span>
<span class="normal"><a href="#__codelineno-4-12">12</a></span>
<span class="normal"><a href="#__codelineno-4-13">13</a></span>
<span class="normal"><a href="#__codelineno-4-14">14</a></span>
<span class="normal"><a href="#__codelineno-4-15">15</a></span>
<span class="normal"><a href="#__codelineno-4-16">16</a></span>
<span class="normal"><a href="#__codelineno-4-17">17</a></span>
<span class="normal"><a href="#__codelineno-4-18">18</a></span>
<span class="normal"><a href="#__codelineno-4-19">19</a></span>
<span class="normal"><a href="#__codelineno-4-20">20</a></span>
<span class="normal"><a href="#__codelineno-4-21">21</a></span>
<span class="normal"><a href="#__codelineno-4-22">22</a></span>
<span class="normal"><a href="#__codelineno-4-23">23</a></span>
<span class="normal"><a href="#__codelineno-4-24">24</a></span>
<span class="normal"><a href="#__codelineno-4-25">25</a></span>
<span class="normal"><a href="#__codelineno-4-26">26</a></span>
<span class="normal"><a href="#__codelineno-4-27">27</a></span>
<span class="normal"><a href="#__codelineno-4-28">28</a></span>
<span class="normal"><a href="#__codelineno-4-29">29</a></span>
<span class="normal"><a href="#__codelineno-4-30">30</a></span>
<span class="normal"><a href="#__codelineno-4-31">31</a></span>
<span class="normal"><a href="#__codelineno-4-32">32</a></span>
<span class="normal"><a href="#__codelineno-4-33">33</a></span>
<span class="normal"><a href="#__codelineno-4-34">34</a></span>
<span class="normal"><a href="#__codelineno-4-35">35</a></span>
<span class="normal"><a href="#__codelineno-4-36">36</a></span>
<span class="normal"><a href="#__codelineno-4-37">37</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-4-1" name="__codelineno-4-1"></a><span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">opt</span><span class="o">.</span><span class="n">n_epochs</span><span class="p">):</span>
<a id="__codelineno-4-2" name="__codelineno-4-2"></a>    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">imgs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">):</span>
<a id="__codelineno-4-3" name="__codelineno-4-3"></a>        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">imgs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<a id="__codelineno-4-4" name="__codelineno-4-4"></a>        <span class="c1"># Adversarial ground truths</span>
<a id="__codelineno-4-5" name="__codelineno-4-5"></a>        <span class="n">valid</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="mf">1.0</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<a id="__codelineno-4-6" name="__codelineno-4-6"></a>        <span class="n">fake</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="mf">0.0</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<a id="__codelineno-4-7" name="__codelineno-4-7"></a>        <span class="c1"># Configure input</span>
<a id="__codelineno-4-8" name="__codelineno-4-8"></a>        <span class="n">real_imgs</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">imgs</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">FloatTensor</span><span class="p">))</span>
<a id="__codelineno-4-9" name="__codelineno-4-9"></a>        <span class="n">labels</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">LongTensor</span><span class="p">))</span>
<a id="__codelineno-4-10" name="__codelineno-4-10"></a>        <span class="c1"># -----------------</span>
<a id="__codelineno-4-11" name="__codelineno-4-11"></a>        <span class="c1">#  Train Generator</span>
<a id="__codelineno-4-12" name="__codelineno-4-12"></a>        <span class="c1"># -----------------</span>
<a id="__codelineno-4-13" name="__codelineno-4-13"></a>        <span class="n">optimizer_G</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
<a id="__codelineno-4-14" name="__codelineno-4-14"></a>        <span class="c1"># Sample noise and labels as generator input</span>
<a id="__codelineno-4-15" name="__codelineno-4-15"></a>        <span class="n">z</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">opt</span><span class="o">.</span><span class="n">latent_dim</span><span class="p">))))</span>
<a id="__codelineno-4-16" name="__codelineno-4-16"></a>        <span class="n">gen_labels</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">opt</span><span class="o">.</span><span class="n">n_classes</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)))</span>
<a id="__codelineno-4-17" name="__codelineno-4-17"></a>        <span class="c1"># Generate a batch of images</span>
<a id="__codelineno-4-18" name="__codelineno-4-18"></a>        <span class="n">gen_imgs</span> <span class="o">=</span> <span class="n">generator</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">gen_labels</span><span class="p">)</span>
<a id="__codelineno-4-19" name="__codelineno-4-19"></a>        <span class="c1"># Loss measures generator&#39;s ability to fool the discriminator</span>
<a id="__codelineno-4-20" name="__codelineno-4-20"></a>        <span class="n">validity</span> <span class="o">=</span> <span class="n">discriminator</span><span class="p">(</span><span class="n">gen_imgs</span><span class="p">,</span> <span class="n">gen_labels</span><span class="p">)</span>
<a id="__codelineno-4-21" name="__codelineno-4-21"></a>        <span class="n">g_loss</span> <span class="o">=</span> <span class="n">adversarial_loss</span><span class="p">(</span><span class="n">validity</span><span class="p">,</span> <span class="n">valid</span><span class="p">)</span>
<a id="__codelineno-4-22" name="__codelineno-4-22"></a>        <span class="n">g_loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<a id="__codelineno-4-23" name="__codelineno-4-23"></a>        <span class="n">optimizer_G</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
<a id="__codelineno-4-24" name="__codelineno-4-24"></a>        <span class="c1"># ---------------------</span>
<a id="__codelineno-4-25" name="__codelineno-4-25"></a>        <span class="c1">#  Train Discriminator</span>
<a id="__codelineno-4-26" name="__codelineno-4-26"></a>        <span class="c1"># ---------------------</span>
<a id="__codelineno-4-27" name="__codelineno-4-27"></a>        <span class="n">optimizer_D</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
<a id="__codelineno-4-28" name="__codelineno-4-28"></a>        <span class="c1"># Loss for real images</span>
<a id="__codelineno-4-29" name="__codelineno-4-29"></a>        <span class="n">validity_real</span> <span class="o">=</span> <span class="n">discriminator</span><span class="p">(</span><span class="n">real_imgs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
<a id="__codelineno-4-30" name="__codelineno-4-30"></a>        <span class="n">d_real_loss</span> <span class="o">=</span> <span class="n">adversarial_loss</span><span class="p">(</span><span class="n">validity_real</span><span class="p">,</span> <span class="n">valid</span><span class="p">)</span>
<a id="__codelineno-4-31" name="__codelineno-4-31"></a>        <span class="c1"># Loss for fake images</span>
<a id="__codelineno-4-32" name="__codelineno-4-32"></a>        <span class="n">validity_fake</span> <span class="o">=</span> <span class="n">discriminator</span><span class="p">(</span><span class="n">gen_imgs</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span> <span class="n">gen_labels</span><span class="p">)</span>
<a id="__codelineno-4-33" name="__codelineno-4-33"></a>        <span class="n">d_fake_loss</span> <span class="o">=</span> <span class="n">adversarial_loss</span><span class="p">(</span><span class="n">validity_fake</span><span class="p">,</span> <span class="n">fake</span><span class="p">)</span>
<a id="__codelineno-4-34" name="__codelineno-4-34"></a>        <span class="c1"># Total discriminator loss</span>
<a id="__codelineno-4-35" name="__codelineno-4-35"></a>        <span class="n">d_loss</span> <span class="o">=</span> <span class="p">(</span><span class="n">d_real_loss</span> <span class="o">+</span> <span class="n">d_fake_loss</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
<a id="__codelineno-4-36" name="__codelineno-4-36"></a>        <span class="n">d_loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<a id="__codelineno-4-37" name="__codelineno-4-37"></a>        <span class="n">optimizer_D</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
<a class="glightbox" href="https://hackmd.io/_uploads/SJkkKEjvkl.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="image" src="https://hackmd.io/_uploads/SJkkKEjvkl.png" /></a>
<em>Source: Mirza et al., "Conditional Generative Adversarial Nets" (2014) arXiv:1411.1784</em></p>
<hr />
<h1 id="3-2015dcgandeep-convolutional-ganunsupervised-representation-learning-with-deep-convolutional-generative-adversarial-networks">3. [2015]DCGAN(Deep Convolutional GAN）：<a href="https://arxiv.org/abs/1511.06434">Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks</a><a class="headerlink" href="#3-2015dcgandeep-convolutional-ganunsupervised-representation-learning-with-deep-convolutional-generative-adversarial-networks" title="Permanent link">&para;</a></h1>
<h2 id="31-overall-introduction-deep-convolutional-gan">3.1 Overall Introduction:  Deep Convolutional GAN<a class="headerlink" href="#31-overall-introduction-deep-convolutional-gan" title="Permanent link">&para;</a></h2>
<p>DCGAN integrates the strengths of Convolutional Neural Networks into GANs with key innovations:</p>
<ol>
<li>
<p>Convolutional Layers: Transposed convolutions in the generator and strided convolutions in the discriminator enhance spatial information retention.</p>
</li>
<li>
<p>Batch Normalization: Used extensively in both parts to improve stability and prevent mode collapse.</p>
</li>
<li>
<p>Activation Functions: The generator uses ReLU with a Tanh final layer, and the discriminator employs LeakyReLU.</p>
</li>
<li>
<p>Starts from 100-dimensional noise z, gradually generating <span class="arithmatex">\(64×64\)</span> images through multiple convolution layers</p>
</li>
<li>
<p>Feature map progression(C<em>H</em>W): </p>
</li>
<li>
<p><span class="arithmatex">\(100\times1\times1\)</span>-&gt;<span class="arithmatex">\(1024\times4\times4\)</span> -&gt; <span class="arithmatex">\(512\times8\times8\)</span>-&gt;<span class="arithmatex">\(256\times16\times16\)</span>-&gt;<span class="arithmatex">\(128\times32\times32\)</span>-&gt;<span class="arithmatex">\(3\times64\times64\)</span></p>
</li>
</ol>
<h2 id="32-base-model-structure">3.2 Base model structure<a class="headerlink" href="#32-base-model-structure" title="Permanent link">&para;</a></h2>
<p><a class="glightbox" href="https://hackmd.io/_uploads/SytbYEsPkl.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="image" src="https://hackmd.io/_uploads/SytbYEsPkl.png" /></a>
<em>Source: Radford et al., "Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks" (2016) arXiv:1511.06434</em></p>
<p>About Transposed convolutions:</p>
<ul>
<li>
<p>Input Matrix Expansion: Initially, the input feature map undergoes an expansion by inserting zeros between each element. The number of zeros inserted depends on the stride parameter. </p>
</li>
<li>
<p>Application of the Convolution Kernel: Next, the convolution kernel is applied to the expanded feature map. This process is similar to traditional convolution operations, where the kernel slides over the expanded feature map, computing the dot product with local regions. Unlike regular convolution, this operation results in a larger output feature map because the input has been expanded.</p>
</li>
<li>
<p>Adjustment of Output Size: Finally, the output feature map might be cropped or padded to adjust its dimensions to the desired size. This adjustment depends on the padding parameter, which can either reduce or increase the spatial dimensions of the output</p>
</li>
</ul>
<h2 id="33-loss-function">3.3 Loss function<a class="headerlink" href="#33-loss-function" title="Permanent link">&para;</a></h2>
<p>Same as GAN objective : <span class="arithmatex">\(\min_G \max_D V(D,G) = \mathbb{E}_{x\sim p_{data}}[\log D(x)] + \mathbb{E}_{z\sim p_z}[\log(1-D(G(z)))]\)</span></p>
<hr />
<h1 id="4-2017-wgan-wasserstein-gan">4. [2017] WGAN:<a href="https://arxiv.org/abs/1701.07875"> Wasserstein GAN</a><a class="headerlink" href="#4-2017-wgan-wasserstein-gan" title="Permanent link">&para;</a></h1>
<h2 id="41-overall-introduction">4.1 Overall Introduction:<a class="headerlink" href="#41-overall-introduction" title="Permanent link">&para;</a></h2>
<p>WGAN introduces Wasserstein distance and Lipschitz constraint  in loss function to "improve the stability of learning, get rid of problems like mode collapse, and provide meaningful learning curves useful for debugging and hyperparameter searches". WGAN replaces the JSD with the Wasserstein distance to measure the distribution distance in the original GAN.</p>
<ul>
<li>
<p>If the discriminator is trained too well, the generator's gradients vanish, and the generator's loss cannot decrease </p>
</li>
<li>
<p>If the discriminator is not trained well enough, the generator's gradients become inaccurate, causing it to move erratically. </p>
</li>
</ul>
<p>The discriminator needs to be trained to just the right degree - neither too well nor too poorly - but this balance is very difficult to achieve. Moreover, this optimal balance might even vary at different stages within the same training epoch, which is why GANs are so difficult to train.</p>
<h2 id="42-drawbacks-as-jsd">4.2 Drawbacks as JSD：<a class="headerlink" href="#42-drawbacks-as-jsd" title="Permanent link">&para;</a></h2>
<h3 id="421-gradient-vanishing-problem-training-instability">4.2.1 Gradient Vanishing Problem &amp; training instability<a class="headerlink" href="#421-gradient-vanishing-problem-training-instability" title="Permanent link">&para;</a></h3>
<p>We have introduced above, under an (approximately) optimal discriminator, minimizing the generator's loss is equivalent to minimizing the JS divergence between <span class="arithmatex">\(P_r\)</span> and <span class="arithmatex">\(P_g\)</span>. Since <span class="arithmatex">\(P_r\)</span> and <span class="arithmatex">\(P_g\)</span> almost inevitably have negligible overlap, their JS divergence will always be the constant <span class="arithmatex">\(\log 2\)</span>, regardless of how far apart they are. This ultimately leads to the generator's gradient (approximately) becoming 0, resulting in gradient vanishing.
<a class="glightbox" href="https://hackmd.io/_uploads/SyN95VovJl.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="image" src="https://hackmd.io/_uploads/SyN95VovJl.png" /></a>
<em>Source: Arjovsky et al., "Wasserstein GAN" (2017) arXiv:1701.07875</em></p>
<h3 id="422-model-collapse">4.2.2 Model collapse<a class="headerlink" href="#422-model-collapse" title="Permanent link">&para;</a></h3>
<p>Secondly, even the previously mentioned standard KL divergence term has flaws. Because KL divergence is not a symmetric measure, <span class="arithmatex">\(KL(P_g\|P_r)\)</span> and <span class="arithmatex">\(KL(P_r\|P_g)\)</span> are different. 
Taking the former as an example: <span class="arithmatex">\(KL(P_g||P_r) = \int_x P_g(x)\log(\frac{P_g(x)}{P_r(x)})dx\)</span></p>
<ul>
<li>
<p>When <span class="arithmatex">\(P_g(x) \to 0\)</span> and <span class="arithmatex">\(P_{r}(x) \to 1\)</span>, <span class="arithmatex">\(P_g(x)\log\frac{P_g(x)}{P_{r}(x)} \to 0\)</span>, contributing nearly 0 to <span class="arithmatex">\(KL(P_g||P_r)\)</span></p>
</li>
<li>
<p>When <span class="arithmatex">\(P_g(x) \to 1\)</span> and <span class="arithmatex">\(P_{r}(x) \to 0\)</span>, <span class="arithmatex">\(P_g(x)\log\frac{P_g(x)}{P_{r}(x)} \to +\infty\)</span>, contributing positively infinite to <span class="arithmatex">\(KL(P_g||P_r)\)</span></p>
</li>
<li>
<p>In other words, <span class="arithmatex">\(KL(P_g||P_r)\)</span> penalizes these two types of errors differently. </p>
</li>
<li>
<p>The first type of error corresponds to <strong>"generator failing to generate real samples"</strong> with small penalty.</p>
</li>
<li>
<p>The second type corresponds to <strong>"generator generating unrealistic samples"</strong> with large penalty. </p>
</li>
</ul>
<p>The first type of error represents a lack of diversity, while the second type represents a lack of accuracy. As a result, the generator would rather generate some repetitive but "safe" samples, and is reluctant to generate diverse samples, because one small mistake could lead to the second type of error, resulting in an unacceptable loss. This phenomenon is commonly referred to as mode collapse.</p>
<p><a class="glightbox" href="https://hackmd.io/_uploads/SJAaYViwJg.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="image" src="https://hackmd.io/_uploads/SJAaYViwJg.png" /></a>
<em>Source: Arjovsky et al., "Wasserstein GAN" (2017) arXiv:1701.07875</em></p>
<p>Why Wasserstein distance?</p>
<p>The superiority of the Wasserstein distance compared to KL divergence and JS divergence lies in its ability to reflect the proximity between two distributions even when they don't overlap. While KL divergence and JS divergence are discontinuous , being either maximum or minimum. The Wasserstein distance is smooth and offers a more natural way to measure distances between distributions.</p>
<ol>
<li>
<p>Training Stability: Provides meaningful gradients even when distributions do not overlap, significantly improving the stability of GAN training.</p>
</li>
<li>
<p>Reduced Mode Collapse: Encourages diversity in generated samples by considering the overall differences between distributions, reducing mode collapse.</p>
</li>
<li>
<p>Intuitive Loss Function: Serves as a loss metric, where a smaller Wasserstein distance indicates closer alignment with the target distribution's statistical properties.</p>
</li>
<li>
<p>Effective GAN Training: WGANs use Wasserstein distance to offer a more stable and effective training process, enhancing the quality and diversity of generated samples.</p>
</li>
</ol>
<h2 id="43-loss-function">4.3 Loss function<a class="headerlink" href="#43-loss-function" title="Permanent link">&para;</a></h2>
<ol>
<li>About Wasserstein Distance (measure distance by estimating the difference between expectation):</li>
<li>Mathematical Definition ：<span class="arithmatex">\(W(P,Q) = \inf_{\gamma \in \Pi(P,Q)} \mathbb{E}_{(x,y)\sim \gamma}[||x-y||]\)</span><ul>
<li><span class="arithmatex">\(\Pi(P_r, P_g)\)</span> is the set of all possible joint distributions whose marginal distributions are <span class="arithmatex">\(P_r\)</span> and <span class="arithmatex">\(P_g\)</span>. </li>
<li>In other words, for each distribution in <span class="arithmatex">\(\Pi(P_r, P_g)\)</span>, its marginal distributions are <span class="arithmatex">\(P_r\)</span> and <span class="arithmatex">\(P_g\)</span>. </li>
<li>For each possible joint distribution <span class="arithmatex">\(\gamma\)</span>,sample <span class="arithmatex">\((x,y) \sim \gamma\)</span> to get a real sample <span class="arithmatex">\(x\)</span> and a generated sample <span class="arithmatex">\(y\)</span>, and calculate the distance between these samples <span class="arithmatex">\(\|x-y\|\)</span>. </li>
<li><span class="arithmatex">\(\mathbb{E}_{(x,y)\sim\gamma}[\|x-y\|]\)</span>calculates the expected value of the sample distance under this joint distribution. The infimum of this expected value among all possible joint distributions <span class="arithmatex">\(\inf_{\gamma\sim\Pi(P_r,P_g)} \mathbb{E}_{(x,y)\sim\gamma}[\|x-y\|]\)</span> is defined as the Wasserstein distance.</li>
<li>Intuitively, <span class="arithmatex">\(\mathbb{E}_{(x,y)\sim\gamma}[\|x-y\|]\)</span> can be understood as the "cost" of moving "<span class="arithmatex">\(P_r\)</span> pile of earth" to " <span class="arithmatex">\(P_g\)</span> location" under this "transport plan", and <span class="arithmatex">\(W(P_r, P_g)\)</span> is the "minimum cost" under the "optimal transport plan", which is why it's called the Earth-Mover distance.</li>
</ul>
</li>
<li>Lipschitz Constraint</li>
<li>A function f is called Lipschitz continuous if it satisfies:<span class="arithmatex">(<span class="arithmatex">\(|f(x) - f(y)| \leq C|x - y|\)</span>\)</span><ul>
<li>where <span class="arithmatex">\(C\)</span> is the Lipschitz constant.</li>
<li>When inputs x and y are close to each other, their corresponding outputs <span class="arithmatex">\(f(x)\)</span> and <span class="arithmatex">\(f(y)\)</span> must also be close. This property ensures smoothness and continuity in the function</li>
</ul>
</li>
<li>As for a discriminator in WGAN, D is constrained to be 1-Lipschitz functions: <span class="arithmatex">\(|D(x) - D(y)| \leq |x - y|\)</span></li>
<li>Wasserstein Distance in WGAN:</li>
<li>GAN objective function :<span class="arithmatex">\(<span class="arithmatex">\(\min_{G} \max_{D} V(D,G) = \mathbb{E}_{x \sim p_{data}(x)}[\log D(x)] + \mathbb{E}_{z \sim p_z(z)}[\log(1 - D(G(z)))]\)</span>\)</span></li>
<li>In WGAN, the objective function can be written as:<span class="arithmatex">(<span class="arithmatex">\(W(P_r, P_g) = \sup_{||f||_L \leq 1} \mathbb{E}_{x \sim \mathbb{P}_r}[D(x)] - \mathbb{E}_{x \sim \mathbb{P}_g}[D(x)]\)</span>\)</span>
  where ：<ul>
<li>D is constrained to be 1-Lipschitz functions.</li>
<li><span class="arithmatex">\(\mathbb{P}_r\)</span> represents the distribution of real data (real probability distribution)</li>
<li><span class="arithmatex">\(x\sim\mathbb{P}_r\)</span> means x is sampled from the real data distribution</li>
<li><span class="arithmatex">\(\mathbb{P}_g\)</span> represents the distribution of generated data (generated probability distribution)</li>
<li><span class="arithmatex">\({x}\sim\mathbb{P}_g\)</span> means x is sampled from the generator's distribution</li>
<li>WGAN tries to minimize the Wasserstein distance between <span class="arithmatex">\(\mathbb{P}_r\)</span> and <span class="arithmatex">\(\mathbb{P}_g\)</span> </li>
<li><span class="arithmatex">\(||f||_L \leq 1\)</span> means that the discriminator D must satisfy the Lipschitz condition.</li>
</ul>
</li>
</ol>
<hr />
<p>how do we get the loss function:</p>
<ul>
<li>Primal Form (Original Wasserstein Distance):</li>
</ul>
<p><span class="arithmatex">\(<span class="arithmatex">\(W(P,Q) = \inf_{\gamma \in \Pi(P,Q)} \mathbb{E}_{(x,y)\sim \gamma}[||x-y||]\)</span>\)</span></p>
<p>where <span class="arithmatex">\(\Pi(P,Q)\)</span> is the set of all joint distributions (couplings) whose margins are P and Q.</p>
<ul>
<li>Kantorovich Duality Theorem:According to the duality Theorem, this problem is equivalent to:</li>
</ul>
<p><span class="arithmatex">\(<span class="arithmatex">\(W(P,Q) = \sup_{f\in Lip_1} \left(\int f\,dP - \int f\,dQ\right)\)</span>\)</span>
where <span class="arithmatex">\(Lip_1\)</span> is the set of 1-Lipschitz functions.</p>
<ul>
<li>Expectation Form:Converting the integrals to expectations:</li>
</ul>
<div class="arithmatex">\[W(P,Q) = \sup_{||f||_L \leq 1} [\mathbb{E}_{x\sim P}[f(x)] - \mathbb{E}_{x\sim Q}[f(x)]]\]</div>
<ul>
<li>Application to GAN: When P = Pr (real distribution) and Q = Pg (generated distribution):</li>
</ul>
<div class="arithmatex">\[W(P_r,P_g) = \sup_{||f||_L \leq 1} [\mathbb{E}_{x\sim P_r}[f(x)] - \mathbb{E}_{x\sim P_g}[f(x)]]\]</div>
<hr />
<ol>
<li>
<p>Weight Clipping : -&gt; implementation of Lipschitz Constraint in WGAN</p>
</li>
<li>
<p>WGAN forces the discriminator to satisfy the Lipschitz constraint through weight clipping or gradient penalty.</p>
</li>
<li>
<p>After each gradient update, the weights of the critic (discriminator) are clipped to a fixed range [-c, c] </p>
</li>
<li>
<p>In the paper, c = 0.01</p>
</li>
</ol>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-5-1">1</a></span>
<span class="normal"><a href="#__codelineno-5-2">2</a></span>
<span class="normal"><a href="#__codelineno-5-3">3</a></span>
<span class="normal"><a href="#__codelineno-5-4">4</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-5-1" name="__codelineno-5-1"></a><span class="c1"># 在每次参数更新后执行</span>
<a id="__codelineno-5-2" name="__codelineno-5-2"></a><span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">discriminator</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
<a id="__codelineno-5-3" name="__codelineno-5-3"></a>    <span class="n">param</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">clamp_</span><span class="p">(</span><span class="o">-</span><span class="n">c</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>  <span class="c1"># c通常设为0.01</span>
<a id="__codelineno-5-4" name="__codelineno-5-4"></a><span class="n">Weight</span> <span class="n">Clipping</span> <span class="o">-&gt;</span> <span class="nb">all</span> <span class="n">weight</span> <span class="n">values</span> <span class="n">are</span> <span class="n">forced</span> <span class="n">to</span> <span class="n">be</span> <span class="n">limited</span> <span class="n">to</span> <span class="n">the</span> <span class="nb">range</span> <span class="n">of</span> <span class="p">[</span><span class="o">-</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">]</span><span class="o">.</span>
</code></pre></div></td></tr></table></div>
<ul>
<li>
<p>Any value outside this range will be "clipped" to the boundary value. </p>
</li>
<li>
<p>This ensures the Lipschitz constraint of the network, but may also lead to limitations in expressiveness.</p>
</li>
</ul>
<p><strong>"Weight clipping is a clearly terrible way to enforce a Lipschitz constraint."</strong> -- M. Arjovsky, S. Chintala and L. Bottou, "Wasserstein Generative Adversarial Networks," in International Conference on Machine Learning, 2017, pp. 214-223.</p>
<h2 id="44-training-process-wasserstein-lipschitz-gradient">4.4 Training process -&gt; Wasserstein &amp; Lipschitz  Gradient<a class="headerlink" href="#44-training-process-wasserstein-lipschitz-gradient" title="Permanent link">&para;</a></h2>
<p><a class="glightbox" href="https://hackmd.io/_uploads/SkSZ5NovJl.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="image" src="https://hackmd.io/_uploads/SkSZ5NovJl.png" /></a>
<em>Source: Arjovsky et al., "Wasserstein GAN" (2017) arXiv:1701.07875</em></p>
<ol>
<li>Discriminator  Gradient:</li>
</ol>
<p>The Wasserstein loss for the Discriminator is:<span class="arithmatex">\(<span class="arithmatex">\(L(w) = \mathbb{E}_{x \sim \mathbb{P}_r}[f_w(x)] - \mathbb{E}_{z \sim p(z)}[f_w(g_\theta(z))]\)</span>\)</span>
where:</p>
<ul>
<li>
<p><span class="arithmatex">\(f_w(x)\)</span> Discriminator evaluates real data samples</p>
</li>
<li>
<p><span class="arithmatex">\(x\sim\mathbb{P}_r\)</span> means x is sampled from the real data distribution</p>
</li>
<li>
<p><span class="arithmatex">\(f_w(g_θ(z))\)</span> Discriminator evaluates generated data samples</p>
<ul>
<li>
<p><span class="arithmatex">\(z\)</span> is random noise transformed by generator <span class="arithmatex">\(g_θ\)</span> </p>
</li>
<li>
<p><span class="arithmatex">\(g_θ(z)\)</span> represents the Generator generated samples</p>
</li>
</ul>
</li>
</ul>
<p>For a batch of size m, the empirical version becomes:
<span class="arithmatex">\(<span class="arithmatex">\(L(w) = \frac{1}{m}\sum_{i=1}^m f_w(x^{(i)}) - \frac{1}{m}\sum_{i=1}^m f_w(g_\theta(z^{(i)}))\)</span>\)</span></p>
<p>Therefore, the gradient with respect to Discriminator parameters w is:</p>
<div class="arithmatex">\[\nabla_w L = \frac{1}{m}\sum_{i=1}^m \nabla_w f_w(x^{(i)}) - \frac{1}{m}\sum_{i=1}^m \nabla_w f_w(g_\theta(z^{(i)}))\]</div>
<ol>
<li>Generator Gradient:</li>
</ol>
<p>The generator's objective is to minimize:</p>
<div class="arithmatex">\[L(θ) = -\mathbb{E}_{z \sim p(z)}[f_w(g_\theta(z))]\]</div>
<p>For a batch of size m, this becomes:</p>
<div class="arithmatex">\[L(θ) = -\frac{1}{m}\sum_{i=1}^m f_w(g_\theta(z^{(i)}))\]</div>
<p>The gradient with respect to generator parameters θ is:</p>
<div class="arithmatex">\[\nabla_\theta L = -\frac{1}{m}\sum_{i=1}^m \nabla_\theta f_w(g_\theta(z^{(i)}))\]</div>
<ul>
<li>
<p>Line 5: Discriminator gradient computation
<span class="arithmatex">\(g_w ← \nabla_w [\frac{1}{m}\sum_{i=1}^m f_w(x^{(i)}) - \frac{1}{m}\sum_{i=1}^m f_w(g_\theta(z^{(i)}))]\)</span></p>
</li>
<li>
<p>Line 10: Generator gradient computation <span class="arithmatex">\(g_\theta ← -\nabla_\theta \frac{1}{m}\sum_{i=1}^m f_w(g_\theta(z^{(i)}))\)</span></p>
</li>
</ul>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-6-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-6-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-6-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-6-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-6-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-6-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-6-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-6-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-6-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-6-10">10</a></span>
<span class="normal"><a href="#__codelineno-6-11">11</a></span>
<span class="normal"><a href="#__codelineno-6-12">12</a></span>
<span class="normal"><a href="#__codelineno-6-13">13</a></span>
<span class="normal"><a href="#__codelineno-6-14">14</a></span>
<span class="normal"><a href="#__codelineno-6-15">15</a></span>
<span class="normal"><a href="#__codelineno-6-16">16</a></span>
<span class="normal"><a href="#__codelineno-6-17">17</a></span>
<span class="normal"><a href="#__codelineno-6-18">18</a></span>
<span class="normal"><a href="#__codelineno-6-19">19</a></span>
<span class="normal"><a href="#__codelineno-6-20">20</a></span>
<span class="normal"><a href="#__codelineno-6-21">21</a></span>
<span class="normal"><a href="#__codelineno-6-22">22</a></span>
<span class="normal"><a href="#__codelineno-6-23">23</a></span>
<span class="normal"><a href="#__codelineno-6-24">24</a></span>
<span class="normal"><a href="#__codelineno-6-25">25</a></span>
<span class="normal"><a href="#__codelineno-6-26">26</a></span>
<span class="normal"><a href="#__codelineno-6-27">27</a></span>
<span class="normal"><a href="#__codelineno-6-28">28</a></span>
<span class="normal"><a href="#__codelineno-6-29">29</a></span>
<span class="normal"><a href="#__codelineno-6-30">30</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-6-1" name="__codelineno-6-1"></a><span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">imgs</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">):</span>
<a id="__codelineno-6-2" name="__codelineno-6-2"></a>        <span class="c1"># Configure input</span>
<a id="__codelineno-6-3" name="__codelineno-6-3"></a>        <span class="n">real_imgs</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">imgs</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">Tensor</span><span class="p">))</span>
<a id="__codelineno-6-4" name="__codelineno-6-4"></a>        <span class="c1"># ---------------------</span>
<a id="__codelineno-6-5" name="__codelineno-6-5"></a>        <span class="c1">#  Train Discriminator</span>
<a id="__codelineno-6-6" name="__codelineno-6-6"></a>        <span class="c1"># ---------------------</span>
<a id="__codelineno-6-7" name="__codelineno-6-7"></a>        <span class="n">optimizer_D</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
<a id="__codelineno-6-8" name="__codelineno-6-8"></a>        <span class="c1"># Sample noise as generator input</span>
<a id="__codelineno-6-9" name="__codelineno-6-9"></a>        <span class="n">z</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="n">imgs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">opt</span><span class="o">.</span><span class="n">latent_dim</span><span class="p">))))</span>
<a id="__codelineno-6-10" name="__codelineno-6-10"></a>        <span class="c1"># Generate a batch of images</span>
<a id="__codelineno-6-11" name="__codelineno-6-11"></a>        <span class="n">fake_imgs</span> <span class="o">=</span> <span class="n">generator</span><span class="p">(</span><span class="n">z</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
<a id="__codelineno-6-12" name="__codelineno-6-12"></a>        <span class="c1"># Adversarial loss</span>
<a id="__codelineno-6-13" name="__codelineno-6-13"></a>        <span class="n">loss_D</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">discriminator</span><span class="p">(</span><span class="n">real_imgs</span><span class="p">))</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">discriminator</span><span class="p">(</span><span class="n">fake_imgs</span><span class="p">))</span>
<a id="__codelineno-6-14" name="__codelineno-6-14"></a>        <span class="n">loss_D</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<a id="__codelineno-6-15" name="__codelineno-6-15"></a>        <span class="n">optimizer_D</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
<a id="__codelineno-6-16" name="__codelineno-6-16"></a>        <span class="c1"># Clip weights of discriminator</span>
<a id="__codelineno-6-17" name="__codelineno-6-17"></a>        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">discriminator</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
<a id="__codelineno-6-18" name="__codelineno-6-18"></a>            <span class="n">p</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">clamp_</span><span class="p">(</span><span class="o">-</span><span class="n">opt</span><span class="o">.</span><span class="n">clip_value</span><span class="p">,</span> <span class="n">opt</span><span class="o">.</span><span class="n">clip_value</span><span class="p">)</span>
<a id="__codelineno-6-19" name="__codelineno-6-19"></a>        <span class="c1"># Train the generator every n_critic iterations</span>
<a id="__codelineno-6-20" name="__codelineno-6-20"></a>        <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="n">opt</span><span class="o">.</span><span class="n">n_critic</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
<a id="__codelineno-6-21" name="__codelineno-6-21"></a>            <span class="c1"># -----------------</span>
<a id="__codelineno-6-22" name="__codelineno-6-22"></a>            <span class="c1">#  Train Generator</span>
<a id="__codelineno-6-23" name="__codelineno-6-23"></a>            <span class="c1"># -----------------</span>
<a id="__codelineno-6-24" name="__codelineno-6-24"></a>            <span class="n">optimizer_G</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
<a id="__codelineno-6-25" name="__codelineno-6-25"></a>            <span class="c1"># Generate a batch of images</span>
<a id="__codelineno-6-26" name="__codelineno-6-26"></a>            <span class="n">gen_imgs</span> <span class="o">=</span> <span class="n">generator</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
<a id="__codelineno-6-27" name="__codelineno-6-27"></a>            <span class="c1"># Adversarial loss</span>
<a id="__codelineno-6-28" name="__codelineno-6-28"></a>            <span class="n">loss_G</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">discriminator</span><span class="p">(</span><span class="n">gen_imgs</span><span class="p">))</span>
<a id="__codelineno-6-29" name="__codelineno-6-29"></a>            <span class="n">loss_G</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<a id="__codelineno-6-30" name="__codelineno-6-30"></a>            <span class="n">optimizer_G</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
<p><a class="glightbox" href="https://hackmd.io/_uploads/r1Q694jv1e.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="image" src="https://hackmd.io/_uploads/r1Q694jv1e.png" /></a>
<em>Source: Arjovsky et al., "Wasserstein GAN" (2017) arXiv:1701.07875</em></p>
<hr />
<h1 id="5-2017-wgan-gp-improved-training-of-wasserstein-gans">5. [2017] WGAN-GP: <a href="https://arxiv.org/abs/1704.00028">Improved Training of Wasserstein GANs</a><a class="headerlink" href="#5-2017-wgan-gp-improved-training-of-wasserstein-gans" title="Permanent link">&para;</a></h1>
<h2 id="51-overall-introduction-gradient-penalty">5.1 Overall Introduction:  gradient penalty<a class="headerlink" href="#51-overall-introduction-gradient-penalty" title="Permanent link">&para;</a></h2>
<p>WGAN-GP replaces the weight clipping in the original WGAN by adding a gradient penalty term at the random interpolation points between the real and generated data, thereby achieving a more stable training process and better generation effects.</p>
<p>Loss function in WGAN: 
<span class="arithmatex">\(<span class="arithmatex">\(L = \sup_{||f||_L \leq 1} \mathbb{E}_{x \sim \mathbb{P}_r}[D(x)] - \mathbb{E}_{x \sim \mathbb{P}_g}[D(x)]\)</span>\)</span></p>
<p>Loss function in WGAN-GP: 
<span class="arithmatex">\(<span class="arithmatex">\(L = \mathbb{E}_{x\sim P_r}[D(x)] - \mathbb{E}_{x\sim P_g}[D(x)] + \lambda \mathbb{E}_{\hat{x}\sim P_{\hat{x}}}[(||\nabla_{\hat{x}}D(\hat{x})||_2 - 1)^2]\)</span>\)</span></p>
<p>where:
- Wasserstein Distance Term :<span class="arithmatex">\(\mathbb{E}_{x\sim P_r}[D(x)] - \mathbb{E}_{x\sim P_g}[D(x)]\)</span></p>
<ul>
<li>
<p>measure distance between real and generated distributions</p>
</li>
<li>
<p>Gradient Penalty Term: <span class="arithmatex">\(\lambda \mathbb{E}_{\hat{x}\sim P_{\hat{x}}}[(||\nabla_{\hat{x}}D(\hat{x})||_2 - 1)^2]\)</span></p>
</li>
<li>
<p>λ is penalty coefficient (typically 10)</p>
</li>
<li>
<p>Ensures gradient norm is close to 1</p>
</li>
<li>
<p><span class="arithmatex">\(\hat{x}\)</span> is a random interpolation between real samples and generated samples:</p>
</li>
</ul>
<h3 id="511-drawbacks-as-weight-clipping">5.1.1 Drawbacks as weight-clipping<a class="headerlink" href="#511-drawbacks-as-weight-clipping" title="Permanent link">&para;</a></h3>
<p><a class="glightbox" href="https://hackmd.io/_uploads/SJUHiEiD1g.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="image" src="https://hackmd.io/_uploads/SJUHiEiD1g.png" /></a>
<em>Source: Gulrajani et al., "Improved Training of Wasserstein GANs" (2017) arXiv:1704.00028</em></p>
<h4 id="5111-capacity-underuse">5.1.1.1 Capacity underuse<a class="headerlink" href="#5111-capacity-underuse" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p>Main Issues:</p>
</li>
<li>
<p>Theoretically, this critic should maintain unit gradient magnitudes everywhere, but when using weight clipping constraints, the critic in WGAN tends to learn overly simplistic functions. </p>
</li>
<li>
<p>Experimental Validation:</p>
</li>
<li>
<p>To verify this, we conducted experiments using the real distribution plus random noise as the generator's output. </p>
</li>
<li>
<p>The results showed that critics with weight clipping indeed overlook the complex features of the data, learning only simple approximations. </p>
</li>
</ul>
<h4 id="5112-exploding-and-vanishing-gradients">5.1.1.2 Exploding and vanishing gradients<a class="headerlink" href="#5112-exploding-and-vanishing-gradients" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p>Main Issues:</p>
</li>
<li>
<p>WGAN faces optimization challenges during training, caused by the interaction between weight constraints and the loss function. If the clipping threshold <span class="arithmatex">\(c\)</span> is not carefully adjusted, it may lead to either vanishing or exploding gradients.</p>
</li>
<li>
<p>Experimental Validation:</p>
</li>
<li>
<p>Researchers conducted experiments on the Swiss Roll toy dataset using three different clipping thresholds: 0.1, 0.01, and 0.001. With weight clipping:</p>
<ul>
<li>
<p>At <span class="arithmatex">\(c=0.1\)</span>, gradients exhibited exponential growth (red line going up).</p>
</li>
<li>
<p>At <span class="arithmatex">\(c=0.01\)</span> and <span class="arithmatex">\(c=0.001\)</span>, gradients exhibited exponential decay (purple and green lines going down).</p>
</li>
</ul>
</li>
</ul>
<p>The two smaller graphs on the right show differences in weight distribution:</p>
<ul>
<li>
<p>The upper graph: Weight clipping pushes weights toward two extreme values.</p>
</li>
<li>
<p>The lower graph: Gradient penalty results in a more normal distribution of weights.</p>
</li>
</ul>
<h2 id="52-loss-function">5.2 Loss function<a class="headerlink" href="#52-loss-function" title="Permanent link">&para;</a></h2>
<p>Training process:
<a class="glightbox" href="https://hackmd.io/_uploads/H1KOo4sw1l.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="image" src="https://hackmd.io/_uploads/H1KOo4sw1l.png" /></a>
<em>Source: Gulrajani et al., "Improved Training of Wasserstein GANs" (2017) arXiv:1704.00028</em></p>
<p><strong>How does the Gradient Penalty term work in WGAN-GP？</strong></p>
<ol>
<li>
<p>The loss function of WGAN-GP:  <span class="arithmatex">\(\min_G \max_D \mathbb{E}_{x\sim P_r}[D(x)] - \mathbb{E}_{z\sim P_z}[D(G(z))] + \lambda \mathbb{E}_{\hat{x}\sim P_{\hat{x}}}[(||\nabla_{\hat{x}}D(\hat{x})||_2 - 1)^2]\)</span></p>
</li>
<li>
<p>The core idea of the Gradient Penalty term is to enforce the 1-Lipschitz constraint on discriminator D across the sample space： <span class="arithmatex">\(|D(x_1) - D(x_2)| \leq |x_1 - x_2|\)</span></p>
</li>
<li>
<p>The 1-Lipschitz constraint above is equivalent to having the gradient norm of the discriminator not exceeding 1 at any point:  <span class="arithmatex">\(||\nabla_x D(x)||_2 \leq 1\)</span></p>
</li>
<li>
<p>WGAN-GP enforces the gradient norm to be equal to 1, rather than less than or equal to 1, through the penalty term:<span class="arithmatex">\(\mathcal{L}_{GP} = \lambda \mathbb{E}_{\hat{x}\sim P_{\hat{x}}}[(||\nabla_{\hat{x}}D(\hat{x})||_2 - 1)^2]\)</span></p>
</li>
<li>
<p><span class="arithmatex">\(\hat{x} = \epsilon x + (1-\epsilon)G(z), \epsilon \sim U[0,1]\)</span></p>
<ul>
<li>
<p>So <span class="arithmatex">\(\hat{x}\)</span> is a linear interpolation between data points of the real data distribution <span class="arithmatex">\(P_r\)</span> and the generated data distribution <span class="arithmatex">\(P_g\)</span>.</p>
</li>
<li>
<p>Why sampling?</p>
</li>
<li>
<p>According to <span class="arithmatex">\(||\nabla_x D(x)||_2 \leq 1\)</span>, the optimal critic forms a line between the paired points of the real and generated distributions with a gradient norm of 1. Therefore, as a compromise, the constraint is only enforced along these sampled lines.</p>
</li>
<li>
<p>Easy to implement and worked out in experiments.</p>
</li>
</ul>
</li>
</ol>
<p><span class="arithmatex">\(\hat{x}\)</span>:
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-7-1">1</a></span>
<span class="normal"><a href="#__codelineno-7-2">2</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-7-1" name="__codelineno-7-1"></a><span class="n">alpha</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">real_samples</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-7-2" name="__codelineno-7-2"></a><span class="n">interpolates</span> <span class="o">=</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">real_samples</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="n">fake_samples</span>
</code></pre></div></td></tr></table></div>
  <span class="arithmatex">\(\nabla_{\hat{x}}D(\hat{x})\)</span>:
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-8-1">1</a></span>
<span class="normal"><a href="#__codelineno-8-2">2</a></span>
<span class="normal"><a href="#__codelineno-8-3">3</a></span>
<span class="normal"><a href="#__codelineno-8-4">4</a></span>
<span class="normal"><a href="#__codelineno-8-5">5</a></span>
<span class="normal"><a href="#__codelineno-8-6">6</a></span>
<span class="normal"><a href="#__codelineno-8-7">7</a></span>
<span class="normal"><a href="#__codelineno-8-8">8</a></span>
<span class="normal"><a href="#__codelineno-8-9">9</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-8-1" name="__codelineno-8-1"></a><span class="c1">#d(x)</span>
<a id="__codelineno-8-2" name="__codelineno-8-2"></a><span class="n">d_interpolates</span> <span class="o">=</span> <span class="n">D</span><span class="p">(</span><span class="n">interpolates</span><span class="p">)</span>  
<a id="__codelineno-8-3" name="__codelineno-8-3"></a><span class="c1"># \nabla_{\hat{x}}D(\hat{x}):</span>
<a id="__codelineno-8-4" name="__codelineno-8-4"></a><span class="n">gradients</span> <span class="o">=</span> <span class="n">autograd</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span>
<a id="__codelineno-8-5" name="__codelineno-8-5"></a>        <span class="n">outputs</span><span class="o">=</span><span class="n">d_interpolates</span><span class="p">,</span>
<a id="__codelineno-8-6" name="__codelineno-8-6"></a>        <span class="n">inputs</span><span class="o">=</span><span class="n">interpolates</span><span class="p">,</span>
<a id="__codelineno-8-7" name="__codelineno-8-7"></a>        <span class="n">grad_outputs</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">d_interpolates</span><span class="p">),</span>
<a id="__codelineno-8-8" name="__codelineno-8-8"></a>        <span class="n">create_graph</span><span class="o">=</span><span class="kc">True</span>
<a id="__codelineno-8-9" name="__codelineno-8-9"></a>    <span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
</code></pre></div></td></tr></table></div></p>
<p><span class="arithmatex">\((||\nabla_{\hat{x}}D(\hat{x})||_2 - 1)^2\)</span>:</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-9-1">1</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-9-1" name="__codelineno-9-1"></a><span class="n">gradient_penalty</span> <span class="o">=</span> <span class="p">((</span><span class="n">gradients</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
<ol>
<li>
<p>The regulatory effect of this penalty term is manifested in:</p>
</li>
<li>
<p>When <span class="arithmatex">\(||\nabla_{\hat{x}}D(\hat{x})||_2 &gt; 1\)</span>, showing:</p>
<ul>
<li>
<p>Too Steep Gradients: Discriminators tend to be "aggressive" in judging real/fake samples and change too rapidly </p>
</li>
<li>
<p>May lead to training instability:</p>
</li>
<li>
<p>Likely to cause discriminator overfitting</p>
</li>
<li>
<p>Provides too strong gradient signals to the generator</p>
</li>
</ul>
</li>
<li>
<p>When <span class="arithmatex">\(||\nabla_{\hat{x}}D(\hat{x})||_2 &lt; 1\)</span>, showing:</p>
<ul>
<li>
<p>Too Flat Gradients: The Discriminator tends to be  insensitive to input changes </p>
</li>
<li>
<p>Insufficient Discrimination :  The Discriminator cannot effectively distinguish real/fake samples</p>
</li>
<li>
<p>Vanishing Gradients: Generator might not receive effective training signals</p>
</li>
</ul>
</li>
<li>
<p>Only when gradient norm  <span class="arithmatex">\(||\nabla_{\hat{x}}D(\hat{x})||_2 = 1\)</span>, the penalty term becomes zero</p>
</li>
</ol>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-10-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-10-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-10-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-10-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-10-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-10-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-10-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-10-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-10-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-10-10">10</a></span>
<span class="normal"><a href="#__codelineno-10-11">11</a></span>
<span class="normal"><a href="#__codelineno-10-12">12</a></span>
<span class="normal"><a href="#__codelineno-10-13">13</a></span>
<span class="normal"><a href="#__codelineno-10-14">14</a></span>
<span class="normal"><a href="#__codelineno-10-15">15</a></span>
<span class="normal"><a href="#__codelineno-10-16">16</a></span>
<span class="normal"><a href="#__codelineno-10-17">17</a></span>
<span class="normal"><a href="#__codelineno-10-18">18</a></span>
<span class="normal"><a href="#__codelineno-10-19">19</a></span>
<span class="normal"><a href="#__codelineno-10-20">20</a></span>
<span class="normal"><a href="#__codelineno-10-21">21</a></span>
<span class="normal"><a href="#__codelineno-10-22">22</a></span>
<span class="normal"><a href="#__codelineno-10-23">23</a></span>
<span class="normal"><a href="#__codelineno-10-24">24</a></span>
<span class="normal"><a href="#__codelineno-10-25">25</a></span>
<span class="normal"><a href="#__codelineno-10-26">26</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-10-1" name="__codelineno-10-1"></a><span class="k">def</span> <span class="nf">compute_gradient_penalty</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="n">real_samples</span><span class="p">,</span> <span class="n">fake_samples</span><span class="p">):</span>
<a id="__codelineno-10-2" name="__codelineno-10-2"></a>    <span class="c1"># Random interpolation coefficient</span>
<a id="__codelineno-10-3" name="__codelineno-10-3"></a>    <span class="n">alpha</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">real_samples</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-10-4" name="__codelineno-10-4"></a>    <span class="c1"># Generate interpolated samples</span>
<a id="__codelineno-10-5" name="__codelineno-10-5"></a>    <span class="n">interpolates</span> <span class="o">=</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">real_samples</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="n">fake_samples</span>
<a id="__codelineno-10-6" name="__codelineno-10-6"></a>    <span class="n">interpolates</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-10-7" name="__codelineno-10-7"></a>    <span class="c1"># Compute discriminator output</span>
<a id="__codelineno-10-8" name="__codelineno-10-8"></a>    <span class="n">d_interpolates</span> <span class="o">=</span> <span class="n">D</span><span class="p">(</span><span class="n">interpolates</span><span class="p">)</span>  
<a id="__codelineno-10-9" name="__codelineno-10-9"></a>    <span class="c1"># Compute gradients</span>
<a id="__codelineno-10-10" name="__codelineno-10-10"></a>    <span class="n">gradients</span> <span class="o">=</span> <span class="n">autograd</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span>
<a id="__codelineno-10-11" name="__codelineno-10-11"></a>        <span class="n">outputs</span><span class="o">=</span><span class="n">d_interpolates</span><span class="p">,</span>
<a id="__codelineno-10-12" name="__codelineno-10-12"></a>        <span class="n">inputs</span><span class="o">=</span><span class="n">interpolates</span><span class="p">,</span>
<a id="__codelineno-10-13" name="__codelineno-10-13"></a>        <span class="n">grad_outputs</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">d_interpolates</span><span class="p">),</span>
<a id="__codelineno-10-14" name="__codelineno-10-14"></a>        <span class="n">create_graph</span><span class="o">=</span><span class="kc">True</span>
<a id="__codelineno-10-15" name="__codelineno-10-15"></a>    <span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<a id="__codelineno-10-16" name="__codelineno-10-16"></a>    <span class="c1"># Compute gradient penalty</span>
<a id="__codelineno-10-17" name="__codelineno-10-17"></a>    <span class="n">gradient_penalty</span> <span class="o">=</span> <span class="p">((</span><span class="n">gradients</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<a id="__codelineno-10-18" name="__codelineno-10-18"></a>    <span class="k">return</span> <span class="n">gradient_penalty</span>
<a id="__codelineno-10-19" name="__codelineno-10-19"></a>
<a id="__codelineno-10-20" name="__codelineno-10-20"></a><span class="c1"># Training loop</span>
<a id="__codelineno-10-21" name="__codelineno-10-21"></a><span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="n">epochs</span><span class="p">:</span>
<a id="__codelineno-10-22" name="__codelineno-10-22"></a>    <span class="k">for</span> <span class="n">real_data</span> <span class="ow">in</span> <span class="n">dataloader</span><span class="p">:</span>
<a id="__codelineno-10-23" name="__codelineno-10-23"></a>        <span class="c1"># Compute gradient penalty</span>
<a id="__codelineno-10-24" name="__codelineno-10-24"></a>        <span class="n">gradient_penalty</span> <span class="o">=</span> <span class="n">compute_gradient_penalty</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="n">real_data</span><span class="p">,</span> <span class="n">fake_data</span><span class="p">)</span>
<a id="__codelineno-10-25" name="__codelineno-10-25"></a>        <span class="c1"># Discriminator loss</span>
<a id="__codelineno-10-26" name="__codelineno-10-26"></a>        <span class="n">d_loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">D</span><span class="p">(</span><span class="n">real_data</span><span class="p">))</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">D</span><span class="p">(</span><span class="n">fake_data</span><span class="p">))</span> <span class="o">+</span> <span class="n">lambda_gp</span> <span class="o">*</span> <span class="n">gradient_penalty</span>
</code></pre></div></td></tr></table></div>
<p><a class="glightbox" href="https://hackmd.io/_uploads/S1MnAVowJl.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="image" src="https://hackmd.io/_uploads/S1MnAVowJl.png" /></a>
<em>Source: Gulrajani et al., "Improved Training of Wasserstein GANs" (2017) arXiv:1704.00028</em></p>
<p><a class="glightbox" href="https://hackmd.io/_uploads/rygjCViDyx.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="image" src="https://hackmd.io/_uploads/rygjCViDyx.png" /></a>
<em>Source: Gulrajani et al., "Improved Training of Wasserstein GANs" (2017) arXiv:1704.00028</em></p>
<hr />
<h1 id="6-2018-pggan-progressive-growing-of-gans-for-improved-quality-stability-and-variation">6. [2018] PGGAN: <a href="https://arxiv.org/abs/1710.10196">Progressive Growing of GANs for Improved Quality, Stability, and Variation</a><a class="headerlink" href="#6-2018-pggan-progressive-growing-of-gans-for-improved-quality-stability-and-variation" title="Permanent link">&para;</a></h1>
<h2 id="61-overall-introduction">6.1 Overall Introduction:<a class="headerlink" href="#61-overall-introduction" title="Permanent link">&para;</a></h2>
<ol>
<li>
<p>Progressive Growing</p>
</li>
<li>
<p>Core Idea: Start at low resolution and progressively increase to higher resolutions.</p>
</li>
<li>
<p>Advantages:  More stable training &amp; Higher computational efficiency &amp; Better memory utilization</p>
</li>
<li>
<p>Implementation: Smoothly fade in new layers and synchronous growth of the generator and discriminator</p>
</li>
<li>
<p>Minibatch Standard Deviation </p>
</li>
<li>
<p>Purpose: Increase the diversity of generated images &amp; prevents mode collapse.</p>
</li>
<li>
<p>Implementation: </p>
<ul>
<li>
<p>Introduce a statistical layer late in the discriminator</p>
</li>
<li>
<p>Calculate the standard deviation within a minibatch of samples</p>
</li>
<li>
<p>Concatenate statistical features with the original features</p>
</li>
</ul>
</li>
<li>
<p>Normalization Strategies</p>
</li>
<li>
<p>Purpose: strategies ensure underlying training stability.</p>
</li>
<li>
<p>Implementation: </p>
<ul>
<li>Generator: Uses PixelNorm </li>
</ul>
</li>
</ol>
<p>The structure of PGGAN laid an important foundation for subsequent work (such as StyleGAN).</p>
<h2 id="62-progressive-growing-of-gans">6.2 PROGRESSIVE GROWING OF GANS<a class="headerlink" href="#62-progressive-growing-of-gans" title="Permanent link">&para;</a></h2>
<p><a class="glightbox" href="https://hackmd.io/_uploads/H1g1JBjvJx.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="image" src="https://hackmd.io/_uploads/H1g1JBjvJx.png" /></a>
<em>Source: Karras et al., "Progressive Growing of GANs for Improved Quality, Stability, and Variation" (2018) arXiv:1710.10196</em></p>
<p><a class="glightbox" href="https://hackmd.io/_uploads/SJvW1HsDye.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="image" src="https://hackmd.io/_uploads/SJvW1HsDye.png" /></a>
<em>Source: Karras et al., "Progressive Growing of GANs for Improved Quality, Stability, and Variation" (2018) arXiv:1710.10196</em></p>
<ul>
<li>
<p>Each resolution stage has two phases:</p>
</li>
<li>
<p>Fade-in Phase:</p>
<ul>
<li>
<p>The new layer is gradually blended in using alpha parameter</p>
</li>
<li>
<p>Alpha increases linearly from 0 to 1</p>
</li>
<li>
<p>In PGGAN, the growth of the α parameter is linear and is controlled by the number of training iterations. This is achieved as follows:</p>
</li>
</ul>
</li>
</ul>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-11-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-11-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-11-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-11-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-11-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-11-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-11-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-11-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-11-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-11-10">10</a></span>
<span class="normal"><a href="#__codelineno-11-11">11</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-11-1" name="__codelineno-11-1"></a><span class="c1"># 假设fade_in_iters是fade-in阶段的总迭代次数</span>
<a id="__codelineno-11-2" name="__codelineno-11-2"></a><span class="n">fade_in_iters</span> <span class="o">=</span> <span class="mi">600000</span>  <span class="c1"># 600k images</span>
<a id="__codelineno-11-3" name="__codelineno-11-3"></a><span class="c1"># 当前迭代次数current_iter</span>
<a id="__codelineno-11-4" name="__codelineno-11-4"></a><span class="n">alpha</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">current_iter</span> <span class="o">/</span> <span class="n">fade_in_iters</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
<a id="__codelineno-11-5" name="__codelineno-11-5"></a>
<a id="__codelineno-11-6" name="__codelineno-11-6"></a><span class="k">def</span> <span class="nf">fade_in</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">upscaled</span><span class="p">,</span> <span class="n">generated</span><span class="p">):</span>
<a id="__codelineno-11-7" name="__codelineno-11-7"></a>    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">alpha</span> <span class="o">*</span> <span class="n">generated</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="n">upscaled</span><span class="p">)</span>
<a id="__codelineno-11-8" name="__codelineno-11-8"></a><span class="o">......</span>
<a id="__codelineno-11-9" name="__codelineno-11-9"></a><span class="n">final_upscaled</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rgb_layers</span><span class="p">[</span><span class="n">steps</span><span class="o">-</span><span class="mi">1</span><span class="p">](</span><span class="n">upscaled</span><span class="p">)</span>
<a id="__codelineno-11-10" name="__codelineno-11-10"></a><span class="n">final_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rgb_layers</span><span class="p">[</span><span class="n">steps</span><span class="p">](</span><span class="n">out</span><span class="p">)</span>
<a id="__codelineno-11-11" name="__codelineno-11-11"></a><span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">fade_in</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">final_upscaled</span><span class="p">,</span> <span class="n">final_out</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<ol>
<li>
<p>Stabilization Phase: </p>
<ul>
<li>
<p>Train network with new layers fully active</p>
</li>
<li>
<p>Old paths are removed</p>
</li>
<li>
<p>Network stabilizes at new resolution</p>
</li>
</ul>
</li>
</ol>
<p>Time Allocation:</p>
<ul>
<li>
<p>Fade-in Phase: 600k images</p>
</li>
<li>
<p>Stabilization Phase: 600k images</p>
</li>
<li>
<p>Total per resolution: 1.2M images (600k + 600k)</p>
</li>
</ul>
<p><div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-12-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-12-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-12-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-12-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-12-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-12-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-12-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-12-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-12-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-12-10">10</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-12-1" name="__codelineno-12-1"></a>Complete Training Process Example (from 4×4 to 1024×1024):
<a id="__codelineno-12-2" name="__codelineno-12-2"></a>4×4:   Only Stabilization     600k images
<a id="__codelineno-12-3" name="__codelineno-12-3"></a>8×8:   Fade-in + Stabilization 1.2M images
<a id="__codelineno-12-4" name="__codelineno-12-4"></a>16×16: Fade-in + Stabilization 1.2M images
<a id="__codelineno-12-5" name="__codelineno-12-5"></a>32×32: Fade-in + Stabilization 1.2M images
<a id="__codelineno-12-6" name="__codelineno-12-6"></a>64×64: Fade-in + Stabilization 1.2M images
<a id="__codelineno-12-7" name="__codelineno-12-7"></a>128×128: Fade-in + Stabilization 1.2M images
<a id="__codelineno-12-8" name="__codelineno-12-8"></a>256×256: Fade-in + Stabilization 1.2M images
<a id="__codelineno-12-9" name="__codelineno-12-9"></a>512×512: Fade-in + Stabilization 1.2M images
<a id="__codelineno-12-10" name="__codelineno-12-10"></a>1024×1024: Fade-in + Stabilization 1.2M images
</code></pre></div></td></tr></table></div>
Smooth Layer Transitions:
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-13-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-13-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-13-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-13-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-13-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-13-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-13-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-13-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-13-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-13-10">10</a></span>
<span class="normal"><a href="#__codelineno-13-11">11</a></span>
<span class="normal"><a href="#__codelineno-13-12">12</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-13-1" name="__codelineno-13-1"></a><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">alpha</span><span class="p">):</span>
<a id="__codelineno-13-2" name="__codelineno-13-2"></a>    <span class="c1"># Old path (lower resolution)</span>
<a id="__codelineno-13-3" name="__codelineno-13-3"></a>    <span class="n">old_rgb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">from_rgb_old</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a id="__codelineno-13-4" name="__codelineno-13-4"></a>    <span class="n">old_rgb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">upsample</span><span class="p">(</span><span class="n">old_rgb</span><span class="p">)</span>
<a id="__codelineno-13-5" name="__codelineno-13-5"></a>
<a id="__codelineno-13-6" name="__codelineno-13-6"></a>    <span class="c1"># New path (higher resolution)</span>
<a id="__codelineno-13-7" name="__codelineno-13-7"></a>    <span class="n">new_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">upsample</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a id="__codelineno-13-8" name="__codelineno-13-8"></a>    <span class="n">new_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv</span><span class="p">(</span><span class="n">new_x</span><span class="p">)</span>
<a id="__codelineno-13-9" name="__codelineno-13-9"></a>    <span class="n">new_rgb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_rgb_new</span><span class="p">(</span><span class="n">new_x</span><span class="p">)</span>
<a id="__codelineno-13-10" name="__codelineno-13-10"></a>
<a id="__codelineno-13-11" name="__codelineno-13-11"></a>    <span class="c1"># Smooth blending</span>
<a id="__codelineno-13-12" name="__codelineno-13-12"></a>    <span class="k">return</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="n">old_rgb</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">new_rgb</span>
</code></pre></div></td></tr></table></div>
  - toRGB: 1×1 convolution to convert features to RGB</p>
<ul>
<li>
<p>fromRGB: 1×1 convolution to convert RGB to features</p>
</li>
<li>
<p>2×: Upsampling (nearest neighbor)</p>
</li>
<li>
<p>0.5×: Downsampling (average pooling)</p>
</li>
</ul>
<h2 id="63-increasing-variation-using-minibatch-standard-deviation">6.3 INCREASING VARIATION USING MINIBATCH STANDARD DEVIATION<a class="headerlink" href="#63-increasing-variation-using-minibatch-standard-deviation" title="Permanent link">&para;</a></h2>
<p><a class="glightbox" href="https://hackmd.io/_uploads/S1bEyBjwkx.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="image" src="https://hackmd.io/_uploads/S1bEyBjwkx.png" /></a>
<em>Source: Wang et al., "Citrus Disease Image Generation and Classification Based on Improved FastGAN and EfficientNet-B5" (2023) Electronics, 12(5), 1232</em></p>
<ol>
<li>For each feature and spatial location i, compute standard deviation across the batch:
  <span class="arithmatex">\(\sigma_i(x) = \sqrt{\frac{1}{N}\sum_{k=1}^{N}(x_{ik} - \mu_i)^2}\)</span>
where:</li>
<li>
<p><span class="arithmatex">\(x_{ik}\)</span> is the feature value for sample k at position i</p>
</li>
<li>
<p><span class="arithmatex">\(\mu_i = \frac{1}{N}\sum_{k=1}^{N}x_{ik}\)</span> is the mean across the batch</p>
</li>
<li>
<p>N is the batch size</p>
</li>
<li>
<p>Average the standard deviations across features and spatial dimensions:
  <span class="arithmatex">\(\sigma = \frac{1}{C \times H \times W}\sum_{i}\sigma_i(x)\)</span></p>
</li>
</ol>
<p>where:</p>
<ul>
<li><span class="arithmatex">\(C\)</span> : channels. <span class="arithmatex">\(H\)</span>: height. <span class="arithmatex">\(W\)</span> :width</li>
</ul>
<p>These statistics are then:</p>
<ol>
<li>
<p>Replicated into a <span class="arithmatex">\([1×1×H×W]\)</span> tensor</p>
</li>
<li>
<p>Further replicated N times to match batch size: <span class="arithmatex">\([N×1×H×W]\)</span></p>
</li>
<li>
<p>Concatenated with original input along channel dimension to get final output of shape <span class="arithmatex">\([N×(C+1)×H×W]\)</span></p>
</li>
</ol>
<p><div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-14-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-14-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-14-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-14-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-14-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-14-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-14-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-14-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-14-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-14-10">10</a></span>
<span class="normal"><a href="#__codelineno-14-11">11</a></span>
<span class="normal"><a href="#__codelineno-14-12">12</a></span>
<span class="normal"><a href="#__codelineno-14-13">13</a></span>
<span class="normal"><a href="#__codelineno-14-14">14</a></span>
<span class="normal"><a href="#__codelineno-14-15">15</a></span>
<span class="normal"><a href="#__codelineno-14-16">16</a></span>
<span class="normal"><a href="#__codelineno-14-17">17</a></span>
<span class="normal"><a href="#__codelineno-14-18">18</a></span>
<span class="normal"><a href="#__codelineno-14-19">19</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-14-1" name="__codelineno-14-1"></a><span class="k">def</span> <span class="nf">minibatch_stddev_layer</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">group_size</span><span class="o">=</span><span class="mi">4</span><span class="p">):</span>
<a id="__codelineno-14-2" name="__codelineno-14-2"></a>    <span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>
<a id="__codelineno-14-3" name="__codelineno-14-3"></a>    <span class="n">G</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">group_size</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>  <span class="c1"># 分组大小</span>
<a id="__codelineno-14-4" name="__codelineno-14-4"></a>
<a id="__codelineno-14-5" name="__codelineno-14-5"></a>    <span class="c1"># [NCHW] -&gt; [GMCHW] 分成G组</span>
<a id="__codelineno-14-6" name="__codelineno-14-6"></a>    <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span>
<a id="__codelineno-14-7" name="__codelineno-14-7"></a>
<a id="__codelineno-14-8" name="__codelineno-14-8"></a>    <span class="c1"># 计算标准差</span>
<a id="__codelineno-14-9" name="__codelineno-14-9"></a>    <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-8</span><span class="p">)</span>  <span class="c1"># [-MCHW]</span>
<a id="__codelineno-14-10" name="__codelineno-14-10"></a>
<a id="__codelineno-14-11" name="__codelineno-14-11"></a>    <span class="c1"># 取平均得到单个值</span>
<a id="__codelineno-14-12" name="__codelineno-14-12"></a>    <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span>  <span class="c1"># []</span>
<a id="__codelineno-14-13" name="__codelineno-14-13"></a>
<a id="__codelineno-14-14" name="__codelineno-14-14"></a>    <span class="c1"># 广播回原始形状</span>
<a id="__codelineno-14-15" name="__codelineno-14-15"></a>    <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-14-16" name="__codelineno-14-16"></a>    <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span>  <span class="c1"># [N1HW]</span>
<a id="__codelineno-14-17" name="__codelineno-14-17"></a>
<a id="__codelineno-14-18" name="__codelineno-14-18"></a>    <span class="c1"># 连接到输入特征图</span>
<a id="__codelineno-14-19" name="__codelineno-14-19"></a>    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># [N(C+1)HW]</span>
</code></pre></div></td></tr></table></div>
The main advantages of this technique are:</p>
<ol>
<li>Helps the discriminator identify the statistical characteristics of the generated images</li>
<li>Encourages the generator to produce more diverse outputs</li>
<li>Helps avoid mode collapse</li>
</ol>
<h2 id="64-normalization-in-generator-and-discriminator">6.4 NORMALIZATION IN GENERATOR AND DISCRIMINATOR<a class="headerlink" href="#64-normalization-in-generator-and-discriminator" title="Permanent link">&para;</a></h2>
<h3 id="641-normalization-in-passed-gan-related-model">6.4.1 Normalization in passed GAN-related-model<a class="headerlink" href="#641-normalization-in-passed-gan-related-model" title="Permanent link">&para;</a></h3>
<table>
<thead>
<tr>
<th>GAN model</th>
<th>Normalization applied</th>
<th>Implementation detail</th>
</tr>
</thead>
<tbody>
<tr>
<td>GAN</td>
<td>batch normalization</td>
<td>Typically employs basic batch normalization in both the generator and discriminator.</td>
</tr>
<tr>
<td>cGAN</td>
<td>batch normalization</td>
<td>Typically employs basic batch normalization in both the generator and discriminator.</td>
</tr>
<tr>
<td>DCGAN</td>
<td>batch normalization</td>
<td>Generator: BN is used in all layers except the output layer. Discriminator: BN is used in all layers except the input and output layers.</td>
</tr>
<tr>
<td>WGAN</td>
<td>Remove BN in the discriminator</td>
<td>Advises against using batch normalization due to its impact on the Lipschitz constraint. Completely removes BN in the discriminator. The generator may use BN, but it is often omitted in practice.</td>
</tr>
<tr>
<td>WGAN-GP</td>
<td>Remove BN in the discriminator</td>
<td>Discriminator: Recommends using layer normalization or instance normalization instead of batch normalization. This is because BN introduces correlations between samples, affecting the calculation of the gradient penalty.</td>
</tr>
<tr>
<td>PGGAN</td>
<td>Completely Remove BN and Pixel-wise normalization in the generator and new weight initialization</td>
<td>Generator: BN is used in all layers except the output layer. Discriminator: BN is used in all layers except the input and output layers.</td>
</tr>
</tbody>
</table>
<h3 id="642-pixelwise-feature-vector-normalization-in-generator">6.4.2 PIXELWISE FEATURE VECTOR NORMALIZATION IN GENERATOR<a class="headerlink" href="#642-pixelwise-feature-vector-normalization-in-generator" title="Permanent link">&para;</a></h3>
<p>Applied after each convolutional layer in the generator at each pixel position independently:</p>
<div class="arithmatex">\[b_{x,y} = \frac{a_{x,y}}{\sqrt{\frac{1}{N}\sum_{j=0}^{N-1}(a_{x,y}^j)^2 + \epsilon}}\]</div>
<p>Where:
- <span class="arithmatex">\(\epsilon = 10^{-8}\)</span></p>
<ul>
<li>
<p><span class="arithmatex">\(a_{x,y} \text{ is the original feature vector at pixel position } (x,y)\)</span></p>
</li>
<li>
<p><span class="arithmatex">\(b_{x,y} \text{ is the normalized feature vector at pixel position } (x,y)\)</span></p>
</li>
<li>
<p><span class="arithmatex">\(N \text{ is the number of feature maps (channels)}\)</span></p>
</li>
<li>
<p><span class="arithmatex">\(\epsilon = 10^{-8} \text{ is a small constant to prevent division by zero}\)</span></p>
</li>
<li>
<p><span class="arithmatex">\(\text{The sum } \sum_{j=0}^{N-1} \text{ is taken over all } N \text{ feature maps for that pixel position}\)</span></p>
</li>
</ul>
<p><div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-15-1">1</a></span>
<span class="normal"><a href="#__codelineno-15-2">2</a></span>
<span class="normal"><a href="#__codelineno-15-3">3</a></span>
<span class="normal"><a href="#__codelineno-15-4">4</a></span>
<span class="normal"><a href="#__codelineno-15-5">5</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-15-1" name="__codelineno-15-1"></a><span class="k">class</span> <span class="nc">PixelNorm</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<a id="__codelineno-15-2" name="__codelineno-15-2"></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<a id="__codelineno-15-3" name="__codelineno-15-3"></a>        <span class="n">norm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-15-4" name="__codelineno-15-4"></a>        <span class="n">norm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">norm</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span><span class="p">)</span>
<a id="__codelineno-15-5" name="__codelineno-15-5"></a>        <span class="k">return</span> <span class="n">x</span> <span class="o">/</span> <span class="n">norm</span>    
</code></pre></div></td></tr></table></div>
- <span class="arithmatex">\(x ** 2\)</span>:  Calculate the squared values of all features at each pixel <span class="arithmatex">\((a_{x,y}^j)^2\)</span></p>
<ul>
<li>
<p><code>torch.mean(..., dim=1)</code>:  Average these squares across all feature maps <span class="arithmatex">\({\frac{1}{N}\sum_{j=0}^{N-1}(a_{x,y}^j)^2 }\)</span></p>
</li>
<li>
<p>torch.sqrt(... + epsilon): Take the square root of the average (plus ε) <span class="arithmatex">\({\sqrt{\frac{1}{N}\sum_{j=0}^{N-1}(a_{x,y}^j)^2 + \epsilon}}\)</span></p>
</li>
<li>
<p><span class="arithmatex">\(x / norm\)</span>:  normalization <span class="arithmatex">\(\frac{a_{x,y}}{\sqrt{\frac{1}{N}\sum_{j=0}^{N-1}(a_{x,y}^j)^2 + \epsilon}}\)</span>$</p>
</li>
</ul>
<h3 id="643-qualized-learning-rate">6.4.3 QUALIZED LEARNING RATE<a class="headerlink" href="#643-qualized-learning-rate" title="Permanent link">&para;</a></h3>
<p><strong>Problem</strong>: In traditional neural network training, parameters of different layers may have different dynamic ranges. When using adaptive optimizers like RMSProp or Adam, they normalize gradient updates based on the standard deviation of parameters. This results in parameters with larger dynamic ranges requiring more time to adjust properly.</p>
<p>Specific Implementation:</p>
<ol>
<li>Traditional Weight Initialization </li>
<li>
<p>In standard neural networks, weights are typically initialized using methods </p>
<ul>
<li>like He initialization N(0, sqrt(2/n)), Better suited for ReLU</li>
</ul>
</li>
</ol>
<p><div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-16-1">1</a></span>
<span class="normal"><a href="#__codelineno-16-2">2</a></span>
<span class="normal"><a href="#__codelineno-16-3">3</a></span>
<span class="normal"><a href="#__codelineno-16-4">4</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-16-1" name="__codelineno-16-1"></a><span class="c1"># Standard He initialization (for comparison)</span>
<a id="__codelineno-16-2" name="__codelineno-16-2"></a><span class="n">weight_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">out_channels</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">kernel</span><span class="p">,</span> <span class="n">kernel</span><span class="p">)</span>
<a id="__codelineno-16-3" name="__codelineno-16-3"></a><span class="n">std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">2.0</span> <span class="o">/</span> <span class="p">(</span><span class="n">in_channels</span> <span class="o">*</span> <span class="n">kernel</span> <span class="o">*</span> <span class="n">kernel</span><span class="p">))</span>
<a id="__codelineno-16-4" name="__codelineno-16-4"></a><span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">std</span><span class="p">,</span> <span class="n">weight_shape</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
  - This can lead to different layers learning at different rates, causing training instability</p>
<ul>
<li>
<p>The variance of the gradients can differ significantly between layers</p>
</li>
<li>
<p>The Equalized Learning Rate Solution: </p>
</li>
<li>
<p>initialization (happens only once when the model is created):</p>
<ul>
<li>Instead of using usual standard initialization, weights are initialized from N(0,1)</li>
</ul>
</li>
</ul>
<h2 id="65-equalized-learning-rate-approach">6.5 Equalized learning rate approach<a class="headerlink" href="#65-equalized-learning-rate-approach" title="Permanent link">&para;</a></h2>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-17-1">1</a></span>
<span class="normal"><a href="#__codelineno-17-2">2</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-17-1" name="__codelineno-17-1"></a><span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">weight_shape</span><span class="p">)</span>
<a id="__codelineno-17-2" name="__codelineno-17-2"></a><span class="n">runtime_coef</span> <span class="o">=</span> <span class="n">std</span>  <span class="c1"># Applied during forward pass</span>
</code></pre></div></td></tr></table></div>
<ul>
<li>
<p>During training (happens every forward pass): scaling process</p>
</li>
<li>
<p>Each layer's weights are explicitly scaled during runtime by a layer-specific constant </p>
</li>
<li>
<p>The scaling factor is the per-layer normalization constant from He initialization</p>
</li>
</ul>
<h3 id="651-in-equalizedconv2d">6.5.1 In EqualizedConv2d<a class="headerlink" href="#651-in-equalizedconv2d" title="Permanent link">&para;</a></h3>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-18-1">1</a></span>
<span class="normal"><a href="#__codelineno-18-2">2</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-18-1" name="__codelineno-18-1"></a><span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">fan_in</span><span class="p">)</span>  <span class="c1"># Calculate He scaling factor</span>
<a id="__codelineno-18-2" name="__codelineno-18-2"></a><span class="n">scaled_weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span>    <span class="c1"># Apply scaling at runtime</span>
</code></pre></div></td></tr></table></div>
<ul>
<li>This ensures that the dynamic range and learning speed are similar for all weights</li>
<li>Standard layers: Apply scaling during initialization<ul>
<li>Equalized layers: Apply scaling during each forward pass</li>
<li>This ensures the gradient updates remain properly scaled throughout training</li>
</ul>
</li>
</ul>
<p>Why It's Useful:</p>
<ol>
<li>
<p>Ensures that all weights have a similar dynamic range.</p>
</li>
<li>
<p>Makes the learning process more balanced, avoiding slow learning for some parameters due to large ranges.</p>
</li>
<li>
<p>Better adapts to c</p>
</li>
<li>
<p>In standard neural networks, weights are typically initialized using methods </p>
</li>
<li>
<p>like He initialization <span class="arithmatex">\(N(0, sqrt(2/n))\)</span>, Better suited for ReLU</p>
</li>
</ol>
<hr />
<p>RMSProp or Adam, they normalize gradient updates based on the standard deviation of parameters：</p>
<p>RMSprop:
<span class="arithmatex">\(<span class="arithmatex">\(\theta_t = \theta_{t-1} - \frac{\eta}{\sqrt{v_t + \epsilon}} g_t\)</span>\)</span> Adam:<span class="arithmatex">\(<span class="arithmatex">\(\theta_t = \theta_{t-1} - \frac{\eta}{\sqrt{\hat{v}_t} + \epsilon} \hat{m}_t\)</span>\)</span></p>
<ol>
<li>Standard Deviation Estimation:</li>
<li>
<p><span class="arithmatex">\(v_t\)</span> actually estimates the exponential moving average of squared gradients:<span class="arithmatex">\(v_t = \beta v_{t-1} + (1-\beta)g_t^2\)</span></p>
</li>
<li>
<p>This accumulated squared gradient <span class="arithmatex">\(v_t\)</span> is essentially estimating the second moment of the gradient, and its square root <span class="arithmatex">\(\sqrt v_t\)</span> approximates the standard deviation of the gradient</p>
</li>
<li>
<p>Normalization Effect:</p>
</li>
<li>
<p>In the update formula, the gradient term (<span class="arithmatex">\(g_t\)</span> or <span class="arithmatex">\(ĥ_t\)</span>) is divided by <span class="arithmatex">\(\sqrt v_t\)</span></p>
</li>
<li>
<p>This is equivalent to normalizing the gradient update by the gradient's standard deviation</p>
</li>
<li>
<p>Mathematically equivalent to:<span class="arithmatex">\(<span class="arithmatex">\(\text{normalized update} = \frac{g_t}{\sqrt{v_t + \epsilon}}\)</span>\)</span></p>
</li>
<li>
<p>Why This Is Standard Deviation Normalization:</p>
</li>
<li>
<p>If a parameter has large gradient variations (high standard deviation), <span class="arithmatex">\(\sqrt v_t\)</span> will become larger</p>
</li>
<li>
<p>This will make the actual update step smaller</p>
</li>
<li>
<p>Conversely, if gradient variations are small (low standard deviation), the update step will become larger accordingly</p>
</li>
<li>
<p>This achieves adaptive standard deviation normalization</p>
<ul>
<li>This is also why EQUALIZED LEARNING RATE solves this problem by explicitly controlling the dynamic range of parameters (<span class="arithmatex">\(ŵᵢ = wᵢ/c\)</span>).</li>
</ul>
</li>
</ol>
<p>Main Advantages:</p>
<ol>
<li>
<p>Keeps the learning speed consistent for all weights.</p>
</li>
<li>
<p>Avoids the issue of having both too high and too low learning rates at the same time.</p>
</li>
<li>
<p>By dynamically scaling during runtime rather than statically at initialization, it makes the training process more stable.</p>
</li>
</ol>
<hr />









  




                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer" >
        
          
          <a href="../../../chapter6_VAE/vq_vae/" class="md-footer__link md-footer__link--prev" aria-label="Previous: VA-VAE">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                VA-VAE
              </div>
            </div>
          </a>
        
        
          
          <a href="../../3.3stylegan/paper/" class="md-footer__link md-footer__link--next" aria-label="Next: StyleGAN">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                StyleGAN
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://mad-sg.github.io/generative-ai-start-to-surrender/" target="_blank" rel="noopener" title="mad-sg.github.io" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://hub.docker.com/r/squidfunk/mkdocs-material/" target="_blank" rel="noopener" title="hub.docker.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M349.9 236.3h-66.1v-59.4h66.1zm0-204.3h-66.1v60.7h66.1zm78.2 144.8H362v59.4h66.1zm-156.3-72.1h-66.1v60.1h66.1zm78.1 0h-66.1v60.1h66.1zm276.8 100c-14.4-9.7-47.6-13.2-73.1-8.4-3.3-24-16.7-44.9-41.1-63.7l-14-9.3-9.3 14c-18.4 27.8-23.4 73.6-3.7 103.8-8.7 4.7-25.8 11.1-48.4 10.7H2.4c-8.7 50.8 5.8 116.8 44 162.1 37.1 43.9 92.7 66.2 165.4 66.2 157.4 0 273.9-72.5 328.4-204.2 21.4.4 67.6.1 91.3-45.2 1.5-2.5 6.6-13.2 8.5-17.1zm-511.1-27.9h-66v59.4h66.1v-59.4zm78.1 0h-66.1v59.4h66.1zm78.1 0h-66.1v59.4h66.1zm-78.1-72.1h-66.1v60.1h66.1z"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://pypi.org/project/mkdocs-material/" target="_blank" rel="noopener" title="pypi.org" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.8 200.5c-7.7-30.9-22.3-54.2-53.4-54.2h-40.1v47.4c0 36.8-31.2 67.8-66.8 67.8H172.7c-29.2 0-53.4 25-53.4 54.3v101.8c0 29 25.2 46 53.4 54.3 33.8 9.9 66.3 11.7 106.8 0 26.9-7.8 53.4-23.5 53.4-54.3v-40.7H226.2v-13.6h160.2c31.1 0 42.6-21.7 53.4-54.2 11.2-33.5 10.7-65.7 0-108.6M286.2 404c11.1 0 20.1 9.1 20.1 20.3 0 11.3-9 20.4-20.1 20.4-11 0-20.1-9.2-20.1-20.4.1-11.3 9.1-20.3 20.1-20.3M167.8 248.1h106.8c29.7 0 53.4-24.5 53.4-54.3V91.9c0-29-24.4-50.7-53.4-55.6-35.8-5.9-74.7-5.6-106.8.1-45.2 8-53.4 24.7-53.4 55.6v40.7h106.9v13.6h-147c-31.1 0-58.3 18.7-66.8 54.2-9.8 40.7-10.2 66.1 0 108.6 7.6 31.6 25.7 54.2 56.8 54.2H101v-48.8c0-35.3 30.5-66.4 66.8-66.4m-6.7-142.6c-11.1 0-20.1-9.1-20.1-20.3.1-11.3 9-20.4 20.1-20.4 11 0 20.1 9.2 20.1 20.4s-9 20.3-20.1 20.3"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://bsky.app/profile/squidfunk.bsky.social" target="_blank" rel="noopener" title="bsky.app" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M111.8 62.2C170.2 105.9 233 194.7 256 242.4c23-47.6 85.8-136.4 144.2-180.2 42.1-31.6 110.3-56 110.3 21.8 0 15.5-8.9 130.5-14.1 149.2-18.2 64.8-84.4 81.4-143.3 71.3C456 322 482.2 380 425.6 438c-107.4 110.2-154.3-27.6-166.3-62.9-1.7-4.9-2.6-7.8-3.3-7.8s-1.6 3-3.3 7.8c-12 35.3-59 173.1-166.3 62.9-56.5-58-30.4-116 72.5-133.5C100 314.6 33.8 298 15.7 233.1 10.4 214.4 1.5 99.4 1.5 83.9c0-77.8 68.2-53.4 110.3-21.8z"/></svg>
    </a>
  
    
    
      
    
    
    
      
      
    
    <a href="https://fosstodon.org/@squidfunk" target="_blank" rel="noopener me" title="fosstodon.org" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M433 179.11c0-97.2-63.71-125.7-63.71-125.7-62.52-28.7-228.56-28.4-290.48 0 0 0-63.72 28.5-63.72 125.7 0 115.7-6.6 259.4 105.63 289.1 40.51 10.7 75.32 13 103.33 11.4 50.81-2.8 79.32-18.1 79.32-18.1l-1.7-36.9s-36.31 11.4-77.12 10.1c-40.41-1.4-83-4.4-89.63-54a102.5 102.5 0 0 1-.9-13.9c85.63 20.9 158.65 9.1 178.75 6.7 56.12-6.7 105-41.3 111.23-72.9 9.8-49.8 9-121.5 9-121.5m-75.12 125.2h-46.63v-114.2c0-49.7-64-51.6-64 6.9v62.5h-46.33V197c0-58.5-64-56.6-64-6.9v114.2H90.19c0-122.1-5.2-147.9 18.41-175 25.9-28.9 79.82-30.8 103.83 6.1l11.6 19.5 11.6-19.5c24.11-37.1 78.12-34.8 103.83-6.1 23.71 27.3 18.4 53 18.4 175z"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://x.com/squidfunk" target="_blank" rel="noopener" title="x.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8l164.9-188.5L26.8 48h145.6l100.5 132.9zm-24.8 373.8h39.1L151.1 88h-42z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../../../..", "features": ["navigation.tabs", "toc.integrate", "content.code.copy", "content.code.select", "content.code.annotate", "content.tabs.link", "content.footnote.tooltips", "content.tooltips", "navigation.tracking", "search.highlight", "search.share", "search.suggest", "toc.follow", "announce.dismiss", "content.action.edit", "content.action.view", "content.code.annotate", "navigation.footer", "navigation.indexes", "navigation.sections", "navigation.tabs", "navigation.top", "navigation.expand", "search.share", "search.suggest"], "search": "../../../../assets/javascripts/workers/search.f8cc74c7.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../../../assets/javascripts/bundle.60a45f97.min.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.min.js"></script>
      
        <script src="../../../../javascripts/mathjax.js"></script>
      
    
  <script id="init-glightbox">const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});
document$.subscribe(() => { lightbox.reload() });
</script></body>
</html>