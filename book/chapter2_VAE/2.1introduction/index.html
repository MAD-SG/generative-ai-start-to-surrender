<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta content="text/html; charset=utf-8" http-equiv="Content-Type">
<title>VAE Introduction - Generative AI: From Start to Surrender</title>
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<meta name="generator" content="mkdocs-1.6.1, mkdocs-gitbook-1.0.7">

<link rel="shortcut icon" href="../../../images/favicon.ico" type="image/x-icon">
<meta name="HandheldFriendly" content="true"/>
<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="black">
<meta rel="next" href="" />
<link href="../../../css/style.min.css" rel="stylesheet"> 
</head>

<body>
<div class="book">
<div class="book-summary">
<div id="book-search-input" role="search">
<input type="text" placeholder="Type to search" />
</div> <!-- end of book-search-input -->

<nav role="navigation">
<ul class="summary">
<li>
<a href="../../.." target="_blank" class="custom-link">Generative AI: From Start to Surrender</a>
</li>
<li class="divider"></li>
<li class="chapter" data-path="">
<a href="../../..">Home</a>
<li class="header">Introduction</li>

<li>
<a href="../../chapter1_Introduction/1.1terminology/" class="">Terms</a>
</li>

<li>
<a href="../../chapter1_Introduction/1.2fourier_transform/" class="">Fourier Transform</a>
</li>

<li>
<a href="../../chapter1_Introduction/1.3signal_processing/" class="">Signal Processing</a>
</li>

<li>
<a href="../../chapter1_Introduction/1.4statistics/" class="">Statistics</a>
</li>

<li>
<a href="../../chapter1_Introduction/1.5SDE/" class="">SDE</a>
</li>

<li class="header">VAE</li>

<li>
<a href="./" class="active">VAE Introduction</a>
</li>

<li class="header">GANs</li>

<li>
<a href="../../chapter3_GAN/3.2pggan/paper/" class="">PGGAN</a>
</li>

<li>
<a href="../../chapter3_GAN/3.3stylegan/paper/" class="">StyleGAN</a>
</li>

<li>
<a href="../../chapter3_GAN/3.4stylegan2/paper/" class="">StyleGAN2</a>
</li>

<li>
<a href="../../chapter3_GAN/3.5stylegan3/paper/" class="">StyleGAN3</a>
</li>

<li>
<a href="../../chapter3_GAN/3.6styleganT/paper/" class="">StyleGAN T</a>
</li>

<li>
<a href="../../chapter3_GAN/3.7R3Gan/paper/" class="">R3Gan</a>
</li>

<li class="header">Diffusion</li>

<li>
<a href="../../chapter4_diffusion/4.1introduction/" class="">Introduction</a>
</li>

<li>
<a href="../../chapter4_diffusion/4.2DDPM/" class="">DDPM</a>
</li>

<li class="header">Generation Theory</li>

<li>
<a href="../../chapter5_generation_theory/5.1MLE/" class="">Maximal Likelihood</a>
</li>

<li class="divider"></li>



<li><a href="http://www.mkdocs.org">
Published with MkDocs
</a></li>

<li><a href="https://github.com/GitbookIO/theme-default">
Theme by GitBook
</a></li>
</ul>

</nav>

</div> <!-- end of book-summary -->

<div class="book-body">
<div class="body-inner">
<div class="book-header" role="navigation">

<!-- Title -->
<h1>
<i class="fa fa-circle-o-notch fa-spin"></i>
<a href="." ></a>
</h1>

</div> <!-- end of book-header -->

<div class="page-wrapper" tabindex="-1" role="main">
<div class="page-inner">
<div id="book-search-results">
<div class="search-noresults">

<section class="normal markdown-section">



<h1 id="vae">VAE 理论<a class="headerlink" href="#vae" title="Permanent link">&para;</a></h1>
<h2 id="1-p_theta">1. <span class="arithmatex">\(p_\theta\)</span> 为高斯分布<a class="headerlink" href="#1-p_theta" title="Permanent link">&para;</a></h2>
<h3 id="11-variational-autoencoder-vae-p_thetaxz">1.1 Variational Autoencoder (VAE) 中关于 <span class="arithmatex">\(P_\theta(x|z)\)</span> 是高斯分布的假设<a class="headerlink" href="#11-variational-autoencoder-vae-p_thetaxz" title="Permanent link">&para;</a></h3>
<p>在 VAE 的框架中，解码器 <span class="arithmatex">\( P_\theta(x|z) \)</span> 通常被假设为 <strong>高斯分布</strong>。这种假设是 VAE 的基础之一，对模型的重建误差定义和优化目标至关重要。以下是关于这个假设的相关知识。</p>
<hr />
<h3 id="12-p_thetaxz">1.2 为什么假设 <span class="arithmatex">\(P_\theta(x|z)\)</span> 为高斯分布？<a class="headerlink" href="#12-p_thetaxz" title="Permanent link">&para;</a></h3>
<h4 id="121">1.2.1 简化问题<a class="headerlink" href="#121" title="Permanent link">&para;</a></h4>
<ul>
<li>高斯分布是一种连续型概率分布，数学性质良好，易于计算。</li>
<li>对于连续型数据（如图像像素值、音频信号等），高斯分布能很好地拟合大多数数据点的波动特性。</li>
</ul>
<h4 id="122">1.2.2 符合重建误差的定义<a class="headerlink" href="#122" title="Permanent link">&para;</a></h4>
<ul>
<li>高斯分布的对数似然具有以下形式：</li>
</ul>
<p>$$
  \log P_\theta(x|z) = -\frac{|x - \mu_\theta(z)|^2}{2\sigma^2} - \frac{1}{2}\log(2\pi\sigma^2)
  $$</p>
<ul>
<li>这里，<span class="arithmatex">\(\mu_\theta(z)\)</span> 是解码器预测的高斯分布均值，<span class="arithmatex">\(\sigma^2\)</span> 是方差（通常可以假设为常量或由解码器预测）。</li>
<li>
<p>最大化 <span class="arithmatex">\(\log P_\theta(x|z)\)</span> 等价于最小化均方误差（MSE）：</p>
<div class="arithmatex">\[
\|x - \mu_\theta(z)\|^2
\]</div>
</li>
</ul>
<h4 id="123">1.2.3 允许建模数据的不确定性<a class="headerlink" href="#123" title="Permanent link">&para;</a></h4>
<ul>
<li>假设 <span class="arithmatex">\(P_\theta(x|z)\)</span> 为高斯分布，解码器不仅预测重构的均值 <span class="arithmatex">\(\mu_\theta(z)\)</span>，还可以通过方差 <span class="arithmatex">\(\sigma^2_\theta(z)\)</span> 捕捉数据的不确定性。</li>
<li>方差的引入有助于避免过度拟合，尤其是在训练数据存在噪声的情况下。</li>
</ul>
<hr />
<h3 id="13">1.3 数学形式<a class="headerlink" href="#13" title="Permanent link">&para;</a></h3>
<h4 id="131">1.3.1 解码器分布<a class="headerlink" href="#131" title="Permanent link">&para;</a></h4>
<p>在 VAE 中，解码器定义为条件概率分布 <span class="arithmatex">\(P_\theta(x|z)\)</span>，假设为高斯分布：</p>
<div class="arithmatex">\[
P_\theta(x|z) = \mathcal{N}(x; \mu_\theta(z), \sigma_\theta^2(z))
\]</div>
<ul>
<li><span class="arithmatex">\(\mu_\theta(z)\)</span>：解码器预测的重构均值，通常由神经网络建模。</li>
<li><span class="arithmatex">\(\sigma_\theta^2(z)\)</span>：解码器预测的重构方差，可以是固定常量，也可以由网络建模。</li>
</ul>
<hr />
<h2 id="2">2. 其他分布<a class="headerlink" href="#2" title="Permanent link">&para;</a></h2>
<h3 id="21-l_1">2.1 拉普拉斯分布与 <span class="arithmatex">\(L_1\)</span> 范数<a class="headerlink" href="#21-l_1" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>假设分布</strong>:
  <span class="arithmatex">\(P_\theta(x|z) = \text{Laplace}(x; \mu_\theta(z), b)\)</span></li>
<li><strong>对数似然</strong>:</li>
</ul>
<p>$$
  \log P_\theta(x|z) = -\frac{|x - \mu_\theta(z)|_1}{b} - \log(2b)
  $$</p>
<ul>
<li><strong>损失函数</strong>:</li>
</ul>
<p>$$
  L = \frac{1}{b}|x - \mu_\theta(z)|_1
  $$</p>
<ul>
<li><strong>对应形式</strong>: 绝对误差（MAE）。</li>
</ul>
<h3 id="22">2.2 伯努利分布与交叉熵<a class="headerlink" href="#22" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>假设分布</strong>:
  <span class="arithmatex">\(P_\theta(x|z) = \text{Bernoulli}(x; p_\theta(z))\)</span></li>
<li><strong>对数似然</strong>:</li>
</ul>
<p>$$
  \log P_\theta(x|z) = x \log p_\theta(z) + (1-x) \log (1-p_\theta(z))
  $$</p>
<ul>
<li><strong>损失函数</strong>:</li>
</ul>
<p>$$
  L = -[x \log p_\theta(z) + (1-x) \log (1-p_\theta(z))]
  $$</p>
<ul>
<li><strong>对应形式</strong>: 二元交叉熵损失。</li>
</ul>
<h3 id="23">2.3 多项分布与多分类交叉熵<a class="headerlink" href="#23" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>假设分布</strong>:
  <span class="arithmatex">\(P_\theta(x|z) = \text{Categorical}(x; \mathbf{p}_\theta(z))\)</span></li>
<li><strong>对数似然</strong>:</li>
</ul>
<p>$$
  \log P_\theta(x|z) = \sum_i x_i \log p_{\theta,i}(z)
  $$</p>
<ul>
<li><strong>损失函数</strong>:</li>
</ul>
<p>$$
  L = -\sum_i x_i \log p_{\theta,i}(z)
  $$</p>
<ul>
<li><strong>对应形式</strong>: 多分类交叉熵。</li>
</ul>
<h3 id="24">2.4 混合高斯分布<a class="headerlink" href="#24" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>假设分布</strong>:
  <span class="arithmatex">\(P_\theta(x|z) = \sum_k \pi_k \mathcal{N}(x; \mu_k(z), \sigma_k^2(z))\)</span></li>
<li><strong>对数似然</strong>:</li>
</ul>
<p>$$
  \log P_\theta(x|z) = \log \sum_k \pi_k \mathcal{N}(x; \mu_k(z), \sigma_k^2(z))
  $$</p>
<ul>
<li><strong>特点</strong>: 用于多模态数据建模，计算损失需要数值近似。</li>
</ul>
<hr />
<h3 id="25">2.5 总结<a class="headerlink" href="#25" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p><strong>核心思想</strong>:
  损失函数与概率分布的关系为我们提供了统一的视角，用于设计和优化机器学习模型。常见损失函数（如 MSE、MAE、交叉熵）均可以从对应的分布假设中推导而来。</p>
</li>
<li>
<p><strong>实际应用</strong>:
  根据数据特性选择合适的分布假设和损失函数可以提高模型的性能。例如：</p>
</li>
<li>连续值数据适用高斯分布（MSE）。</li>
<li>二值数据适用伯努利分布（交叉熵）。</li>
<li>稀疏数据适用拉普拉斯分布（MAE）。</li>
</ul>
<hr />
<h3 id="26">2.6 相关论文<a class="headerlink" href="#26" title="Permanent link">&para;</a></h3>
<ol>
<li><strong>《Auto-Encoding Variational Bayes》</strong></li>
<li><strong>作者</strong>: Kingma, D.P., Welling, M.</li>
<li><strong>链接</strong>: <a href="https://arxiv.org/abs/1312.6114">https://arxiv.org/abs/1312.6114</a></li>
<li>
<p><strong>内容</strong>: 提出变分自编码器（VAE），推导出重建误差项与分布假设的关系。</p>
</li>
<li>
<p><strong>《Hybridised Loss Functions for Improved Neural Network Generalisation》</strong></p>
</li>
<li><strong>作者</strong>: Matthew C. Malan 等</li>
<li><strong>链接</strong>: <a href="https://arxiv.org/abs/2204.12241">https://arxiv.org/abs/2204.12241</a></li>
<li>
<p><strong>内容</strong>: 探讨交叉熵和均方误差的混合损失及其影响。</p>
</li>
<li>
<p><strong>《p-Huber损失函数及其鲁棒性研究》</strong></p>
</li>
<li><strong>作者</strong>: 余博天</li>
<li><strong>链接</strong>: <a href="https://pdf.hanspub.org/AAM20201200000_75579140.pdf">https://pdf.hanspub.org/AAM20201200000_75579140.pdf</a></li>
<li><strong>内容</strong>: 研究 p-Huber 损失在有噪声数据中的表现。</li>
</ol>


</section>
</div> <!-- end of search-noresults -->
<div class="search-results">
<div class="has-results">

<h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
<ul class="search-results-list"></ul>

</div> <!-- end of has-results -->
<div class="no-results">

<h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>

</div> <!-- end of no-results -->
</div> <!-- end of search-results -->
</div> <!-- end of book-search-results -->

</div> <!-- end of page-inner -->
</div> <!-- end of page-wrapper -->

</div> <!-- end of body-inner -->

</div> <!-- end of book-body -->
<script src="../../../js/main.js"></script>
<script src="../../../javascripts/mathjax.js"></script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<script src="../../../search/main.js"></script>
<script src="../../../js/gitbook.min.js"></script>
<script src="../../../js/theme.min.js"></script>
</body>
</html>