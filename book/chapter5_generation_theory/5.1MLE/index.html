<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta content="text/html; charset=utf-8" http-equiv="Content-Type">
<title>Maximal Likelihood - Generative AI: From Start to Surrender</title>
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<meta name="generator" content="mkdocs-1.6.1, mkdocs-gitbook-1.0.7">

<link rel="shortcut icon" href="../../../images/favicon.ico" type="image/x-icon">
<meta name="HandheldFriendly" content="true"/>
<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="black">
<meta rel="next" href="" />
<link href="../../../css/style.min.css" rel="stylesheet"> 
</head>

<body>
<div class="book">
<div class="book-summary">
<div id="book-search-input" role="search">
<input type="text" placeholder="Type to search" />
</div> <!-- end of book-search-input -->

<nav role="navigation">
<ul class="summary">
<li>
<a href="../../.." target="_blank" class="custom-link">Generative AI: From Start to Surrender</a>
</li>
<li class="divider"></li>
<li class="chapter" data-path="">
<a href="../../..">Home</a>
<li class="header">Introduction</li>

<li>
<a href="../../chapter1_Introduction/1.1terminology/" class="">Terms</a>
</li>

<li>
<a href="../../chapter1_Introduction/1.2fourier_transform/" class="">Fourier Transform</a>
</li>

<li>
<a href="../../chapter1_Introduction/1.3signal_processing/" class="">Signal Processing</a>
</li>

<li>
<a href="../../chapter1_Introduction/1.4statistics/" class="">Statistics</a>
</li>

<li>
<a href="../../chapter1_Introduction/1.5SDE/" class="">SDE</a>
</li>

<li class="header">VAE</li>

<li>
<a href="../../chapter2_VAE/2.1introduction/" class="">VAE Introduction</a>
</li>

<li class="header">GANs</li>

<li>
<a href="../../chapter3_GAN/3.2pggan/paper/" class="">PGGAN</a>
</li>

<li>
<a href="../../chapter3_GAN/3.3stylegan/paper/" class="">StyleGAN</a>
</li>

<li>
<a href="../../chapter3_GAN/3.4stylegan2/paper/" class="">StyleGAN2</a>
</li>

<li>
<a href="../../chapter3_GAN/3.5stylegan3/paper/" class="">StyleGAN3</a>
</li>

<li>
<a href="../../chapter3_GAN/3.6styleganT/paper/" class="">StyleGAN T</a>
</li>

<li>
<a href="../../chapter3_GAN/3.7R3Gan/paper/" class="">R3Gan</a>
</li>

<li class="header">Diffusion</li>

<li>
<a href="../../chapter4_diffusion/4.1introduction/" class="">Introduction</a>
</li>

<li>
<a href="../../chapter4_diffusion/4.2DDPM/" class="">DDPM</a>
</li>

<li class="header">Generation Theory</li>

<li>
<a href="./" class="active">Maximal Likelihood</a>
</li>

<li class="divider"></li>



<li><a href="http://www.mkdocs.org">
Published with MkDocs
</a></li>

<li><a href="https://github.com/GitbookIO/theme-default">
Theme by GitBook
</a></li>
</ul>

</nav>

</div> <!-- end of book-summary -->

<div class="book-body">
<div class="body-inner">
<div class="book-header" role="navigation">

<!-- Title -->
<h1>
<i class="fa fa-circle-o-notch fa-spin"></i>
<a href="." ></a>
</h1>

</div> <!-- end of book-header -->

<div class="page-wrapper" tabindex="-1" role="main">
<div class="page-inner">
<div id="book-search-results">
<div class="search-noresults">

<section class="normal markdown-section">



<h1 id="_1">最大似然估计</h1>
<h2 id="_2">生成模型可以根据其目标和方法分类</h2>
<table>
<thead>
<tr>
<th>模型类别</th>
<th>目标</th>
<th>典型模型</th>
<th>应用领域</th>
</tr>
</thead>
<tbody>
<tr>
<td>GAN</td>
<td>最小分布距离</td>
<td>GAN DCGAN、StyleGAN、BigGAN</td>
<td>图像生成</td>
</tr>
<tr>
<td>隐变量模型</td>
<td>最大化对数似然</td>
<td>VAE, PixelVAE</td>
<td>图像生成、序列生成</td>
</tr>
<tr>
<td>概率密度估计</td>
<td>最大化对数似然</td>
<td>Normalizing Flow, Energy-Based Models</td>
<td>密度估计、图像生成</td>
</tr>
<tr>
<td>逐步最大似然估计模型</td>
<td>逐步最大化对数似然</td>
<td>DDPM、Latent Diffusion Models (LDM)</td>
<td>图像生成、补全、超分辨率</td>
</tr>
<tr>
<td>自回归模型</td>
<td>最大化条件对数似然</td>
<td>自回归模型</td>
<td>图像生成、补全、超分辨率</td>
</tr>
<tr>
<td>几何/物理约束模型</td>
<td>最小化重建误差</td>
<td>NeRF, DeepSDF</td>
<td>三维建模、视点合成</td>
</tr>
<tr>
<td>规则/统计生成模型</td>
<td>基于规则或经验</td>
<td>Procedural Generation, SMOTE</td>
<td>数据增强、生成纹理</td>
</tr>
<tr>
<td>离散生成模型</td>
<td>离散最大似然估计</td>
<td>GPT, Transformer</td>
<td>文本生成、代码生成</td>
</tr>
<tr>
<td>稀疏/压缩生成模型</td>
<td>稀疏表示或压缩后重建</td>
<td>Sparse Coding, Autoencoders</td>
<td>特征提取、数据压缩</td>
</tr>
<tr>
<td>混合生成模型</td>
<td>结合多个生成目标</td>
<td>VAE-GAN, Diffusion-GAN</td>
<td>图像生成、高质量数据生成</td>
</tr>
</tbody>
</table>
<p>主要生成任务使用的方法</p>
<table>
<thead>
<tr>
<th>数据类型</th>
<th>常用方法</th>
<th>特点</th>
<th>典型模型</th>
</tr>
</thead>
<tbody>
<tr>
<td>图像生成</td>
<td>GAN、扩散模型、VAE、自回归模型</td>
<td>生成质量高，适合单帧图像生成，多样性和控制性视模型而定</td>
<td>StyleGAN、DDPM、PixelCNN</td>
</tr>
<tr>
<td>语音生成</td>
<td>自回归模型、谱图生成、GAN、扩散模型</td>
<td>高保真语音生成，常结合声码器完成端到端生成</td>
<td>WaveNet、Tacotron、HiFi-GAN、DiffWave</td>
</tr>
<tr>
<td>视频生成</td>
<td>GAN、自回归模型、扩散模型、混合模型</td>
<td>视频生成需要考虑时间一致性，模型更复杂，生成质量依赖于时间和空间的建模能力</td>
<td>MoCoGAN、VideoGPT、Video Diffusion Models</td>
</tr>
</tbody>
</table>
<p>接下来我们主要介绍在最小距离分布和最大似然估计的框架下，怎么统一解释不同的生成模型。同时最大似然估计是最小分布距离的一种特例，我们其实可以在”最小距离分布“这个统一的框架下来解释生成方法的原理。</p>
<p>记住这个公式，最大似然估计的表达式</p>
<div class="arithmatex">\[
 \int_{x\sim p_{\text {data }}} p_{\text {data }}(x) \log p_{\theta}(x) d x
\]</div>
<p>从离散的角度，最大似然估计表示为</p>
<div class="arithmatex">\[
 \sum_{x\sim p_{\text {data }}}  \log p_{\theta}(x)
\]</div>
<hr />
<h2 id="1-mlp">定理1. MLP 是最小化分布差异的特定形式</h2>
<p><strong>证明</strong>:
先说明结论：两个分布间的“距离”可以用不同的指标来衡量（如 KL 散度、Jensen-Shannon 散度、Wasserstein 距离等）。MLE 的目标是最小化 KL 散度：</p>
<div class="arithmatex">\[
D_{\text{KL}}(p_{\text{data}} || p_\theta)
\]</div>
<p>因此，MLE 可以被认为是以 <strong>KL 散度</strong>  作为距离衡量标准的特例。
下面我们只要证明MLP目标等价于优化KL散度就行。</p>
<p>其中</p>
<div class="arithmatex">\[D_{\mathrm{KL}}\left(p_{\text {data }} \| p_\theta\right)=\int p_{\text {data }}(x) \log \frac{p_{\text {data }}(x)}{p_\theta(x)} d x\]</div>
<p>展开为</p>
<div class="arithmatex">\[D_{\mathrm{KL}}\left(p_{\text {data }} \| p_\theta\right)=\int p_{\text {data }}(x) \log p_{\text {data }}(x) d x-\int p_{\text {data }}(x) \log p_\theta(x) d x\]</div>
<p>第一项和<span class="arithmatex">\(\theta\)</span> 也就是模型无关，因此可以忽略。第二项和<span class="arithmatex">\(\theta\)</span>有关，因此可以看成KL的目标。</p>
<p>另外MLE的原始定义为</p>
<div class="arithmatex">\[
\theta^*=\arg \max_{\theta} L_{\theta}  \\
== \arg\max_{\theta} E_{x \sim p_{\text {data }}}[\log p_{\theta}(x)]\\
= \arg\min_{\theta} - \int p_{\text {data }}(x) \log p_{\theta}(x) d x
\]</div>
<hr />
<p>从这个角度从新不同的生成模型，包括VAE, GAN, Diffusion等等，它们的目标都是最小化生成分布和原始数据分布的差异(距离)的最小化。</p>
<hr />
<h2 id="2gan">定理2：gan的优化目标等价最小化分布距离</h2>
<p>GAN的目的是最小化分布差异，其中vanila GAN的目的是最小化两个分布之间的JSD散度, WGAN的目的是最小化连个分布之前的Wasserstein距离</p>
<p><strong>证明</strong>：</p>
<hr />
<p><strong>1. Vanilla GAN 的优化目标与 Jensen-Shannon 散度</strong></p>
<p><strong>1.1 GAN 的优化目标</strong></p>
<p>GAN 的目标函数由生成器 <span class="arithmatex">\(G\)</span> 和判别器 <span class="arithmatex">\(D\)</span> 的对抗博弈组成：$
 \min_G \max_D \mathbb{E}<em>{x \sim p</em>{\text{data}}} [\log D(x)] + \mathbb{E}_{z \sim p(z)} [\log (1 - D(G(z)))]
$</p>
<p>其中：</p>
<ul>
<li>
<p><span class="arithmatex">\(p_{\text{data}}(x)\)</span>：真实数据分布。</p>
</li>
<li>
<p><span class="arithmatex">\(p_\theta(x) = G(z)\)</span>：生成分布。</p>
</li>
</ul>
<p><strong>1.2 判别器的优化</strong></p>
<p>对于固定的生成器 <span class="arithmatex">\(G\)</span>，判别器 <span class="arithmatex">\(D\)</span> 的目标是最大化：</p>
<div class="arithmatex">\[
 \mathcal{L}(D) = \mathbb{E}_{x \sim p_{\text{data}}} [\log D(x)] + \mathbb{E}_{x \sim p_\theta} [\log (1 - D(x))]
\]</div>
<p>优化 <span class="arithmatex">\(D(x)\)</span>：</p>
<p>假设 <span class="arithmatex">\(D(x)\)</span> 输出的值是 <span class="arithmatex">\(D(x) \in [0, 1]\)</span>，对其求导并找到最优解</p>
<div class="arithmatex">\[
D^*(x) = \frac{p_{\text{data}}(x)}{p_{\text{data}}(x) + p_\theta(x)}
\]</div>
<p>此时最优判别器 <span class="arithmatex">\(D^*(x)\)</span> 表示输入样本来自真实分布的概率。</p>
<p><strong>1.3 将最优判别器代入损失</strong></p>
<p>将 <span class="arithmatex">\(D^*(x)\)</span> 代入 GAN 的目标函数，得到生成器的优化目标：</p>
<div class="arithmatex">\[
 \min_G \max_D \mathcal{L}(D) = \mathbb{E}*{x \sim p*{\text{data}}} \left[\log \frac{p_{\text{data}}(x)}{p_{\text{data}}(x) + p_\theta(x)} \right] + \mathbb{E}*{x \sim p*\theta} \left[\log \frac{p_\theta(x)}{p_{\text{data}}(x) + p_\theta(x)} \right]
\]</div>
<p>化简：</p>
<div class="arithmatex">\[
 \mathcal{L}(G) = -\log(4) + 2 \cdot D_{\text{JS}}(p_{\text{data}} || p_\theta)
\]</div>
<p>其中 <span class="arithmatex">\(D_{\text{JS}}\)</span> 是 <strong>Jensen-Shannon 散度</strong> ，定义为：</p>
<div class="arithmatex">\[
 D_{\text{JS}}(p_{\text{data}} || p_\theta) = \frac{1}{2} D_{\text{KL}}(p_{\text{data}} || m) + \frac{1}{2} D_{\text{KL}}(p_\theta || m)
\]</div>
<p><span class="arithmatex">\(m = \frac{1}{2}(p_{\text{data}} + p_\theta)\)</span>。<strong>结论：</strong>
Vanilla GAN 的优化目标是最小化生成分布和数据分布之间的 Jensen-Shannon 散度。</p>
<hr />
<p><strong>2. WGAN 的优化目标与 Wasserstein 距离</strong> <strong>2.1 WGAN 的目标函数</strong></p>
<p>WGAN 的目标函数是：</p>
<div class="arithmatex">\[
 \mathcal{L}(G, D) = \min_G \max_{D \in \text{Lip-1}} \mathbb{E}_{x \sim p_{\text{data}}} [D(x)] - \mathbb{E}_{x \sim p_\theta} [D(x)]
\]</div>
<p><strong>2.1 约束条件：</strong></p>
<ul>
<li>
<p>判别器 <span class="arithmatex">\(D(x)\)</span> 不再输出概率，而是标量值。</p>
</li>
<li>
<p><span class="arithmatex">\(D(x)\)</span> 是 1-Lipschitz 连续函数，即满足 <span class="arithmatex">\(|D(x_1) - D(x_2)| \leq \|x_1 - x_2\|\)</span>。</p>
</li>
</ul>
<p><strong>2.2 Wasserstein 距离定义</strong> Wasserstein 距离（<span class="arithmatex">\(W_1\)</span> 距离）定义为：</p>
<div class="arithmatex">\[
 W_1(p_{\text{data}}, p_\theta) = \inf_{\gamma \in \Pi(p_{\text{data}}, p_\theta)} \mathbb{E}_{(x, y) \sim \gamma} [\|x - y\|]
\]</div>
<p>其中 <span class="arithmatex">\(\Pi(p_{\text{data}}, p_\theta)\)</span> 是所有使边缘分布为 <span class="arithmatex">\(p_{\text{data}}\)</span> 和 <span class="arithmatex">\(p_\theta\)</span> 的联合分布。
根据 Kantorovich-Rubinstein 对偶性，Wasserstein 距离可以重写为：</p>
<div class="arithmatex">\[
 W_1(p_{\text{data}}, p_\theta) = \sup_{\|D\|_L \leq 1} \mathbb{E}_{x \sim p_{\text{data}}} [D(x)] - \mathbb{E}_{x \sim p_\theta} [D(x)]
\]</div>
<p><strong>3. 总结</strong></p>
<ul>
<li>
<p><strong>Vanilla GAN：</strong>  判别器 <span class="arithmatex">\(D\)</span> 输出的是概率，优化目标是最小化生成分布和真实分布的 Jensen-Shannon 散度（JSD）。</p>
</li>
<li>
<p><strong>WGAN：</strong>  判别器 <span class="arithmatex">\(D\)</span> 输出的是标量值，优化目标是最小化生成分布和真实分布的 Wasserstein 距离（<span class="arithmatex">\(W_1\)</span>）。</p>
</li>
<li>
<p><strong>两者的本质：</strong>  都在通过不同的分布差异度量指标优化生成分布 <span class="arithmatex">\(p_\theta(x)\)</span> 逼近真实数据分布 <span class="arithmatex">\(p_{\text{data}}(x)\)</span>。</p>
</li>
</ul>
<p><strong>4. 备注</strong></p>
<p>在wgan 中为什么出现了Lipschitz 条件。这是因为 Kantorovich-Rubinstein 对偶性要求目标函数 <span class="arithmatex">\(𝑓(𝑥)\)</span> 是 1-Lipschitz 函数。如果没有这个条件，Wasserstein 距离无法通过对偶形式计算。
在 WGAN 中，判别器 D(x) 实际上是 f(x) 的实现，因此需要满足 Lipschitz 连续性，保证优化目标与 Wasserstein 距离的数学定义一致。</p>
<hr />
<p>从另外一个角度说明：判别器<span class="arithmatex">\(D\)</span>的作用可能不一致，但是D的loss 都表示了两个分布之间的距离，分别是JSD 散度和Wasserstein 距离。优化<span class="arithmatex">\(D\)</span> 的作用及时让这个Loss 尽量准确模拟出两个分布之间的距离。如果把这个loss <span class="arithmatex">\(L_\theta(x,y)\)</span> 作为一个函数看待,它在训练过程中学习的就是两个分布之间的距离的近似。</p>
<p>当然在上面的分析中，我们是知道了GAN的实现，然后证明了它的作用。</p>
<p>理论上我们衡量两个分布之间的距离有不同的选择，那在"GAN"的设计中，我们就可以根据不同的距离选择可以让我们去设计不同的D和D的loss。</p>
<p>那么假设我们想要用KL 散度去衡量两个分布之间的距离，那是不是可以设计出相应的loss。
答案是肯定的，</p>
<p>我们可以推导出对特定散度的优化近似于
<span class="arithmatex">\(\min _\theta \max _\omega F(\theta, \omega)=\mathbb{E}_{x \sim P}\left[T_\omega(x)\right]-\mathbb{E}_{x \sim Q_\theta}\left[f^*\left(T_\omega(x)\right)\right]\)</span>.</p>
<p>从而KL散度对应的loss 则为</p>
<div class="arithmatex">\[E_{x\sim P}\left[\log D(x)\right]-E_{x\sim Q_\theta}\left[\log D(x)\right]\]</div>
<p>参考这个论文 <a href="https://arxiv.org/pdf/1606.00709">https://arxiv.org/pdf/1606.00709</a> 了解更多散度对应的loss</p>
<h3 id="_3">广泛含义上的分布之间的衡量设计</h3>
<table>
<thead>
<tr>
<th>距离衡量方法</th>
<th>GAN 类型</th>
<th>优势</th>
<th>劣势</th>
<th>论文链接</th>
</tr>
</thead>
<tbody>
<tr>
<td>Jensen-Shannon 散度</td>
<td>Vanilla GAN</td>
<td>理论基础清晰，目标明确</td>
<td>梯度消失，模式崩溃</td>
<td><a href="https://arxiv.org/abs/1406.2661">Generative Adversarial Nets</a></td>
</tr>
<tr>
<td>Wasserstein 距离</td>
<td>WGAN</td>
<td>更稳定的训练过程，有意义的梯度</td>
<td>计算代价高，需强制 Lipschitz 条件</td>
<td><a href="https://arxiv.org/abs/1701.07875">Wasserstein GAN</a></td>
</tr>
<tr>
<td>f-散度</td>
<td>f-GAN</td>
<td>灵活的散度选择，适应不同任务需求</td>
<td>需选择合适的 f-散度</td>
<td><a href="https://arxiv.org/abs/1606.00709">f-GAN: Training Generative Neural Samplers using Variational Divergence Minimization</a></td>
</tr>
<tr>
<td>MMD（最大均值差异）</td>
<td>MMD-GAN</td>
<td>核函数灵活，高维数据表现优越</td>
<td>核函数选择影响性能</td>
<td><a href="https://arxiv.org/abs/1705.08584">MMD GAN: Towards Deeper Understanding of Moment Matching Network</a></td>
</tr>
<tr>
<td>Sliced Wasserstein 距离</td>
<td>Sliced-WGAN</td>
<td>改善高维数据的训练稳定性</td>
<td>需要选择适当的投影方向</td>
<td><a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Deshpande_Max-Sliced_Wasserstein_Distance_and_Its_Use_for_GANs_CVPR_2019_paper.pdf">Max-Sliced Wasserstein Distance and Its Use for GANs</a></td>
</tr>
<tr>
<td>Sobolev 距离</td>
<td>Sobolev GAN</td>
<td>放宽 Lipschitz 条件，提高训练灵活性</td>
<td>理论复杂性增加</td>
<td><a href="https://arxiv.org/abs/2012.03420">Towards Generalized Implementation of Wasserstein Distance in GANs</a></td>
</tr>
</tbody>
</table>
<hr />
<h2 id="3-vae">定理3: VAE 是对最大似然的优化</h2>
<p>证明</p>
<ol>
<li>连续分布的最大似然估计目标</li>
</ol>
<p>对于观测数据的概率分布 <span class="arithmatex">\(p_{\text{data}}(x)\)</span>，最大似然估计的目标是最大化数据分布下模型 <span class="arithmatex">\(p_\theta(x)\)</span> 的对数似然：</p>
<div class="arithmatex">\[
 \int_{x \sim p_{\text{data}}} p_{\text{data}}(x) \log p_\theta(x) \, dx
\]</div>
<p>这里我们需要找到一种办法去表达或者近似 <span class="arithmatex">\(p_\theta(x)\)</span>。 这是关键的一部分。 对于隐变量生成模型而言，会有一个<span class="arithmatex">\(z\)</span> 和<span class="arithmatex">\(X\)</span>的对应关系，</p>
<p>我们可以写成 <span class="arithmatex">\(p_\theta(x) = \int p_\theta(x, z) \, dz\)</span> 包含对隐变量 <span class="arithmatex">\(z\)</span> 的积分。再对<span class="arithmatex">\(z\)</span> 做一些假设，可能就会简化求解的过程。</p>
<ol>
<li>重写边缘似然</li>
</ol>
<p>对于单个数据点 <span class="arithmatex">\(x\)</span>，观测数据的边缘对数似然可以写为：</p>
<div class="arithmatex">\[
 \log p_\theta(x) = \log \int p_\theta(x, z) \, dz
\]</div>
<p>利用联合分布的分解 <span class="arithmatex">\(p_\theta(x, z) = p_\theta(x \mid z) p(z)\)</span>，我们有：</p>
<div class="arithmatex">\[
 \log p_\theta(x) = \log \int p_\theta(x \mid z) p(z) \, dz
\]</div>
<p>直接优化这个目标通常很困难，因为积分 <span class="arithmatex">\(\int p_\theta(x \mid z)p(z) dz\)</span> 对于高维 <span class="arithmatex">\(z\)</span> 不可解析。</p>
<ol>
<li>引入变分分布 <span class="arithmatex">\(q_\phi(z \mid x)\)</span>为了解决积分不可解析的问题</li>
</ol>
<p>引入一个近似后验分布 <span class="arithmatex">\(q_\phi(z \mid x)\)</span>，用于近似真实后验 <span class="arithmatex">\(p_\theta(z \mid x)\)</span>。我们可以通过以下分解重新表示 <span class="arithmatex">\(\log p_\theta(x)\)</span>：</p>
<div class="arithmatex">\[
 \log p_\theta(x) = \mathbb{E}_{q_\phi(z \mid x)} \left[ \log \frac{p_\theta(x, z)}{q_\phi(z \mid x)} \right] + \mathrm{KL}(q_\phi(z \mid x) \| p_\theta(z \mid x))
\]</div>
<p>证明细节请看 <a href="../../chapter1_Introduction/1.4statistics/#elbo">ELBP证明</a>。ELBO也可以由凸函数的性质利用 Jensen's inequality直接推导出不等式(https://en.wikipedia.org/wiki/Evidence_lower_bound).</p>
<p>其中：</p>
<ul>
<li>
<p>第一项是变分下界（Evidence Lower Bound, ELBO)),我们可以优化它来间接优化 <span class="arithmatex">\(\log p_\theta(x)\)</span>。</p>
</li>
<li>
<p>第二项是 KL 散度，表示近似后验 <span class="arithmatex">\(q_\phi(z \mid x)\)</span> 与真实后验 <span class="arithmatex">\(p_\theta(z \mid x)\)</span> 的差距。</p>
</li>
</ul>
<p>由于 KL 散度总是非负：<span class="arithmatex">\(\mathrm{KL}(q_\phi(z \mid x) \| p_\theta(z \mid x)) \geq 0\)</span>，所以：<span class="arithmatex">\(\log p_\theta(x) \geq \mathcal{L}(\theta, \phi; x)\)</span>, 其中<span class="arithmatex">\(L\)</span> 表示变分下界,也就是 ELBO，为上式的第一项。</p>
<ol>
<li>. 变分下界（ELBO, 设为 $ \mathcal{L}$）的分解</li>
</ol>
<p>变分下界的具体形式为：</p>
<div class="arithmatex">\[
 \mathcal{L}(\theta, \phi; x) = \mathbb{E}_{q_\phi(z \mid x)} \left[ \log p_\theta(x, z) - \log q_\phi(z \mid x) \right]
\]</div>
<p>进一步分解联合概率 <span class="arithmatex">\(p_\theta(x, z) = p_\theta(x \mid z)p(z)\)</span>，得到：</p>
<div class="arithmatex">\[
 \mathcal{L}(\theta, \phi; x) = \mathbb{E}_{q_\phi(z \mid x)} \left[ \log p_\theta(x \mid z) \right] - \mathrm{KL}(q_\phi(z \mid x) \| p(z))
\]</div>
<ul>
<li><strong>第一项</strong>  <span class="arithmatex">\(\mathbb{E}_{q_\phi(z \mid x)} [\log p_\theta(x \mid z)]\)</span>：重构误差（Reconstruction Error），鼓励生成器能够生成接近真实数据 <span class="arithmatex">\(x\)</span> 的分布。 这个没法直接计算。如果用蒙特卡洛采样的话，也需要有 <span class="arithmatex">\(p_\theta(z|x)\)</span>的值，但是这个值也是不可解析的。 因此在原始的论文里，假设 <span class="arithmatex">\(p_\theta(z|x)\)</span>是一个高斯分布，这样就可以计算。</li>
</ul>
<p>如果我们假设 <span class="arithmatex">\(p_\theta(x|z)\)</span> 是高斯分布：$
  p_\theta(x|z) = \mathcal{N}(\hat{x}, \sigma^2 I),
  $
  其中 <span class="arithmatex">\(\hat{x}\)</span> 是解码器生成的均值，<span class="arithmatex">\(\sigma^2\)</span> 是固定方差。
  对数似然展开：</p>
<p>$$
  \log p_\theta(x|z) = \log \mathcal{N}(x; \hat{x}, \sigma^2 I) = -\frac{1}{2} \left( \frac{|x - \hat{x}|^2}{\sigma^2} + d \log(2\pi\sigma^2) \right),
  $$</p>
<p>其中 <span class="arithmatex">\(d\)</span> 是 <span class="arithmatex">\(x\)</span> 的维度。</p>
<p>重构误差等价于负对数似然，忽略常数项后为：</p>
<p>$$
  \mathbb{E}<em>{q</em>\phi(z|x)}[-\log p_\theta(x|z)] \propto \mathbb{E}<em>{q</em>\phi(z|x)}[|x - \hat{x}|^2].
  $$</p>
<ol>
<li>重建误差简化为 <span class="arithmatex">\(|x - \hat{x}|\)</span><strong> 在具体实现中，通常假设方差 <span class="arithmatex">\(\sigma^2 = 1\)</span> 且重建误差仅考虑均值估计，此时：</strong></li>
</ol>
<p>$$
  \mathbb{E}<em>{q</em>\phi(z|x)}[|x - \hat{x}|^2] \approx |x - \hat{x}|^2,
  $$</p>
<p>对应的差项为 <span class="arithmatex">\(|x - \hat{x}|\)</span> 或其平方形式。</p>
<p>当然如果我们假设 <span class="arithmatex">\(p_\theta(x|z)\)</span> 是属于其他分布，那就会导出不同的重构误差。更进一步，对于任意一个重建差的度量，其实都对应着一个<span class="arithmatex">\(p_\theta(x|z)\)</span>, 这个可以由度量函数去构建一个密度函数。
  具体，查看 <a href="../../chapter2_VAE/2.1introduction/">VAE: introduction</a></p>
<ul>
<li>
<p><strong>第二项</strong>  <span class="arithmatex">\(\mathrm{KL}(q_\phi(z \mid x) \| p(z))\)</span>：正则化项，约束 <span class="arithmatex">\(q_\phi(z \mid x)\)</span> 的分布接近先验 <span class="arithmatex">\(p(z)\)</span>。</p>
</li>
<li>
<p>最终形式（VAE 损失函数）
为了优化上述目标，我们需要进行采样 <span class="arithmatex">\(z \sim q_\phi(z \mid x)\)</span>。为了解决采样过程中不可微的问题，使用 <strong>重参数化技巧（Reparameterization Trick）</strong> ：将 <span class="arithmatex">\(q_\phi(z \mid x)\)</span> 定义为高斯分布 <span class="arithmatex">\(\mathcal{N}(\mu_\phi(x), \sigma_\phi(x)^2)\)</span>，通过如下方式采样：$
 z = \mu_\phi(x) + \sigma_\phi(x) \odot \epsilon, \quad \epsilon \sim \mathcal{N}(0, I)
$</p>
</li>
</ul>
<p>最终，VAE 的损失函数可以表示为：</p>
<div class="arithmatex">\[
 \mathcal{L}(\theta, \phi; x) = \mathbb{E}_{z \sim q_\phi(z \mid x)} [\log p_\theta(x \mid z)] - \mathrm{KL}(q_\phi(z \mid x) \| p(z))
\]</div>
<p>这对应于：</p>
<ol>
<li>
<p><strong>重构误差</strong> ：通过生成分布 <span class="arithmatex">\(p_\theta(x \mid z)\)</span> 学习如何生成数据。</p>
</li>
<li>
<p><strong>KL 散度正则化</strong> ：约束潜变量分布。</p>
</li>
</ol>
<p>优化该目标，即实现从最大似然估计到 VAE 的转化。</p>
<p>从这里我们也能看到，VAE和通常的神经网络构造不一样，它预测的时一个分布，不管编码器还是解码器，预测的都是一个分布。更精确得来说，最初的VAE 编码器预测的时高斯分布的mean 和variance， 解码器预测的时高斯分布的mean。但在实际应用时，我们使用VAE 进行重建时，直接使用的就是这个mean，因此忽略掉了其实decoder 也是本质上预测的是mean.</p>
<p>实际的VAE过程
<img alt="alt text" src="../../../images/image-19.png" /></p>
<p>对于VAE而言，第一项的计算是等价于重建loss 的，关键是第二项需要怎么设计。不同的设计可能就以为着不同的方法。</p>
<p>这里我们列举了一系列对第二项计算的改进方法</p>
<table>
<thead>
<tr>
<th>方法</th>
<th>描述</th>
<th>优点</th>
<th>缺点</th>
<th>适用场景</th>
</tr>
</thead>
<tbody>
<tr>
<td>标准高斯 VAE</td>
<td>假设 <span class="arithmatex">\(q_\phi(z \mid x)\)</span>为高斯分布，编码器输出均值和方差。</td>
<td>简单高效，可解析计算 KL 散度。</td>
<td>表达能力有限，无法处理复杂分布。</td>
<td>常规任务，数据分布简单。</td>
</tr>
<tr>
<td>高斯混合 VAE</td>
<td>假设 <span class="arithmatex">\(q_\phi(z \mid x)\)</span> 是混合高斯分布（多个高斯成分）。</td>
<td>能够捕捉多模态分布，更适合复杂数据分布。</td>
<td>增加计算复杂度，需要估计更多参数。</td>
<td>多模态数据建模，例如聚类或分类任务。</td>
</tr>
<tr>
<td>正态化流 VAE</td>
<td>用一系列可逆变换构造 <span class="arithmatex">\(q_\phi(z \mid x)\)</span>，提高后验分布的灵活性。</td>
<td>后验分布更灵活，适合复杂分布建模。</td>
<td>增加计算复杂度，需要设计合理的流模型。</td>
<td>高维复杂分布的表示和建模。</td>
</tr>
<tr>
<td>离散 VAE</td>
<td>假设潜变量是离散变量，用 Gumbel-Softmax 技巧实现可微优化。</td>
<td>适合离散潜变量空间（如分类或文本生成）。</td>
<td>无法捕捉连续分布的细节，对温度参数<span class="arithmatex">\(\tau\)</span>敏感。</td>
<td>离散数据生成或分类任务。</td>
</tr>
<tr>
<td>能量模型 VAE</td>
<td>用能量函数定义 <span class="arithmatex">\(q_\phi(z \mid x)\)</span>,如<span class="arithmatex">\(q_\phi(z \mid x) \propto \exp(-E_\phi(x, z))\)</span>，并通过 MCMC 采样。</td>
<td>非参数化，能够灵活建模复杂分布。</td>
<td>采样效率较低，计算成本较高。</td>
<td>高度复杂或未知分布建模。</td>
</tr>
<tr>
<td>对抗式 VAE (AAE)</td>
<td>用 GAN 的对抗学习替代 KL 散度正则化，判别器用于匹配 <span class="arithmatex">\(q_\phi(z)\)</span> 和 <span class="arithmatex">\(p(z)\)</span>。</td>
<td>不需要显式计算 KL 散度，适合复杂分布。</td>
<td>对抗训练可能不稳定，需要精心调试。</td>
<td>复杂数据分布生成任务。</td>
</tr>
<tr>
<td>β-VAE</td>
<td>在 VAE 损失中增加 KL 散度的权重 <span class="arithmatex">\(1\beta &gt; 1\)</span>，强调潜变量的压缩性和解耦性。</td>
<td>提高潜变量的表示质量，更适合表征学习任务。</td>
<td>可能导致重构性能下降，平衡重构和正则化较难。</td>
<td>表征学习，特征解耦（如生成 disentangled 表示）。</td>
</tr>
<tr>
<td>层次化 VAE</td>
<td>引入多个层次的潜变量，例如 $z_1 \sim q_\phi(z_1 \mid x), z_2 \sim q_\phi(z_2 \mid z_1) $，捕捉分布的层次特性。</td>
<td>能够更好地表示复杂数据分布的层次关系。</td>
<td>增加模型复杂度，训练更困难。</td>
<td>高维复杂数据，例如图像或自然语言处理任务。</td>
</tr>
</tbody>
</table>
<p><strong>总结</strong></p>
<p>对于VAE，直观上看，因为直接估计 <span class="arithmatex">\(p_\theta(x)\)</span> 是比较困难的，因此引入分布 <span class="arithmatex">\(q_\phi(z)\)</span>，根据 <span class="arithmatex">\(p_\theta(x) = \int_z p_\theta(x, z) \, dz= \int_z p_\theta(x|z) p(z) \, dz\)</span> 来计算 <span class="arithmatex">\(p_\theta(x)\)</span>。</p>
<p>我们可以选一个<span class="arithmatex">\(p(z)\)</span> 比较好计算的分布来简化问题。到这一步，仍然没有办法计算。因此论文里有两个比较重要的假设，</p>
<ol>
<li><span class="arithmatex">\(q_\phi(z|x)\)</span> 服从正态分布</li>
<li><span class="arithmatex">\(p_\theta(x|z)\)</span> 服从正态分布</li>
</ol>
<p>根据这两个假设从而使得loss 可以计算。第2个假设可以理解成，我们没有办法假设 <span class="arithmatex">\(p_\theta(x)\)</span> 服从正态分布，因此弱化一下条件, 那 <span class="arithmatex">\(p_\theta(x)\)</span> 相当于混合高斯分布（离散和的极限形式),从这个形式上这个假设是存在合理性的，最终的分布也是能满足多样性的要求。</p>
<p>值得注意的是，这里VAE 都是在极大似然估计的情况下进行推导的。但是衡量两个分布的距离也可以用其他的度量。
可以参考</p>
<ul>
<li>
<p>(Wasserstein AE) https://arxiv.org/pdf/1711.01558</p>
</li>
<li>
<p>(GW-AE) https://arxiv.org/pdf/2209.07007</p>
</li>
</ul>
<p>对于不同的假设条件，可以得出不同的实现方案。</p>
<h2 id="normalize-flow-nf">normalize flow （NF）</h2>
<p>如果映射是可逆的，那么我们就可以直接计算出生成样本的密度函数(分布), 这个时候直接优化最大似然就行了。
<img alt="alt text" src="../../../images/image-20.png" /></p>
<p>归一化流（Normalizing Flow）是一种概率密度估计方法，其核心思想是通过一系列可逆的变换，将一个复杂分布映射到一个简单分布（通常是标准正态分布），这些变换是由具有可微参数的函数定义的，因此可以通过最大似然估计对模型进行训练。以下是从最大似然的角度详细解释归一化流的原理：</p>
<h3 id="_4">最大似然估计</h3>
<ol>
<li><strong>目标：通过最大似然估计复杂分布的概率密度</strong> 给定一个数据集 <span class="arithmatex">\(\{x_1, x_2, \dots, x_N\}\)</span>，我们希望拟合一个概率分布 <span class="arithmatex">\(p_X(x)\)</span> 来描述数据的生成过程。通过最大似然估计（MLE)),目标是最大化模型分布对数据的对数似然：<span class="arithmatex">\(\mathcal{L} = \sum_{i=1}^N \log p_X(x_i)\)</span>.</li>
</ol>
<p>由于直接建模 <span class="arithmatex">\(p_X(x)\)</span> 可能非常复杂，归一化流通过变换将复杂分布 <span class="arithmatex">\(p_X(x)\)</span> 映射到一个简单的分布（如正态分布）。</p>
<ol>
<li><strong>可逆变换与变化公式</strong> 归一化流假设数据 <span class="arithmatex">\(x\)</span> 可以通过一系列可逆变换 <span class="arithmatex">\(f\)</span> 从一个简单的分布 <span class="arithmatex">\(p_Z(z)\)</span> 中生成：$
 x = f(z), \quad z = f^{-1}(x),
$
其中 <span class="arithmatex">\(z\)</span> 是潜在空间中的表示，其概率密度为 <span class="arithmatex">\(p_Z(z)\)</span>。根据概率变化公式，<span class="arithmatex">\(x\)</span> 的概率密度可以通过变换的雅可比行列式计算为：$
 p_X(x) = p_Z(z) \left| \det \frac{\partial f^{-1}}{\partial x} \right|,
$</li>
</ol>
<p>或者等价地：
$
 \log p_X(x) = \log p_Z(z) - \log \left| \det \frac{\partial f(x)}{\partial x} \right|.
$
这里 <span class="arithmatex">\(\det \frac{\partial f(x)}{\partial x}\)</span> 是变换 <span class="arithmatex">\(f\)</span> 的雅可比矩阵的行列式。</p>
<hr />
<ol>
<li><strong>最大似然估计</strong> 为了最大化对数似然 <span class="arithmatex">\(\mathcal{L}\)</span>，需要计算每个数据点 <span class="arithmatex">\(x\)</span> 的对数密度：</li>
<li>
<p><strong>计算潜在变量 <span class="arithmatex">\(z\)</span>：</strong>
利用 <span class="arithmatex">\(z = f^{-1}(x)\)</span>，将输入数据 <span class="arithmatex">\(x\)</span> 映射到潜在空间。</p>
</li>
<li>
<p><strong>计算简单分布 <span class="arithmatex">\(p_Z(z)\)</span>：</strong>
简单分布通常选择为标准正态分布 <span class="arithmatex">\(\mathcal{N}(0, I)\)</span>，因此 <span class="arithmatex">\(\log p_Z(z)\)</span> 可以直接通过 <span class="arithmatex">\(z\)</span> 的值计算。</p>
</li>
<li>
<p><strong>计算雅可比行列式：</strong>
变换 <span class="arithmatex">\(f(x)\)</span> 必须设计成易于计算其雅可比行列式 <span class="arithmatex">\(\det \frac{\partial f(x)}{\partial x}\)</span>。</p>
</li>
</ol>
<p>最终，通过优化参数，最大化以下对数似然：
$
 \log p_X(x) = \log p_Z(f^{-1}(x)) - \log \left| \det \frac{\partial f(x)}{\partial x} \right|.
$</p>
<hr />
<ol>
<li>
<p><strong>设计归一化流的变换</strong> 为了有效训练归一化流，变换 <span class="arithmatex">\(f\)</span> 通常需要满足以下要求：</p>
</li>
<li>
<p><strong>可逆性</strong> ：确保 <span class="arithmatex">\(f\)</span> 和 <span class="arithmatex">\(f^{-1}\)</span> 易于计算。</p>
</li>
<li>
<p><strong>雅可比行列式高效计算</strong> ：使得 <span class="arithmatex">\(\det \frac{\partial f(x)}{\partial x}\)</span> 的计算成本较低。</p>
</li>
</ol>
<p>常用的变换包括：</p>
<ol>
<li>
<p><strong>Affine Coupling Layer</strong> ：只对部分变量进行变换，简化雅可比行列式的计算。</p>
</li>
<li>
<p><strong>Spline Flows</strong> ：基于分段函数的流，能够捕获更多复杂性。</p>
</li>
<li>
<p><strong>RealNVP</strong>  和 <strong>Glow</strong> ：利用特定的结构设计高效的变换。</p>
</li>
</ol>
<h3 id="loss">Loss 的公式直观拆解</h3>
<p>在归一化流中，对数似然可以写为：</p>
<div class="arithmatex">\[
 \log p_X(x) = \log p_Z(f^{-1}(x)) - \log \left| \det \frac{\partial f(x)}{\partial x} \right|.
\]</div>
<p>训练的目标是<strong>最大化这个对数似然</strong> ，即最小化负对数似然（Negative Log-Likelihood, NLL）：</p>
<div class="arithmatex">\[
 \text{Loss} = -\mathbb{E}_{x \sim p_X} \left[ \log p_Z(f^{-1}(x)) - \log \left| \det \frac{\partial f(x)}{\partial x} \right| \right].
\]</div>
<p>从直观角度，Loss 的两个部分可以理解为：</p>
<ol>
<li>
<p><strong>潜在空间的负对数密度</strong> （<span class="arithmatex">\(-\log p_Z(f^{-1}(x))\)</span>）：</p>
</li>
<li>
<p>这个项表示数据点 <span class="arithmatex">\(x\)</span> 映射到潜在空间的点 <span class="arithmatex">\(z = f^{-1}(x)\)</span> 在简单分布 <span class="arithmatex">\(p_Z(z)\)</span> 上的概率密度。</p>
</li>
<li>
<p>直观上，越高的密度表示 <span class="arithmatex">\(x\)</span> 被模型解释得越好，Loss 越小。</p>
</li>
<li>
<p>目标是让数据点 <span class="arithmatex">\(z\)</span> 更接近简单分布的高密度区域（如标准正态分布的中心）。</p>
</li>
<li>
<p><strong>变换复杂性的代价</strong> （<span class="arithmatex">\(-\log \left| \det \frac{\partial f(x)}{\partial x} \right|\)</span>）：</p>
</li>
<li>
<p>这个项量化了变换 <span class="arithmatex">\(f\)</span> 的复杂性，特别是变换如何拉伸或压缩空间。</p>
</li>
<li>
<p>直观上，如果变换需要对数据进行大范围的扭曲或拉伸来匹配数据分布，雅可比行列式会较大，导致这个项的值增加，从而损失增大。</p>
</li>
<li>
<p>目标是让变换 <span class="arithmatex">\(f\)</span> 尽量简单，同时能有效匹配数据分布。</p>
</li>
</ol>
<hr />
<h3 id="_5">用日常比喻直观理解</h3>
<p>可以将 Loss 的两个部分类比为：</p>
<ol>
<li>
<p><strong>适配数据的过程</strong> ：</p>
</li>
<li>
<p>想象你有一块布（简单分布），需要将它拉伸和折叠（变换）以完全覆盖一个复杂的地形（数据分布）。</p>
</li>
<li>
<p>布的每个部分越接近目标地形的实际形状（即概率密度高的区域），就说明你越贴合目标，第一项的 Loss 越小。</p>
</li>
<li>
<p><strong>拉伸布的复杂性</strong> ：</p>
</li>
<li>
<p>如果需要对布进行非常复杂的变形，布会变得更紧或更松（对应雅可比行列式的变化），这会增加第二项的 Loss。</p>
</li>
</ol>
<p>最终，Loss 就是这两者的加权总成本：既希望布能很好地覆盖地形，又希望变形的过程不要过于复杂。</p>
<p>实际实现的时候，normalize flow 可以设计为可逆映射的复合。</p>
<h2 id="diffusion-model">Diffusion Model</h2>
<p>我们也可以从最大似然的角度推到出 Diffusion model 的优化目标。类似于VAE，不过这里的<span class="arithmatex">\(z\)</span> 要看做为 <span class="arithmatex">\(X_{1:T}\)</span>, <span class="arithmatex">\(x\)</span> 为 <span class="arithmatex">\(X_0\)</span>。同样利用变分得到ELBO.</p>
<p><strong>1. 最大似然目标</strong></p>
<p>最大化数据分布的对数似然 <span class="arithmatex">\(\log p_\theta(x_0)\)</span>。根据变分原理，引入中间变量 <span class="arithmatex">\(x_{1:T}\)</span>，得到：</p>
<div class="arithmatex">\[
 \log p_\theta(x_0) = \log \int p_\theta(x_0, x_{1:T}) \, dx_{1:T}.
\]</div>
<p>通过引入分布 <span class="arithmatex">\(q(x_{1:T} \mid x_0)\)</span>，利用对数分解：</p>
<div class="arithmatex">\[
 \log p_\theta(x_0) = \mathbb{E}_{q(x_{1:T} \mid x_0)} \left[ \log \frac{p_\theta(x_0, x_{1:T})}{q(x_{1:T} \mid x_0)} \right] + D_{\text{KL}}(q(x_{1:T} \mid x_0) \| p_\theta(x_{1:T} \mid x_0)).
\]</div>
<p>由于 KL 散度非负，得到变分下界（ELBO）：</p>
<div class="arithmatex">\[
 \log p_\theta(x_0) \geq \mathbb{E}_{q(x_{1:T} \mid x_0)} \left[ \log \frac{p_\theta(x_0, x_{1:T})}{q(x_{1:T} \mid x_0)} \right].
\]</div>
<hr />
<p><strong>2. 联合分布分解</strong></p>
<p>模型的联合分布 <span class="arithmatex">\(p_\theta(x_0, x_{1:T})\)</span> 和扩散过程 <span class="arithmatex">\(q(x_{1:T} \mid x_0)\)</span> 分别表示为：</p>
<div class="arithmatex">\[
 p_\theta(x_0, x_{1:T}) = p(x_T) \prod_{t=1}^T p_\theta(x_{t-1} \mid x_t),
\]</div>
<div class="arithmatex">\[
 q(x_{1:T} \mid x_0) = \prod_{t=1}^T q(x_t \mid x_{t-1}),
\]</div>
<p>代入 ELBO：</p>
<div class="arithmatex">\[
 \log p_\theta(x_0) \geq \mathbb{E}*{q(x*{1:T} \mid x_0)} \left[ \log \frac{p(x_T) \prod_{t=1}^T p_\theta(x_{t-1} \mid x_t)}{\prod_{t=1}^T q(x_t \mid x_{t-1})} \right].
\]</div>
<hr />
<p><strong>3. 分解和简化</strong></p>
<p>将对数展开：</p>
<div class="arithmatex">\[
 \log p_\theta(x_0) \geq \mathbb{E}*{q(x*{1:T} \mid x_0)} \Bigg[ \log p(x_T) + \sum_{t=1}^T \log p_\theta(x_{t-1} \mid x_t) - \sum_{t=1}^T \log q(x_t \mid x_{t-1}) \Bigg].
\]</div>
<p>注意 <span class="arithmatex">\(q(x_t \mid x_{t-1})\)</span> 是扩散过程的已知高斯分布，下一步将重点分析。</p>
<hr />
<p><strong>4. 逐步调整分布项</strong></p>
<p>由于 <span class="arithmatex">\(q(x_{1:T} \mid x_0)\)</span> 是已知的加噪过程，我们可以利用条件分布 <span class="arithmatex">\(q(x_{t-1} \mid x_t, x_0)\)</span> 来替代直接的 <span class="arithmatex">\(q(x_t \mid x_{t-1})\)</span>。通过 <span class="arithmatex">\(q(x_{t-1} \mid x_t, x_0) \cdot q(x_t \mid x_0)\)</span> 的关系：</p>
<div class="arithmatex">\[
 \mathbb{E}_{q(x_{1:T} \mid x_0)} \Bigg[ \sum_{t=1}^T \log \frac{p_\theta(x_{t-1} \mid x_t)}{q(x_t \mid x_{t-1})} \Bigg] = \mathbb{E}_{q(x_{1:T} \mid x_0)} \Bigg[ \log \frac{p_\theta(x_{t-1} \mid x_t)}{q(x_{t-1} \mid x_t, x_0)} \Bigg].
\]</div>
<p>于是，目标分解为以下几部分：</p>
<ol>
<li><strong>重建误差（Reconstruction Term）：</strong></li>
</ol>
<div class="arithmatex">\[
 \mathbb{E}_{q(x_{1:T} \mid x_0)} \Big[ \log p_\theta(x_0 \mid x_1) \Big].
\]</div>
<ol>
<li><strong>先验匹配误差（Prior Matching Term）：</strong></li>
</ol>
<div class="arithmatex">\[
 \mathbb{E}_{q(x_T \mid x_0)} \Big[ \log p(x_T) - \log q(x_T \mid x_0) \Big] = -D_{\text{KL}}(q(x_T \mid x_0) \| p(x_T)).
\]</div>
<ol>
<li><strong>去噪误差（Denoising Matching Term）：</strong></li>
</ol>
<div class="arithmatex">\[
 \sum_{t=2}^T \mathbb{E}_{q(x_t \mid x_0)} \Big[ D_{\text{KL}}(q(x_{t-1} \mid x_t, x_0) \| p_\theta(x_{t-1} \mid x_t)) \Big].
\]</div>
<hr />
<p><strong>5. 最终损失函数</strong></p>
<p>最终损失函数为：</p>
<div class="arithmatex">\[
 \mathcal{L} = \mathbb{E}_{q(x_{1:T} \mid x_0)} \Big[ \underbrace{-\log p_\theta(x_0 \mid x_1)}_{\text{重建误差}} + \underbrace{D_{\text{KL}}(q(x_T \mid x_0) \| p(x_T))}_{\text{先验匹配误差}} + \underbrace{\sum_{t=2}^T D_{\text{KL}}(q(x_{t-1} \mid x_t, x_0) \| p_\theta(x_{t-1} \mid x_t))}_{\text{去噪误差}} \Big].
\]</div>
<hr />
<p><strong>6. 简化与优化</strong></p>
<p>通过假设 <span class="arithmatex">\(p_\theta(x_{t-1} \mid x_t)\)</span> 和 <span class="arithmatex">\(q(x_{t-1} \mid x_t, x_0)\)</span> 都是高斯分布，进一步优化去噪误差：</p>
<div class="arithmatex">\[
 \mathcal{L}_{\text{DDPM}} = \mathbb{E}_{x_0, \epsilon, t} \Big[ \| \epsilon - \epsilon_\theta(x_t, t) \|^2 \Big].
\]</div>
<h2 id="_6">自回归模型</h2>
<ol>
<li><strong>图片表示与最大似然目标</strong></li>
</ol>
<p>对于一张图片 <span class="arithmatex">\(<span class="arithmatex">\(\mathbf{x}\)</span>\)</span>，我们可以将其表示为像素值的序列：</p>
<div class="arithmatex">\[
 \mathbf{x} = (x_1, x_2, \ldots, x_T)
\]</div>
<p>其中 <span class="arithmatex">\(T\)</span> 是图片像素的总数。生成图片的目标是最大化图片在模型下的概率：</p>
<div class="arithmatex">\[
 P(\mathbf{x}|\theta) = P(x_1, x_2, \ldots, x_T|\theta)
\]</div>
<p>这里，<span class="arithmatex">\(\theta\)</span> 是模型的参数。</p>
<ol>
<li><strong>自回归分解</strong>
根据概率的链式规则，图片的联合概率可以分解为每个像素的条件概率的乘积：</li>
</ol>
<div class="arithmatex">\[
 P(\mathbf{x}|\theta) = \prod_{t=1}^T P(x_t | x_1, x_2, \ldots, x_{t-1}, \theta)
\]</div>
<p>这表示当前像素 <span class="arithmatex">\(x_t\)</span> 的生成依赖于之前生成的像素值。</p>
<ol>
<li><strong>对数似然函数</strong></li>
</ol>
<p>由于直接优化概率存在数值不稳定性，我们使用对数形式：</p>
<div class="arithmatex">\[
 \log P(\mathbf{x}|\theta) = \sum_{t=1}^T \log P(x_t | x_1, x_2, \ldots, x_{t-1}, \theta)
\]</div>
<ol>
<li><strong>负对数似然作为损失函数</strong></li>
</ol>
<p>为了进行最小化优化，转化为负对数似然形式：</p>
<div class="arithmatex">\[
 \mathcal{L}(\theta) = - \log P(\mathbf{x}|\theta) = - \sum_{t=1}^T \log P(x_t | x_1, x_2, \ldots, x_{t-1}, \theta)
\]</div>
<p>这就是自回归生成模型的损失函数。</p>
<ol>
<li><strong>像素分布建模</strong></li>
</ol>
<p>为了计算条件概率 <span class="arithmatex">\(<span class="arithmatex">\(P(x_t | x_1, x_2, \ldots, x_{t-1}, \theta)\)</span>\)</span>，需要对像素值的分布进行建模。常见的选择包括：</p>
<ol>
<li>
<p>离散像素值</p>
<p>如果像素值是离散的（如 <span class="arithmatex">\([0, 255]\)</span> 的整数值)),条件概率 <span class="arithmatex">\(P(x_t|\cdot)\)</span> 可以通过分类器（如 softmax 输出层）建模：</p>
<div class="arithmatex">\[
P(x_t | x_1, x_2, \ldots, x_{t-1}, \theta) = \text{Softmax}(f_\theta(x_1, x_2, \ldots, x_{t-1}))
\]</div>
<p>此时，损失函数可以具体化为交叉熵损失：</p>
<div class="arithmatex">\[
\mathcal{L}(\theta) = - \sum_{t=1}^T \log P(x_t | x_1, x_2, \ldots, x_{t-1}, \theta)
\]</div>
</li>
<li>
<p>连续像素值</p>
<p>如果像素值是连续的（如归一化到 <span class="arithmatex">\([0, 1]\)</span> 的浮点数)),通常假设像素值服从某种概率分布（如高斯分布）：</p>
<div class="arithmatex">\[
P(x_t | x_1, x_2, \ldots, x_{t-1}, \theta) = \mathcal{N}(x_t | \mu_\theta, \sigma_\theta)
\]</div>
<p>其中 <span class="arithmatex">\(\mu_\theta\)</span> 和 <span class="arithmatex">\(\sigma_\theta\)</span> 是条件均值和标准差，由模型预测得到。负对数似然损失在这种情况下等价于均方误差（MSE）：</p>
<div class="arithmatex">\[
\mathcal{L}(\theta) = \frac{1}{2} \sum_{t=1}^T \left(x_t - \mu_\theta(x_1, x_2, \ldots, x_{t-1})\right)^2
\]</div>
</li>
<li>
<p><strong>生成图片的像素顺序</strong></p>
</li>
</ol>
<p>为了定义序列生成顺序，自回归模型需要明确像素的生成方式。常见方法包括：
- <strong>行优先生成</strong> ：逐行从左到右、从上到下生成像素。
- <strong>块优先生成</strong> ：以块的形式生成像素。
- <strong>自定义顺序</strong> ：基于特定的排列规则生成。
顺序的选择直接影响条件概率的建模方式。</p>
<ol>
<li><strong>总结：自回归生成图片模型的损失</strong></li>
</ol>
<p>自回归模型用于图片生成的通用损失函数为：</p>
<div class="arithmatex">\[
 \mathcal{L}(\theta) = - \sum_{t=1}^T \log P(x_t | x_1, x_2, \ldots, x_{t-1}, \theta)
\]</div>
<ul>
<li>
<p>对于离散像素，使用交叉熵损失。</p>
</li>
<li>
<p>对于连续像素，通常使用均方误差或负对数似然。</p>
</li>
</ul>
<p>通过对每个像素的条件概率进行优化，模型能够学习生成图片的复杂分布。</p>
<h2 id="refenrence">Refenrence</h2>
<ul>
<li><a href="https://chatgpt.com/c/6788e69d-7f1c-8001-a4e2-f6c8abda90db">normalize flow</a></li>
<li><a href="https://www.cnblogs.com/Meloniala/p/18285101">Diffusion 综述阅读笔记</a></li>
</ul>


</section>
</div> <!-- end of search-noresults -->
<div class="search-results">
<div class="has-results">

<h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
<ul class="search-results-list"></ul>

</div> <!-- end of has-results -->
<div class="no-results">

<h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>

</div> <!-- end of no-results -->
</div> <!-- end of search-results -->
</div> <!-- end of book-search-results -->

</div> <!-- end of page-inner -->
</div> <!-- end of page-wrapper -->

</div> <!-- end of body-inner -->

</div> <!-- end of book-body -->
<script src="../../../js/main.js"></script>
<script src="../../../javascripts/mathjax.js"></script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<script src="../../../search/main.js"></script>
<script src="../../../js/gitbook.min.js"></script>
<script src="../../../js/theme.min.js"></script>
</body>
</html>