{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"blog/","title":"Blog","text":""},{"location":"book/chapter11_hybrid_sota_models/sota_open_models/dalle_series/","title":"Dalle Series","text":""},{"location":"book/chapter11_hybrid_sota_models/sota_open_models/dalle_series/#1-dalle-2-unclip","title":"1. Dalle 2 (unCLIP)","text":"<ul> <li>Year: 2022 Apr</li> <li>Paper: https://arxiv.org/pdf/2204.06125</li> <li>Author: Open AI Aditya Ramesh, etc.</li> </ul>"},{"location":"book/chapter11_hybrid_sota_models/sota_open_models/dalle_series/#11-overall-structure","title":"1.1 Overall structure","text":"<p>Theoretically  Let \\(y\\) be the condition, i.e., the caption of the image, \\(x\\) be the image. SO the \\(x\\) and \\(y\\) are 1-1 corresponded.</p> <p>Let \\(z_i\\) and \\(z_t\\) be the CIP image and text embedding.</p> <p>We have</p> <ul> <li>prio \\(P(z_i|y)\\) that produces CLIP image embedding given condition \\(y\\).</li> <li>decoder \\(P(x|z_i,y)\\) that preduces the image samples dontiionaed on clip image embedding and caption</li> </ul> \\[P(x|y) = P(x,z_i|y) = P(x|z_i,y)P(z_i|y)\\] <p>Which means we can first sample the clip image embedding from the caption, and then use the clip image embedding to decode the image.</p> <p>There are two different types of Prior</p> <ol> <li>Autoregressive Prior</li> <li>DIffusion Prior</li> </ol> <p>In the diffusion prior, we can also use clip text embedding to map text to vector.</p>"},{"location":"book/chapter11_hybrid_sota_models/sota_open_models/dalle_series/#12-experiments","title":"1.2 Experiments","text":"<p>Interplate on the caption text embedding</p> <p></p>"},{"location":"book/chapter11_hybrid_sota_models/sota_open_models/flux1/","title":"Flux.1","text":"<p>Code explain: https://zhuanlan.zhihu.com/p/741939590/</p>"},{"location":"book/chapter11_hybrid_sota_models/sota_open_models/stable_diffusion_3_reading/","title":"Scaling Rectified Flow Transformers for High-Resolution Image Synthesis","text":"<p>Paper: https://arxiv.org/pdf/2403.03206/</p> <p>Before reading this paper, we suggest reader to undertand the flow matching chapter first.</p>"},{"location":"book/chapter11_hybrid_sota_models/sota_open_models/stable_diffusion_3_reading/#1-abstract","title":"1. Abstract","text":"<ul> <li>Establish the practic for the rectified flow</li> </ul>"},{"location":"book/chapter11_hybrid_sota_models/sota_open_models/stable_diffusion_3_reading/#2-introduction","title":"2. Introduction","text":"<ul> <li> <p>The forward path from data to noise is important in efficient training</p> </li> <li> <p>Fails to remove all noise from the data (? now understand what this meaning)</p> </li> <li>affect sampling efficiency</li> <li>curved paths required more integration steps</li> <li>straight path has less error accumulations</li> <li>No large size experiments for class conditional rectified flow models</li> <li> <p>Introduce re-weighting of the noise scales in rectified flow models</p> </li> <li> <p>Text representation fussion</p> </li> <li>claim that text representation fed into model directly is not ideal</li> <li>Introduce new architecture for information flow between text and image</li> </ul>"},{"location":"book/chapter11_hybrid_sota_models/sota_open_models/stable_diffusion_3_reading/#3-preliminary","title":"3. Preliminary","text":"<ul> <li>Refer  for the details of DiT model</li> </ul> <p>This section revisted the flow matching scheme</p>"},{"location":"book/chapter11_hybrid_sota_models/sota_open_models/stable_diffusion_series/","title":"Stable Diffusion Series","text":""},{"location":"book/chapter11_hybrid_sota_models/sota_open_models/stable_diffusion_series/#1-vq-gan","title":"1. VQ-GAN","text":"<ul> <li>Year: 2020 Dec - 2022 Jan</li> <li>Paper:</li> <li>Taming Transformers for High-Resolution Image Synthesis</li> <li>Repo: taming-transformers</li> <li>Organization: CompVis</li> </ul> <p>Please refer VQ-GAN for more details.</p>"},{"location":"book/chapter11_hybrid_sota_models/sota_open_models/stable_diffusion_series/#2-stable-diffusion-v0","title":"2. Stable Diffusion v0","text":"<ul> <li>Year: Dec 2021 -Nov 2022</li> <li>Paper: High-Resolution Image Synthesis with Latent Diffusion Models</li> <li>Repo: https://github.com/Stability-AI/stablediffusion?tab=readme-ov-file</li> <li>Organization: CompVis</li> </ul> <p>Please refer LDM for more details</p>"},{"location":"book/chapter11_hybrid_sota_models/sota_open_models/stable_diffusion_series/#3-stable-diffusion-v1","title":"3. Stable DIffusion v1","text":"<ul> <li>Year</li> <li>Ideas</li> <li>High-Resolution Image Synthesis with Latent Diffusion Models</li> <li>classifier free guidance sampling</li> <li>Repo: Stable_Diffusion_v1_Model_Card.md</li> <li>Organization: CompVis</li> </ul>"},{"location":"book/chapter11_hybrid_sota_models/sota_open_models/stable_diffusion_series/#31-summary","title":"3.1 Summary","text":"<ul> <li>Architecture:</li> <li>A latent diffusion model that combines an autoencoder with a diffusion model operating in the autoencoder\u2019s latent space.</li> <li>Image Encoding: Images are downsampled by a factor of 8, converting an image from shape H x W x 3 to a latent representation of shape H/8 x W/8 x 4.</li> <li> <p>Text Conditioning: Uses a ViT-L/14 text encoder; its non-pooled output is integrated into the UNet backbone via cross-attention.</p> </li> <li> <p>Training Objective:</p> </li> <li> <p>The model is trained to reconstruct the noise added to the latent representations, essentially predicting the noise in the latent space.</p> </li> <li> <p>Training Data:</p> </li> <li> <p>Primarily trained on LAION-5B and various curated subsets, including:</p> <ul> <li>laion2B-en</li> <li>laion-high-resolution (for high-resolution images)</li> <li>laion-aesthetics v2 5+ (filtered for aesthetics and watermark probability)</li> </ul> </li> <li> <p>Checkpoints Overview:</p> </li> <li>sd-v1-1.ckpt:<ul> <li>237k steps at 256x256 resolution (laion2B-en)</li> <li>194k steps at 512x512 resolution (laion-high-resolution)</li> </ul> </li> <li>sd-v1-2.ckpt:<ul> <li>Continued from v1-1; 515k steps at 512x512 using laion-aesthetics v2 5+ data.</li> </ul> </li> <li> <p>sd-v1-3.ckpt &amp; sd-v1-4.ckpt:</p> <ul> <li>Both resumed from v1-2 with additional 10% text-conditioning drop to improve classifier-free guidance sampling.</li> </ul> </li> <li> <p>Training Setup:</p> </li> <li>Hardware: 32 x 8 x A100 GPUs</li> <li>Optimizer: AdamW</li> <li>Batch Details: Gradient accumulations and batch size set to a total of 2048 images per update</li> <li>Learning Rate: Warmup to 0.0001 over 10,000 steps, then kept constant</li> </ul>"},{"location":"book/chapter11_hybrid_sota_models/sota_open_models/stable_diffusion_series/#32-difference-between-v0-and-v1","title":"3.2 Difference between v0 and v1","text":"<p>The code is basically the same with stable diffusion v0, which is latent diffusion.</p>"},{"location":"book/chapter11_hybrid_sota_models/sota_open_models/stable_diffusion_series/#33-dataset","title":"3.3 Dataset","text":""},{"location":"book/chapter11_hybrid_sota_models/sota_open_models/stable_diffusion_series/#331-laion-aesthetics-dataset-summary","title":"3.3.1 LAION-Aesthetics Dataset Summary","text":"<ul> <li>Overview:</li> <li>A curated subset of the larger LAION image-text dataset that emphasizes high-quality, visually appealing images.</li> <li> <p>Utilizes a deep learning\u2013based aesthetic predictor to assign scores reflecting the perceived visual quality of each image.</p> </li> <li> <p>Filtering Process:</p> </li> <li>Aesthetic Scoring: Images are evaluated with the LAION-Aesthetics Predictor, and only those exceeding a certain score threshold (e.g., &gt;5.0) are selected.</li> <li> <p>Additional Filters:</p> <ul> <li>Ensures images have a minimum resolution (original size \u2265 512\u00d7512).</li> <li>Applies a watermark probability filter to exclude images with a high likelihood of watermarks.</li> </ul> </li> <li> <p>Purpose and Applications:</p> </li> <li>Designed to serve as high-quality training data for generative models, such as Stable Diffusion.</li> <li>Aims to improve the aesthetic quality of generated images by providing models with visually appealing training examples.</li> </ul> <p>This dataset provided a smaller dataset with higher aesthetics scores, so that it may be used to fine-tune a model.</p> <ul> <li>1,2B image-text pairs with predicted aesthetics scores of 4.5 or higher: huggingface</li> <li>939M image-text pairs with predicted aesthetics scores of 4.75 or higher: huggingface</li> <li>600M image-text pairs with predicted aesthetics scores of 5 or higher: huggingface</li> <li>12M image-text pairs with predicted aesthetics scores of 6 or higher: huggingface</li> <li>3M image-text pairs with predicted aesthetics scores of 6.25 or higher: huggingface</li> <li>625K image-text pairs with predicted aesthetics scores of 6.5 or higher: huggingface</li> </ul>"},{"location":"book/chapter11_hybrid_sota_models/sota_open_models/stable_diffusion_series/#332-laion-5b-dataset","title":"3.3.2 LAION-5B Dataset","text":"<ul> <li>Massive Scale: Contains around 5 billion image-text pairs scraped from the internet.</li> <li>Diversity: Offers a broad spectrum of visual content and associated textual descriptions.</li> <li>Purpose: Designed to power large-scale machine learning and generative models, ensuring rich semantic variety.</li> <li>Open Access: Available for research and development, promoting transparency and innovation in</li> <li>Total size: 12 TB</li> </ul>"},{"location":"book/chapter11_hybrid_sota_models/sota_open_models/stable_diffusion_series/#4-stable-diffusion-v2","title":"4. Stable Diffusion v2","text":"<ul> <li>Year: Dec 2021 -Nov 2022</li> <li>Ideas:</li> <li>/https://arxiv.org/pdf/2204.06125</li> <li>https://arxiv.org/pdf/2202.00512</li> <li>repo: https://github.com/Stability-AI/stablediffusion?tab=readme-ov-file</li> <li>oganization: Stability-AI</li> </ul>"},{"location":"book/chapter11_hybrid_sota_models/sota_open_models/stable_diffusion_series/#41-summary","title":"4.1 Summary","text":"<p>Generated Image   Unchanged</p> <ol> <li>VAE structure</li> <li>Latent Difffuions Structure (text condition embedding changes)</li> <li>Basic DDPM sampling (it has extra pregressive sampling method)</li> </ol> <p>The base model is still the latent diffusion. The main differences is</p> <ol> <li>Resolution. The original model is 512x512, we use 768x768 in the future.</li> <li>Use the idea of progessive distillation for fast sampling</li> <li>Use clip guided for text2image sampling</li> </ol>"},{"location":"book/chapter11_hybrid_sota_models/sota_open_models/stable_diffusion_series/#42-differences-change-details","title":"4.2 Differences change details","text":"<p>The code is still based on the original LDM repo</p>"},{"location":"book/chapter11_hybrid_sota_models/sota_open_models/stable_diffusion_series/#421-latentdiffusion-with-condition-processing","title":"4.2.1 LatentDiffusion with condition processing","text":""},{"location":"book/chapter11_hybrid_sota_models/sota_open_models/stable_diffusion_series/#422-image-embedding-condition","title":"4.2.2 Image Embedding Condition","text":"<p>This used the image embedding as the condition to guide the generation</p> ImageEmbeddingConditionedLatentDiffusion<pre><code>class ImageEmbeddingConditionedLatentDiffusion(LatentDiffusion):\n    def __init__(self, embedder_config, embedding_key=\"jpg\", embedding_dropout=0.5,\n                 freeze_embedder=True, noise_aug_config=None, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.embed_key = embedding_key\n        self.embedding_dropout = embedding_dropout\n        self._init_embedder(embedder_config, freeze_embedder)\n        self._init_noise_aug(noise_aug_config)\n\n    def _init_embedder(self, config, freeze=True):\n        embedder = instantiate_from_config(config)\n        if freeze:\n            self.embedder = embedder.eval()\n            self.embedder.train = disabled_train\n            for param in self.embedder.parameters():\n                param.requires_grad = False\n\n    def _init_noise_aug(self, config):\n        if config is not None:\n            # use the KARLO schedule for noise augmentation on CLIP image embeddings\n            noise_augmentor = instantiate_from_config(config)\n            assert isinstance(noise_augmentor, nn.Module)\n            noise_augmentor = noise_augmentor.eval()\n            noise_augmentor.train = disabled_train\n            self.noise_augmentor = noise_augmentor\n        else:\n            self.noise_augmentor = None\n\n    def get_input(self, batch, k, cond_key=None, bs=None, **kwargs):\n        outputs = LatentDiffusion.get_input(self, batch, k, bs=bs, **kwargs)\n        z, c = outputs[0], outputs[1]\n        img = batch[self.embed_key][:bs]\n        img = rearrange(img, 'b h w c -&gt; b c h w')\n        c_adm = self.embedder(img)\n        if self.noise_augmentor is not None:\n            c_adm, noise_level_emb = self.noise_augmentor(c_adm)\n            # assume this gives embeddings of noise levels\n            c_adm = torch.cat((c_adm, noise_level_emb), 1)\n        if self.training:\n            c_adm = torch.bernoulli((1. - self.embedding_dropout) * torch.ones(c_adm.shape[0],\n                                                                               device=c_adm.device)[:, None]) * c_adm\n        all_conds = {\"c_crossattn\": [c], \"c_adm\": c_adm}\n        noutputs = [z, all_conds]\n        noutputs.extend(outputs[2:])\n        return noutputs\n</code></pre> <p>Compared with privious LDM, it added another variable <code>c_adm</code> for the clip image bedding of the images. Please see unCLIP for the details on takeing CLIP image embedding as condition.</p> <p>Refer the code explanation of latent diffusion model Latent Diffusion Model, the <code>c_adm</code> is assigned to <code>y</code> and later will be added into the time embedding.</p> <p>It also takes the embedding_drop out such that the model is trained both with image embedding or not.</p>"},{"location":"book/chapter11_hybrid_sota_models/sota_open_models/stable_diffusion_series/#423-v-prediction","title":"4.2.3 v-prediction","text":"get_v<pre><code>def get_v(self, x, noise, t):\n    return (\n            extract_into_tensor(self.sqrt_alphas_cumprod, t, x.shape) * noise -\n            extract_into_tensor(self.sqrt_one_minus_alphas_cumprod, t, x.shape) * x\n    )\n\nif self.parameterization == \"x0\":\n    target = x_start\nelif self.parameterization == \"eps\":\n    target = noise\nelif self.parameterization == \"v\":\n    target = self.get_v(x_start, noise, t)\n</code></pre> <p>In many diffusion models, the forward process is defined as:</p> \\[  x_t = \\sqrt{\\bar{\\alpha}_t}\\, x_0 + \\sqrt{1 - \\bar{\\alpha}_t}\\, \\varepsilon, \\quad \\varepsilon \\sim \\mathcal{N}(0, I) \\] <p>For v-prediction, we reparameterize the process by defining a new variable \\(v\\) as:</p> \\[  v = \\sqrt{\\bar{\\alpha}_t}\\, \\varepsilon - \\sqrt{1 - \\bar{\\alpha}_t}\\, x_0 \\] <p>This formulation offers certain benefits in terms of training stability and sample quality. With \\(v\\) predicted by the model, one can later recover either the noise \\(\\varepsilon\\) or the original image \\(x_0\\) via:</p> <ul> <li>Recovering \\(x_0\\):</li> </ul> \\[ x_0 = \\sqrt{\\bar{\\alpha}_t}\\, x_t - \\sqrt{1 - \\bar{\\alpha}_t}\\, v \\] <ul> <li>Recovering \\(\\varepsilon\\):</li> </ul> \\[  \\varepsilon = \\sqrt{1 - \\bar{\\alpha}_t}\\, x_t + \\sqrt{\\bar{\\alpha}_t}\\, v \\] <p>Different</p>"},{"location":"book/chapter11_hybrid_sota_models/sota_open_models/stable_diffusion_series/#43-other-types-of-conditions","title":"4.3 Other Types of Conditions","text":"<p>In the main latent diffusion condition process block, all the concat condition will follow the process</p> concat condition processing<pre><code>        assert exists(self.concat_keys)\n        c_cat = list()\n        for ck in self.concat_keys:\n            cc = rearrange(batch[ck], 'b h w c -&gt; b c h w').to(memory_format=torch.contiguous_format).float()\n            if bs is not None:\n                cc = cc[:bs]\n                cc = cc.to(self.device)\n            bchw = z.shape\n            if ck != self.masked_image_key:\n                cc = torch.nn.functional.interpolate(cc, size=bchw[-2:])\n            else:\n                cc = self.get_first_stage_encoding(self.encode_first_stage(cc))\n            c_cat.append(cc)\n        c_cat = torch.cat(c_cat, dim=1)\n        all_conds = {\"c_concat\": [c_cat], \"c_crossattn\": [c]}\n        if return_first_stage_outputs:\n            return z, all_conds, x, xrec, xc\n        return z, all_conds\n</code></pre> <p>If the concat condition is not of the same shape, it will be interpolated into the same shape with the image shape. Recall the steps in the Latent Diffusion forward step, the concat condition will be concated together with the input \\(z\\) as the start of the diffusion model.</p>"},{"location":"book/chapter11_hybrid_sota_models/sota_open_models/stable_diffusion_series/#431-low-resolution-condition","title":"4.3.1 Low resolution condition","text":"LatentUpscaleDiffusionLatentUpscaleFinetuneDiffusion LatentUpscaleDiffusion<pre><code>        x_low = batch[self.low_scale_key][:bs]\n        x_low = rearrange(x_low, 'b h w c -&gt; b c h w')\n        x_low = x_low.to(memory_format=torch.contiguous_format).float()\n        zx, noise_level = self.low_scale_model(x_low)\n        if self.noise_level_key is not None:\n            # get noise level from batch instead, e.g. when extracting a custom noise level for bsr\n            raise NotImplementedError('TODO')\n        all_conds = {\"c_concat\": [zx], \"c_crossattn\": [c], \"c_adm\": noise_level}\n</code></pre> Low Res Condition<pre><code>    @torch.no_grad()\n    def get_input(self, batch, k, cond_key=None, bs=None, return_first_stage_outputs=False):\n        # note: restricted to non-trainable encoders currently\n        assert not self.cond_stage_trainable, 'trainable cond stages not yet supported for upscaling-ft'\n        z, c, x, xrec, xc = super().get_input(batch, self.first_stage_key, return_first_stage_outputs=True,\n                                              force_c_encode=True, return_original_cond=True, bs=bs)\n        assert exists(self.concat_keys)\n        assert len(self.concat_keys) == 1\n        # optionally make spatial noise_level here\n        c_cat = list()\n        noise_level = None\n        for ck in self.concat_keys:\n            cc = batch[ck]\n            cc = rearrange(cc, 'b h w c -&gt; b c h w')\n            if exists(self.reshuffle_patch_size):\n                assert isinstance(self.reshuffle_patch_size, int)\n                cc = rearrange(cc, 'b c (p1 h) (p2 w) -&gt; b (p1 p2 c) h w',\n                              p1=self.reshuffle_patch_size, p2=self.reshuffle_patch_size)\n            if bs is not None:\n                cc = cc[:bs]\n                cc = cc.to(self.device)\n            if exists(self.low_scale_model) and ck == self.low_scale_key:\n                cc, noise_level = self.low_scale_model(cc)\n            c_cat.append(cc)\n        c_cat = torch.cat(c_cat, dim=1)\n        if exists(noise_level):\n            all_conds = {\"c_concat\": [c_cat], \"c_crossattn\": [c], \"c_adm\": noise_level}\n        else:\n            all_conds = {\"c_concat\": [c_cat], \"c_crossattn\": [c]}\n        if return_first_stage_outputs:\n            return z, all_conds, x, xrec, xc\n        return z, all_conds\n</code></pre> <p>The low resolutoin condition is considered as the concat condition and will later concat with the input \\(z\\). Also, the condition combined with the noise to match the diffusion steps in case it provided too much clear information for the model.</p>"},{"location":"book/chapter11_hybrid_sota_models/sota_open_models/stable_diffusion_series/#432-depth-condition","title":"4.3.2 Depth Condition","text":"<p>The MiDaSInference module is used for predicting depth information from a single RGB image, using the MiDaS model. The MiDaS model is a monocular depth estimation model, which is trained on multiple datasets and has strong cross-domain generalization capabilities. It can generate relative depth maps for images, which are commonly used in 3D reconstruction, augmented reality, and other computer vision tasks. For more details, refer to the open-source implementation of the project.</p> <p>With the help from the MiDaSInference, we can convert the image into depth, thus used in the diffusion model to train depth2image model.</p> depth condition<pre><code>        c_cat = list()\n        for ck in self.concat_keys:\n            cc = batch[ck]\n            if bs is not None:\n                cc = cc[:bs]\n                cc = cc.to(self.device)\n            cc = self.depth_model(cc)\n            cc = torch.nn.functional.interpolate(\n                cc,\n                size=z.shape[2:],\n                mode=\"bicubic\",\n                align_corners=False,\n            )\n\n            depth_min, depth_max = torch.amin(cc, dim=[1, 2, 3], keepdim=True), torch.amax(cc, dim=[1, 2, 3],\n                                                                                           keepdim=True)\n            cc = 2. * (cc - depth_min) / (depth_max - depth_min + 0.001) - 1.\n            c_cat.append(cc)\n        c_cat = torch.cat(c_cat, dim=1)\n        all_conds = {\"c_concat\": [c_cat], \"c_crossattn\": [c]}\n</code></pre> <p>It processed the condition same as low-res condition</p>"},{"location":"book/chapter11_hybrid_sota_models/sota_open_models/stable_diffusion_series/#433-inpaint-condition","title":"4.3.3 Inpaint Condition","text":"Inpaint Condition<pre><code>        c_cat = list()\n        for ck in self.concat_keys:\n            cc = rearrange(batch[ck], 'b h w c -&gt; b c h w').to(memory_format=torch.contiguous_format).float()\n            if bs is not None:\n                cc = cc[:bs]\n                cc = cc.to(self.device)\n            bchw = z.shape\n            if ck != self.masked_image_key:\n                cc = torch.nn.functional.interpolate(cc, size=bchw[-2:])\n            else:\n                cc = self.get_first_stage_encoding(self.encode_first_stage(cc))\n            c_cat.append(cc)\n        c_cat = torch.cat(c_cat, dim=1)\n</code></pre> <p>The concat keys is <code>[\"mask\", \"masked_image\"]</code> which provided the masked image and the masks.</p> <ul> <li>The mask will be resized to the same of the input \\(z\\)</li> <li>The masked_image will be encoded by the same encoder as the target image.</li> </ul>"},{"location":"book/chapter11_hybrid_sota_models/sota_open_models/stable_diffusion_series/#5-stable-diffusion-sdxl","title":"5. Stable Diffusion SDXL","text":"<ul> <li>repo: https://github.com/Stability-AI/generative-models</li> <li>paper: /https://arxiv.org/pdf/2307.01952</li> <li>date: 2023 July</li> <li>Main changes</li> <li>Three times large UNet</li> <li>Second text encoder</li> <li>novel conditioning schemes</li> <li>train on multiple aspect ratios</li> <li>refinement model to improve the visual fidelity</li> </ul>"},{"location":"book/chapter11_hybrid_sota_models/sota_open_models/stable_diffusion_series/#51-architecture","title":"5.1 Architecture","text":"<p> Participants were asked to choose their favorite image generation among four models, the results are show above.</p>"},{"location":"book/chapter11_hybrid_sota_models/sota_open_models/stable_diffusion_series/#511-network-stucture","title":"5.1.1 Network stucture","text":"<ul> <li>VAE:</li> <li>VAE is almost the same, but it implemented a meomory Efficient Scross Attention, which used the package <code>xformers</code></li> </ul>"},{"location":"book/chapter11_hybrid_sota_models/sota_open_models/stable_diffusion_series/#512-condition-no-image-size","title":"5.1.2 Condition no image size","text":"<p>Previous training discard images under 512 pixels which could discard large portion of data, lead to a loss in performance and generalization</p> <p>we provide the original (i.e., before any rescaling) height and width of the images as an additional conditioning to the model csize = (h-original,w-original). Each component is independently embedded using a Fourier feature encoding, and these encodings are concatenated into a single vector that we feed into the model by adding it to the timestep embedding</p> <p></p>"},{"location":"book/chapter11_hybrid_sota_models/sota_open_models/stable_diffusion_series/#513-condition-on-cropping-parameters","title":"5.1.3 Condition on cropping parameters","text":"<p>Random cropping during training coulde leads to incomplete generation like the following. So we put it in the condition and set (\\(c_top,c_left\\)) be zeros to obtained the object centered samples. Further, we can tune the two parameters to simulate the amount of cropping during inference.  </p> <ul> <li>Method     During dataloading, we uniformly sample crop coordinates ctop and cleft (integers specifying the amount of pixels cropped from the top-left corner along the height and width axes, respectively) and feed them into the model as conditioning parameters via Fourier feature embeddings, similar to the size conditioning described above</li> </ul>"},{"location":"book/chapter11_hybrid_sota_models/sota_open_models/stable_diffusion_series/#514-condition-on-aspect-ratio","title":"5.1.4 Condition on aspect ratio","text":"<pre><code>Most text2image models produces saure images.\n- Trainig tricks\n  - Prepare different bukets of images, each bucket has the same shape, while the total number of pixels is approximaly $1024^2$.\n  - During training, single batch comes from same bucket, and change the bucket for different step in the training loop\n- Condition tricks\n  - similar to the size condition and crop-parameter condition, the target shape $(h_{target},w_{target})$ is embedded into a Fourier space\n</code></pre>"},{"location":"book/chapter11_hybrid_sota_models/sota_open_models/stable_diffusion_series/#515-improved-autoencoder","title":"5.1.5 Improved autoencoder","text":"<ol> <li>used ema in training</li> <li>large batchsize 9-&gt; 256      See more details for stable-diffusion xl in stable diffusion xl</li> </ol>"},{"location":"book/chapter11_hybrid_sota_models/sota_open_models/stable_diffusion_series/#6-stable-diffusion-v3","title":"6. Stable Diffusion v3","text":"<p>Scaling Rectified Flow Transformers for High-Resolution Image Synthesis</p> <ul> <li>Paper: https://arxiv.org/pdf/2403.03206</li> <li>Report: https://stability.ai/news/stable-diffusion-3</li> <li>Year: 2024 Mar</li> <li>Resources</li> <li>stable diffusion 3 reading: https://zhuanlan.zhihu.com/p/684068402?utm_source=chatgpt.com</li> <li>Code:</li> <li>sd 3 inference code</li> <li>Instruct Training script based on SD3</li> <li>Flexible PyTorch implementation of StableDiffusion-3 based on  diffusers</li> <li>Stable Diffusion 3 Fintune Guide</li> </ul> <p>study of sd3</p> <p>See the paper reading in Stable Diffusion v3</p>"},{"location":"book/chapter11_hybrid_sota_models/sota_open_models/stable_diffusion_series/#7-stable-diffusion-v35","title":"7. Stable Diffusion v3.5","text":"<ul> <li> <p>repo: https://github.com/Stability-AI/sd3.5</p> </li> <li> <p>Resources:</p> </li> <li>applications on stable diffusion: https://github.com/awesome-stable-diffusion/awesome-stable-diffusion</li> <li>inference code: https://github.com/Stability-AI/sd3.5</li> </ul>"},{"location":"book/chapter11_hybrid_sota_models/sota_open_models/stable_diffusion_xl/","title":"Stable Diffusion SDXL","text":"<ul> <li>repo: https://github.com/Stability-AI/generative-models</li> <li>paper: /https://arxiv.org/pdf/2307.01952</li> <li>date: 2023 July</li> <li>Main changes</li> <li>Three times large UNet</li> <li>Second text encoder</li> <li>novel conditioning schemes</li> <li>train on multiple aspect ratios</li> <li>refinement model to improve the visual fidelity</li> </ul>"},{"location":"book/chapter11_hybrid_sota_models/sota_open_models/stable_diffusion_xl/#architecture","title":"Architecture","text":"<p> Participants were asked to choose their favorite image generation among four models, the results are show above.</p>"},{"location":"book/chapter11_hybrid_sota_models/sota_open_models/stable_diffusion_xl/#network-stucture","title":"Network stucture","text":"<ul> <li>VAE:</li> <li>VAE is almost the same, but it implemented a meomory Efficient Scross Attention, which used the package <code>xformers</code></li> </ul>"},{"location":"book/chapter11_hybrid_sota_models/sota_open_models/stable_diffusion_xl/#condition-no-image-size","title":"Condition no image size","text":"<p>Previous training discard images under 512 pixels which could discard large portion of data, lead to a loss in performance and generalization</p> <p>we provide the original (i.e., before any rescaling) height and width of the images as an additional conditioning to the model csize = (h-original,w-original). Each component is independently embedded using a Fourier feature encoding, and these encodings are concatenated into a single vector that we feed into the model by adding it to the timestep embedding</p> <p></p>"},{"location":"book/chapter11_hybrid_sota_models/sota_open_models/stable_diffusion_xl/#condition-on-cropping-parameters","title":"Condition on cropping parameters","text":"<p>Random cropping during training coulde leads to incomplete generation like the following. So we put it in the condition and set (\\(c_top,c_left\\)) be zeros to obtained the object centered samples. Further, we can tune the two parameters to simulate the amount of cropping during inference.  </p> <ul> <li>Method     During dataloading, we uniformly sample crop coordinates ctop and cleft (integers specifying the amount of pixels cropped from the top-left corner along the height and width axes, respectively) and feed them into the model as conditioning parameters via Fourier feature embeddings, similar to the size conditioning described above</li> </ul>"},{"location":"book/chapter11_hybrid_sota_models/sota_open_models/stable_diffusion_xl/#condition-on-aspect-ratio","title":"Condition on aspect ratio","text":"<pre><code>Most text2image models produces saure images.\n- Trainig tricks\n  - Prepare different bukets of images, each bucket has the same shape, while the total number of pixels is approximaly $1024^2$.\n  - During training, single batch comes from same bucket, and change the bucket for different step in the training loop\n- Condition tricks\n  - similar to the size condition and crop-parameter condition, the target shape $(h_{target},w_{target})$ is embedded into a Fourier space\n</code></pre>"},{"location":"book/chapter11_hybrid_sota_models/sota_open_models/stable_diffusion_xl/#improved-autoencoder","title":"Improved autoencoder","text":"<pre><code>1. used ema in training\n2. large batchsize 9-&gt; 256\n![alt text](../../../images/image-63.png)\n</code></pre>"},{"location":"book/chapter11_hybrid_sota_models/sota_open_models/stable_diffusion_xl/#experiment","title":"Experiment","text":""},{"location":"book/chapter11_hybrid_sota_models/sota_open_models/stable_diffusion_xl/#final-model-sdxl-training-overview","title":"Final Model (SDXL) Training Overview:","text":"<ul> <li>SDXL is trained using a multi-stage procedure.</li> <li>It uses the autoencoder described in Sec. 2.4.</li> <li>A discrete-time diffusion schedule with 1000 steps [14, 45] is employed.</li> </ul>"},{"location":"book/chapter11_hybrid_sota_models/sota_open_models/stable_diffusion_xl/#stage-1-base-model-pretraining","title":"Stage 1 \u2013 Base Model Pretraining:","text":"<ul> <li>Pretrain a base model (see Tab. 1) on an internal dataset.</li> <li>The dataset\u2019s height and width distribution is visualized in Fig. 2.</li> <li>Training is performed for 600,000 optimization steps.</li> <li>Images are at a resolution of 256\u00d7256 pixels.</li> <li>A batch size of 2048 is used.</li> <li>Size- and crop-conditioning is applied as described in Sec. 2.2.</li> </ul>"},{"location":"book/chapter11_hybrid_sota_models/sota_open_models/stable_diffusion_xl/#stage-2-continued-training-on-higher-resolution","title":"Stage 2 \u2013 Continued Training on Higher Resolution:","text":"<ul> <li>Continue training on images resized to 512\u00d7512 pixels.</li> <li>Training is performed for an additional 200,000 optimization steps.</li> </ul>"},{"location":"book/chapter11_hybrid_sota_models/sota_open_models/stable_diffusion_xl/#stage-3-multi-aspect-training","title":"Stage 3 \u2013 Multi-Aspect Training:","text":"<ul> <li>Utilize multi-aspect training (Sec. 2.3) combined with an offset-noise level of 0.05 [11, 25].</li> <li>Train the model on images with different aspect ratios (Sec. 2.3, App. I) covering an approximate area of 1024\u00d71024 pixels.</li> </ul>"},{"location":"book/chapter11_hybrid_sota_models/sota_open_models/stable_diffusion_xl/#optional-refinement-stage","title":"Optional Refinement Stage","text":"<pre><code>![alt text](../../../images/image-64.png)\n</code></pre>"},{"location":"book/chapter11_hybrid_sota_models/sota_open_models/stable_diffusion_xl/#observed-issue","title":"Observed Issue:","text":"<ul> <li>The base model sometimes produces samples with low local quality</li> </ul>"},{"location":"book/chapter11_hybrid_sota_models/sota_open_models/stable_diffusion_xl/#solution-to-improve-sample-quality","title":"Solution to Improve Sample Quality:","text":"<ul> <li>Training a Separate Refinement Model:</li> <li>A separate latent diffusion model (LDM) is trained in the same latent space.</li> <li>This refinement LDM is specialized on high-quality, high-resolution data.</li> <li>It employs a noising-denoising process as introduced by SDEdit [28].</li> <li>The refinement model is specialized on the first 200 discrete noise scales (following [1]).</li> </ul>"},{"location":"book/chapter11_hybrid_sota_models/sota_open_models/stable_diffusion_xl/#inference-process-with-refinement","title":"Inference Process with Refinement:","text":"<ul> <li>Render latents from the base SDXL using the same text input.</li> <li>Directly diffuse and denoise these latents in the latent space with the refinement model     </li> <li>Optional Step:</li> <li>Although this refinement step is optional, it improves sample quality\u2014especially for detailed backgrounds and human faces</li> </ul>"},{"location":"book/chapter11_hybrid_sota_models/sota_open_models/stable_diffusion_xl/#limitation","title":"Limitation","text":"<ul> <li> <p>Difficulty with Intricate Structures:   The model sometimes struggles with synthesizing fine details in complex structures (e.g., human hands) due to high variance and the challenge of extracting accurate 3D shape information.</p> </li> <li> <p>Imperfect Photorealism:   While the generated images are very realistic, they may lack certain nuances such as subtle lighting effects or fine texture variations.</p> </li> <li> <p>Biases in Training Data:   The heavy reliance on large-scale datasets can inadvertently introduce social and racial biases, which may be reflected in the generated outputs.</p> </li> <li> <p>Concept Bleeding:   The model can sometimes merge or incorrectly bind attributes between distinct objects (e.g., mixing up the colors of a hat and gloves or an orange sunglass bleeding from an orange sweater).</p> </li> <li> <p>Text Rendering Issues:   The model encounters challenges in rendering long, legible text, occasionally producing random characters or inconsistent text output.</p> </li> </ul>"},{"location":"book/chapter11_hybrid_sota_models/sota_open_models/stable_diffusion_xl/#codes","title":"Codes","text":""},{"location":"book/chapter11_hybrid_sota_models/sota_open_models/stable_diffusion_xl/#diffusoin-engine","title":"Diffusoin Engine","text":"<p>The latent diffusion class is refactored compared with LDM. There are seperate modules</p> <ol> <li>model</li> <li>denoiser</li> <li>sampler</li> <li>conditioner</li> <li>scheduler</li> <li>loss_fn</li> <li>ema</li> </ol> <p>Now let's check the training steps compared with stable diffusion v2</p> encode_first_stageforwardloss <p><pre><code>    def encode_first_stage(self, x):\n        n_samples = default(self.en_and_decode_n_samples_a_time, x.shape[0])\n        n_rounds = math.ceil(x.shape[0] / n_samples)\n        all_out = []\n        with torch.autocast(\"cuda\", enabled=not self.disable_first_stage_autocast):\n            for n in range(n_rounds):\n                out = self.first_stage_model.encode(\n                    x[n * n_samples : (n + 1) * n_samples]\n                )\n                all_out.append(out)\n        z = torch.cat(all_out, dim=0)\n        z = self.scale_factor * z\n        return z\n</code></pre> the difference is that the encoding split the batch into sub batches to save memory, which may due to the larger training batchsize</p> <p>forward<pre><code>    def shared_step(self, batch: Dict) -&gt; Any:\n        x = self.get_input(batch)\n        x = self.encode_first_stage(x)\n        batch[\"global_step\"] = self.global_step\n        loss, loss_dict = self(x, batch)\n        return loss, loss_dict\n</code></pre> Exactly the same</p> <p>loss config<pre><code>    loss_fn_config:\n    target: sgm.modules.diffusionmodules.loss.StandardDiffusionLoss\n    params:\n        loss_weighting_config:\n        target: sgm.modules.diffusionmodules.loss_weighting.EpsWeighting\n        sigma_sampler_config:\n        target: sgm.modules.diffusionmodules.sigma_sampling.DiscreteSampling\n        params:\n            num_idx: 1000\n\n            discretization_config:\n            target: sgm.modules.diffusionmodules.discretizer.LegacyDDPMDiscretization\n</code></pre> the loss is defined seperately, we will lookinto the details in following sections</p>"},{"location":"book/chapter11_hybrid_sota_models/sota_open_models/stable_diffusion_xl/#model","title":"Model","text":"<pre><code>    network_config:\n    target: sgm.modules.diffusionmodules.openaimodel.UNetModel\n    params:\n        use_checkpoint: True\n        in_channels: 4\n        out_channels: 4\n        model_channels: 320\n        attention_resolutions: [1, 2, 4]\n        num_res_blocks: 2\n        channel_mult: [1, 2, 4, 4]\n        num_head_channels: 64\n        num_classes: sequential\n        adm_in_channels: 1792\n        num_heads: 1\n        transformer_depth: 1\n        context_dim: 768\n        spatial_transformer_attn_type: softmax-xformers\n</code></pre> <p>use the same vae structure compared with stable diffusion v2</p>"},{"location":"book/chapter11_hybrid_sota_models/sota_open_models/stable_diffusion_xl/#denoise","title":"Denoise","text":"ConfigDiscreteDenoiserdiscritilizationScaling <p><pre><code>denoiser_config:\n  target: sgm.modules.diffusionmodules.denoiser.DiscreteDenoiser\n  params:\n    num_idx: 1000\n    scaling_config:\n      target: sgm.modules.diffusionmodules.denoiser_scaling.EpsScaling\n    discretization_config:\n      target: sgm.modules.diffusionmodules.discretizer.LegacyDDPMDiscretization\n</code></pre> the module also contains two sub modeuls, denoiser scaling and discretizer</p> <pre><code>class DiscreteDenoiser(Denoiser):\ndef __init__(\n    self,\n    scaling_config: Dict,\n    num_idx: int,\n    discretization_config: Dict,\n    do_append_zero: bool = False,\n    quantize_c_noise: bool = True,\n    flip: bool = True,\n):\n    super().__init__(scaling_config)\n    self.discretization: Discretization = instantiate_from_config(\n        discretization_config\n    )\n    sigmas = self.discretization(num_idx, do_append_zero=do_append_zero, flip=flip)\n    self.register_buffer(\"sigmas\", sigmas)\n    self.quantize_c_noise = quantize_c_noise\n    self.num_idx = num_idx\ndef sigma_to_idx(self, sigma: torch.Tensor) -&gt; torch.Tensor:\n    dists = sigma - self.sigmas[:, None]\n    return dists.abs().argmin(dim=0).view(sigma.shape)\ndef idx_to_sigma(self, idx: Union[torch.Tensor, int]) -&gt; torch.Tensor:\n    return self.sigmas[idx]\ndef possibly_quantize_sigma(self, sigma: torch.Tensor) -&gt; torch.Tensor:\n    return self.idx_to_sigma(self.sigma_to_idx(sigma))\ndef possibly_quantize_c_noise(self, c_noise: torch.Tensor) -&gt; torch.Tensor:\n    if self.quantize_c_noise:\n        return self.sigma_to_idx(c_noise)\n    else:\n        return c_noise\n</code></pre> <ul> <li> <p>Purpose:   Quantizes continuous noise scales into a discrete set, facilitating controlled denoising.</p> </li> <li> <p>Key Methods:</p> <ul> <li>sigma_to_idx:    Maps a continuous \u03c3 to the index of the closest discrete \u03c3 value:</li> </ul> <p>$$    \\text{index} = \\arg\\min_i \\left| \\sigma - \\sigma_i \\right|    $$</p> <ul> <li> <p>idx_to_sigma:    Returns the discrete \u03c3 corresponding to a given index.</p> </li> <li> <p>possibly_quantize_sigma:    Quantizes a continuous \u03c3 by mapping it to its nearest discrete value.</p> </li> <li> <p>possibly_quantize_c_noise:    Optionally quantizes the noise conditioning value (<code>c_noise</code>) based on a flag.</p> </li> </ul> </li> </ul> <pre><code>class LegacyDDPMDiscretization(Discretization):\n    def **init**(\n        self,\n        linear_start=0.00085,\n        linear_end=0.0120,\n        num_timesteps=1000,\n    ):\n        super().**init**()\n        self.num_timesteps = num_timesteps\n        betas = make_beta_schedule(\n            \"linear\", num_timesteps, linear_start=linear_start, linear_end=linear_end\n        )\n        alphas = 1.0 - betas\n        self.alphas_cumprod = np.cumprod(alphas, axis=0)\n        self.to_torch = partial(torch.tensor, dtype=torch.float32)\n    def get_sigmas(self, n, device=\"cpu\"):\n        if n &lt; self.num_timesteps:\n            timesteps = generate_roughly_equally_spaced_steps(n, self.num_timesteps)\n            alphas_cumprod = self.alphas_cumprod[timesteps]\n        elif n == self.num_timesteps:\n            alphas_cumprod = self.alphas_cumprod\n        else:\n            raise ValueError\n        to_torch = partial(torch.tensor, dtype=torch.float32, device=device)\n        sigmas = to_torch((1 - alphas_cumprod) / alphas_cumprod) ** 0.5\n        return torch.flip(sigmas, (0,))\n</code></pre> <ul> <li> <p>Purpose:     Computes discrete noise scales (\u03c3 values) for a DDPM.</p> </li> <li> <p>Process &amp; Formulas:</p> <ul> <li>Beta Schedule:   Generates a sequence of \u03b2\u209c values linearly spaced between <code>linear_start</code> and <code>linear_end</code> for t = 1,\u2026,T.</li> <li>Alpha Calculation:</li> </ul> <p>$$   \\alpha_t = 1 - \\beta_t   $$</p> <ul> <li>Cumulative Product:</li> </ul> <p>$$   \\bar{\\alpha}t = \\prod \\alpha_i   $$}^{t</p> <ul> <li>Sigma Calculation:</li> </ul> <p>$$   \\sigma_t = \\sqrt{\\frac{1 - \\bar{\\alpha}_t}{\\bar{\\alpha}_t}}   $$</p> <ul> <li>The <code>get_sigmas</code> method selects \u03c3 values (optionally a subset) and flips them so that they go from high to low noise levels.</li> </ul> </li> </ul> <pre><code>class EpsScaling:\n    def __call__(\n        self, sigma: torch.Tensor\n    ) -&gt; Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n        c_skip = torch.ones_like(sigma, device=sigma.device)\n        c_out = -sigma\n        c_in = 1 / (sigma**2 + 1.0) ** 0.5\n        c_noise = sigma.clone()\n        return c_skip, c_out, c_in, c_noise\n</code></pre> <ul> <li> <p>Purpose:   Provides scaling factors for different branches in the network based on a given noise scale \u03c3.</p> </li> <li> <p>Scaling Factors &amp; Formulas:</p> <ul> <li>Skip Connection Factor: \\(c_{\\text{skip}} = 1\\)</li> <li>Output Factor: \\(c_{\\text{out}} = -\\sigma\\)</li> <li>Input Factor: \\(c_{\\text{in}} = \\frac{1}{\\sqrt{\\sigma^2 + 1}}\\)</li> <li>Noise Factor: \\(c_{\\text{noise}} = \\sigma\\)</li> </ul> </li> </ul>"},{"location":"book/chapter11_hybrid_sota_models/sota_open_models/stable_diffusion_xl/#conditioner","title":"Conditioner","text":"configcodetxt embedder 1txt embedder 2concat timesstep embedderTime Embedding <pre><code>conditioner_config:\n  target: sgm.modules.GeneralConditioner\n  params:\n    emb_models:\n      - is_trainable: False\n        input_key: txt\n        target: sgm.modules.encoders.modules.FrozenCLIPEmbedder\n        params:\n          layer: hidden\n          layer_idx: 11\n      - is_trainable: False\n        input_key: txt\n        target: sgm.modules.encoders.modules.FrozenOpenCLIPEmbedder2\n        params:\n          arch: ViT-bigG-14\n          version: laion2b_s39b_b160k\n          freeze: True\n          layer: penultimate\n          always_return_pooled: True\n          legacy: False\n      - is_trainable: False\n        input_key: original_size_as_tuple\n        target: sgm.modules.encoders.modules.ConcatTimestepEmbedderND\n        params:\n          outdim: 256\n      - is_trainable: False\n        input_key: crop_coords_top_left\n        target: sgm.modules.encoders.modules.ConcatTimestepEmbedderND\n        params:\n          outdim: 256\n      - is_trainable: False\n        input_key: target_size_as_tuple\n        target: sgm.modules.encoders.modules.ConcatTimestepEmbedderND\n        params:\n          outdim: 256\n</code></pre> <p><pre><code>class GeneralConditioner(nn.Module):\n    OUTPUT_DIM2KEYS = {2: \"vector\", 3: \"crossattn\", 4: \"concat\"} # , 5: \"concat\"}\n    KEY2CATDIM = {\"vector\": 1, \"crossattn\": 2, \"concat\": 1, \"cond_view\": 1, \"cond_motion\": 1}\n    def __init__(self, emb_models: Union[List, ListConfig]):\n        super().__init__()\n        embedders = []\n        for n, embconfig in enumerate(emb_models):\n            embedder = instantiate_from_config(embconfig)\n            assert isinstance(\n                embedder, AbstractEmbModel\n            ), f\"embedder model {embedder.__class__.__name__} has to inherit from AbstractEmbModel\"\n            embedder.is_trainable = embconfig.get(\"is_trainable\", False)\n            embedder.ucg_rate = embconfig.get(\"ucg_rate\", 0.0)\n            if not embedder.is_trainable:\n                embedder.train = disabled_train\n                for param in embedder.parameters():\n                    param.requires_grad = False\n                embedder.eval()\n            print(\n                f\"Initialized embedder #{n}: {embedder.__class__.__name__} \"\n                f\"with {count_params(embedder, False)} params. Trainable: {embedder.is_trainable}\"\n            )\n            if \"input_key\" in embconfig:\n                embedder.input_key = embconfig[\"input_key\"]\n            elif \"input_keys\" in embconfig:\n                embedder.input_keys = embconfig[\"input_keys\"]\n            else:\n                raise KeyError(\n                    f\"need either 'input_key' or 'input_keys' for embedder {embedder.__class__.__name__}\"\n                )\n            embedder.legacy_ucg_val = embconfig.get(\"legacy_ucg_value\", None)\n            if embedder.legacy_ucg_val is not None:\n                embedder.ucg_prng = np.random.RandomState()\n            embedders.append(embedder)\n        self.embedders = nn.ModuleList(embedders)\n    def possibly_get_ucg_val(self, embedder: AbstractEmbModel, batch: Dict) -&gt; Dict:\n        assert embedder.legacy_ucg_val is not None\n        p = embedder.ucg_rate\n        val = embedder.legacy_ucg_val\n        for i in range(len(batch[embedder.input_key])):\n            if embedder.ucg_prng.choice(2, p=[1 - p, p]):\n                batch[embedder.input_key][i] = val\n        return batch\n    def forward(\n        self, batch: Dict, force_zero_embeddings: Optional[List] = None\n    ) -&gt; Dict:\n        output = dict()\n        if force_zero_embeddings is None:\n            force_zero_embeddings = []\n        for embedder in self.embedders:\n            embedding_context = nullcontext if embedder.is_trainable else torch.no_grad\n            with embedding_context():\n                if hasattr(embedder, \"input_key\") and (embedder.input_key is not None):\n                    if embedder.legacy_ucg_val is not None:\n                        batch = self.possibly_get_ucg_val(embedder, batch)\n                    emb_out = embedder(batch[embedder.input_key])\n                elif hasattr(embedder, \"input_keys\"):\n                    emb_out = embedder(*[batch[k] for k in embedder.input_keys])\n            assert isinstance(\n                emb_out, (torch.Tensor, list, tuple)\n            ), f\"encoder outputs must be tensors or a sequence, but got {type(emb_out)}\"\n            if not isinstance(emb_out, (list, tuple)):\n                emb_out = [emb_out]\n            for emb in emb_out:\n                if embedder.input_key in [\"cond_view\", \"cond_motion\"]:\n                    out_key = embedder.input_key\n                else:\n                    out_key = self.OUTPUT_DIM2KEYS[emb.dim()]\n                if embedder.ucg_rate &gt; 0.0 and embedder.legacy_ucg_val is None:\n                    emb = (\n                        expand_dims_like(\n                            torch.bernoulli(\n                                (1.0 - embedder.ucg_rate)\n                                * torch.ones(emb.shape[0], device=emb.device)\n                            ),\n                            emb,\n                        )\n                        * emb\n                    )\n                if (\n                    hasattr(embedder, \"input_key\")\n                    and embedder.input_key in force_zero_embeddings\n                ):\n                    emb = torch.zeros_like(emb)\n                if out_key in output:\n                    output[out_key] = torch.cat(\n                        (output[out_key], emb), self.KEY2CATDIM[out_key]\n                    )\n                else:\n                    output[out_key] = emb\n        return output\n    def get_unconditional_conditioning(\n        self,\n        batch_c: Dict,\n        batch_uc: Optional[Dict] = None,\n        force_uc_zero_embeddings: Optional[List[str]] = None,\n        force_cond_zero_embeddings: Optional[List[str]] = None,\n    ):\n        if force_uc_zero_embeddings is None:\n            force_uc_zero_embeddings = []\n        ucg_rates = list()\n        for embedder in self.embedders:\n            ucg_rates.append(embedder.ucg_rate)\n            embedder.ucg_rate = 0.0\n        c = self(batch_c, force_cond_zero_embeddings)\n        uc = self(batch_c if batch_uc is None else batch_uc, force_uc_zero_embeddings)\n        for embedder, rate in zip(self.embedders, ucg_rates):\n            embedder.ucg_rate = rate\n        return c, uc\n</code></pre> Convet the original input to the embeding with different embedding model. Have three different kind of conditoin types. 1. vector: similar to time embedding 2. crossattn: similar to text embedding which is a sequence 3. concat: shape of [B,C,H,W] that can concat with original input like the depth, low-res, and masked image condition</p> <p>FrozenCLIPEmbedder<pre><code>class FrozenCLIPEmbedder(AbstractEmbModel):\n    LAYERS = [\"last\", \"pooled\", \"hidden\"]\n    def __init__(\n        self,\n        version=\"openai/clip-vit-large-patch14\",\n        device=\"cuda\",\n        max_length=77,\n        freeze=True,\n        layer=\"last\",\n        layer_idx=None,\n        always_return_pooled=False,\n    ):  # clip-vit-base-patch32\n        super().__init__()\n        assert layer in self.LAYERS\n        self.tokenizer = CLIPTokenizer.from_pretrained(version)\n        self.transformer = CLIPTextModel.from_pretrained(version)\n        self.device = device\n        self.max_length = max_length\n        if freeze:\n            self.freeze()\n        self.layer = layer\n        self.layer_idx = layer_idx\n        self.return_pooled = always_return_pooled\n        if layer == \"hidden\":\n            assert layer_idx is not None\n            assert 0 &lt;= abs(layer_idx) &lt;= 12\n    @autocast\n    def forward(self, text):\n        batch_encoding = self.tokenizer(\n            text,\n            truncation=True,\n            max_length=self.max_length,\n            return_length=True,\n            return_overflowing_tokens=False,\n            padding=\"max_length\",\n            return_tensors=\"pt\",\n        )\n        tokens = batch_encoding[\"input_ids\"].to(self.device)\n        outputs = self.transformer(\n            input_ids=tokens, output_hidden_states=self.layer == \"hidden\"\n        )\n        if self.layer == \"last\":\n            z = outputs.last_hidden_state\n        elif self.layer == \"pooled\":\n            z = outputs.pooler_output[:, None, :]\n        else:\n            z = outputs.hidden_states[self.layer_idx]\n        if self.return_pooled:\n            return z, outputs.pooler_output\n        return z\n</code></pre> It provides three different embedding reresentation 1. last hidder state: [B,S,D] 2. pooled hidden state: [B,D] 3. hidden stage correspoding to given layer index: [B,S,D] In this model, it uses the 11-th  layer</p> <p><pre><code>class FrozenOpenCLIPEmbedder2(AbstractEmbModel):\n    LAYERS = [\"pooled\", \"last\", \"penultimate\"]\n    def **init**(\n        self,\n        arch=\"ViT-H-14\",\n        version=\"laion2b_s32b_b79k\",\n        device=\"cuda\",\n        max_length=77,\n        freeze=True,\n        layer=\"last\",\n        always_return_pooled=False,\n        legacy=True,\n    ):\n        super().**init**()\n        assert layer in self.LAYERS\n        model,_, _= open_clip.create_model_and_transforms(\n            arch,\n            device=torch.device(\"cpu\"),\n            pretrained=version,\n        )\n        del model.visual\n        self.model = model\n        self.device = device\n        self.max_length = max_length\n        self.return_pooled = always_return_pooled\n        if freeze:\n            self.freeze()\n        self.layer = layer\n        if self.layer == \"last\":\n            self.layer_idx = 0\n        elif self.layer == \"penultimate\":\n            self.layer_idx = 1\n        else:\n            raise NotImplementedError()\n        self.legacy = legacy\n    @autocast\n    def forward(self, text):\n        tokens = open_clip.tokenize(text)\n        z = self.encode_with_transformer(tokens.to(self.device))\n        if not self.return_pooled and self.legacy:\n            return z\n        if self.return_pooled:\n            assert not self.legacy\n            return z[self.layer], z[\"pooled\"]\n        return z[self.layer]\n    def encode_with_transformer(self, text):\n        x = self.model.token_embedding(text)  # [batch_size, n_ctx, d_model]\n        x = x + self.model.positional_embedding\n        x = x.permute(1, 0, 2)  # NLD -&gt; LND\n        x = self.text_transformer_forward(x, attn_mask=self.model.attn_mask)\n        if self.legacy:\n            x = x[self.layer]\n            x = self.model.ln_final(x)\n            return x\n        else:\n            # x is a dict and will stay a dict\n            o = x[\"last\"]\n            o = self.model.ln_final(o)\n            pooled = self.pool(o, text)\n            x[\"pooled\"] = pooled\n            return x\n    def pool(self, x, text):\n        # take features from the eot embedding (eot_token is the highest number in each sequence)\n        x = (\n            x[torch.arange(x.shape[0]), text.argmax(dim=-1)]\n            @ self.model.text_projection\n        )\n        return x\n    def text_transformer_forward(self, x: torch.Tensor, attn_mask=None):\n        outputs = {}\n        for i, r in enumerate(self.model.transformer.resblocks):\n            if i == len(self.model.transformer.resblocks) - 1:\n                outputs[\"penultimate\"] = x.permute(1, 0, 2)  # LND -&gt; NLD\n            if (\n                self.model.transformer.grad_checkpointing\n                and not torch.jit.is_scripting()\n            ):\n                x = checkpoint(r, x, attn_mask)\n            else:\n                x = r(x, attn_mask=attn_mask)\n        outputs[\"last\"] = x.permute(1, 0, 2)  # LND -&gt; NLD\n        return outputs\n</code></pre> In this model, it used ViT-bigG-14. It also supports three different types of embedding. Here it chosed 'penultimate', (second last) layer and returned pooled hidden state. If returned pool is true, this embedder will output two hidden stages: origina one and pooled one, and this two will be treated differently. pooled embedding will be treated as vector embedding same as the process of time step embedding. Original hidden stage will be treated as sequential embedding which fed into the U-Net through the cross-attention.</p> <p><pre><code>class ConcatTimestepEmbedderND(AbstractEmbModel):\n    \"\"\"embeds each dimension independently and concatenates them\"\"\"\n    def __init__(self, outdim):\n        super().__init__()\n        self.timestep = Timestep(outdim)\n        self.outdim = outdim\n    def forward(self, x):\n        if x.ndim == 1:\n            x = x[:, None]\n        assert len(x.shape) == 2\n        b, dims = x.shape[0], x.shape[1]\n        x = rearrange(x, \"b d -&gt; (b d)\")\n        emb = self.timestep(x)\n        emb = rearrange(emb, \"(b d) d2 -&gt; b (d d2)\", b=b, d=dims, d2=self.outdim)\n        return emb\n</code></pre> this embedding handles the 'scalar' conditions including the class label, time step, cropping parameter, original image size, target image size</p> <p><pre><code>def timestep_embedding(timesteps, dim, max_period=10000, repeat_only=False):\n    \"\"\"\n    Create sinusoidal timestep embeddings.\n    :param timesteps: a 1-D Tensor of N indices, one per batch element.\n                    These may be fractional.\n    :param dim: the dimension of the output.\n    :param max_period: controls the minimum frequency of the embeddings.\n    :return: an [N x dim] Tensor of positional embeddings.\n    \"\"\"\n    if not repeat_only:\n        half = dim // 2\n        freqs = torch.exp(\n            -math.log(max_period)\n            * torch.arange(start=0, end=half, dtype=torch.float32)\n            / half\n        ).to(device=timesteps.device)\n        args = timesteps[:, None].float() * freqs[None]\n        embedding = torch.cat([torch.cos(args), torch.sin(args)], dim=-1)\n        if dim % 2:\n            embedding = torch.cat(\n                [embedding, torch.zeros_like(embedding[:, :1])], dim=-1\n            )\n    else:\n        embedding = repeat(timesteps, \"b -&gt; b d\", d=dim)\n    return embedding\n</code></pre> Here are the formulas expressed in mathematical notation using the English exp and log functions:</p> <ol> <li> <p>Frequency Calculation:     Let</p> \\[ H = \\left\\lfloor \\frac{D}{2} \\right\\rfloor, \\] <p>where \\( D \\) is the embedding dimension. For each index \\( i \\) (with \\( 0 \\le i &lt; H \\)), define the frequency as:</p> \\[ \\omega_i = \\exp\\!\\left(-\\frac{i}{H} \\cdot \\log(\\text{max\\_period})\\right) = \\text{max\\_period}^{-\\frac{i}{H}}. \\] </li> <li> <p>Angle Computation: For a given time step \\( t \\), compute:</p> </li> </ol> \\[ \\theta_{t,i} = t \\cdot \\omega_i. \\] <ol> <li>Embedding Vector: The embedding for time step \\( t \\) is then given by:</li> </ol> \\[ \\mathbf{e}(t) = \\Bigl[\\cos\\bigl(\\theta_{t,0}\\bigr),\\, \\cos\\bigl(\\theta_{t,1}\\bigr),\\, \\dots,\\, \\cos\\bigl(\\theta_{t,H-1}\\bigr),\\, \\sin\\bigl(\\theta_{t,0}\\bigr),\\, \\sin\\bigl(\\theta_{t,1}\\bigr),\\, \\dots,\\, \\sin\\bigl(\\theta_{t,H-1}\\bigr)\\Bigr]. \\] <p>If \\( D \\) is odd, append one extra zero to reach the dimension \\( D \\).</p> <ol> <li>Alternate Case (repeat_only): If the <code>repeat_only</code> flag is set to true, then the embedding is simply:</li> </ol> \\[ \\mathbf{e}(t) = \\underbrace{[t,\\, t,\\, \\dots,\\, t]}_{D\\text{ times}}. \\]"},{"location":"book/chapter11_hybrid_sota_models/sota_open_models/stable_diffusion_xl/#standarddiffusionloss","title":"StandardDiffusionLoss","text":"<p>here is the code from the repo, but it seems not belong to the one use in sd-xl.</p> <pre><code>class StandardDiffusionLoss(nn.Module):\n    def __init__(\n        self,\n        sigma_sampler_config: dict,\n        loss_weighting_config: dict,\n        loss_type: str = \"l2\",\n        offset_noise_level: float = 0.0,\n        batch2model_keys: Optional[Union[str, List[str]]] = None,\n    ):\n        super().__init__()\n        assert loss_type in [\"l2\", \"l1\", \"lpips\"]\n        self.sigma_sampler = instantiate_from_config(sigma_sampler_config)\n        self.loss_weighting = instantiate_from_config(loss_weighting_config)\n        self.loss_type = loss_type\n        self.offset_noise_level = offset_noise_level\n        if loss_type == \"lpips\":\n            self.lpips = LPIPS().eval()\n        if not batch2model_keys:\n            batch2model_keys = []\n        if isinstance(batch2model_keys, str):\n            batch2model_keys = [batch2model_keys]\n        self.batch2model_keys = set(batch2model_keys)\n    def get_noised_input(\n        self, sigmas_bc: torch.Tensor, noise: torch.Tensor, input: torch.Tensor\n    ) -&gt; torch.Tensor:\n        noised_input = input + noise * sigmas_bc\n        return noised_input\n    def forward(\n        self,\n        network: nn.Module,\n        denoiser: Denoiser,\n        conditioner: GeneralConditioner,\n        input: torch.Tensor,\n        batch: Dict,\n    ) -&gt; torch.Tensor:\n        cond = conditioner(batch)\n        return self._forward(network, denoiser, cond, input, batch)\n    def _forward(\n        self,\n        network: nn.Module,\n        denoiser: Denoiser,\n        cond: Dict,\n        input: torch.Tensor,\n        batch: Dict,\n    ) -&gt; Tuple[torch.Tensor, Dict]:\n        additional_model_inputs = {\n            key: batch[key] for key in self.batch2model_keys.intersection(batch)\n        }\n        sigmas = self.sigma_sampler(input.shape[0]).to(input)\n        noise = torch.randn_like(input)\n        if self.offset_noise_level &gt; 0.0:\n            offset_shape = (\n                (input.shape[0], 1, input.shape[2])\n                if self.n_frames is not None\n                else (input.shape[0], input.shape[1])\n            )\n            noise = noise + self.offset_noise_level * append_dims(\n                torch.randn(offset_shape, device=input.device),\n                input.ndim,\n            )\n        sigmas_bc = append_dims(sigmas, input.ndim)\n        noised_input = self.get_noised_input(sigmas_bc, noise, input)\n\n        model_output = denoiser(\n            network, noised_input, sigmas, cond, **additional_model_inputs\n        )\n        w = append_dims(self.loss_weighting(sigmas), input.ndim)\n        return self.get_loss(model_output, input, w)\n    def get_loss(self, model_output, target, w):\n        if self.loss_type == \"l2\":\n            return torch.mean(\n                (w * (model_output - target) ** 2).reshape(target.shape[0], -1), 1\n            )\n        elif self.loss_type == \"l1\":\n            return torch.mean(\n                (w * (model_output - target).abs()).reshape(target.shape[0], -1), 1\n            )\n        elif self.loss_type == \"lpips\":\n            loss = self.lpips(model_output, target).reshape(-1)\n            return loss\n        else:\n            raise NotImplementedError(f\"Unknown loss type {self.loss_type}\")\n</code></pre> <p>Fot the EDM training, the sampling of sigma is continuous class</p> <pre><code>EDMSampling:\n    def __init__(self, p_mean=-1.2, p_std=1.2):\n        self.p_mean = p_mean\n        self.p_std = p_std\n    def __call__(self, n_samples, rand=None):\n        log_sigma = self.p_mean + self.p_std * default(rand, torch.randn((n_samples,)))\n        return log_sigma.exp()\n</code></pre> <p>One thing need to mention in the code, the forward process</p> \\[x_t =x_0 +\\sigma_t \\epsilon\\] <p>And different from the previous versoin, the network predicted the original input but not the noise.</p>"},{"location":"book/chapter1_Introduction/1.1terminology/","title":"\u672f\u8bed\u8868\uff08Terminology\uff09","text":"<p>\u6240\u6709\u672f\u8bed\u4f1a\u88ab\u6839\u636e\u5df2\u6709\u5185\u5bb9\u81ea\u52a8\u751f\u6210 </p>"},{"location":"book/chapter1_Introduction/1.1terminology/#1","title":"1. \u56fe\u5f62\u5b66\u672f\u8bed","text":""},{"location":"book/chapter1_Introduction/1.1terminology/#11-artifacts","title":"1.1 [Artifacts]","text":"<p>Artifacts\u662f\u56fe\u5f62\u5b66\u4e0a\u7684\u4e00\u4e2a\u6982\u5ff5\uff0c\u6216\u8005\u8bf4\u662f\u4e00\u4e2a\u6897\uff0c\u8868\u793a\u4e86\u4e00\u5207\u5728\u56fe\u5f62\u5b66\u4e0a\u7684\u9519\u8bef\uff0c\u5f02\u5e38\uff0c\u4e0d\u5e0c\u671b\u770b\u5230\u7684\u7ed3\u679c\uff0c\u770b\u4e0a\u53bb\u4e0d\u5bf9\u7684\u6548\u679c\u4ee5\u53ca\u5404\u79cd\u7455\u75b5\u3002</p>"},{"location":"book/chapter1_Introduction/1.1terminology/#12-aliasing-artifacts","title":"1.2 [Aliasing Artifacts]","text":"<p>\u91c7\u6837\u800c\u5bfc\u81f4\u7684\u8d70\u6837\uff08Aliasing Artifacts\uff09\u4f1a\u5bfc\u81f4\u5f88\u591a\u73b0\u8c61\uff0c\u6bd4\u5982\uff1a</p> <ul> <li>\u952f\u9f7f\uff08Jaggies\uff0c\u5bf9\u7a7a\u95f4\u8fdb\u884c\u91c7\u6837\uff09</li> <li>\u6469\u5c14\u7eb9\uff08Moire\uff0c\u5bf9\u56fe\u50cf\u8fdb\u884c\u91c7\u6837\uff09</li> <li>\u8f6c\u8f6e\u6548\u5e94\uff08\u4e00\u5757\u8f6c\u8f6e\u4e0a\u4ea7\u751f\u89c6\u89c9\u4e0a\u7684\u4e0d\u540c\u8f6c\u901f\uff0c\u5bf9\u65f6\u95f4\u8fdb\u884c\u91c7\u6837\uff09</li> </ul>"},{"location":"book/chapter1_Introduction/1.1terminology/#2","title":"2. \u4fe1\u53f7\u5904\u7406\u672f\u8bed","text":""},{"location":"book/chapter1_Introduction/1.1terminology/#21","title":"2.1 \u5e26\u9650\u4fe1\u53f7","text":"<p>\u9891\u8c31\uff08\u5085\u91cc\u53f6\u53d8\u6362\uff09\u5728\u67d0\u4e2a\u9891\u7387\u8303\u56f4\u5185\u6709\u9650\u7684\u4fe1\u53f7\uff0c\u5373\u5b58\u5728\u6700\u9ad8\u9891\u7387B\uff0c\u4f7f\u5f97\u6240\u6709\u9ad8\u4e8eB\u7684\u9891\u7387\u5206\u91cf\u4e3a\u96f6\u3002</p>"},{"location":"book/chapter1_Introduction/1.1terminology/#22","title":"2.2 \u5948\u594e\u65af\u7279\u9891\u7387","text":"<p>\u91c7\u6837\u9891\u7387\u5fc5\u987b\u5927\u4e8e\u4fe1\u53f7\u6700\u9ad8\u9891\u7387\u7684\u4e24\u500d\uff0c\u8fd9\u4e2a\u6700\u5c0f\u91c7\u6837\u9891\u7387\u79f0\u4e3a\u5948\u594e\u65af\u7279\u9891\u7387\u3002</p>"},{"location":"book/chapter1_Introduction/1.1terminology/#23","title":"2.3 \u7406\u60f3\u6ee4\u6ce2\u5668","text":"<p>\u9891\u7387\u54cd\u5e94\u5728\u901a\u5e26\u548c\u963b\u5e26\u4e4b\u95f4\u6709\u7a81\u53d8\uff0c\u65e0\u8fc7\u6e21\u5e26\u7684\u6ee4\u6ce2\u5668\u3002\u4e0e\u4e4b\u76f8\u5bf9\u7684\u662f\u5b9e\u9645\u6ee4\u6ce2\u5668\uff0c\u5b83\u5b58\u5728\u8fc7\u6e21\u5e26\u548c\u901a\u5e26\u6ce2\u7eb9\u3002</p>"},{"location":"book/chapter1_Introduction/1.1terminology/#3","title":"3. \u793a\u4f8b\u56fe\u7247","text":""},{"location":"book/chapter1_Introduction/1.1terminology/#31","title":"3.1 \u51e0\u4f55\u8d70\u6837","text":""},{"location":"book/chapter1_Introduction/1.1terminology/#32","title":"3.2 \u6e32\u67d3\u8d70\u6837","text":""},{"location":"book/chapter1_Introduction/1.1terminology/#4","title":"4. \u7f29\u5199","text":""},{"location":"book/chapter1_Introduction/1.1terminology/#41-ebm","title":"4.1 EBM","text":"<p>Energey Based Model, \u80fd\u91cf\u6a21\u578b</p>"},{"location":"book/chapter1_Introduction/1.2fourier_transform/","title":"1. \u5085\u91cc\u53f6\u53d8\u5316","text":""},{"location":"book/chapter1_Introduction/1.2fourier_transform/#1-11","title":"1. 1.1 \u5085\u91cc\u53f6\u53d8\u6362\u548c\u9006\u53d8\u6362\u516c\u5f0f","text":""},{"location":"book/chapter1_Introduction/1.2fourier_transform/#11-111-continuous-fourier-transform","title":"1.1 1.1.1 \u8fde\u7eed\u5085\u91cc\u53f6\u53d8\u6362 (Continuous Fourier Transform)","text":"<ul> <li>\u516c\u5f0f\uff1a   \\(X(f) = \\int_{-\\infty}^{\\infty} x(t) e^{-j 2\\pi f t} \\, dt\\)</li> </ul> <p>\u5176\u4e2d\uff1a   - \\(x(t)\\)\uff1a\u65f6\u57df\u4fe1\u53f7\u3002   - \\(X(f)\\)\uff1a\u9891\u57df\u4fe1\u53f7\uff08\u9891\u8c31\uff09\u3002   - \\(f\\)\uff1a\u9891\u7387\uff0c\u5355\u4f4d\u4e3a\u8d6b\u5179 (Hz)\u3002</p>"},{"location":"book/chapter1_Introduction/1.2fourier_transform/#12-112-inverse-continuous-fourier-transform","title":"1.2 1.1.2 \u8fde\u7eed\u5085\u91cc\u53f6\u9006\u53d8\u6362 (Inverse Continuous Fourier Transform)","text":"<ul> <li>\u516c\u5f0f\uff1a   \\(x(t) = \\int_{-\\infty}^{\\infty} X(f) e^{j 2\\pi f t} \\, df\\)</li> </ul> <p>\u5176\u4e2d\uff1a   - \\(X(f)\\)\uff1a\u9891\u57df\u4fe1\u53f7\u3002   - \\(x(t)\\)\uff1a\u91cd\u5efa\u56de\u6765\u7684\u65f6\u57df\u4fe1\u53f7\u3002</p>"},{"location":"book/chapter1_Introduction/1.2fourier_transform/#13-113-discrete-fourier-transform-dft","title":"1.3 1.1.3 \u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362 (Discrete Fourier Transform, DFT)","text":"<p>\u5bf9\u4e8e\u79bb\u6563\u4fe1\u53f7 \\(x[n]\\)\uff1a - \u516c\u5f0f\uff1a   \\(X[k] = \\sum_{n=0}^{N-1} x[n] e^{-j \\frac{2\\pi}{N} kn}, \\quad k = 0, 1, 2, \\dots, N-1\\)</p> <p>\u5176\u4e2d\uff1a   - \\(x[n]\\)\uff1a\u65f6\u57df\u79bb\u6563\u4fe1\u53f7\u3002   - \\(X[k]\\)\uff1a\u9891\u57df\u79bb\u6563\u4fe1\u53f7\u3002</p>"},{"location":"book/chapter1_Introduction/1.2fourier_transform/#14-114-inverse-discrete-fourier-transform-idft","title":"1.4 1.1.4 \u79bb\u6563\u5085\u91cc\u53f6\u9006\u53d8\u6362 (Inverse Discrete Fourier Transform, IDFT)","text":"<ul> <li>\u516c\u5f0f\uff1a   \\(x[n] = \\frac{1}{N} \\sum_{k=0}^{N-1} X[k] e^{j \\frac{2\\pi}{N} kn}, \\quad n = 0, 1, 2, \\dots, N-1\\)</li> </ul> <p>\u5176\u4e2d\uff1a   - \\(X[k]\\)\uff1a\u9891\u57df\u79bb\u6563\u4fe1\u53f7\u3002   - \\(x[n]\\)\uff1a\u91cd\u5efa\u56de\u6765\u7684\u65f6\u57df\u4fe1\u53f7\u3002</p>"},{"location":"book/chapter1_Introduction/1.2fourier_transform/#2-12","title":"2. 1.2 \u516c\u5f0f\u4e2d\u7684\u5173\u952e\u70b9","text":""},{"location":"book/chapter1_Introduction/1.2fourier_transform/#21-121","title":"2.1 1.2.1 \u6b63\u8d1f\u53f7\u533a\u522b\uff1a","text":"<ul> <li>\u5085\u91cc\u53f6\u53d8\u6362\u4e2d\uff0c\u6307\u6570\u90e8\u5206\u4e3a \\(e^{-j 2\\pi f t}\\)\uff08\u6b63\u5f26\u548c\u4f59\u5f26\u5206\u91cf\uff09\u3002</li> <li>\u9006\u53d8\u6362\u4e2d\uff0c\u6307\u6570\u90e8\u5206\u4e3a \\(e^{j 2\\pi f t}\\)\uff08\u76f8\u4f4d\u76f8\u53cd\uff09\u3002</li> </ul>"},{"location":"book/chapter1_Introduction/1.2fourier_transform/#22-122-vs","title":"2.2 1.2.2 \u8fde\u7eed vs \u79bb\u6563\uff1a","text":"<ul> <li>\u8fde\u7eed\u53d8\u6362\u6d89\u53ca\u79ef\u5206\uff08\u65f6\u57df\u5230\u9891\u57df\uff0c\u6216\u9891\u57df\u5230\u65f6\u57df\uff09\u3002</li> <li>\u79bb\u6563\u53d8\u6362\u6d89\u53ca\u6c42\u548c\uff08\u7528\u4e8e\u79bb\u6563\u4fe1\u53f7\u5904\u7406\uff09\u3002</li> </ul>"},{"location":"book/chapter1_Introduction/1.2fourier_transform/#23-123","title":"2.3 1.2.3 \u5f52\u4e00\u5316\u7cfb\u6570\uff1a","text":"<ul> <li>\u5bf9\u4e8e\u8fde\u7eed\u5085\u91cc\u53f6\u53d8\u6362\uff0c\u4e0d\u9700\u8981\u663e\u5f0f\u5f52\u4e00\u5316\u7cfb\u6570\u3002</li> <li>\u5bf9\u4e8e\u79bb\u6563\u5085\u91cc\u53f6\u9006\u53d8\u6362\uff0c\u9700\u8981\u9664\u4ee5\u4fe1\u53f7\u957f\u5ea6 \\(N\\)\u3002</li> </ul>"},{"location":"book/chapter1_Introduction/1.2fourier_transform/#3-13","title":"3. 1.3 \u793a\u4f8b","text":""},{"location":"book/chapter1_Introduction/1.2fourier_transform/#31-131","title":"3.1 1.3.1 \u8fde\u7eed\u4fe1\u53f7\u793a\u4f8b","text":"<p>\u65f6\u57df\u4fe1\u53f7\uff1a\\(x(t) = \\cos(2\\pi f_0 t)\\)</p> <ul> <li> <p>\u5085\u91cc\u53f6\u53d8\u6362\uff1a   \\(X(f) = \\frac{1}{2}[\\delta(f - f_0) + \\delta(f + f_0)]\\)</p> </li> <li> <p>\u9006\u53d8\u6362\uff1a   \\(x(t) = \\int_{-\\infty}^\\infty \\left[\\frac{1}{2}\\delta(f - f_0) + \\frac{1}{2}\\delta(f + f_0)\\right] e^{j 2\\pi f t} \\, df\\)   \u5f97\u5230 \\(x(t) = \\cos(2\\pi f_0 t)\\)\u3002</p> </li> </ul>"},{"location":"book/chapter1_Introduction/1.2fourier_transform/#32-132","title":"3.2 1.3.2 \u79bb\u6563\u4fe1\u53f7\u793a\u4f8b","text":"<p>\u65f6\u57df\u4fe1\u53f7\uff1a\\(x[n] = [1, 2, 3, 4]\\)</p> <ul> <li> <p>\u5085\u91cc\u53f6\u53d8\u6362\uff1a   \u4f7f\u7528\u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362\u516c\u5f0f\u8ba1\u7b97 \\(X[k]\\)\u3002</p> </li> <li> <p>\u9006\u53d8\u6362\uff1a   \u4f7f\u7528\u9006\u53d8\u6362\u516c\u5f0f\u8ba1\u7b97 \\(x[n]\\)\uff0c\u91cd\u5efa\u4fe1\u53f7\u3002</p> </li> </ul>"},{"location":"book/chapter1_Introduction/1.2fourier_transform/#4-14","title":"4. 1.4 \u79bb\u6563\u4fe1\u53f7\u505a\u5085\u91cc\u53f6\u53d8\u6362\u7684\u4f8b\u5b50","text":""},{"location":"book/chapter1_Introduction/1.2fourier_transform/#41-141","title":"4.1 1.4.1 \u79bb\u6563\u4fe1\u53f7","text":"<p>\u5047\u8bbe\u4e00\u4e2a\u957f\u5ea6\u4e3a \\(N=4\\) \u7684\u79bb\u6563\u4fe1\u53f7\uff1a</p> \\[ x[n] = [1, 2, 3, 4], \\quad n = 0, 1, 2, 3 \\] <p>\u6211\u4eec\u7528\u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362 (DFT) \u7684\u516c\u5f0f\u8ba1\u7b97\u5176\u9891\u57df\u4fe1\u53f7 \\(X[k]\\)\u3002</p>"},{"location":"book/chapter1_Introduction/1.2fourier_transform/#42-142-dft","title":"4.2 1.4.2 DFT \u516c\u5f0f","text":"\\[ X[k] = \\sum_{n=0}^{N-1} x[n] e^{-j \\frac{2\\pi}{N} kn}, \\quad k = 0, 1, \\dots, N-1 \\]"},{"location":"book/chapter1_Introduction/1.2fourier_transform/#43-143","title":"4.3 1.4.3 \u8ba1\u7b97\u6b65\u9aa4","text":"<ol> <li> <p>\u4fe1\u53f7\u957f\u5ea6 \\(N=4\\)\uff0c\u9891\u7387\u7d22\u5f15 \\(k = 0, 1, 2, 3\\)\u3002</p> </li> <li> <p>\u6307\u6570\u9879\uff1a\\(e^{-j \\frac{2\\pi}{N} kn} = e^{-j \\frac{\\pi}{2} kn}\\)\u3002</p> </li> <li> <p>\u5206\u522b\u8ba1\u7b97 \\(k = 0, 1, 2, 3\\) \u65f6\u7684 \\(X[k]\\)\uff1a</p> </li> </ol>"},{"location":"book/chapter1_Introduction/1.2fourier_transform/#44-144-k-0","title":"4.4 1.4.4 k = 0","text":"\\[ X[0] = \\sum_{n=0}^{3} x[n] e^{-j \\frac{2\\pi}{4} \\cdot 0 \\cdot n} = x[0] + x[1] + x[2] + x[3] = 1 + 2 + 3 + 4 = 10 \\]"},{"location":"book/chapter1_Introduction/1.2fourier_transform/#45-145-k-1","title":"4.5 1.4.5 k = 1","text":"\\[ X[1] = \\sum_{n=0}^{3} x[n] e^{-j \\frac{\\pi}{2} n} = x[0] + x[1] e^{-j \\frac{\\pi}{2}} + x[2] e^{-j \\pi} + x[3] e^{-j \\frac{3\\pi}{2}} \\] <p>\u8ba1\u7b97\u6bcf\u4e00\u9879:</p> <ul> <li>\\(x[0] = 1\\)</li> <li>\\(x[1] e^{-j \\frac{\\pi}{2}} = 2 \\cdot (-j) = -2j\\)</li> <li>\\(x[2] e^{-j \\pi} = 3 \\cdot (-1) = -3\\)</li> <li>\\(x[3] e^{-j \\frac{3\\pi}{2}} = 4 \\cdot j = 4j\\)</li> </ul> <p>\u76f8\u52a0\uff1a</p> \\[ X[1] = 1 - 2\\cdot j - 3 + 4\\cdot j = -2 + 2\\cdot j \\]"},{"location":"book/chapter1_Introduction/1.2fourier_transform/#46-146-k-2","title":"4.6 1.4.6 k = 2","text":"\\[ X[2] = \\sum_{n=0}^{3} x[n] e^{-j \\pi n} = x[0] + x[1] e^{-j \\pi} + x[2] e^{-j 2\\pi} + x[3] e^{-j 3\\pi} \\] <p>\u8ba1\u7b97\u6bcf\u4e00\u9879\uff1a</p> <ul> <li>\\(x[0] = 1\\)</li> <li>\\(x[1] e^{-j \\pi} = 2 \\cdot (-1) = -2\\)</li> <li>\\(x[2] e^{-j 2\\pi} = 3 \\cdot 1 = 3\\)</li> <li>\\(x[3] e^{-j 3\\pi} = 4 \\cdot (-1) = -4\\)</li> </ul> <p>\u76f8\u52a0\uff1a</p> \\[ X[2] = 1 - 2 + 3 - 4 = -2 \\]"},{"location":"book/chapter1_Introduction/1.2fourier_transform/#47-147-k-3","title":"4.7 1.4.7 k = 3","text":"\\[ X[3] = \\sum_{n=0}^{3} x[n] e^{-j \\frac{3\\pi}{2} n} = x[0] + x[1] e^{-j \\frac{3\\pi}{2}} + x[2] e^{-j 3\\pi} + x[3] e^{-j \\frac{9\\pi}{2}} \\] <p>\u8ba1\u7b97\u6bcf\u4e00\u9879\uff1a</p> <ul> <li>\\(x[0] = 1\\)</li> <li>\\(x[1] e^{-j \\frac{3\\pi}{2}} = 2 \\cdot j = 2j\\)</li> <li>\\(x[2] e^{-j 3\\pi} = 3 \\cdot (-1) = -3\\)</li> <li>\\(x[3] e^{-j \\frac{9\\pi}{2}} = 4 \\cdot (-j) = -4j\\)</li> </ul> <p>\u76f8\u52a0:</p> \\[ X[3] = 1 + 2j - 3 - 4j = -2 - 2j \\]"},{"location":"book/chapter1_Introduction/1.2fourier_transform/#5-15","title":"5. 1.5 \u7ed3\u679c\u6c47\u603b","text":"<p>\u9891\u57df\u4fe1\u53f7 \\(X[k]\\) \u4e3a\uff1a</p> \\[ X[k] = [10, -2 + 2j, -2, -2 - 2j] \\]"},{"location":"book/chapter1_Introduction/1.2fourier_transform/#6-16","title":"6. 1.6 \u89e3\u91ca","text":"<ol> <li>\\(X[0] = 10\\)\uff1a\u76f4\u6d41\u5206\u91cf\uff0c\u8868\u793a\u4fe1\u53f7\u7684\u5e73\u5747\u503c\u3002</li> <li>\u5176\u4f59 \\(X[k]\\)\uff1a\u8868\u793a\u4fe1\u53f7\u7684\u5176\u4ed6\u9891\u7387\u5206\u91cf\uff0c\u5305\u62ec\u632f\u5e45\u548c\u76f8\u4f4d\u3002</li> </ol>"},{"location":"book/chapter1_Introduction/1.2fourier_transform/#7-17","title":"7. 1.7 \u53ef\u89c6\u5316\u9891\u8c31","text":"<ol> <li>\u5e45\u503c \\(|X[k]|\\)\uff1a</li> </ol> <p>$$    |X[0]| = 10, \\quad |X[1]| = \\sqrt{(-2)^2 + 2^2} = \\sqrt{8}, \\quad |X[2]| = 2, \\quad |X[3]| = \\sqrt{8}    $$</p> <ol> <li>\u76f8\u4f4d \\(\\text{arg}(X[k])\\)\uff1a</li> </ol> <p>$$    \\text{arg}(X[1]) = \\arctan\\left(\\frac{2}{-2}\\right) = \\frac{3\\pi}{4}, \\quad \\text{arg}(X[3]) = \\arctan\\left(\\frac{-2}{-2}\\right) = -\\frac{3\\pi}{4}    $$</p>"},{"location":"book/chapter1_Introduction/1.2fourier_transform/#8-18","title":"8. 1.8 \u5085\u91cc\u53f6\u53d8\u6362\u540e\u7684\u7cfb\u6570\u4ee3\u8868\u7684\u6027\u8d28","text":""},{"location":"book/chapter1_Introduction/1.2fourier_transform/#81-181-magnitude","title":"8.1 1.8.1 \u5e45\u503c\uff08Magnitude\uff09","text":"<p>\u5e45\u503c \\(|X(f)|\\) \u6216 \\(|X[k]|\\) \u8868\u793a\u4fe1\u53f7\u5728\u67d0\u4e2a\u9891\u7387\u4e0a\u7684\u5f3a\u5ea6\u6216\u80fd\u91cf\u5206\u5e03\u3002</p> <ul> <li>\u8f83\u5927\u7684\u5e45\u503c\u610f\u5473\u7740\u4fe1\u53f7\u5728\u8be5\u9891\u7387\u4e0a\u5177\u6709\u8f83\u5f3a\u7684\u6210\u5206\u3002</li> <li>\u8f83\u5c0f\u7684\u5e45\u503c\u610f\u5473\u7740\u8be5\u9891\u7387\u4e0a\u7684\u6210\u5206\u8f83\u5f31\uff0c\u751a\u81f3\u53ef\u4ee5\u5ffd\u7565\u3002</li> </ul> <p>\u793a\u4f8b\uff1a - \u5982\u679c\u4fe1\u53f7\u4e3b\u8981\u662f\u4e00\u4e2a\u9891\u7387\u4e3a \\(f_0\\) \u7684\u6b63\u5f26\u6ce2\uff0c\u5176\u9891\u8c31\u5728 \\(f = f_0\\) \u548c \\(f = -f_0\\) \u5904\u6709\u5cf0\u503c\u3002 - \u591a\u4e2a\u9891\u7387\u6210\u5206\u7684\u4fe1\u53f7\u5728\u5bf9\u5e94\u9891\u7387\u4f4d\u7f6e\u4f1a\u51fa\u73b0\u591a\u4e2a\u5cf0\u503c\u3002</p>"},{"location":"book/chapter1_Introduction/1.2fourier_transform/#82-182-phase","title":"8.2 1.8.2 \u76f8\u4f4d\uff08Phase\uff09","text":"<p>\u76f8\u4f4d \\(\\text{arg}(X(f))\\) \u6216 \\(\\text{arg}(X[k])\\) \u8868\u793a\u4fe1\u53f7\u5728\u5bf9\u5e94\u9891\u7387\u4e0a\u7684\u76f8\u4f4d\u504f\u79fb\u3002</p> <ul> <li>\u76f8\u4f4d\u51b3\u5b9a\u4e86\u8be5\u9891\u7387\u6210\u5206\u7684\u6b63\u5f26\u6ce2\uff08\u6216\u4f59\u5f26\u6ce2\uff09\u5728\u65f6\u95f4\u4e0a\u7684\u504f\u79fb\u3002</li> <li>\u6539\u53d8\u76f8\u4f4d\u4f1a\u6539\u53d8\u4fe1\u53f7\u7684\u65f6\u57df\u8868\u73b0\uff0c\u4f46\u4e0d\u4f1a\u5f71\u54cd\u5176\u80fd\u91cf\u3002</li> </ul> <p>\u793a\u4f8b\uff1a - \u5982\u679c\u4fe1\u53f7\u7684\u76f8\u4f4d\u4e3a\u96f6\uff0c\u9891\u7387\u6210\u5206\u4e0e\u65f6\u95f4\u8f74\u5bf9\u9f50\u3002 - \u975e\u96f6\u76f8\u4f4d\u8868\u793a\u8be5\u9891\u7387\u6210\u5206\u7684\u65f6\u95f4\u504f\u79fb\u91cf\u3002</p>"},{"location":"book/chapter1_Introduction/1.2fourier_transform/#83-183-dc-component","title":"8.3 1.8.3 \u76f4\u6d41\u5206\u91cf\uff08DC Component\uff09","text":"<p>\u5f53\u9891\u7387 \\(f = 0\\) \u6216 \\(k = 0\\) \u65f6\u7684\u7cfb\u6570 \\(X(0)\\) \u6216 \\(X[0]\\) \u8868\u793a\u4fe1\u53f7\u7684\u5e73\u5747\u503c\uff0c\u79f0\u4e3a\u76f4\u6d41\u5206\u91cf\u3002</p> <ul> <li>\u5982\u679c\u4fe1\u53f7\u7684\u5e73\u5747\u503c\u4e3a\u96f6\uff08\u4f8b\u5982\u7eaf\u4ea4\u6d41\u4fe1\u53f7\uff09\uff0c\u76f4\u6d41\u5206\u91cf\u4e3a\u96f6\u3002</li> <li>\u5982\u679c\u4fe1\u53f7\u6709\u975e\u96f6\u5e73\u5747\u503c\uff0c\u5219 \\(X[0]\\) \u5bf9\u5e94\u8be5\u503c\u3002</li> </ul>"},{"location":"book/chapter1_Introduction/1.2fourier_transform/#84-184","title":"8.4 1.8.4 \u9891\u7387\u5206\u91cf","text":"<p>\u6bcf\u4e2a\u5085\u91cc\u53f6\u7cfb\u6570 \\(X(f)\\) \u6216 \\(X[k]\\) \u5bf9\u5e94\u4e8e\u4fe1\u53f7\u5728\u67d0\u4e2a\u7279\u5b9a\u9891\u7387\u4e0a\u7684\u8d21\u732e\u3002</p> <ul> <li>\u8fde\u7eed\u5085\u91cc\u53f6\u53d8\u6362\u4e2d\u7684 \\(X(f)\\)\uff1a\u5bf9\u5e94\u8fde\u7eed\u9891\u7387 \\(f\\)\u3002</li> <li>\u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362\u4e2d\u7684 \\(X[k]\\)\uff1a\u5bf9\u5e94\u79bb\u6563\u9891\u7387 \\(k \\cdot f_s / N\\)\uff0c\u5176\u4e2d \\(f_s\\) \u662f\u91c7\u6837\u9891\u7387\uff0c\\(N\\) \u662f\u4fe1\u53f7\u957f\u5ea6\u3002</li> </ul>"},{"location":"book/chapter1_Introduction/1.2fourier_transform/#85-185","title":"8.5 1.8.5 \u80fd\u91cf\u548c\u529f\u7387","text":"<p>\u901a\u8fc7\u5e15\u585e\u74e6\u5c14\u5b9a\u7406\uff0c\u5085\u91cc\u53f6\u53d8\u6362\u7684\u7cfb\u6570\u53ef\u4ee5\u7528\u6765\u8ba1\u7b97\u4fe1\u53f7\u7684\u603b\u80fd\u91cf\u6216\u529f\u7387\uff1a</p> <ul> <li>\u8fde\u7eed\u4fe1\u53f7\u7684\u80fd\u91cf\uff1a</li> </ul> <p>$$   E = \\int_{-\\infty}^\\infty |x(t)|^2 dt = \\int_{-\\infty}^\\infty |X(f)|^2 df   $$</p> <ul> <li>\u79bb\u6563\u4fe1\u53f7\u7684\u80fd\u91cf\uff1a</li> </ul> <p>$$   E = \\sum_{n=0}^{N-1} |x[n]|^2 = \\frac{1}{N} \\sum_{k=0}^{N-1} |X[k]|^2   $$</p>"},{"location":"book/chapter1_Introduction/1.2fourier_transform/#86-186","title":"8.6 1.8.6 \u5bf9\u79f0\u6027","text":"<p>\u5982\u679c\u4fe1\u53f7\u662f\u5b9e\u503c\u4fe1\u53f7\uff08\u4f8b\u5982\u97f3\u9891\u4fe1\u53f7\uff09\uff1a - \u9891\u8c31\u5173\u4e8e\u96f6\u9891\u5bf9\u79f0\uff1a</p> <p>$$   X(-f) = \\overline{X(f)} \\quad \\text{\uff08\u5171\u8f6d\u5bf9\u79f0\uff09}   $$</p> <p>\u5bf9\u4e8e\u79bb\u6563\u4fe1\u53f7\uff1a</p> <p>$$   X[N-k] = \\overline{X[k]}   $$</p> <p>\u5982\u679c\u4fe1\u53f7\u662f\u5076\u51fd\u6570\u6216\u5947\u51fd\u6570\uff0c\u9891\u8c31\u4e5f\u4f1a\u8868\u73b0\u51fa\u5bf9\u79f0\u6027\u6216\u53cd\u5bf9\u79f0\u6027\u3002</p>"},{"location":"book/chapter1_Introduction/1.2fourier_transform/#87-187","title":"8.7 1.8.7 \u9891\u57df\u5206\u8fa8\u7387","text":"<p>\u5085\u91cc\u53f6\u7cfb\u6570\u7684\u6570\u91cf\u548c\u95f4\u9694\u53d6\u51b3\u4e8e\u4fe1\u53f7\u7684\u91c7\u6837\u7387\u548c\u957f\u5ea6\uff1a - \u4fe1\u53f7\u957f\u5ea6\u8d8a\u957f\uff0c\u9891\u57df\u5206\u8fa8\u7387\u8d8a\u9ad8\uff08\u9891\u7387\u95f4\u9694\u8d8a\u5c0f\uff09\u3002 - \u5982\u679c\u4fe1\u53f7\u662f\u5468\u671f\u4fe1\u53f7\uff0c\u5176\u9891\u8c31\u4f1a\u8868\u73b0\u4e3a\u79bb\u6563\u7684\u5cf0\u503c\u3002</p>"},{"location":"book/chapter1_Introduction/1.2fourier_transform/#9-19","title":"9. 1.9 \u603b\u7ed3","text":"<p>\u5085\u91cc\u53f6\u53d8\u6362\u540e\u7684\u7cfb\u6570\u4e3b\u8981\u63cf\u8ff0\u4fe1\u53f7\u7684\u4ee5\u4e0b\u6027\u8d28\uff1a 1. \u9891\u7387\u6210\u5206\u7684\u5f3a\u5ea6\uff08\u5e45\u503c\uff09\u3002 2. \u9891\u7387\u6210\u5206\u7684\u65f6\u95f4\u504f\u79fb\uff08\u76f8\u4f4d\uff09\u3002 3. \u4fe1\u53f7\u7684\u76f4\u6d41\u5206\u91cf\uff08\u96f6\u9891\u5206\u91cf\uff09\u3002 4. \u4fe1\u53f7\u7684\u9891\u7387\u5206\u5e03\u548c\u80fd\u91cf\u5206\u5e03\u3002</p> <p>\u8fd9\u4e9b\u6027\u8d28\u5171\u540c\u5b9a\u4e49\u4e86\u4fe1\u53f7\u5728\u9891\u57df\u4e2d\u7684\u8868\u73b0\uff0c\u662f\u4fe1\u53f7\u5206\u6790\u548c\u5904\u7406\u7684\u57fa\u7840\u3002</p>"},{"location":"book/chapter1_Introduction/1.2fourier_transform/#10-110","title":"10. 1.10 \u89d2\u9891\u7387\u4e0e\u9891\u7387","text":""},{"location":"book/chapter1_Introduction/1.2fourier_transform/#101-1101-frequency","title":"10.1 1.10.1 \u9891\u7387\uff08Frequency\uff09","text":"<ul> <li>\u5b9a\u4e49\uff1a\u9891\u7387\u8868\u793a\u4fe1\u53f7\u6bcf\u79d2\u5b8c\u6210\u632f\u8361\u7684\u6b21\u6570\uff0c\u901a\u5e38\u7528\u7b26\u53f7 \\(f\\) \u8868\u793a\u3002</li> <li>\u5355\u4f4d\uff1a\u8d6b\u5179 (Hz)\uff0c\u5373\u6bcf\u79d2\u632f\u8361\u7684\u5468\u671f\u6570\u3002</li> <li>\u516c\u5f0f\uff1a</li> </ul> <p>$$   f = \\frac{1}{T}   $$</p> <p>\u5176\u4e2d \\(T\\) \u662f\u4fe1\u53f7\u7684\u5468\u671f\uff0c\u8868\u793a\u5b8c\u6210\u4e00\u6b21\u5b8c\u6574\u632f\u8361\u6240\u9700\u7684\u65f6\u95f4\u3002</p> <p>\u793a\u4f8b\uff1a - \u4e00\u4e2a\u4fe1\u53f7\u6bcf\u79d2\u632f\u8361 50 \u6b21\uff0c\u5176\u9891\u7387\u4e3a \\(f = 50 \\, \\text{Hz}\\)\u3002 - \u7535\u7f51\u4ea4\u6d41\u7535\u7684\u9891\u7387\u901a\u5e38\u4e3a \\(50 \\, \\text{Hz}\\) \u6216 \\(60 \\, \\text{Hz}\\)\u3002</p>"},{"location":"book/chapter1_Introduction/1.2fourier_transform/#102-1102-angular-frequency","title":"10.2 1.10.2 \u89d2\u9891\u7387\uff08Angular Frequency\uff09","text":"<ul> <li>\u5b9a\u4e49\uff1a\u89d2\u9891\u7387\u8868\u793a\u4fe1\u53f7\u6bcf\u79d2\u8f6c\u8fc7\u7684\u5f27\u5ea6\u6570\uff0c\u901a\u5e38\u7528\u7b26\u53f7 \\(\\omega\\) \u8868\u793a\u3002</li> <li>\u5355\u4f4d\uff1a\u5f27\u5ea6\u6bcf\u79d2 (rad/s)\u3002</li> <li>\u516c\u5f0f\uff1a</li> </ul> <p>$$   \\omega = 2\\pi f   $$</p> <p>\u5176\u4e2d \\(2\\pi\\) \u8868\u793a\u4e00\u4e2a\u5b8c\u6574\u7684\u5706\uff08\u5bf9\u5e94\u4fe1\u53f7\u5b8c\u6210\u4e00\u4e2a\u5468\u671f\uff09\u3002</p> <p>\u89d2\u9891\u7387\u7684\u7269\u7406\u610f\u4e49\uff1a - \u4e00\u4e2a\u5468\u671f\u5185\uff0c\u4fe1\u53f7\u7684\u76f8\u4f4d\u53d8\u5316\u4e3a \\(2\\pi\\) \u5f27\u5ea6\uff08\u5bf9\u5e94\u5b8c\u6574\u7684\u4e00\u4e2a\u6ce2\u5f62\uff09\u3002 - \u89d2\u9891\u7387\u662f\u9891\u7387\u7684\u53e6\u4e00\u79cd\u8868\u793a\u65b9\u5f0f\uff0c\u66f4\u9002\u5408\u63cf\u8ff0\u6b63\u5f26\u6ce2\u4e2d\u7684\u632f\u8361\u7279\u6027\u3002</p>"},{"location":"book/chapter1_Introduction/1.2fourier_transform/#103-1103","title":"10.3 1.10.3 \u9891\u7387\u4e0e\u89d2\u9891\u7387\u7684\u533a\u522b\u4e0e\u8054\u7cfb","text":"<ul> <li>\u9891\u7387 \\(f\\) \u63cf\u8ff0\u7684\u662f\u4fe1\u53f7\u5728\u5355\u4f4d\u65f6\u95f4\u5185\u7684\u5468\u671f\u6570\uff08\u6b21/\u79d2\uff09\u3002</li> <li>\u89d2\u9891\u7387 \\(\\omega\\) \u63cf\u8ff0\u7684\u662f\u4fe1\u53f7\u5728\u5355\u4f4d\u65f6\u95f4\u5185\u7684\u76f8\u4f4d\u53d8\u5316\u91cf\uff08\u5f27\u5ea6/\u79d2\uff09\u3002</li> <li>\u5b83\u4eec\u4e4b\u95f4\u7684\u5173\u7cfb\u4e3a\uff1a</li> </ul> <p>$$   \\omega = 2\\pi f \\quad \\text{\u6216} \\quad f = \\frac{\\omega}{2\\pi}   $$</p>"},{"location":"book/chapter1_Introduction/1.2fourier_transform/#104-1104","title":"10.4 1.10.4 \u6b63\u5f26\u6ce2\u4e2d\u7684\u4f7f\u7528","text":"<p>\u5728\u6b63\u5f26\u6ce2\u4e2d\uff1a - \u4f7f\u7528\u89d2\u9891\u7387\u7684\u8868\u8fbe\uff1a</p> <p>$$   x(t) = A \\cos(\\omega t + \\phi)   $$</p> <p>\u5176\u4e2d\uff1a   - \\(\\omega\\) \u662f\u89d2\u9891\u7387\uff08\u5f27\u5ea6/\u79d2\uff09\u3002   - \\(A\\) \u662f\u632f\u5e45\u3002   - \\(\\phi\\) \u662f\u521d\u59cb\u76f8\u4f4d\u3002</p> <ul> <li>\u4f7f\u7528\u9891\u7387\u7684\u8868\u8fbe\uff1a</li> </ul> <p>$$   x(t) = A \\cos(2\\pi f t + \\phi)   $$</p> <p>\u6ce8\u610f\uff1a - \u89d2\u9891\u7387\u5728\u6b63\u5f26\u4fe1\u53f7\u7684\u6570\u5b66\u5206\u6790\u4e2d\u66f4\u4e3a\u5e38\u7528\u3002 - \u9891\u7387\u7528\u4e8e\u63cf\u8ff0\u4fe1\u53f7\u7684\u5468\u671f\u6027\u548c\u8ba1\u6570\u7279\u6027\u3002</p>"},{"location":"book/chapter1_Introduction/1.2fourier_transform/#105-1105","title":"10.5 1.10.5 \u793a\u4f8b\u5bf9\u6bd4","text":"<p>\u5047\u8bbe\u4e00\u4e2a\u4fe1\u53f7\u7684\u9891\u7387\u4e3a \\(f = 10 \\, \\text{Hz}\\)\uff1a - \u5468\u671f\uff1a</p> <p>$$   T = \\frac{1}{f} = \\frac{1}{10} = 0.1 \\, \\text{\u79d2}   $$</p> <ul> <li>\u89d2\u9891\u7387\uff1a</li> </ul> <p>$$   \\omega = 2\\pi f = 2\\pi \\cdot 10 \\approx 62.8 \\, \\text{rad/s}   $$</p> <p>\u8fd9\u610f\u5473\u7740\u6bcf\u79d2\u5b8c\u6210 10 \u4e2a\u5468\u671f\uff0c\u540c\u65f6\u6bcf\u79d2\u76f8\u4f4d\u53d8\u5316\u7ea6\u4e3a \\(62.8 \\, \\text{\u5f27\u5ea6}\\)\u3002</p>"},{"location":"book/chapter1_Introduction/1.2fourier_transform/#106-1106","title":"10.6 1.10.6 \u4fe1\u53f7\u9891\u8c31\u56fe","text":"<p>\u70b9\u51fb\u94fe\u63a5\u67e5\u770b\u4fe1\u53f7\u9891\u8c31\u4ecb\u7ecd  \u7eb5\u8f74\u8868\u793a\u5e45\u5ea6\uff0c\u6a2a\u8f74\u8868\u793a\u89d2\u8bc4\u7387\uff0c\u5ffd\u7565\u4e86\u76f8\u4f4d\u4fe1\u606f\u3002</p>"},{"location":"book/chapter1_Introduction/1.2fourier_transform/#107-1107","title":"10.7 1.10.7 \u603b\u7ed3","text":"\u7279\u6027 \u9891\u7387 \\(f\\) \u89d2\u9891\u7387 \\(\\omega\\) \u5355\u4f4d \u8d6b\u5179 (Hz) \u5f27\u5ea6\u6bcf\u79d2 (rad/s) \u63cf\u8ff0 \u6bcf\u79d2\u7684\u5468\u671f\u6570 \u6bcf\u79d2\u7684\u76f8\u4f4d\u53d8\u5316\u91cf \u5173\u7cfb \\(f = \\frac{\\omega}{2\\pi}\\) \\(\\omega = 2\\pi f\\) \u5e94\u7528\u573a\u666f \u5468\u671f\u6027\u4fe1\u53f7\u7684\u63cf\u8ff0 \u6b63\u5f26\u6ce2\u548c\u52a8\u6001\u7cfb\u7edf\u7684\u6570\u5b66\u8868\u8fbe"},{"location":"book/chapter1_Introduction/1.2fourier_transform/#1-2","title":"1. 2. \u5468\u671f\u4fe1\u53f7\u548c\u975e\u5468\u671f\u4fe1\u53f7\u7684\u9891\u8c31","text":""},{"location":"book/chapter1_Introduction/1.2fourier_transform/#11-21","title":"1.1 2.1 \u5468\u671f\u4fe1\u53f7\u4e0e\u975e\u5468\u671f\u4fe1\u53f7\u7684\u9891\u8c31","text":""},{"location":"book/chapter1_Introduction/1.2fourier_transform/#111-211","title":"1.1.1 2.1.1 \u57fa\u672c\u6982\u5ff5","text":"<ul> <li>\u5468\u671f\u4fe1\u53f7\u7684\u9891\u8c31\u662f\u79bb\u6563\u7684\uff0c\u7531\u57fa\u9891\u53ca\u5176\u6574\u6570\u500d\uff08\u8c10\u6ce2\uff09\u7ec4\u6210\u3002   \u5468\u671f\u4fe1\u53f7\u53ef\u4ee5\u7528\u5085\u91cc\u53f6\u7ea7\u6570\u8868\u793a\u4e3a\uff1a</li> </ul> <p>$$   x(t) = \\sum_{n=-\\infty}^\\infty c_n e^{j 2\\pi n f_0 t}   $$</p> <p>\u5176\u4e2d \\(f_0 = 1/T\\) \u662f\u57fa\u9891\uff0c\\(c_n\\) \u662f\u5085\u91cc\u53f6\u7cfb\u6570\u3002</p> <ul> <li>\u975e\u5468\u671f\u4fe1\u53f7\u7684\u9891\u8c31\u662f\u8fde\u7eed\u7684\uff0c\u4e0d\u80fd\u4ec5\u7528\u57fa\u9891\u53ca\u5176\u6574\u6570\u500d\u7684\u9891\u7387\u6765\u8868\u793a\u3002   \u975e\u5468\u671f\u4fe1\u53f7\u901a\u5e38\u901a\u8fc7\u5085\u91cc\u53f6\u53d8\u6362\u5f97\u5230\u9891\u8c31\uff1a</li> </ul> <p>$$   X(f) = \\int_{-\\infty}^\\infty x(t) e^{-j 2\\pi f t} dt   $$</p> <p>\u5b83\u5728\u6574\u4e2a\u9891\u7387\u8f74\u4e0a\u662f\u8fde\u7eed\u5206\u5e03\u7684\u3002</p>"},{"location":"book/chapter1_Introduction/1.2fourier_transform/#12-22","title":"1.2 2.2 \u4fe1\u53f7\u91cd\u5efa\u5206\u6790","text":""},{"location":"book/chapter1_Introduction/1.2fourier_transform/#121-221","title":"1.2.1 2.2.1 \u5b8c\u5168\u91cd\u5efa","text":"<ul> <li>\u5468\u671f\u4fe1\u53f7\u53ef\u4ee5\u5b8c\u5168\u7528\u57fa\u9891\u53ca\u5176\u6574\u6570\u500d\u7684\u9891\u7387\u5206\u91cf\u6765\u8868\u793a\u3002</li> <li>\u975e\u5468\u671f\u4fe1\u53f7\u5219\u4e0d\u80fd\u5b8c\u5168\u91cd\u5efa\uff0c\u56e0\u4e3a\u5b83\u7684\u9891\u8c31\u662f\u8fde\u7eed\u7684\uff0c\u9891\u7387\u6210\u5206\u4e0d\u5c40\u9650\u4e8e\u79bb\u6563\u70b9\u3002</li> </ul>"},{"location":"book/chapter1_Introduction/1.2fourier_transform/#122-222","title":"1.2.2 2.2.2 \u8fd1\u4f3c\u91cd\u5efa","text":"<p>\u5c3d\u7ba1\u975e\u5468\u671f\u4fe1\u53f7\u65e0\u6cd5\u5b8c\u5168\u7528\u79bb\u6563\u9891\u7387\u6210\u5206\u6765\u91cd\u5efa\uff0c\u4f46\u53ef\u4ee5\u7528\u6709\u9650\u4e2a\u79bb\u6563\u9891\u7387\u6210\u5206\u6765\u8fd1\u4f3c\u91cd\u5efa\uff0c\u5373\uff1a</p> \\[ x(t) \\approx \\sum_{n=-N}^N c_n e^{j 2\\pi n f_0 t} \\] <p>\u5f53\u9009\u53d6\u7684\u9891\u7387\u70b9\uff08\\(N\\) \u8f83\u5927\uff09\u8db3\u591f\u591a\u65f6\uff0c\u53ef\u4ee5\u8fd1\u4f3c\u6a21\u62df\u4fe1\u53f7\u7684\u4e3b\u8981\u7279\u6027\uff0c\u4f46\u8fd9\u79cd\u65b9\u6cd5\u6709\u4ee5\u4e0b\u9650\u5236\uff1a - \u6a21\u62df\u7684\u7ed3\u679c\u662f\u6709\u9650\u7cbe\u5ea6\u7684\u3002 - \u5bf9\u9ad8\u9891\u5206\u91cf\u8f83\u4e30\u5bcc\u7684\u4fe1\u53f7\uff0c\u8fd1\u4f3c\u9700\u8981\u66f4\u591a\u7684\u9891\u7387\u70b9\u3002</p>"},{"location":"book/chapter1_Introduction/1.2fourier_transform/#13-23","title":"1.3 2.3 \u793a\u4f8b\u5206\u6790","text":""},{"location":"book/chapter1_Introduction/1.2fourier_transform/#131-231","title":"1.3.1 2.3.1 \u5468\u671f\u4fe1\u53f7\u793a\u4f8b","text":"<p>\u8bbe \\(x(t) = \\cos(2\\pi f_0 t)\\) \u662f\u4e00\u4e2a\u5468\u671f\u4fe1\u53f7\uff0c\u5176\u9891\u8c31\u4e3a\uff1a</p> \\[ X(f) = \\frac{1}{2}[\\delta(f - f_0) + \\delta(f + f_0)] \\] <p>\u663e\u7136\u53ef\u4ee5\u7528\u57fa\u9891 \\(f_0\\) \u7684\u79bb\u6563\u9891\u7387\u5206\u91cf\u8868\u793a\uff0c\u65e0\u9700\u989d\u5916\u9891\u7387\u3002</p>"},{"location":"book/chapter1_Introduction/1.2fourier_transform/#132-232","title":"1.3.2 2.3.2 \u975e\u5468\u671f\u4fe1\u53f7\u793a\u4f8b\uff08\u77e9\u5f62\u8109\u51b2\uff09","text":"<p>\u8bbe \\(x(t)\\) \u662f\u4e00\u4e2a\u5bbd\u5ea6\u4e3a \\(T\\) \u7684\u77e9\u5f62\u8109\u51b2\uff1a</p> \\[ x(t) = \\begin{cases} 1, &amp; -T/2 \\leq t \\leq T/2 \\\\ 0, &amp; \\text{\u5176\u4ed6} \\end{cases} \\] <p>\u5176\u9891\u8c31\u4e3a\uff1a</p> \\[ X(f) = T \\cdot \\text{sinc}(fT) \\] <p>\\(\\text{sinc}(fT)\\) \u662f\u4e00\u4e2a\u8fde\u7eed\u51fd\u6570\uff0c\u8986\u76d6\u6240\u6709\u9891\u7387\uff0c\u4e0d\u80fd\u5b8c\u5168\u7528\u79bb\u6563\u9891\u7387\u8868\u793a\u3002\u4f46\u5982\u679c\u53ea\u53d6\u82e5\u5e72\u4e3b\u8981\u9891\u7387\u5206\u91cf\uff0c\u53ef\u4ee5\u8fd1\u4f3c\u91cd\u5efa\u3002</p>"},{"location":"book/chapter1_Introduction/1.2fourier_transform/#133-233","title":"1.3.3 2.3.3 \u5e26\u566a\u4fe1\u53f7\u793a\u4f8b","text":"<p>\u5bf9\u4e8e\u975e\u5468\u671f\u4e14\u5e26\u566a\u58f0\u7684\u4fe1\u53f7\uff0c\u5176\u9891\u8c31\u53ef\u80fd\u5206\u5e03\u5728\u4e00\u4e2a\u8f83\u5bbd\u7684\u9891\u7387\u8303\u56f4\u5185\uff0c\u7528\u79bb\u6563\u9891\u7387\u5206\u91cf\u53ea\u80fd\u90e8\u5206\u8fd1\u4f3c\u91cd\u5efa\uff0c\u4e14\u9ad8\u9891\u90e8\u5206\u7684\u8bef\u5dee\u53ef\u80fd\u8f83\u5927\u3002</p>"},{"location":"book/chapter1_Introduction/1.2fourier_transform/#14-24","title":"1.4 2.4 \u5e38\u89c1\u7684\u9891\u8c31\u903c\u8fd1\u65b9\u6cd5","text":"<p>\u5bf9\u4e8e\u975e\u5468\u671f\u4fe1\u53f7\uff0c\u5982\u679c\u5e0c\u671b\u7528\u79bb\u6563\u9891\u7387\u8868\u793a\uff0c\u53ef\u4ee5\u8003\u8651\u4ee5\u4e0b\u65b9\u6cd5\uff1a</p>"},{"location":"book/chapter1_Introduction/1.2fourier_transform/#141-241-dft","title":"1.4.1 2.4.1 \u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362 (DFT)","text":"<ul> <li>\u5c06\u8fde\u7eed\u4fe1\u53f7\u91c7\u6837\u4e3a\u79bb\u6563\u4fe1\u53f7\uff0c\u5e76\u7528\u6709\u9650\u9891\u7387\u70b9\u7684\u9891\u8c31\u8868\u793a\u3002</li> <li>\u7ed3\u679c\u662f\u4fe1\u53f7\u7684\u9891\u8c31\u5728\u6709\u9650\u9891\u7387\u70b9\u4e0a\u7684\u79bb\u6563\u8fd1\u4f3c\u3002</li> </ul>"},{"location":"book/chapter1_Introduction/1.2fourier_transform/#142-242","title":"1.4.2 2.4.2 \u7a97\u53e3\u5316\u5904\u7406","text":"<ul> <li>\u975e\u5468\u671f\u4fe1\u53f7\u53ef\u4ee5\u901a\u8fc7\u65f6\u95f4\u7a97\u53e3\u622a\u65ad\uff0c\u4f7f\u5176\u8fd1\u4f3c\u4e3a\u6709\u9650\u65f6\u957f\u7684\u5468\u671f\u4fe1\u53f7\u3002</li> <li>\u622a\u65ad\u540e\u7684\u4fe1\u53f7\u9891\u8c31\u4f1a\u63a5\u8fd1\u4e8e\u79bb\u6563\u9891\u7387\u5206\u91cf\uff0c\u4f46\u4f1a\u5f15\u5165\u9891\u8c31\u6cc4\u9732\u3002</li> </ul>"},{"location":"book/chapter1_Introduction/1.2fourier_transform/#143-243","title":"1.4.3 2.4.3 \u5e26\u5bbd\u9650\u5236","text":"<ul> <li>\u5bf9\u975e\u5468\u671f\u4fe1\u53f7\u65bd\u52a0\u4f4e\u901a\u6ee4\u6ce2\u5668\uff0c\u53bb\u6389\u9ad8\u9891\u5206\u91cf\u3002</li> <li>\u5e26\u5bbd\u9650\u5236\u540e\uff0c\u4fe1\u53f7\u9891\u8c31\u80fd\u66f4\u597d\u5730\u7528\u6709\u9650\u79bb\u6563\u9891\u7387\u6a21\u62df\u3002</li> </ul>"},{"location":"book/chapter1_Introduction/1.2fourier_transform/#15-25","title":"1.5 2.5 \u603b\u7ed3","text":"<ul> <li>\u5b8c\u5168\u91cd\u5efa\uff1a\u53ea\u6709\u5468\u671f\u4fe1\u53f7\u80fd\u5b8c\u5168\u7528\u57fa\u9891\u53ca\u5176\u6574\u6570\u500d\u9891\u7387\u8868\u793a\u3002</li> <li>\u8fd1\u4f3c\u91cd\u5efa\uff1a\u975e\u5468\u671f\u4fe1\u53f7\u53ef\u4ee5\u7528\u6709\u9650\u4e2a\u79bb\u6563\u9891\u7387\u5206\u91cf\u8fdb\u884c\u8fd1\u4f3c\uff0c\u4f46\u65e0\u6cd5\u5b8c\u5168\u91cd\u5efa\u3002</li> <li>\u5bf9\u4e8e\u975e\u5468\u671f\u4fe1\u53f7\uff0c\u7528\u79bb\u6563\u9891\u7387\u8868\u793a\u7684\u7cbe\u5ea6\u53d6\u51b3\u4e8e\uff1a</li> <li>\u9891\u7387\u5206\u91cf\u7684\u6570\u91cf\u3002</li> <li>\u4fe1\u53f7\u7684\u9891\u8c31\u5e26\u5bbd\u3002</li> </ul>"},{"location":"book/chapter1_Introduction/1.3signal_processing/","title":"signal processing","text":""},{"location":"book/chapter1_Introduction/1.3signal_processing/#1","title":"1. \u91c7\u6837\u5b9a\u7406","text":"<pre><code>\u6838\u5fc3\uff1a\u91c7\u6837\u9891\u7387\u9700\u8981\u662f\u539f\u59cb\u4fe1\u53f7\u7684\u5e26\u5bbd\u7684\u4e24\u500d\n</code></pre>"},{"location":"book/chapter1_Introduction/1.3signal_processing/#11","title":"1.1 \u91c7\u6837\u5b9a\u7406\u7684\u6570\u5b66\u63cf\u8ff0","text":"<p>\u5047\u8bbe\u4e00\u4e2a\u8fde\u7eed\u65f6\u95f4\u4fe1\u53f7 \\(x(t)\\) \u662f\u5e26\u9650\u7684\uff0c\u5373\u5b83\u7684\u9891\u8c31\uff08\u5085\u91cc\u53f6\u53d8\u6362\uff09\u6ee1\u8db3\uff1a \\(X(f)=0,\\quad\\forall |f|&gt;B\\), \u5176\u4e2d \\(B\\) \u662f\u4fe1\u53f7\u7684\u6700\u9ad8\u9891\u7387\uff08\u5e26\u5bbd\uff09\uff0c\u5355\u4f4d\u662f\u8d6b\u5179\uff08Hz\uff09\u3002\u8fd9\u79cd\u4fe1\u53f7\u79f0\u4e3a\u5e26\u9650\u4fe1\u53f7\u3002 \u6839\u636e\u91c7\u6837\u5b9a\u7406\uff1a</p> <ol> <li>\u5982\u679c\u7528\u91c7\u6837\u95f4\u9694 \\(T_s = \\frac{1}{2B}\\) \u6216\u66f4\u5c0f\u7684\u65f6\u95f4\u95f4\u9694\u5bf9\u4fe1\u53f7 \\(x(t)\\) \u8fdb\u884c\u91c7\u6837\uff1a\\(x[n] = x(nT_s), \\quad n \\in \\mathbb{Z},\\)    \u5219\u53ef\u4ee5\u901a\u8fc7\u91c7\u6837\u503c\u5b8c\u5168\u91cd\u5efa\u539f\u4fe1\u53f7 \\(x(t)\\)\u3002</li> <li>\u91cd\u5efa\u516c\u5f0f\u662f\u901a\u8fc7\u5948\u594e\u65af\u7279\u91cd\u5efa\u516c\u5f0f\u7ed9\u51fa\u7684\uff1a</li> </ol> <p>$$    x(t) = \\sum_{n=-\\infty}^{\\infty} x[n] \\, \\text{sinc}\\left(\\frac{t - nT_s}{T_s}\\right),    $$</p> <p>\u5176\u4e2d    \\(\\text{sinc}(x) = \\frac{\\sin(\\pi x)}{\\pi x}\\)</p>"},{"location":"book/chapter1_Introduction/1.3signal_processing/#12","title":"1.2 \u5173\u952e\u6761\u4ef6\u4e0e\u89e3\u91ca","text":"<ul> <li>\u5e26\u9650\u6027\uff1a\u4fe1\u53f7 $ x(t) $ \u7684\u9891\u8c31\u4e2d\u6ca1\u6709\u8d85\u8fc7 $ B $ \u7684\u9891\u7387\u5206\u91cf\u3002</li> <li>\u91c7\u6837\u7387\u8981\u6c42\uff1a\u91c7\u6837\u9891\u7387\u5fc5\u987b\u6ee1\u8db3 $ f_s \\geq 2B $\uff0c\u5373\u91c7\u6837\u95f4\u9694 $ T_s \\leq \\frac{1}{2B} $\u3002\u8fd9\u91cc\u7684 $ f_s = \\frac{1}{T_s} $ \u662f\u91c7\u6837\u9891\u7387\uff0c\u79f0\u4e3a\u5948\u594e\u65af\u7279\u9891\u7387\u3002 \u53ea\u6709\u5728\u6ee1\u8db3\u8fd9\u4e9b\u6761\u4ef6\u65f6\uff0c\u91c7\u6837\u4fe1\u53f7 $ x[n] $ \u53ef\u4ee5\u65e0\u635f\u5730\u91cd\u5efa\u4e3a\u539f\u4fe1\u53f7 $ x(t) $.</li> </ul>"},{"location":"book/chapter1_Introduction/1.3signal_processing/#13","title":"1.3 \u91cd\u5efa\u4f8b\u5b50","text":""},{"location":"book/chapter1_Introduction/1.3signal_processing/#14-13","title":"1.4 1.3 \u91cd\u5efa\u4f8b\u5b50","text":"<p>\u8003\u8651\u4e00\u4e2a\u8fde\u7eed\u65f6\u95f4\u4fe1\u53f7\uff1a</p> \\[ x(t) = \\cos(10\\pi t) \\] <p>\u8fd9\u4e2a\u4fe1\u53f7\u7684\u9891\u7387\u4e3a \\(f = 5\\text{ Hz}\\)\uff08\u56e0\u4e3a \\(10\\pi = 2\\pi \\cdot 5\\)\uff09\u3002\u6839\u636e\u5948\u594e\u65af\u7279\u91c7\u6837\u5b9a\u7406\uff0c\u91c7\u6837\u9891\u7387\u5e94\u6ee1\u8db3\uff1a</p> \\[ f_s &gt; 2f = 10\\text{ Hz} \\] <p>\u8ba9\u6211\u4eec\u9009\u62e9\u91c7\u6837\u9891\u7387 \\(f_s = 12\\text{ Hz}\\)\uff0c\u5373\u91c7\u6837\u95f4\u9694 \\(T_s = \\frac{1}{12}\\text{ s}\\)\u3002</p>"},{"location":"book/chapter1_Introduction/1.3signal_processing/#141-131","title":"1.4.1 1.3.1 \u91c7\u6837\u8fc7\u7a0b","text":"<p>\u91c7\u6837\u70b9\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a</p> \\[ x[n] = \\cos(10\\pi \\cdot \\frac{n}{12}), \\quad n = 0, \\pm1, \\pm2, \\dots \\]"},{"location":"book/chapter1_Introduction/1.3signal_processing/#142-132","title":"1.4.2 1.3.2 \u91cd\u5efa\u516c\u5f0f","text":"<p>\u6839\u636e\u5948\u594e\u65af\u7279\u91cd\u5efa\u516c\u5f0f\uff0c\u539f\u59cb\u4fe1\u53f7\u53ef\u4ee5\u901a\u8fc7\u4ee5\u4e0b\u516c\u5f0f\u91cd\u5efa\uff1a</p> \\[ x(t) = \\sum_{n=-\\infty}^{\\infty} x[n] \\cdot \\text{sinc}(\\frac{t-nT_s}{T_s}) \\] <p>\u4ee3\u5165\u6211\u4eec\u7684\u4f8b\u5b50\uff1a</p> \\[ x(t) = \\sum_{n=-\\infty}^{\\infty} \\cos(10\\pi \\cdot \\frac{n}{12}) \\cdot \\text{sinc}(12t-n) \\]"},{"location":"book/chapter1_Introduction/1.3signal_processing/#143-133","title":"1.4.3 1.3.3 \u91cd\u5efa\u539f\u7406\u89e3\u91ca","text":"<ol> <li>\u6bcf\u4e2a\u91c7\u6837\u70b9 \\(x[n]\\) \u90fd\u901a\u8fc7 sinc \u51fd\u6570\u8fdb\u884c\u63d2\u503c</li> <li>sinc \u51fd\u6570\u5177\u6709\u4ee5\u4e0b\u6027\u8d28\uff1a</li> <li>\u5728\u91c7\u6837\u70b9\u5904\uff0c\u5f53\u524d\u91c7\u6837\u70b9\u7684 sinc \u51fd\u6570\u503c\u4e3a 1\uff0c\u5176\u4ed6\u91c7\u6837\u70b9\u5904\u4e3a 0</li> <li>\u6240\u6709\u91c7\u6837\u70b9\u7684 sinc \u51fd\u6570\u4e4b\u548c\u5728\u4efb\u610f\u65f6\u523b t \u90fd\u80fd\u91cd\u5efa\u51fa\u539f\u59cb\u4fe1\u53f7\u503c</li> </ol>"},{"location":"book/chapter1_Introduction/1.3signal_processing/#144-134","title":"1.4.4 1.3.4 \u9a8c\u8bc1","text":"<p>\u53ef\u4ee5\u8bc1\u660e\u8fd9\u4e2a\u91cd\u5efa\u516c\u5f0f\u786e\u5b9e\u80fd\u5f97\u5230\u539f\u59cb\u4fe1\u53f7 \\(\\cos(10\\pi t)\\)\uff1a</p> <ol> <li>\u91cd\u5efa\u4fe1\u53f7\u7684\u9891\u8c31\u88ab\u9650\u5236\u5728 \\([-6\\text{ Hz}, 6\\text{ Hz}]\\) \u8303\u56f4\u5185</li> <li>\u7531\u4e8e\u539f\u59cb\u4fe1\u53f7\u9891\u7387\u4e3a 5 Hz\uff0c\u4f4e\u4e8e\u5948\u594e\u65af\u7279\u9891\u7387 6 Hz</li> <li>\u56e0\u6b64\u91cd\u5efa\u4fe1\u53f7\u4e0e\u539f\u59cb\u4fe1\u53f7\u5b8c\u5168\u76f8\u540c</li> </ol>"},{"location":"book/chapter1_Introduction/1.3signal_processing/#145-135","title":"1.4.5 1.3.5 \u63a8\u5bfc\u8fc7\u7a0b","text":"<p>\u8ba9\u6211\u4eec\u8bc1\u660e\u91cd\u5efa\u516c\u5f0f \\(\\sum_{n=-\\infty}^{\\infty} \\cos(10\\pi \\cdot \\frac{n}{12}) \\cdot \\text{sinc}(12t-n)\\) \u7b49\u4e8e \\(\\cos(10\\pi t)\\)\uff1a</p> <ol> <li>\u9891\u57df\u5206\u6790</li> <li> <p>\u539f\u59cb\u4fe1\u53f7 \\(\\cos(10\\pi t)\\) \u7684\u9891\u8c31\u5305\u542b\u4e24\u4e2a\u51b2\u6fc0\u51fd\u6570\uff1a</p> <p>$$  X(f) = \\frac{1}{2}[\\delta(f-5) + \\delta(f+5)]  $$</p> </li> <li> <p>\u91c7\u6837\u4fe1\u53f7\u9891\u8c31</p> </li> <li>\u91c7\u6837\u540e\u7684\u4fe1\u53f7\u9891\u8c31\u662f\u539f\u59cb\u9891\u8c31\u7684\u5468\u671f\u5ef6\u62d3\uff0c\u5468\u671f\u4e3a\u91c7\u6837\u9891\u7387 \\(f_s = 12\\text{ Hz}\\)\uff1a</li> </ol> <p>$$X_s(f) = \\frac{1}{12}\\sum_{k=-\\infty}^{\\infty} \\frac{1}{2}[\\delta(f-5-12k) + \\delta(f+5-12k)]    $$</p> <ol> <li>\u91cd\u5efa\u6ee4\u6ce2\u5668</li> <li>sinc \u51fd\u6570\u7684\u5085\u91cc\u53f6\u53d8\u6362\u662f\u77e9\u5f62\u7a97\uff1a</li> </ol> <p>$$    \\mathcal{F}{\\text{sinc}(12t)} = \\text{rect}(\\frac{f}{12})    $$</p> <ul> <li> <p>\u8fd9\u4e2a\u7406\u60f3\u4f4e\u901a\u6ee4\u6ce2\u5668\u5728 \\([-6\\text{ Hz}, 6\\text{ Hz}]\\) \u8303\u56f4\u5185\u4e3a 1\uff0c\u5176\u4ed6\u9891\u7387\u4e3a 0</p> </li> <li> <p>\u9891\u57df\u91cd\u5efa\u8fc7\u7a0b</p> </li> <li> <p>\u91cd\u5efa\u8fc7\u7a0b\u7b49\u4ef7\u4e8e\u91c7\u6837\u4fe1\u53f7\u4e0e\u7406\u60f3\u4f4e\u901a\u6ee4\u6ce2\u5668\u76f8\u4e58\uff1a</p> <p>$$  X_r(f) = X_s(f) \\cdot \\text{rect}(\\frac{f}{12})  $$</p> </li> <li> <p>\u7531\u4e8e\u539f\u59cb\u4fe1\u53f7\u9891\u7387\uff085 Hz\uff09\u5c0f\u4e8e\u5948\u594e\u65af\u7279\u9891\u7387\uff086 Hz\uff09\uff0c\u53ea\u6709 \\(k=0\\) \u7684\u9891\u8c31\u5206\u91cf\u4f1a\u88ab\u4fdd\u7559\uff1a</p> <p>$$  X_r(f) = \\frac{1}{2}[\\delta(f-5) + \\delta(f+5)]  $$</p> </li> <li> <p>\u65f6\u57df\u7ed3\u679c</p> </li> <li> <p>\u5bf9 \\(X_r(f)\\) \u8fdb\u884c\u9006\u5085\u91cc\u53f6\u53d8\u6362\uff0c\u5f97\u5230\uff1a</p> <p>$$  x_r(t) = \\cos(10\\pi t)  $$</p> </li> </ul> <p>\u56e0\u6b64\uff0c\u6211\u4eec\u8bc1\u660e\u4e86\u91cd\u5efa\u516c\u5f0f\u786e\u5b9e\u80fd\u5b8c\u7f8e\u91cd\u5efa\u539f\u59cb\u4fe1\u53f7 \\(\\cos(10\\pi t)\\)\u3002\u8fd9\u4e2a\u63a8\u5bfc\u8fc7\u7a0b\u4e5f\u8bf4\u660e\u4e86\u4e3a\u4ec0\u4e48\u91c7\u6837\u9891\u7387\u5fc5\u987b\u5927\u4e8e\u4fe1\u53f7\u9891\u7387\u7684\u4e24\u500d\uff1a\u53ea\u6709\u8fd9\u6837\uff0c\u91c7\u6837\u540e\u7684\u9891\u8c31\u5468\u671f\u5ef6\u62d3\u624d\u4e0d\u4f1a\u53d1\u751f\u6df7\u53e0\u3002</p>"},{"location":"book/chapter1_Introduction/1.3signal_processing/#2-2","title":"2. 2. \u9891\u8c31\u6df7\u53e0","text":""},{"location":"book/chapter1_Introduction/1.3signal_processing/#21","title":"2.1 \u72c4\u62c9\u514b\u51fd\u6570\u4e0e\u72c4\u62c9\u514b\u68b3\u72b6\u51fd\u6570\u7684\u7279\u6027","text":""},{"location":"book/chapter1_Introduction/1.3signal_processing/#211-1-dirac-delta-function","title":"2.1.1 1. \u72c4\u62c9\u514b\u51fd\u6570\uff08Dirac Delta Function\uff09","text":""},{"location":"book/chapter1_Introduction/1.3signal_processing/#2111","title":"2.1.1.1 \u5b9a\u4e49","text":"<ul> <li>\u72c4\u62c9\u514b\u51fd\u6570 \\(\\delta(t)\\) \u662f\u4e00\u4e2a\u7406\u60f3\u5316\u7684\u8109\u51b2\u51fd\u6570\uff0c\u7528\u4e8e\u63cf\u8ff0\u65f6\u95f4 \\(t=0\\) \u65f6\u7684\u65e0\u9650\u7a84\u548c\u65e0\u9650\u9ad8\u7684\u4fe1\u53f7\u3002 </li> <li>\u6ee1\u8db3\u4ee5\u4e0b\u6027\u8d28\uff1a</li> </ul> <p>$$   \\int_{-\\infty}^\\infty \\delta(t) \\, dt = 1   $$</p> <p>\u5bf9\u4efb\u610f\u51fd\u6570 \\(x(t)\\)\uff0c\u6709\uff1a</p> <p>$$   \\int_{-\\infty}^\\infty x(t) \\delta(t - t_0) \\, dt = x(t_0)   $$</p>"},{"location":"book/chapter1_Introduction/1.3signal_processing/#2112","title":"2.1.1.2 \u7279\u6027","text":"<ol> <li>\u96c6\u4e2d\u6027\uff1a\\(\\delta(t) = 0\\) \u5f53 \\(t \\neq 0\\)\u3002</li> <li>\u5355\u4f4d\u5316\uff1a\\(\\int_{-\\infty}^\\infty \\delta(t) \\, dt = 1\\)\u3002</li> <li>\u5bf9\u79f0\u6027\uff1a\\(\\delta(-t) = \\delta(t)\\)\u3002</li> <li>\u7f29\u653e\u6027\uff1a\\(\\delta(at) = \\frac{1}{|a|} \\delta(t)\\)\u3002</li> <li>\u5377\u79ef\u7279\u6027\uff1a</li> <li>\u4e0e\u4efb\u610f\u51fd\u6570\u5377\u79ef\uff1a\\((x * \\delta)(t) = x(t)\\)\u3002</li> <li>\u4e0e\u4f4d\u79fb\u7684\u72c4\u62c9\u514b\u51fd\u6570\u5377\u79ef\uff1a\\((x * \\delta(t - t_0))(t) = x(t - t_0)\\)\u3002</li> </ol>"},{"location":"book/chapter1_Introduction/1.3signal_processing/#212-2-dirac-comb-function","title":"2.1.2 2. \u72c4\u62c9\u514b\u68b3\u72b6\u51fd\u6570\uff08Dirac Comb Function\uff09","text":""},{"location":"book/chapter1_Introduction/1.3signal_processing/#2121","title":"2.1.2.1 \u72c4\u62c9\u514b\u68b3\u72b6\u51fd\u6570\u5b9a\u4e49","text":"<ul> <li>\u72c4\u62c9\u514b\u68b3\u72b6\u51fd\u6570 \\(\\mathrm{III}(t)\\) \u662f\u4e00\u5217\u7b49\u95f4\u9694\u7684\u72c4\u62c9\u514b\u51fd\u6570\u7ec4\u6210\u7684\u5468\u671f\u6027\u8109\u51b2\u5217\uff1a </li> </ul> <p>$$   \\mathrm{III}(t) = \\sum_{n=-\\infty}^\\infty \\delta(t - nT)   $$</p> <p>\u5176\u4e2d \\(T\\) \u662f\u8109\u51b2\u95f4\u9694\u3002</p>"},{"location":"book/chapter1_Introduction/1.3signal_processing/#2122","title":"2.1.2.2 \u72c4\u62c9\u514b\u68b3\u72b6\u51fd\u6570\u7684\u7279\u6027","text":"<ol> <li>\u5468\u671f\u6027\uff1a\\(\\mathrm{III}(t)\\) \u662f\u5468\u671f\u4e3a \\(T\\) \u7684\u51fd\u6570\u3002</li> <li>\u9891\u57df\u5173\u7cfb\uff1a</li> <li> <p>\u5085\u91cc\u53f6\u53d8\u6362\u4ecd\u662f\u4e00\u4e2a\u72c4\u62c9\u514b\u68b3\u72b6\u51fd\u6570\uff0c\u9891\u7387\u95f4\u9694\u4e3a \\(\\frac{1}{T}\\)\uff1a</p> <p>$$  \\mathcal{F}{\\mathrm{III}(t)} = \\frac{1}{T} \\mathrm{III}\\left(\\frac{f}{T}\\right)  $$</p> </li> <li> <p>\u5377\u79ef\u7279\u6027\uff1a</p> </li> <li>\u4e0e\u4efb\u610f\u51fd\u6570\u5377\u79ef\uff1a\\((x * \\mathrm{III})(t) = \\sum_{n=-\\infty}^\\infty x(t - nT)\\)\u3002</li> <li>\u4e0e\u81ea\u8eab\u5377\u79ef\uff1a\\(\\mathrm{III}(t) * \\mathrm{III}(t) = \\mathrm{III}(t)\\)\u3002</li> </ol>"},{"location":"book/chapter1_Introduction/1.3signal_processing/#213-3","title":"2.1.3 3. \u72c4\u62c9\u514b\u51fd\u6570\u4e0e\u4fe1\u53f7\u91c7\u6837","text":""},{"location":"book/chapter1_Introduction/1.3signal_processing/#2131","title":"2.1.3.1 \u91c7\u6837\u8fc7\u7a0b","text":"<ul> <li>\u8fde\u7eed\u4fe1\u53f7 \\(x(t)\\) \u7684\u91c7\u6837\u53ef\u8868\u793a\u4e3a\u4e0e\u72c4\u62c9\u514b\u68b3\u72b6\u51fd\u6570\u7684\u4e58\u79ef\uff1a</li> </ul> <p>$$   x_s(t) = x(t) \\cdot \\mathrm{III}(t) = \\sum_{n=-\\infty}^\\infty x(nT) \\delta(t - nT)   $$</p> <p>\u5176\u4e2d \\(T\\) \u662f\u91c7\u6837\u95f4\u9694\u3002 </p>"},{"location":"book/chapter1_Introduction/1.3signal_processing/#2132","title":"2.1.3.2 \u9891\u57df\u7279\u6027","text":"<ul> <li>\u91c7\u6837\u7684\u9891\u8c31\u662f\u539f\u4fe1\u53f7\u9891\u8c31\u7684\u5468\u671f\u6027\u5ef6\u62d3\uff1a</li> </ul> <p>$$   X_s(f) = \\frac{1}{T} \\sum_{k=-\\infty}^\\infty X(f - kf_s)   $$</p> <p>\u5176\u4e2d \\(f_s = \\frac{1}{T}\\) \u662f\u91c7\u6837\u9891\u7387\u3002    \u4fe1\u53f7\u9891\u8c31        \u91c7\u6837\u578b\u53f7\u9891\u8c31    </p>"},{"location":"book/chapter1_Introduction/1.3signal_processing/#214-4","title":"2.1.4 4. \u603b\u7ed3","text":"\u7279\u6027 \u72c4\u62c9\u514b\u51fd\u6570 \u72c4\u62c9\u514b\u68b3\u72b6\u51fd\u6570 \u5b9a\u4e49 \u7406\u60f3\u5316\u7684\u8109\u51b2\uff0c\u53ea\u6709 \\(t=0\\) \u65f6\u975e\u96f6 \u5468\u671f\u6027\u8109\u51b2\u5217\uff0c\u7531\u591a\u4e2a\u72c4\u62c9\u514b\u51fd\u6570\u7ec4\u6210 \u6570\u5b66\u8868\u793a \\(\\delta(t)\\) \\(\\mathrm{III}(t) = \\sum_{n=-\\infty}^\\infty \\delta(t - nT)\\) \u5377\u79ef\u7279\u6027 \u4fdd\u6301\u51fd\u6570\u539f\u6837\u6216\u5e73\u79fb \u751f\u6210\u4fe1\u53f7\u7684\u5468\u671f\u6027\u91cd\u590d \u9891\u57df\u5173\u7cfb \u4e0e\u4efb\u610f\u51fd\u6570\u5377\u79ef\u4fdd\u6301\u9891\u8c31\u4e0d\u53d8 \u9891\u8c31\u5ef6\u62d3\u6216\u5468\u671f\u6027\u91cd\u590d \u91c7\u6837\u4e2d\u7684\u4f5c\u7528 \u63d0\u53d6\u8fde\u7eed\u4fe1\u53f7\u7684\u79bb\u6563\u503c \u8868\u793a\u91c7\u6837\u8fc7\u7a0b\u53ca\u9891\u8c31\u5ef6\u62d3"},{"location":"book/chapter1_Introduction/1.3signal_processing/#3-3","title":"3. 3. \u6ee4\u6ce2\u5668","text":"<p>\u6ee4\u6ce2\u5668\u662f\u4e00\u79cd\u5bf9\u4fe1\u53f7\u8fdb\u884c\u9891\u7387\u9009\u62e9\u6027\u5904\u7406\u7684\u7cfb\u7edf\uff0c\u53ef\u4ee5\u8ba9\u67d0\u4e9b\u9891\u7387\u6210\u5206\u901a\u8fc7\uff0c\u540c\u65f6\u6291\u5236\u6216\u963b\u6b62\u5176\u4ed6\u9891\u7387\u6210\u5206\u3002</p>"},{"location":"book/chapter1_Introduction/1.3signal_processing/#31-31","title":"3.1 3.1 \u57fa\u672c\u6982\u5ff5","text":""},{"location":"book/chapter1_Introduction/1.3signal_processing/#311-311","title":"3.1.1 3.1.1 \u9891\u7387\u54cd\u5e94","text":"<p>\u6ee4\u6ce2\u5668\u7684\u9891\u7387\u54cd\u5e94 \\(H(f)\\) \u63cf\u8ff0\u4e86\u6ee4\u6ce2\u5668\u5bf9\u4e0d\u540c\u9891\u7387\u5206\u91cf\u7684\u5904\u7406\u65b9\u5f0f\uff1a</p> <ul> <li>\u5e45\u9891\u54cd\u5e94 \\(|H(f)|\\)\uff1a\u8868\u793a\u5bf9\u4e0d\u540c\u9891\u7387\u5206\u91cf\u7684\u589e\u76ca\u6216\u8870\u51cf</li> <li>\u76f8\u9891\u54cd\u5e94 \\(\\angle H(f)\\)\uff1a\u8868\u793a\u5bf9\u4e0d\u540c\u9891\u7387\u5206\u91cf\u7684\u76f8\u4f4d\u53d8\u5316</li> </ul>"},{"location":"book/chapter1_Introduction/1.3signal_processing/#312-312","title":"3.1.2 3.1.2 \u91cd\u8981\u53c2\u6570","text":"<ul> <li>\u622a\u6b62\u9891\u7387\uff08Cutoff Frequency\uff09\uff1a\u6ee4\u6ce2\u5668\u7684\u5e45\u9891\u54cd\u5e94\u4e0b\u964d\u5230 -3dB \u5904\u7684\u9891\u7387</li> <li>\u901a\u5e26\uff08Passband\uff09\uff1a\u4fe1\u53f7\u51e0\u4e4e\u65e0\u8870\u51cf\u901a\u8fc7\u7684\u9891\u7387\u8303\u56f4</li> <li>\u963b\u5e26\uff08Stopband\uff09\uff1a\u4fe1\u53f7\u88ab\u663e\u8457\u8870\u51cf\u7684\u9891\u7387\u8303\u56f4</li> <li>\u8fc7\u6e21\u5e26\uff08Transition Band\uff09\uff1a\u901a\u5e26\u548c\u963b\u5e26\u4e4b\u95f4\u7684\u8fc7\u6e21\u533a\u57df</li> <li>\u963b\u5e26\u8870\u51cf\uff08Stopband Attenuation\uff09\uff1a\u5728\u963b\u5e26\u4e2d\u7684\u6700\u5c0f\u8870\u51cf\u91cf</li> </ul>"},{"location":"book/chapter1_Introduction/1.3signal_processing/#32-32","title":"3.2 3.2 \u6ee4\u6ce2\u5668\u7c7b\u578b","text":""},{"location":"book/chapter1_Introduction/1.3signal_processing/#321-321-low-pass-filter","title":"3.2.1 3.2.1 \u4f4e\u901a\u6ee4\u6ce2\u5668\uff08Low-Pass Filter\uff09","text":"<ul> <li>\u529f\u80fd\uff1a\u5141\u8bb8\u4f4e\u9891\u4fe1\u53f7\u901a\u8fc7\uff0c\u8870\u51cf\u9ad8\u9891\u4fe1\u53f7</li> <li>\u5e94\u7528\uff1a\u53bb\u9664\u9ad8\u9891\u566a\u58f0\uff0c\u5e73\u6ed1\u4fe1\u53f7</li> <li>\u9891\u7387\u54cd\u5e94\uff1a</li> </ul> <p>$$   H(f) = \\begin{cases}   1, &amp; |f| \\leq f_c \\   0, &amp; |f| &gt; f_c   \\end{cases}   $$</p>"},{"location":"book/chapter1_Introduction/1.3signal_processing/#322-322-high-pass-filter","title":"3.2.2 3.2.2 \u9ad8\u901a\u6ee4\u6ce2\u5668\uff08High-Pass Filter\uff09","text":"<ul> <li>\u529f\u80fd\uff1a\u5141\u8bb8\u9ad8\u9891\u4fe1\u53f7\u901a\u8fc7\uff0c\u8870\u51cf\u4f4e\u9891\u4fe1\u53f7</li> <li>\u5e94\u7528\uff1a\u53bb\u9664\u76f4\u6d41\u5206\u91cf\uff0c\u7a81\u51fa\u4fe1\u53f7\u7684\u5feb\u901f\u53d8\u5316</li> <li>\u9891\u7387\u54cd\u5e94\uff1a</li> </ul> <p>$$   H(f) = \\begin{cases}   0, &amp; |f| \\leq f_c \\   1, &amp; |f| &gt; f_c   \\end{cases}   $$</p>"},{"location":"book/chapter1_Introduction/1.3signal_processing/#323-323-band-pass-filter","title":"3.2.3 3.2.3 \u5e26\u901a\u6ee4\u6ce2\u5668\uff08Band-Pass Filter\uff09","text":"<ul> <li>\u529f\u80fd\uff1a\u53ea\u5141\u8bb8\u7279\u5b9a\u9891\u7387\u8303\u56f4\u5185\u7684\u4fe1\u53f7\u901a\u8fc7</li> <li>\u5e94\u7528\uff1a\u63d0\u53d6\u7279\u5b9a\u9891\u6bb5\u7684\u4fe1\u53f7\uff0c\u5982\u97f3\u9891\u5904\u7406</li> <li>\u9891\u7387\u54cd\u5e94\uff1a</li> </ul> <p>$$   H(f) = \\begin{cases}   1, &amp; f_1 \\leq |f| \\leq f_2 \\   0, &amp; \\text{\u5176\u4ed6}   \\end{cases}   $$</p>"},{"location":"book/chapter1_Introduction/1.3signal_processing/#324-324-band-stop-filter","title":"3.2.4 3.2.4 \u5e26\u963b\u6ee4\u6ce2\u5668\uff08Band-Stop Filter\uff09","text":"<ul> <li>\u529f\u80fd\uff1a\u963b\u6b62\u7279\u5b9a\u9891\u7387\u8303\u56f4\u5185\u7684\u4fe1\u53f7\u901a\u8fc7</li> <li>\u5e94\u7528\uff1a\u53bb\u9664\u7279\u5b9a\u9891\u7387\u7684\u5e72\u6270\uff0c\u5982\u5de5\u9891\u5e72\u6270</li> <li>\u9891\u7387\u54cd\u5e94\uff1a</li> </ul> <p>$$   H(f) = \\begin{cases}   0, &amp; f_1 \\leq |f| \\leq f_2 \\   1, &amp; \\text{\u5176\u4ed6}   \\end{cases}   $$</p>"},{"location":"book/chapter1_Introduction/1.3signal_processing/#33-33","title":"3.3 3.3 \u6ee4\u6ce2\u5668\u7279\u6027","text":""},{"location":"book/chapter1_Introduction/1.3signal_processing/#331-331","title":"3.3.1 3.3.1 \u7406\u60f3\u6ee4\u6ce2\u5668\u4e0e\u5b9e\u9645\u6ee4\u6ce2\u5668","text":"<ul> <li>\u7406\u60f3\u6ee4\u6ce2\u5668\uff1a\u9891\u7387\u54cd\u5e94\u5728\u901a\u5e26\u548c\u963b\u5e26\u4e4b\u95f4\u6709\u7a81\u53d8\uff0c\u65e0\u8fc7\u6e21\u5e26</li> <li>\u5b9e\u9645\u6ee4\u6ce2\u5668\uff1a</li> <li>\u5b58\u5728\u8fc7\u6e21\u5e26</li> <li>\u901a\u5e26\u6709\u6ce2\u7eb9</li> <li>\u963b\u5e26\u8870\u51cf\u6709\u9650</li> <li>\u76f8\u4f4d\u54cd\u5e94\u975e\u7ebf\u6027</li> </ul>"},{"location":"book/chapter1_Introduction/1.3signal_processing/#332-332","title":"3.3.2 3.3.2 \u5e38\u89c1\u6ee4\u6ce2\u5668\u7c7b\u578b","text":"<ol> <li>\u5df4\u7279\u6c83\u65af\u6ee4\u6ce2\u5668\uff1a</li> <li>\u7279\u70b9\uff1a\u901a\u5e26\u6700\u5e73\u5766\uff0c\u76f8\u4f4d\u54cd\u5e94\u8f83\u597d</li> <li> <p>\u7f3a\u70b9\uff1a\u8fc7\u6e21\u5e26\u8f83\u5bbd</p> </li> <li> <p>\u5207\u6bd4\u96ea\u592b\u6ee4\u6ce2\u5668\uff1a</p> </li> <li>\u7279\u70b9\uff1a\u8fc7\u6e21\u5e26\u8f83\u7a84</li> <li> <p>\u7f3a\u70b9\uff1a\u901a\u5e26\u6709\u6ce2\u7eb9</p> </li> <li> <p>\u692d\u5706\u6ee4\u6ce2\u5668\uff1a</p> </li> <li>\u7279\u70b9\uff1a\u6700\u9661\u5ced\u7684\u8fc7\u6e21\u5e26</li> <li>\u7f3a\u70b9\uff1a\u901a\u5e26\u548c\u963b\u5e26\u90fd\u6709\u6ce2\u7eb9</li> </ol>"},{"location":"book/chapter1_Introduction/1.3signal_processing/#34-34","title":"3.4 3.4 \u6ee4\u6ce2\u5668\u7684\u5e94\u7528","text":""},{"location":"book/chapter1_Introduction/1.3signal_processing/#341-341","title":"3.4.1 3.4.1 \u4fe1\u53f7\u5904\u7406\u4e2d\u7684\u5e94\u7528","text":"<ol> <li>\u566a\u58f0\u53bb\u9664\uff1a\u4f7f\u7528\u4f4e\u901a\u6ee4\u6ce2\u5668\u53bb\u9664\u9ad8\u9891\u566a\u58f0</li> <li>\u4fe1\u53f7\u5206\u79bb\uff1a\u4f7f\u7528\u5e26\u901a\u6ee4\u6ce2\u5668\u63d0\u53d6\u7279\u5b9a\u9891\u6bb5\u7684\u4fe1\u53f7</li> <li>\u5e72\u6270\u6d88\u9664\uff1a\u4f7f\u7528\u5e26\u963b\u6ee4\u6ce2\u5668\u53bb\u9664\u7279\u5b9a\u9891\u7387\u7684\u5e72\u6270</li> <li>\u4fe1\u53f7\u91cd\u5efa\uff1a\u4f7f\u7528\u7406\u60f3\u4f4e\u901a\u6ee4\u6ce2\u5668\u8fdb\u884c\u4fe1\u53f7\u91cd\u5efa</li> </ol>"},{"location":"book/chapter1_Introduction/1.3signal_processing/#342-342","title":"3.4.2 3.4.2 \u5b9e\u9645\u5e94\u7528\u4e3e\u4f8b","text":"<ol> <li>\u97f3\u9891\u5904\u7406\uff1a\u5747\u8861\u5668\u4f7f\u7528\u591a\u4e2a\u5e26\u901a\u6ee4\u6ce2\u5668</li> <li>\u901a\u4fe1\u7cfb\u7edf\uff1a\u4fe1\u9053\u9009\u62e9\u4f7f\u7528\u5e26\u901a\u6ee4\u6ce2\u5668</li> <li>\u751f\u7269\u533b\u5b66\uff1a\u5fc3\u7535\u4fe1\u53f7\u5904\u7406\u4f7f\u7528\u5e26\u963b\u6ee4\u6ce2\u5668\u53bb\u9664\u5de5\u9891\u5e72\u6270</li> </ol>"},{"location":"book/chapter1_Introduction/1.3signal_processing/#4-4-idea-upsampling","title":"4. 4. idea upsampling","text":"<p>\u5728\u6570\u5b57\u4fe1\u53f7\u5904\u7406\uff08DSP\uff09\u4e2d\uff0c\u7406\u60f3\u5347\u91c7\u6837\u6307\u7684\u662f\u5c06\u4e00\u4e2a\u79bb\u6563\u4fe1\u53f7\u4ece\u539f\u91c7\u6837\u7387 \\(F_s\\) \u65e0\u5931\u771f\u5730\u53d8\u6362\u5230\u66f4\u9ad8\u91c7\u6837\u7387 \\(L \\times F_s\\) \u7684\u7406\u8bba\u8fc7\u7a0b\u3002\u5b83\u901a\u5e38\u5305\u542b\u4e24\u6b65\uff1a\u63d2\u96f6\uff08Zero-stuffing\uff09 \u548c \u7406\u60f3\u4f4e\u901a\u6ee4\u6ce2\uff08Ideal LPF\uff09\u3002\u4e0b\u9762\u4ece\u591a\u4e2a\u89d2\u5ea6\u8fdb\u884c\u9610\u8ff0\u3002</p>"},{"location":"book/chapter1_Introduction/1.3signal_processing/#41-41","title":"4.1 4.1. \u57fa\u672c\u6982\u5ff5","text":"<ol> <li>\u63d2\u96f6\uff08Zero-stuffing\uff09    \u5728\u65f6\u57df\u4e0a\u5c06\u539f\u4fe1\u53f7 \\(x[n]\\) \u7684\u6bcf\u4e2a\u91c7\u6837\u4e4b\u95f4\u63d2\u5165 \\(L-1\\) \u4e2a\u96f6\uff0c\u5f97\u5230\u65b0\u5e8f\u5217 \\(x_{\\uparrow L}[n]\\)\u3002\u5f62\u5f0f\u4e0a\u53ef\u5199\u4e3a\uff1a</li> </ol> <p>$$    x_{\\uparrow L}[m] =    \\begin{cases}    x\\bigl(\\tfrac{m}{L}\\bigr), &amp; \\text{\u5f53 } m \\text{ \u4e3a } L \\text{ \u7684\u6574\u6570\u500d} \\    0, &amp; \\text{\u5426\u5219}    \\end{cases}    $$</p> <ol> <li>\u7406\u60f3\u4f4e\u901a\u6ee4\u6ce2\uff08Ideal LPF\uff09    \u5bf9\u63d2\u96f6\u540e\u7684\u4fe1\u53f7\u8fdb\u884c\u7406\u60f3\u4f4e\u901a\u6ee4\u6ce2\uff08\u5e26\u5bbd\u4e3a \\(\\pi/L\\)\uff09\uff0c\u5373\u4f7f\u7528\u7406\u60f3\u77e9\u5f62\u9891\u7387\u54cd\u5e94\u6ee4\u6ce2\u5668 \\(H_{\\text{ideal}}(e^{j\\omega})\\)\u3002\u5b83\u5728 \\(|\\omega|\\le \\pi/L\\) \u4e0a\u4e3a 1\uff0c\u5176\u4ed6\u533a\u95f4\u4e3a 0\u3002\u6b64\u8fc7\u7a0b\u53ef\u6ee4\u9664\u63d2\u96f6\u5bfc\u81f4\u7684\u201c\u955c\u50cf\u9891\u8c31\u201d\u6210\u5206\u3002</li> </ol>"},{"location":"book/chapter1_Introduction/1.3signal_processing/#42-42","title":"4.2 4.2. \u9891\u57df\u5206\u6790","text":"<ol> <li> <p>\u539f\u4fe1\u53f7\u7684\u9891\u8c31    \u8bbe\u539f\u4fe1\u53f7 \\(x[n]\\) \u7684\u79bb\u6563\u65f6\u95f4\u5085\u91cc\u53f6\u53d8\u6362\u4e3a \\(X(e^{j\\omega})\\)\uff0c\u4e14\u5b83\u5e26\u9650\u4e8e\u67d0\u4e2a \\(\\omega_0 \\le \\pi\\)\u3002</p> </li> <li> <p>\u63d2\u96f6\u540e\u9891\u8c31\u7684\u590d\u5236    \u63d2\u96f6\u64cd\u4f5c\u4f1a\u5728\u9891\u57df\u4ea7\u751f\u5468\u671f\u6027\u590d\u5236\uff1a\u65b0\u4fe1\u53f7 \\(x_{\\uparrow L}[n]\\) \u7684\u9891\u8c31\u5728 \\([-\\pi,\\pi]\\) \u5185\u51fa\u73b0\u591a\u4e2a\u7b49\u8ddd\u201c\u955c\u50cf\uff08image\uff09\u201d\u526f\u672c\uff0c\u6bcf\u4e2a\u526f\u672c\u5bbd\u5ea6\u4e3a\u539f\u5e26\u5bbd\u7684 \\(1/L\\)\u3002</p> </li> </ol> <p>\u89e3\u91ca    \u5728\u5b9a\u4e49\u4e86 \u63d2\u96f6\u540e\u5e8f\u5217 \\(x_{\\uparrow L}[n]\\) \u4e4b\u540e\uff0c\u6211\u4eec\u53ef\u5199\u51fa\u5b83\u7684\u79bb\u6563\u65f6\u95f4\u5085\u91cc\u53f6\u53d8\u6362 (DTFT) \u5982\u4e0b\uff1a</p> <p>$$    \\begin{aligned}    X_{\\uparrow L}(e^{j\\omega})    &amp;=\\; \\sum_{n=-\\infty}^{\\infty} x_{\\uparrow L}[n]\\;e^{-j\\,\\omega\\,n}    \\,=\\, \\sum_{n=-\\infty}^{\\infty}    \\Bigl[\\underbrace{x_{\\uparrow L}[n]}{\\text{\u4ec5\u5f53 }n=Lm\\text{\u65f6\u975e\u96f6}}\\Bigr] e^{-j\\,\\omega\\,n}.\\    &amp;=\\; \\sum    \\Bigl[x_{\\uparrow L}\\bigl(L\\,m\\bigr)\\Bigr]\\;    e^{-j\\,\\omega\\,(L\\,m)}.    \\end{aligned}    $$}^{\\infty</p> <p>\u7531\u4e8e \\(x_{\\uparrow L}[\\,L\\,m\\,] = x[m]\\)\uff0c\u4e0a\u5f0f\u7ee7\u7eed\u5316\u7b80\u5f97\u5230\uff1a</p> <p>$$    X_{\\uparrow L}(e^{j\\omega})    =\\; \\sum_{m=-\\infty}^{\\infty} x[m]\\;e^{-j\\,(\\omega\\,L)\\,m}.    $$</p> <p>\u5982\u679c\u5c06 \\(\\omega\\,L\\) \u89c6\u4e3a\u65b0\u7684\u9891\u7387\u53d8\u91cf \\(\\Theta\\)\uff0c\u5219\u53ef\u8bc6\u522b\u4e3a\u539f\u4fe1\u53f7 \\(x[n]\\) \u7684 DTFT\uff1a</p> <p>$$    X_{\\uparrow L}(e^{j\\omega})    =\\; X\\bigl(e^{\\,j(\\omega\\,L)}\\bigr).    $$</p> <p>\u5728 \\(\\omega\\) \u7684\u4e00\u4e2a \\(2\\pi\\) \u5468\u671f\u8303\u56f4\u5185\uff0c\\(X_{\\uparrow L}(e^{j\\omega})\\) \u4f1a\u51fa\u73b0\u591a\u6b21\u91cd\u590d\uff08\u955c\u50cf\uff09\u5206\u91cf\u3002</p> <ol> <li>\u7406\u60f3\u6ee4\u6ce2\u5668\u4fdd\u7559\u4e3b\u74e3    \u7406\u60f3\u4f4e\u901a\u6ee4\u6ce2\u5668 \\(H_{\\text{ideal}}(e^{j\\omega})\\) \u5728 \\(|\\omega|\\le \\pi/L\\) \u5185\u4e3a 1\uff0c\u8d85\u51fa\u6b64\u8303\u56f4\u4e3a 0\uff0c\u4ec5\u4fdd\u7559\u6700\u4e2d\u5fc3\u7684\u90a3\u6bb5\u539f\u59cb\u9891\u8c31\u526f\u672c\uff0c\u5176\u4f59\u955c\u50cf\u5206\u91cf\u88ab\u6ee4\u9664\u3002</li> </ol>"},{"location":"book/chapter1_Introduction/1.3signal_processing/#43-43","title":"4.3 4.3. \u65f6\u57df\u7ed3\u679c","text":"<p>\u6ee4\u6ce2\u540e\u7684\u8f93\u51fa\u4fe1\u53f7\u53ef\u5199\u4e3a</p> \\[ y[n] = \\bigl[x_{\\uparrow L} * h_{\\text{ideal}}\\bigr](n), \\] <p>\u5176\u4e2d \\(h_{\\text{ideal}}[n]\\) \u4e3a\u7406\u60f3\u4f4e\u901a\u6ee4\u6ce2\u5668\u7684\u51b2\u6fc0\u54cd\u5e94\uff08\u79bb\u6563\u7248 \\(\\mathrm{sinc}\\) \u51fd\u6570\uff09\u3002\u82e5\u6ee4\u6ce2\u5668\u53ef\u7406\u60f3\u5b9e\u73b0\uff0c\u5219\u8f93\u51fa \\(y[n]\\) \u4e0e\u539f\u4fe1\u53f7\u5728\u66f4\u9ad8\u91c7\u6837\u7387\u4e0b\u4e00\u4e00\u5bf9\u5e94\uff0c\u8fbe\u5230\u201c\u5b8c\u7f8e\u63d2\u503c\u201d\u7684\u6548\u679c\u3002</p>"},{"location":"book/chapter1_Introduction/1.3signal_processing/#44-44","title":"4.4 4.4. \u5b9e\u9645\u5b9e\u73b0\u7684\u5dee\u5f02","text":"<ul> <li> <p>\u65e0\u9650\u957f\u6ee4\u6ce2\u5668\u7684\u96be\u9898   \u7406\u60f3\u4f4e\u901a\u6ee4\u6ce2\u5668\u5728\u65f6\u57df\u4e2d\u5bf9\u5e94\u65e0\u9650\u957f\u7684 \\(\\mathrm{sinc}\\)\uff0c\u73b0\u5b9e\u4e2d\u96be\u4ee5\u5b9e\u73b0\u3002</p> </li> <li> <p>FIR \u6ee4\u6ce2\u5668\u8fd1\u4f3c   \u5de5\u7a0b\u4e0a\u4f7f\u7528\u6709\u9650\u957f\u5ea6\u7684 FIR\uff08\u6216 IIR\uff09\u6ee4\u6ce2\u5668\u6765\u903c\u8fd1\u7406\u60f3\u4f4e\u901a\u6ee4\u6ce2\u5668\uff0c\u9700\u8981\u5728\u8fc7\u6e21\u5e26\u4e0e\u963b\u5e26\u8870\u51cf\u7b49\u65b9\u9762\u505a\u6743\u8861\u3002</p> </li> </ul>"},{"location":"book/chapter1_Introduction/1.3signal_processing/#45-45","title":"4.5 4.5. \u7ed3\u8bba","text":"<ol> <li> <p>\u7406\u60f3\u5347\u91c7\u6837\u7684\u672c\u8d28    \u5148\u8fdb\u884c\u201c\u63d2\u96f6\u201d\uff0c\u518d\u7528\u7406\u60f3\u4f4e\u901a\u6ee4\u6ce2\u5668\u6291\u5236\u955c\u50cf\u9891\u8c31\uff0c\u4ec5\u4fdd\u7559\u539f\u59cb\u5e26\u9650\u4fe1\u606f\u3002</p> </li> <li> <p>\u610f\u4e49    \u5728\u66f4\u9ad8\u91c7\u6837\u7387\u4e0b\uff0c\u5b9e\u73b0\u7406\u8bba\u4e0a\u201c\u65e0\u5931\u771f\u201d\u7684\u4fe1\u53f7\u63d2\u503c\u4e0e\u91cd\u91c7\u6837\u3002</p> </li> <li> <p>\u5de5\u7a0b\u6298\u4e2d    \u7531\u4e8e\u771f\u6b63\u7684\u7406\u60f3\u6ee4\u6ce2\u5668\u65e0\u6cd5\u5b9e\u73b0\uff0c\u5b9e\u9645\u53ea\u80fd\u505a\u201c\u5c3d\u53ef\u80fd\u597d\u201d\u7684\u63d2\u503c\u6ee4\u6ce2\uff0c\u5f97\u5230\u8f83\u597d\u7684\u8fd1\u4f3c\u7ed3\u679c\u3002</p> <p>\u4e00\u53e5\u8bdd\u6982\u62ec\uff1a\u7406\u60f3\u5347\u91c7\u6837 = \u201c\u63d2\u96f6\u201d + \u201c\u7406\u60f3\u4f4e\u901a\u201d\uff0c\u4f7f\u5f97\u5728\u66f4\u9ad8\u91c7\u6837\u7387\u4e0b\u4fdd\u6301\u539f\u5e26\u9650\u4fe1\u53f7\u7684\u6240\u6709\u9891\u8c31\u4fe1\u606f\u800c\u4e0d\u5931\u771f\u3002</p> </li> <li> <p>\u201c\u4fe1\u53f7\u4e0d\u53d8\u201d\u4e0e\u201c\u9891\u7387\u538b\u7f29\u201d\u5e76\u4e0d\u77db\u76fe    \u7269\u7406\u4e0a/\u8fde\u7eed\u57df\u770b\uff0c\u201c\u540c\u4e00\u4e2a\u4fe1\u53f7\u201d\u5e76\u6ca1\u6709\u771f\u6b63\u88ab\u7be1\u6539\uff1b\u82e5\u771f\u7684\u589e\u52a0\u91c7\u6837\u7387\uff0c\u4fe1\u53f7\u672c\u8eab\u5728\u6ce2\u5f62\u4e0a\u4e5f\u662f\u5149\u6ed1\u5730\u63d2\u503c\u3002    \u79bb\u6563-\u6570\u5b66\u4e0a\u770b\uff0c\u201c\u4e0a\u91c7\u6837\u201d\u5c31\u610f\u5473\u7740\u63d2\u5165\u96f6(\u6216\u901a\u8fc7\u63d2\u503c\u6ee4\u6ce2\u5668\u8ba9\u65b0\u6837\u672c\u5e76\u975e\u5168\u662f\u96f6)\uff0c\u5bfc\u81f4\u201c\u5e8f\u5217\u7d22\u5f15\u201d\u52a0\u5bc6\uff1b\u7531\u6b64\u5728\u79bb\u6563\u9891\u7387\u5750\u6807(    \\(\\omega\\)\u4e0a\u4f1a\u770b\u5230\u9891\u8c31\u538b\u7f29\u548c\u955c\u50cf\u7684\u73b0\u8c61\u3002    \u5173\u952e\u662f\uff1a\u201c\u79bb\u6563\u89d2\u9891\u7387 \\(\\omega\\)\u4e0d\u662f\u76f4\u63a5\u7b49\u540c\u4e8e\u7269\u7406\u9891\u7387(Hz)\uff0c\u800c\u662f\u76f8\u5bf9\u2018\u6bcf\u4e2a\u91c7\u6837\u70b9\u2019\u7684\u5f52\u4e00\u5316\u9891\u7387\u3002</p> </li> </ol> <p>\u5f53\u4f60\u6539\u53d8\u201c\u6bcf\u4e2a\u91c7\u6837\u70b9\u95f4\u7684\u5b9e\u9645\u65f6\u95f4\u95f4\u9694\u201d\uff0c\u5c31\u4f1a\u5728 \\(\\omega\\)\u8f74\u4e0a\u770b\u5230\u5e26\u5bbd\u53d1\u751f\u53d8\u5316(\u53d8\u5f97\u66f4\u5c0f\u6216\u66f4\u5927)\u3002\u4f46\u662f\u201c\u7269\u7406\u4fe1\u53f7\u201d\u5e76\u672a\u5fc5\u4ea7\u751f\u5931\u771f\uff0c\u53ea\u662f\u5b83\u7684\u79bb\u6563\u7d22\u5f15\u523b\u5ea6\u53d1\u751f\u4e86\u4f38\u7f29\u3002    \u5728\u201c\u7406\u60f3\u4e0a\u91c7\u6837\u201d\u4e2d\uff0c\u4e3a\u4ec0\u4e48\u8981\u914d\u5408\u6ee4\u6ce2\u5668\uff1f    \u4ec5\u63d2\u96f6\u4e0d\u591f\uff1a\u4f1a\u5728\u9891\u57df\u4ea7\u751f\u955c\u50cf\u5206\u91cf\uff08image/alias\uff09\u3002    \u7406\u60f3\u4e0a\u91c7\u6837 = \u201c\u63d2\u96f6 + \u7406\u60f3\u4f4e\u901a\u6ee4\u6ce2(\u5e26\u5bbd \\(\\pi/L\\)\u201d\uff0c\u4ece\u800c\u6ee4\u9664\u9664\u4e3b\u5e26\u5916\u7684\u90a3\u4e9b\u955c\u50cf\u9891\u8c31\u3002    \u8fd9\u6837\u5f97\u5230\u7684\u8f93\u51fa\u5728\u65b0\u7684\u91c7\u6837\u7387\u4e0b\u4ecd\u7136\u53ea\u4fdd\u7559\u539f\u5148\u7684\u5e26\u5bbd\u4fe1\u606f\uff0c\u4f46\u5bf9\u5e94\u4e8e\u79bb\u6563\u89d2\u9891\u7387\\(\\omega\\)\uff0c\u5b83\u5c31\u538b\u7f29\u5230\u4e86 \\(- \\pi/L, + \\pi/L\\) \u4ee5\u5185\u3002    \u6b64\u65f6\u4f60\u4f1a\u770b\u5230\uff0c\u9891\u8c31\u4e5f\u4e0d\u4f1a\u201c\u53d8\u5927\u201d\uff0c\u800c\u662f\u4fdd\u6301\u539f\u5e26\u5bbd\u201d \u2014\u2014 \u53ea\u662f\u91cf\u7eb2\u4ece\u201c\u9891\u7387/\u91c7\u6837\u70b9\u201d\u53d8\u6210\u65b0\u7684\u66f4\u5bc6\u96c6\u91c7\u6837\u4e0b\u7684\u201c\u9891\u7387/\u91c7\u6837\u70b9\u201d\u3002\u8fd9\u5c31\u662f\u201c\u5728\u79bb\u6563\u57df\u51fa\u73b0\u4e86\u9891\u7387\u538b\u7f29\u201d\u3002</p>"},{"location":"book/chapter1_Introduction/1.3signal_processing/#5-5-downsampling","title":"5. 5. \u4e0b\u91c7\u6837\uff08Downsampling\uff09","text":"<p>\u4e0b\u91c7\u6837\uff08\u4e5f\u79f0\u201c\u964d\u91c7\u6837\u201d\u6216\u201c\u62bd\u53d6\u201d\uff09\u6307\u5728\u6570\u5b57\u4fe1\u53f7\u5904\u7406\u4e2d\uff0c\u5c06\u79bb\u6563\u4fe1\u53f7\u7684\u91c7\u6837\u7387\u4ece\u539f\u5148\u7684 \\(F_s\\) \u964d\u4f4e\u5230 \\(\\tfrac{F_s}{M}\\)\uff08\\(M\\) \u4e3a\u964d\u91c7\u6837\u56e0\u5b50\uff09\uff0c\u4ece\u800c\u51cf\u5c11\u91c7\u6837\u70b9\u6570\u3002\u8bbe\u539f\u5e8f\u5217\u4e3a \\(x[n]\\)\uff0c\u5219\u4e0b\u91c7\u6837\u540e\u7684\u5e8f\u5217\u4e3a</p> \\[ y[m] \\;=\\; x[m\\,M]. \\]"},{"location":"book/chapter1_Introduction/1.3signal_processing/#51-51","title":"5.1 5.1. \u65f6\u57df\u63cf\u8ff0","text":"<ul> <li>\u64cd\u4f5c\uff1a\u6bcf\u95f4\u9694 \\(M\\) \u4e2a\u7d22\u5f15\u53d6\u4e00\u4e2a\u6837\u672c\uff0c\u5176\u4f59\u6837\u672c\u88ab\u820d\u5f03\u3002</li> <li>\u793a\u4f8b\uff1a\u5982\u679c \\(M = 2\\)\uff0c\u5219</li> </ul> <p>$$     y[0] = x[0], \\quad y[1] = x[2], \\quad y[2] = x[4], \\dots   $$</p>"},{"location":"book/chapter1_Introduction/1.3signal_processing/#52-52-aliasing","title":"5.2 5.2. \u9891\u57df\u5f71\u54cd\uff1a\u6df7\u53e0(Aliasing)","text":"<p>\u5728\u79bb\u6563\u65f6\u95f4\u5085\u91cc\u53f6\u53d8\u6362(DTFT)\u89c6\u89d2\uff0c\u4e0b\u91c7\u6837\u4f1a\u4ea7\u751f\u6df7\u53e0(aliasing)\u3002 \u5e38\u89c1\u7ed3\u8bba\u662f\uff1a</p> \\[ Y(e^{j\\Omega}) \\;=\\; \\frac{1}{M}\\, \\sum_{k=0}^{M-1} X\\!\\Bigl(e^{\\,j\\,\\tfrac{\\Omega + 2\\pi k}{M}}\\Bigr), \\] <p>\u5176\u4e2d \\(X(e^{j\\omega})\\) \u548c \\(Y(e^{j\\Omega})\\) \u5206\u522b\u4e3a \\(x[n]\\) \u548c \\(y[m]\\) \u7684 DTFT\u3002\u8be5\u516c\u5f0f\u8868\u660e\uff0c\u65b0\u5e8f\u5217\u7684\u9891\u8c31\u662f\u539f\u5e8f\u5217\u9891\u8c31\u7684\u591a\u4e2a\u5e73\u79fb/\u6298\u53e0\u526f\u672c\u76f8\u52a0\u5728\u4e00\u8d77\uff0c\u8fd9\u5c31\u662f\u6df7\u53e0\u7684\u672c\u8d28\u3002</p>"},{"location":"book/chapter1_Introduction/1.3signal_processing/#53-53-anti-aliasing-filter","title":"5.3 5.3. \u9700\u8981\u5148\u4f4e\u901a\u6ee4\u6ce2 (\u6297\u6df7\u53e0\u6ee4\u6ce2\uff0cAnti-Aliasing Filter)","text":"<ol> <li>\u76ee\u7684</li> <li>\u82e5\u4fe1\u53f7\u539f\u672c\u5305\u542b\u9ad8\u4e8e\u65b0\u7684\u5948\u594e\u65af\u7279\u9891\u7387 \\(\\tfrac{\\pi}{M}\\)\uff08\u76f8\u5bf9\u4e8e\u65e7\u91c7\u6837\u7387\u8ba1\uff09\u7684\u6210\u5206\uff0c\u5219\u5728\u4e0b\u91c7\u6837\u540e\u4f1a\u51fa\u73b0\u91cd\u53e0\u6df7\u53e0\u3002</li> <li>\u89e3\u51b3\u65b9\u6848</li> <li>\u5728\u4e0b\u91c7\u6837\u524d\u7528\u4f4e\u901a\u6ee4\u6ce2\u5668\u6ee4\u9664\u8d85\u51fa \\(\\tfrac{\\pi}{M}\\) \u7684\u9ad8\u9891\u5206\u91cf\uff0c\u907f\u514d\u8fd9\u4e9b\u9891\u7387\u5206\u91cf\u5728\u65b0\u91c7\u6837\u7387\u4e0b\u4ea7\u751f\u6df7\u53e0\u5931\u771f\u3002</li> <li>\u5b9e\u73b0</li> <li>\u5b9e\u9645\u4e2d\u5e38\u7528\u6709\u9650\u51b2\u6fc0\u54cd\u5e94(FIR)\u4f4e\u901a\u6ee4\u6ce2\u5668\u6216 IIR \u6ee4\u6ce2\u5668\u8fdb\u884c\u5904\u7406\uff0c\u7136\u540e\u518d\u6bcf\u9694 \\(M\\) \u70b9\u53d6\u6837\u3002</li> </ol>"},{"location":"book/chapter1_Introduction/1.3signal_processing/#54-54","title":"5.4 5.4. \u5e94\u7528\u573a\u666f","text":"<ul> <li>\u591a\u901f\u7387\u6570\u5b57\u4fe1\u53f7\u5904\u7406\uff1a\u5728\u6ee4\u6ce2\u5668\u7ec4\u3001\u5b50\u5e26\u7f16\u7801\u7b49\u4e2d\uff0c\u901a\u8fc7\u964d\u91c7\u6837\u51cf\u5c11\u6570\u636e\u901f\u7387\uff0c\u964d\u4f4e\u8fd0\u7b97\u91cf\u3002</li> <li>\u97f3\u9891/\u56fe\u50cf\u8f6c\u7801\uff1a\u4ece\u66f4\u9ad8\u91c7\u6837\u7387\u8f6c\u5230\u66f4\u4f4e\u91c7\u6837\u7387\uff1b\u4f8b\u5982\u97f3\u9891\u4ece 48 kHz \u964d\u5230 16 kHz\uff0c\u5fc5\u987b\u5148\u6ee4\u9664 8 kHz \u4ee5\u4e0a\u7684\u9891\u7387\u6210\u5206\u3002</li> <li>\u5c0f\u6ce2\u53d8\u6362\uff1a\u5c06\u4fe1\u53f7\u5206\u89e3\u4e3a\u4e0d\u540c\u5206\u8fa8\u7387\u5b50\u5e26\u540e\uff0c\u5bf9\u6bcf\u4e2a\u5b50\u5e26\u505a\u62bd\u53d6\u4ee5\u51cf\u5c11\u5197\u4f59\u3002</li> </ul>"},{"location":"book/chapter1_Introduction/1.3signal_processing/#55-55","title":"5.5 5.5 \u79bb\u6563\u8868\u8ff0\u548c\u8fde\u7eed\u8868\u8ff0\u7684\u5173\u7cfb","text":"<p>\u4e0b\u91c7\u6837\u9891\u8c31\u5206\u6790\uff1a\u79bb\u6563\u8868\u8ff0 vs. \u8fde\u7eed\u8868\u8ff0</p> <p>\u5728\u6570\u5b57\u4fe1\u53f7\u5904\u7406\u91cc\uff0c\u5e38\u89c1\u201c\u4e0b\u91c7\u6837(Downsampling)\u201d\u64cd\u4f5c\u662f\u5c06\u91c7\u6837\u7387\u964d\u4f4e\u5230\u539f\u6765\u7684 <code>1/M</code>\u3002\u4e0b\u91c7\u6837\u524d\u540e\uff0c\u4fe1\u53f7\u5728\u79bb\u6563\u57df\u4e0e\u8fde\u7eed\u57df\u4f1a\u6709\u4e0d\u540c\u7684\u9891\u8c31\u8868\u8ff0\uff0c\u4f46\u5b83\u4eec\u672c\u8d28\u4e0a\u8868\u8fbe\u7684\u662f\u540c\u4e00\u4e2a\u6df7\u53e0(aliasing)\u539f\u7406\u3002\u4ee5\u4e0b\u5206\u522b\u505a\u7b80\u8981\u8bf4\u660e\u3002</p>"},{"location":"book/chapter1_Introduction/1.3signal_processing/#551-551-m","title":"5.5.1 5.5.1. \u79bb\u6563\u8868\u8ff0\uff1a\u5e26\u5bbd &lt; \u03c0/M","text":"<ul> <li>\u79bb\u6563\u65f6\u95f4\u4e2d\uff0c\u4e0b\u91c7\u6837\u56e0\u5b50\u4e3a <code>M</code> \u65f6\uff0c\u82e5\u8981\u907f\u514d\u6df7\u53e0\uff0c\u9700\u8981\u4fe1\u53f7\u5728 \u79bb\u6563\u89d2\u9891\u7387 <code>\u03c9</code> \u4e0a\u6ee1\u8db3</li> </ul> <p>$$   \\text{(\u5e26\u5bbd)} \\;&lt;\\; \\frac{\\pi}{M} \\quad (\\text{rad/sample}).   $$</p> <ul> <li>\u5728\u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362(DTFT)\u4e2d\uff0c<code>\u03c9</code> \u53d6\u503c\u8303\u56f4\u901a\u5e38\u662f <code>[-\u03c0, \u03c0]</code>\uff0c\u5bf9\u5e94\u4e00\u4e2a\u5b8c\u6574\u7684 2\u03c0-\u5468\u671f\u3002\u82e5\u539f\u4fe1\u53f7\u5e26\u5bbd\u8d85\u8fc7 <code>\u03c0/M</code>\uff0c\u4e0b\u91c7\u6837\u540e\u4f1a\u51fa\u73b0\u591a\u4e2a\u5e73\u79fb\u526f\u672c\u4e92\u76f8\u91cd\u53e0\uff0c\u5f15\u53d1\u6df7\u53e0\u3002</li> </ul>"},{"location":"book/chapter1_Introduction/1.3signal_processing/#552-552-f2m","title":"5.5.2 5.5.2. \u8fde\u7eed\u8868\u8ff0\uff1a\u5e26\u5bbd &lt; F/(2M)","text":"<ul> <li>\u8fde\u7eed\u65f6\u95f4\u4e2d\uff0c\u5982\u679c\u539f\u5148\u91c7\u6837\u7387\u662f <code>F</code> (Hz)\uff0c\u4e0b\u91c7\u6837\u56e0\u5b50 <code>M</code> \u4f1a\u4f7f \u65b0\u91c7\u6837\u7387 \u53d8\u4e3a <code>F' = F/M</code>\u3002</li> <li>\u6839\u636e\u91c7\u6837\u5b9a\u7406(Nyquist-Shannon)\uff0c\u8981\u907f\u514d\u6df7\u53e0\uff0c\u9700\u8981\u5e26\u5bbd <code>B</code> \u5c0f\u4e8e\u65b0\u5948\u594e\u65af\u7279\u9891\u7387 <code>(F/M)/2</code>\uff0c\u5373</li> </ul> <p>$$   B \\;&lt;\\; \\frac{F}{2\\,M} \\quad (\\text{Hz}).   $$</p> <ul> <li>\u5f53\u5e26\u5bbd\u8d85\u8fc7 <code>F/(2M)</code> \u65f6\uff0c\u5728\u65b0\u7684\u91c7\u6837\u7387\u4e0b\u5fc5\u7136\u4f1a\u4ea7\u751f aliasing\uff08\u522b\u540d\u5931\u771f\uff09\u3002</li> </ul>"},{"location":"book/chapter1_Introduction/1.3signal_processing/#553-553","title":"5.5.3 5.5.3. \u4e8c\u8005\u4e00\u81f4\u6027","text":"<ul> <li>\u79bb\u6563\u57df\u91cc \u201c\u5e26\u5bbd &lt; \u03c0/M (rad/sample)\u201d</li> <li>\u8fde\u7eed\u57df\u91cc \u201c\u5e26\u5bbd &lt; F/(2M) (Hz)\u201d</li> </ul> <p>\u4e8c\u8005\u770b\u4f3c\u4e0d\u540c\uff0c\u4f46\u672c\u8d28\u662f\u540c\u4e00\u4e2a\u6761\u4ef6\uff0c\u56e0\u4e3a\u79bb\u6563\u89d2\u9891\u7387 <code>\u03c9 = \u03c0</code> \u76f8\u5f53\u4e8e\u7269\u7406\u9891\u7387 <code>F/2</code> (Nyquist \u9891\u7387)\u3002\u6362\u8a00\u4e4b\uff1a</p> \\[ \\omega = \\pi \\;\\;\\longleftrightarrow\\;\\; f = \\frac{F}{2}. \\] <p>\u56e0\u6b64\uff0c</p> \\[ \\omega &lt; \\frac{\\pi}{M} \\quad\\longleftrightarrow\\quad f &lt; \\frac{F}{2\\,M}. \\] <p>\u8fd9\u5c31\u662f\u4e3a\u4ec0\u4e48\u5728\u79bb\u6563\u516c\u5f0f\u548c\u8fde\u7eed\u516c\u5f0f\u4e2d\uff0c\u9608\u503c\u770b\u8d77\u6765\u4e0d\u540c\u4f46\u542b\u4e49\u76f8\u540c\u3002</p>"},{"location":"book/chapter1_Introduction/1.3signal_processing/#554-554","title":"5.5.4 5.5.4. \u4e0b\u91c7\u6837\u5728\u8fde\u7eed\u57df\u7684\u9891\u8c31\u516c\u5f0f","text":"<p>\u5728\u8fde\u7eed\u57df\uff0c\u7528\u51b2\u6fc0\u5217(Dirac comb) \u8868\u793a\u91c7\u6837\uff0c\u5468\u671f\u4ece <code>T = 1/F</code> \u589e\u5927\u5230 <code>M\u00b7T</code> \u65f6\uff0c\u9891\u57df\u8868\u73b0\u4e3a \u539f\u4fe1\u53f7\u8c31\u7684\u591a\u4e2a\u5e73\u79fb\u5e76\u76f8\u52a0\uff1a</p> \\[ Y_{\\mathrm{sample}}(\\omega) \\;=\\; \\frac{1}{M\\,T} \\sum_{k=-\\infty}^{\\infty} X\\!\\Bigl(\\omega - 2\\pi\\,\\tfrac{k}{M\\,T}\\Bigr). \\] <ul> <li>\u8fd9\u91cc\uff0c<code>X(\u03c9)</code> \u662f <code>x(t)</code> \u7684\u5085\u91cc\u53f6\u53d8\u6362\uff0c<code>Y_sample(\u03c9)</code> \u5219\u662f\u4e0b\u91c7\u6837\u540e\u4fe1\u53f7\u7684\u9891\u8c31\u3002</li> <li>\u82e5\u5e26\u5bbd\u8d85\u8fc7 <code>1/(2M\u00b7T) = F/(2M)</code>\uff0c\u8fd9\u4e9b\u526f\u672c\u5728\u9891\u57df\u91cc\u53d1\u751f\u91cd\u53e0\uff0c\u5bfc\u81f4\u6df7\u53e0\u3002</li> </ul>"},{"location":"book/chapter1_Introduction/1.3signal_processing/#555-5","title":"5.5.5 5. \u5c0f\u7ed3","text":"<ol> <li>\u79bb\u6563 vs. \u8fde\u7eed</li> <li>\u79bb\u6563\u65f6\u95f4\u5085\u91cc\u53f6\u53d8\u6362(DTFT)\u4ee5 <code>\u03c9</code> (rad/sample) \u4e3a\u8f74\uff0c\u5b8c\u6574\u5468\u671f\u662f <code>2\u03c0</code>\uff1b</li> <li> <p>\u8fde\u7eed\u5085\u91cc\u53f6\u53d8\u6362(CFT)\u4ee5 <code>\u03c9</code> (rad/s) \u6216 <code>f</code> (Hz) \u4e3a\u8f74\uff0c\u53ef\u80fd\u6709\u65e0\u7a77\u5bbd\u5ea6\uff0c\u4f46\u91c7\u6837\u540e\u51fa\u73b0\u9891\u8c31\u5468\u671f\u590d\u5236\u3002</p> </li> <li> <p>\u907f\u514d\u6df7\u53e0\u7684\u5e26\u5bbd\u9650\u5236</p> </li> <li>\u79bb\u6563\u57df\uff1a<code>\u03c9_band &lt; \u03c0/M</code>\uff1b</li> <li> <p>\u8fde\u7eed\u57df\uff1a<code>B &lt; F/(2M)</code>\u3002    \u8fd9\u4e8c\u8005\u76f8\u4e92\u5bf9\u5e94\uff1a\u201c<code>\u03c9 = \u03c0</code>\u201d \u2194 \u201c<code>f = F/2</code>\u201d\uff0c\u5b9e\u5219\u540c\u4e00\u4e2aNyquist\u9650\u5236\u3002</p> </li> <li> <p>\u4e0b\u91c7\u6837\u524d\u5e38\u7528\u4f4e\u901a\u6ee4\u6ce2</p> </li> <li>\u5b9e\u9645\u7cfb\u7edf\u4e2d\uff0c\u4e3a\u4e86\u6ee1\u8db3\u4e0a\u8ff0\u5e26\u5bbd\u9650\u5236\uff0c\u5f80\u5f80\u5728\u4e0b\u91c7\u6837\u4e4b\u524d\u5148\u505a\u4f4e\u901a\u6ee4\u6ce2 (\u6297\u6df7\u53e0\u6ee4\u6ce2\u5668)\uff0c\u5c06\u4fe1\u53f7\u5e26\u5bbd\u7ea6\u675f\u5230 <code>(F/2M)</code> \u4ee5\u5185\u3002</li> </ol> <p>\u4e00\u53e5\u8bdd\u603b\u7ed3\uff1a\u5728\u79bb\u6563\u8868\u8ff0\u4e0e\u8fde\u7eed\u8868\u8ff0\u4e0b\uff0c\u907f\u514d\u6df7\u53e0\u7684\u6761\u4ef6\u4e4b\u6240\u4ee5\u770b\u8d77\u6765\u6709\u4e24\u4e2a\u4e0d\u540c\u7684\u9608\u503c(\u201c&lt; \u03c0/M\u201d vs. \u201c&lt; F/(2M)\u201d)\uff0c\u53ea\u662f\u9891\u7387\u5355\u4f4d\u53d8\u5316\u7684\u7f18\u6545\uff0c\u672c\u8d28\u4e0a\u662f\u540c\u4e00\u4e2a\u9891\u7387\u5e26\u5bbd\u9650\u5236\u3002</p>"},{"location":"book/chapter1_Introduction/1.3signal_processing/#6-references","title":"6. references","text":"<ol> <li>\u9891\u8c31\u6df7\u53e0</li> <li>\u89c6\u9891\u6559\u7a0b\u91c7\u6837</li> <li>\u4e8c\u7ef4\u63d2\u503c\u5b9a\u7406</li> </ol>"},{"location":"book/chapter1_Introduction/1.4statistics/","title":"\u7edf\u8ba1\u5b66\u7b80\u4ecb","text":""},{"location":"book/chapter1_Introduction/1.4statistics/#1-1-sampling","title":"1. 1.  \u62bd\u6837 sampling","text":""},{"location":"book/chapter1_Introduction/1.4statistics/#11-11-sampling-in-statistics","title":"1.1 1.1 \u62bd\u6837 (Sampling in Statistics)\u6570\u5b66\u548c\u7edf\u8ba1\u5b9a\u4e49","text":"<ul> <li>\u62bd\u6837\u662f\u4ece\u4e00\u4e2a\u603b\u4f53 (Population) \u4e2d\u9009\u53d6\u4e00\u4e2a\u5b50\u96c6 (Sample) \u7684\u8fc7\u7a0b\u3002</li> <li>\u5047\u8bbe\u603b\u4f53\u662f\u96c6\u5408 \\(\\mathcal{P}\\)\uff0c\u5176\u5927\u5c0f\u4e3a \\(N\\)\uff0c\u62bd\u6837\u9009\u53d6\u7684\u6837\u672c\u96c6\u5408\u8bb0\u4e3a \\(\\mathcal{S} \\subset \\mathcal{P}\\)\uff0c\u6837\u672c\u5927\u5c0f\u4e3a \\(n\\)\uff0c\u5176\u4e2d \\(n \\ll N\\)\u3002 \u6838\u5fc3\u76ee\u6807</li> <li> <p>\u7edf\u8ba1\u63a8\u65ad \uff1a\u901a\u8fc7\u7814\u7a76\u6837\u672c \\(\\mathcal{S}\\)\uff0c\u4f30\u8ba1\u603b\u4f53 \\(\\mathcal{P}\\) \u7684\u53c2\u6570\uff08\u5982\u5747\u503c\u3001\u65b9\u5dee\u3001\u5206\u5e03\u7b49\uff09\u3002</p> </li> <li> <p>\u6838\u5fc3\u95ee\u9898 \uff1a\u5982\u4f55\u4fdd\u8bc1\u6837\u672c\u5177\u6709\u4ee3\u8868\u6027\uff0c\u4ee5\u51cf\u5c11\u603b\u4f53\u4e0e\u6837\u672c\u4e4b\u95f4\u7684\u8bef\u5dee\u3002 \u6570\u5b66\u65b9\u6cd5</p> </li> <li>\u968f\u673a\u62bd\u6837\uff1a\u6837\u672c\u662f\u4ece\u603b\u4f53\u4e2d\u72ec\u7acb\u4e14\u7b49\u6982\u7387\u5730\u62bd\u53d6\u7684\uff0c\u6bcf\u4e2a\u5143\u7d20\u88ab\u62bd\u53d6\u7684\u6982\u7387\u4e3a \\(\\frac{1}{N}\\)\u3002</li> <li>\u5206\u5c42\u62bd\u6837\uff1a\u603b\u4f53\u5206\u4e3a\u82e5\u5e72\u5b50\u96c6\uff0c\u5206\u522b\u4ece\u6bcf\u4e2a\u5b50\u96c6\u4e2d\u6309\u6bd4\u4f8b\u62bd\u53d6\u6837\u672c\u3002</li> <li>\u6837\u672c\u5747\u503c\uff1a$ \\bar{x} = \\frac{1}{n} \\sum_{i=1}^n x_i$</li> </ul> <p>\u6837\u672c\u5747\u503c\u662f\u603b\u4f53\u5747\u503c\u7684\u65e0\u504f\u4f30\u8ba1\u3002</p>"},{"location":"book/chapter1_Introduction/1.4statistics/#12-12","title":"1.2 1.2 \u7edf\u8ba1\u4f9d\u636e","text":"<ul> <li> <p>\u5927\u6570\u5b9a\u5f8b \uff1a\u6837\u672c\u91cf \\(n\\) \u8d8a\u5927\uff0c\u6837\u672c\u5747\u503c \\(\\bar{x}\\) \u8d8b\u8fd1\u4e8e\u603b\u4f53\u5747\u503c \\(\\mu\\)\u3002</p> </li> <li> <p>\u4e2d\u5fc3\u6781\u9650\u5b9a\u7406 \uff1a\u5f53\u6837\u672c\u91cf\u8db3\u591f\u5927\u65f6\uff0c\u6837\u672c\u5747\u503c \\(\\bar{x}\\) \u7684\u5206\u5e03\u63a5\u8fd1\u6b63\u6001\u5206\u5e03\u3002</p> <p>\u5e94\u7528\u793a\u4f8b</p> <ol> <li> <p>\u8c03\u67e5\u7814\u7a76 \uff1a\u4ece\u57ce\u5e02\u4e2d\u7684\u5c45\u6c11\u4e2d\u968f\u673a\u62bd\u53d6 1000 \u4eba\uff0c\u8c03\u67e5\u4ed6\u4eec\u7684\u6536\u5165\u5206\u5e03\u3002</p> </li> <li> <p>\u673a\u5668\u5b66\u4e60 \uff1a\u4ece\u4e00\u4e2a\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e2d\u9009\u53d6\u5b50\u96c6\uff0c\u7528\u4e8e\u8bad\u7ec3\u6a21\u578b\u3002</p> </li> </ol> </li> </ul>"},{"location":"book/chapter1_Introduction/1.4statistics/#13-13-signal-sampling-in-mathematics","title":"1.3 1.3 \u548c \u91c7\u6837 (Signal Sampling in Mathematics) \u7684\u533a\u522b","text":"<ul> <li>\u91c7\u6837\u662f\u4ece\u4e00\u4e2a\u8fde\u7eed\u4fe1\u53f7 \\(f(t)\\) \u4e2d\uff0c\u6309\u7167\u4e00\u5b9a\u89c4\u5219\u5728\u79bb\u6563\u70b9 \\(\\{t_n\\}\\) \u4e0a\u53d6\u503c\uff0c\u5f62\u6210\u79bb\u6563\u4fe1\u53f7 \\(f[n]\\) \u7684\u8fc7\u7a0b\u3002</li> <li>\u79bb\u6563\u5316\u7684\u4fe1\u53f7\u8868\u793a\u4e3a\uff1a</li> </ul> \\[  f[n] = f(t_n), \\quad t_n = nT, \\quad n \\in \\mathbb{Z} \\] <p>\u5176\u4e2d \\(T\\) \u662f\u91c7\u6837\u95f4\u9694\uff0c\\(1/T\\) \u662f\u91c7\u6837\u9891\u7387\u3002</p> <p>\u6838\u5fc3\u533a\u522b</p> <ul> <li>\u62bd\u6837 \uff1a\u7814\u7a76\u79bb\u6563\u603b\u4f53\u7684\u5b50\u96c6\uff0c\u63a8\u65ad\u603b\u4f53\u7279\u6027\u3002</li> <li>\u91c7\u6837 \uff1a\u5c06\u8fde\u7eed\u4fe1\u53f7\u79bb\u6563\u5316\uff0c\u4e3a\u6570\u5b57\u5904\u7406\u6216\u5206\u6790\u505a\u51c6\u5907\u3002 \u64cd\u4f5c\u5bf9\u8c61</li> <li>\u62bd\u6837 \uff1a\u79bb\u6563\u603b\u4f53\uff08\u6709\u9650\u96c6\u5408\uff09\u3002</li> <li>\u91c7\u6837 \uff1a\u8fde\u7eed\u4fe1\u53f7\uff08\u65f6\u95f4\u57df\u6216\u7a7a\u95f4\u57df\u51fd\u6570\uff09\u3002 \u7406\u8bba\u4f9d\u636e</li> </ul> \u7279\u6027 \u62bd\u6837 \u91c7\u6837 \u57fa\u7840\u7406\u8bba \u5927\u6570\u5b9a\u5f8b\u3001\u4e2d\u5fc3\u6781\u9650\u5b9a\u7406 \u5948\u594e\u65af\u7279\u91c7\u6837\u5b9a\u7406\u3001\u63d2\u503c\u7406\u8bba \u6837\u672c\u4ee3\u8868\u6027 \u968f\u673a\u6027\u548c\u8986\u76d6\u6027\u662f\u5173\u952e \u91c7\u6837\u9891\u7387\u51b3\u5b9a\u662f\u5426\u80fd\u591f\u8fd8\u539f\u4fe1\u53f7 \u6570\u5b66\u516c\u5f0f \u7279\u6027 \u62bd\u6837\u516c\u5f0f --- --- --- \u5747\u503c\u4f30\u8ba1 \\(\\bar{x}=\\frac{1}{n}\\sum_{i=1}^n x_i\\) \\(f[n]=f(tn),t_n = nT\\) \u8bef\u5dee\u8303\u56f4 \u6807\u51c6\u8bef\u5dee\uff1a\\(text{SE} = \\frac{\\sigma}{\\sqrt{n}}\\)\u200b \u91c7\u6837\u8bef\u5dee\uff1a\u7531\u6df7\u53e0\u9891\u7387\u5f15\u8d77"},{"location":"book/chapter1_Introduction/1.4statistics/#2-2-lln","title":"2. 2. \u5927\u6570\u5b9a\u5f8b (LLN)","text":"<p>\u5728\u5927\u6570\u5b9a\u5f8b\u4e2d\uff0c\u6837\u672c\u5e73\u5747\u503c \u7684\u5b9a\u4e49\u4e3a\uff1a$ \\bar{X}n = \\frac{1}{n} \\sum^n X_i$, \u5176\u4e2d \\(X_1, X_2, \\dots, X_n\\) \u662f\u72ec\u7acb\u540c\u5206\u5e03\u7684\u968f\u673a\u53d8\u91cf\uff0c\u5177\u6709\u671f\u671b\u503c \\(\\mu = \\mathbb{E}[X_i]\\) \u548c\u6709\u9650\u65b9\u5dee \\(\\sigma^2 = \\mathrm{Var}(X_i)\\)\u3002</p> <p>\u5927\u6570\u5b9a\u5f8b\u7684\u7ed3\u8bba\uff1a</p> \\[  \\bar{X}_n \\xrightarrow{\\text{a.s.}} \\mu, \\quad \\text{\u6216\u8005} \\quad \\mathbb{P}(|\\bar{X}_n - \\mu| &gt; \\epsilon) \\to 0 \\; (\\forall \\epsilon &gt; 0, \\; n \\to \\infty). \\] <p>\u5927\u6570\u5b9a\u5f8b\u7684\u5173\u952e\u70b9\uff1a</p> <ul> <li>\u5b83\u7814\u7a76\u7684\u662f \\(\\bar{X}_n\\) \u7684\u957f\u671f\u884c\u4e3a\uff08\u968f\u7740 \\(n \\to \\infty\\)\uff09\u3002</li> <li>\u5b83\u4e0d\u6d89\u53ca\u6837\u672c\u5e73\u5747\u503c\u7684\u6982\u7387\u5206\u5e03\u6216\u6ce2\u52a8\u6027\uff0c\u53ea\u5f3a\u8c03\\(\\bar{X}_n\\)\u4f1a\u9010\u6e10\u63a5\u8fd1 \\(\\mu\\)\u3002</li> </ul>"},{"location":"book/chapter1_Introduction/1.4statistics/#3-3-clt","title":"3. 3 \u4e2d\u592e\u6781\u9650\u5b9a\u7406 (CLT)","text":"<p>\u5728\u4e2d\u592e\u6781\u9650\u5b9a\u7406\u4e2d\uff0c\u8003\u8651\u7684\u4e5f\u662f\u6837\u672c\u5e73\u5747\u503c \uff1a\\(\\bar{X}_n = \\frac{1}{n} \\sum_{i=1}^n X_i\\).</p> <p>\u4f46\u8fd9\u91cc\u8fdb\u4e00\u6b65\u7814\u7a76\u4e86\\(\\bar{X}_n\\) \u7684\u6ce2\u52a8\u6027\u6216\u6982\u7387\u5206\u5e03\u7684\u884c\u4e3a\u3002</p> <p>\u6807\u51c6\u5316\u5f62\u5f0f\uff1a</p> <p>\u6211\u4eec\u6784\u9020\u4e00\u4e2a\u6807\u51c6\u5316\u7684\u968f\u673a\u53d8\u91cf \\(Z_n\\)\uff0c\u7528\u6765\u8861\u91cf \\(\\bar{X}_n\\) \u504f\u79bb\u671f\u671b\u503c\u7684\u7a0b\u5ea6\uff1a</p> \\[Z_n = \\frac{\\sqrt{n}(\\bar{X}_n - \\mu)}{\\sigma}.\\] <p>CLT \u7684\u7ed3\u8bba\uff1a \u5f53 \\(n \\to \\infty\\)\uff0c\u6807\u51c6\u5316\u7684\u53d8\u91cf \\(Z_n\\) \u7684\u5206\u5e03\u6536\u655b\u4e8e\u6807\u51c6\u6b63\u6001\u5206\u5e03\uff1a\\(Z_n \\xrightarrow{d} N(0, 1)\\)\u3002</p> <p>\u8fd9\u8bf4\u660e\uff1a</p> <ul> <li> <p>\u6837\u672c\u5e73\u5747\u503c \u5728 \\(n\\) \u8db3\u591f\u5927\u65f6\u7684\u5206\u5e03\u4f1a\u8d8b\u4e8e\u6b63\u6001\u5206\u5e03\uff0c\u4e14\u4e2d\u5fc3\u662f \\(\\mu\\)\uff0c\u6807\u51c6\u5dee\u662f \\(\\frac{\\sigma}{\\sqrt{n}}\\)\u3002</p> </li> <li> <p>\u6837\u672c\u5e73\u5747\u503c \\(\\bar{X}_n\\) \u7684\u5206\u5e03\u8fd1\u4f3c\u4e3a\uff1a</p> </li> </ul> \\[  \\bar{X}_n \\sim N\\left(\\mu, \\frac{\\sigma^2}{n}\\right). \\]"},{"location":"book/chapter1_Introduction/1.4statistics/#4-4","title":"4. 4. \u4e2d\u5fc3\u6781\u9650\u5b9a\u7406\u548c\u5927\u6570\u5b9a\u5f8b\u4e24\u4e2a\u5e73\u5747\u503c\u7684\u6838\u5fc3\u5dee\u5f02","text":"<p>\u5dee\u5f02\u7684\u6838\u5fc3\uff1a</p> <ul> <li>LLN \u7684\u5e73\u5747\u503c \uff1a\u5173\u6ce8 \\(\\bar{X}_n\\) \u662f\u5426\u5728 \\(n \\to \\infty\\) \u65f6\u6536\u655b\u5230\u4e00\u4e2a\u56fa\u5b9a\u503c \\(\\mu\\)\u3002</li> <li>CLT \u7684\u5e73\u5747\u503c \uff1a\u5173\u6ce8 \\(\\bar{X}_n\\) \u5728\u6709\u9650 $n \u65f6\u7684\u6982\u7387\u5206\u5e03\u884c\u4e3a\uff08\u6ce2\u52a8\u6027\uff09\u3002</li> </ul> <p>\u7528\u6570\u5b66\u516c\u5f0f\u8868\u793a\uff1a</p> <ol> <li>LLN  \u63cf\u8ff0\uff1a</li> </ol> \\[  \\bar{X}_n \\xrightarrow{\\text{a.s.}} \\mu \\quad \\text{\uff08\u6536\u655b\u5230\u671f\u671b\u503c \\(\\mu\\)\uff09}. \\] <ol> <li>CLT  \u63cf\u8ff0\uff1a</li> </ol> \\[  \\sqrt{n}(\\bar{X}_n - \\mu) \\xrightarrow{d} N(0, \\sigma^2) \\quad \\text{\uff08\u63cf\u8ff0\u6807\u51c6\u5316\u504f\u5dee\u7684\u5206\u5e03\u884c\u4e3a\uff09}. \\] <p>\u516c\u5f0f\u5dee\u5f02\u603b\u7ed3\uff1a</p> <ul> <li>\u5728 LLN \u4e2d\uff0c\u5f3a\u8c03\u7684\u662f\uff1a</li> </ul> \\[  \\bar{X}_n \\approx \\mu \\quad (\\text{\u5f53 } n \\to \\infty). \\] <p>\u5373\uff0c\u968f\u7740 \\(n\\) \u589e\u52a0\uff0c\u6837\u672c\u5e73\u5747\u503c\\(\\bar{X}_n\\) \u8d8a\u6765\u8d8a\u63a5\u8fd1\u671f\u671b\u503c \\(\\mu\\)\u3002</p> <ul> <li>\u5728 CLT \u4e2d\uff0c\u5f3a\u8c03\u7684\u662f\uff1a</li> </ul> \\[  \\bar{X}_n \\sim N\\left(\\mu, \\frac{\\sigma^2}{n}\\right), \\] <p>\u5373\uff0c\u6837\u672c\u5e73\u5747\u503c\u5728\u6709\u9650 \\(n\\) \u65f6\u670d\u4ece\u6b63\u6001\u5206\u5e03\uff0c\u65b9\u5dee \\(\\sigma^2 / n\\) \u4f1a\u968f\u7740 \\(n\\) \u589e\u5927\u9010\u6e10\u51cf\u5c0f\uff0c\u4f46\u5b58\u5728\u6ce2\u52a8\u6027\u3002</p> <p>\u76f4\u89c2\u89e3\u91ca\u4e24\u8005\u5dee\u5f02\uff1a</p> <ul> <li>LLN \uff1a\u544a\u8bc9\u6211\u4eec\uff0c\u5f53 \\(n\\) \u8d8a\u6765\u8d8a\u5927\u65f6\uff0c\\(\\bar{X}_n\\) \u6700\u7ec8\u4f1a\u65e0\u9650\u63a5\u8fd1\u4e8e\u671f\u671b\u503c \\(\\mu\\)\uff08\u503c\u8d8a\u6765\u8d8a\u7a33\u5b9a\uff09\u3002</li> <li>CLT \uff1a\u544a\u8bc9\u6211\u4eec\uff0c\u5bf9\u4e8e\u6709\u9650\u7684 \\(n\\)\uff0c\\(\\bar{X}_n\\) \u4ecd\u7136\u6709\u6ce2\u52a8\uff0c\u5e76\u4e14\u8fd9\u79cd\u6ce2\u52a8\u9075\u5faa\u6b63\u6001\u5206\u5e03\uff0c\u4e14\u6ce2\u52a8\u8303\u56f4\u968f \\(n\\) \u589e\u5927\u800c\u51cf\u5c0f\uff08\\(\\sim \\frac{1}{\\sqrt{n}}\\)\uff09\u3002 \u4f8b\u5b50</li> </ul> <p>\u5047\u5982\u4f60\u6d4b\u91cf\u67d0\u673a\u5668\u96f6\u4ef6\u7684\u957f\u5ea6\uff0c\u5355\u4e2a\u96f6\u4ef6\u7684\u957f\u5ea6\u662f\u968f\u673a\u53d8\u91cf \\(X\\):</p> <ul> <li>\u5927\u6570\u5b9a\u5f8b \uff1a\u5982\u679c\u4f60\u6d4b\u91cf \\(n\\) \u4e2a\u96f6\u4ef6\uff0c\u8ba1\u7b97\u5b83\u4eec\u7684\u5e73\u5747\u957f\u5ea6 \\(\\bar{X}_n\\)\uff0c\u5f53 \\(n\\) \u8db3\u591f\u5927\u65f6\uff0c\u8fd9\u4e2a\u5e73\u5747\u503c\u4f1a\u65e0\u9650\u63a5\u8fd1\u4e8e\u96f6\u4ef6\u7684\u771f\u5b9e\u5e73\u5747\u957f\u5ea6\uff08\u671f\u671b\u503c \\(\\mu\\)\uff09\u3002</li> <li>\u4e2d\u592e\u6781\u9650\u5b9a\u7406 \uff1a\u5982\u679c \\(n\\) \u4e0d\u662f\u65e0\u9650\u5927\uff08\u6bd4\u5982 \\(n = 100\\))),\u90a3\u4e48\u5e73\u5747\u957f\u5ea6 \\(\\bar{X}_n\\) \u4f1a\u5728\u67d0\u4e2a\u8303\u56f4\u5185\u6ce2\u52a8\uff0c\u4e14\u8fd9\u79cd\u6ce2\u52a8\u7684\u6982\u7387\u5206\u5e03\u662f\u6b63\u6001\u5206\u5e03\u3002</li> </ul> <p>\u603b\u7ed3\uff1aLLN \u548c CLT \u7684\u5e73\u5747\u503c\u5dee\u5f02</p> <ol> <li> <p>LLN  \u7814\u7a76\u7684\u662f \\(\\bar{X}_n\\) \u662f\u5426\u7a33\u5b9a\u5e76\u6700\u7ec8\u6536\u655b\u5230 \\(\\mu\\)\uff0c\u5f3a\u8c03\u957f\u671f\u6536\u655b\u6027\u3002</p> </li> <li> <p>CLT  \u7814\u7a76\u7684\u662f \\(\\bar{X}_n\\) \u7684\u5206\u5e03\u5982\u4f55\u6f14\u53d8\u4e3a\u6b63\u6001\u5206\u5e03\uff0c\u5f3a\u8c03\u5206\u5e03\u5f62\u72b6\u548c\u6ce2\u52a8\u6027\u3002</p> </li> </ol> <p>\u7528\u66f4\u76f4\u89c2\u7684\u6bd4\u55bb\uff1a</p> <ul> <li> <p>LLN  \u5c31\u50cf\u4f60\u6d4b\u91cf\u5f88\u591a\u6b21\uff0c\u9010\u6e10\u903c\u8fd1\u201c\u771f\u5b9e\u503c\u201d\u3002</p> </li> <li> <p>CLT  \u544a\u8bc9\u4f60\u5728\u6709\u9650\u6b21\u6d4b\u91cf\u65f6\uff0c\u8fd9\u4e2a\u201c\u903c\u8fd1\u503c\u201d\u6709\u591a\u5927\u7684\u6ce2\u52a8\u8303\u56f4\uff0c\u4ee5\u53ca\u6ce2\u52a8\u7684\u6982\u7387\u5206\u5e03\u662f\u4ec0\u4e48\u6837\u7684\u3002</p> </li> </ul>"},{"location":"book/chapter1_Introduction/1.4statistics/#5-5-change-of-variable","title":"5. 5. change of variable","text":"<p>\u968f\u673a\u53d8\u91cf\u5206\u5e03\u7684 Change of Variable \uff08\u53d8\u91cf\u53d8\u6362\uff09\u662f\u6982\u7387\u8bba\u4e2d\u4e00\u4e2a\u91cd\u8981\u7684\u516c\u5f0f\uff0c\u7528\u4e8e\u63cf\u8ff0\u5f53\u968f\u673a\u53d8\u91cf\u901a\u8fc7\u67d0\u79cd\u51fd\u6570\u8fdb\u884c\u53d8\u6362\u65f6\uff0c\u5176\u6982\u7387\u5bc6\u5ea6\u5982\u4f55\u53d8\u5316\u3002</p> <p>\u516c\u5f0f\u63a8\u5bfc \u5047\u8bbe\u6211\u4eec\u6709\u4e00\u4e2a\u968f\u673a\u53d8\u91cf \\(z\\)\uff0c\u5176\u6982\u7387\u5bc6\u5ea6\u4e3a \\(p_Z(z)\\)\uff0c\u5e76\u5b9a\u4e49\u4e86\u4e00\u4e2a\u53ef\u9006\u53d8\u6362 \\(z = f(x)\\)\uff0c\u5176\u9006\u53d8\u6362\u4e3a \\(x = f^{-1}(z)\\)\u3002\u76ee\u6807\u662f\u6c42\u53d8\u6362\u540e\u968f\u673a\u53d8\u91cf \\(x\\) \u7684\u6982\u7387\u5bc6\u5ea6 \\(p_X(x)\\)\u3002</p> <p>Change of Variable \u5b9a\u7406 \u5f53 \\(z = f(x)\\) \u4e14\u53d8\u6362 \\(f(x)\\) \u53ef\u9006\u65f6\uff0c\u53d8\u6362\u540e\u7684\u6982\u7387\u5bc6\u5ea6 \\(p_X(x)\\) \u53ef\u4ee5\u901a\u8fc7\u4ee5\u4e0b\u516c\u5f0f\u8ba1\u7b97\uff1a</p> \\[  p_X(x) = p_Z(f(x)) \\cdot \\left| \\det \\left( \\frac{\\partial f(x)}{\\partial x} \\right) \\right| \\] <ul> <li> <p>\\(p_Z(f(x))\\)\uff1a\u662f\u539f\u59cb\u53d8\u91cf \\(z\\) \u7684\u6982\u7387\u5bc6\u5ea6\u51fd\u6570\u503c\u3002</p> </li> <li> <p>\\(\\frac{\\partial f(x)}{\\partial x}\\)\uff1a\u662f\u53d8\u6362 \\(f(x)\\) \u7684\u96c5\u53ef\u6bd4\u77e9\u9635\uff08Jacobian Matrix\uff09\u3002</p> </li> <li> <p>\\(\\det \\left( \\frac{\\partial f(x)}{\\partial x} \\right)\\)\uff1a\u662f\u96c5\u53ef\u6bd4\u77e9\u9635\u7684\u884c\u5217\u5f0f\uff0c\u8868\u793a\u53d8\u6362\u5bf9\u6982\u7387\u5bc6\u5ea6\u7684\u7f29\u653e\u7a0b\u5ea6\u3002</p> </li> <li> <p>\\(\\left| \\cdot \\right|\\)\uff1a\u662f\u884c\u5217\u5f0f\u7684\u7edd\u5bf9\u503c\uff0c\u56e0\u4e3a\u6982\u7387\u5bc6\u5ea6\u9700\u8981\u975e\u8d1f\u3002</p> </li> </ul> <p>\u76f4\u89c2\u7406\u89e3</p> <ol> <li> <p>\u53d8\u6362\u5e26\u6765\u7684\u5bc6\u5ea6\u53d8\u5316 \uff1a \u5982\u679c\u53d8\u6362 \\(f(x)\\) \u538b\u7f29\u4e86\u67d0\u4e00\u533a\u57df\u7684\u4f53\u79ef\uff08\u5373\u884c\u5217\u5f0f\u5c0f\u4e8e 1\uff09\uff0c\u5219\u8be5\u533a\u57df\u7684\u6982\u7387\u5bc6\u5ea6\u4f1a\u589e\u52a0\uff1b\u53cd\u4e4b\uff0c\u5982\u679c\u4f53\u79ef\u6269\u5927\uff0c\u5219\u6982\u7387\u5bc6\u5ea6\u4f1a\u51cf\u5c0f\u3002</p> </li> <li> <p>\u6982\u7387\u4fdd\u6301\u4e0d\u53d8 \uff1a \u968f\u673a\u53d8\u91cf\u7684\u603b\u6982\u7387\u59cb\u7ec8\u4e3a 1\uff0c\u56e0\u6b64\u53d8\u6362\u53ea\u6539\u53d8\u5bc6\u5ea6\u7684\u5206\u5e03\u5f62\u5f0f\uff0c\u800c\u4e0d\u6539\u53d8\u603b\u4f53\u79ef\u3002</p> </li> </ol> <p>\u4e00\u7ef4\u60c5\u51b5 \u5728\u4e00\u7ef4\u60c5\u51b5\u4e0b\uff08\u5373 \\(z\\) \u548c \\(x\\) \u662f\u6807\u91cf\uff09\uff0c\u96c5\u53ef\u6bd4\u77e9\u9635 \\(\\frac{\\partial f(x)}{\\partial x}\\) \u9000\u5316\u4e3a\u5bfc\u6570 \\(f'(x)\\)\uff0c\u516c\u5f0f\u7b80\u5316\u4e3a\uff1a$  p_X(x) = p_Z(f(x)) \\cdot \\left| f'(x) \\right| $</p> <p>\u4f8b\u5982\uff1a</p> <ul> <li>\u5982\u679c \\(z \\sim \\mathcal{N}(0, 1)\\) \u4e14 \\(z = f(x) = 2x + 3\\)\uff0c\u5219\uff1a $  p_X(x) = \\mathcal{N}(f(x) \\mid 0, 1) \\cdot \\left| f'(x) \\right| = \\mathcal{N}(2x + 3 \\mid 0, 1) \\cdot 2 $</li> </ul> <p>\u591a\u7ef4\u60c5\u51b5 \u5728\u591a\u7ef4\u60c5\u51b5\u4e0b\uff08\u5373 \\(z\\) \u548c \\(x\\) \u662f\u5411\u91cf\uff09\uff0c\u9700\u8981\u4f7f\u7528\u96c5\u53ef\u6bd4\u77e9\u9635\u3002\u96c5\u53ef\u6bd4\u77e9\u9635\u5b9a\u4e49\u4e3a\uff1a$  J_f(x) = \\frac{\\partial f(x)}{\\partial x} = \\begin{bmatrix} \\frac{\\partial f_1}{\\partial x_1} &amp; \\cdots &amp; \\frac{\\partial f_1}{\\partial x_n} \\ \\vdots &amp; \\ddots &amp; \\vdots \\ \\frac{\\partial f_m}{\\partial x_1} &amp; \\cdots &amp; \\frac{\\partial f_m}{\\partial x_n} \\end{bmatrix} $</p> <p>\u591a\u7ef4\u60c5\u51b5\u4e0b\uff0c\u516c\u5f0f\u4e3a\uff1a\\(p_X(x) = p_Z(f(x)) \\cdot \\left| \\det J_f(x) \\right|\\)</p>"},{"location":"book/chapter1_Introduction/1.4statistics/#6-6","title":"6. 6. \u968f\u673a\u53d8\u91cf\u548c\u5206\u5e03","text":"<p>\u8868\u793a\u4e00\u4e2a\u968f\u673a\u53d8\u91cf\u7684\u5206\u5e03\u901a\u5e38\u4f7f\u7528\u4ee5\u4e0b\u51e0\u79cd\u65b9\u5f0f\uff1a</p>"},{"location":"book/chapter1_Introduction/1.4statistics/#61-60-random-variable","title":"6.1 6.0 \u968f\u673a\u53d8\u91cf (Random Variable)","text":"<p>Random Variable</p> <p>A random variable is defined rigorously as a measurable function between two measurable spaces. More precisely, let</p> <ul> <li>\\((\\Omega, \\mathcal{F}, P)\\) be a probability space, where:</li> <li>\\(\\Omega\\) is the sample space,</li> <li>\\(\\mathcal{F}\\) is a \\(\\sigma\\)-algebra on \\(\\Omega\\) (a collection of events), and</li> <li> <p>\\(P\\) is a probability measure defined on \\(\\mathcal{F}\\).</p> </li> <li> <p>\\((S, \\mathcal{S})\\) be a measurable space, where typically \\(S = \\mathbb{R}\\) (or \\(\\mathbb{R}^d\\)) and \\(\\mathcal{S}\\) is the Borel \\(\\sigma\\)-algebra on \\(S\\).</p> </li> </ul> <p>Then a function $$ X: \\Omega \\to S $$ is called a random variable if it is measurable; that is, for every set \\(B \\in \\mathcal{S}\\), the preimage $$ X^{-1}(B) = {\\omega \\in \\Omega : X(\\omega) \\in B} $$ belongs to \\(\\mathcal{F}\\).</p> <p>Explanation</p> <p>In the simplest terms, when working in Euclidean space, a random variable is a function that maps each outcome of a random experiment (an element from the sample space) to a point in Euclidean space (typically \\(\\mathbb{R}\\) or \\(\\mathbb{R}^d\\)).</p> <p>More concretely, let \\(\\Omega\\) be your sample space (representing all possible outcomes) and consider the Euclidean space \\(\\mathbb{R}^d\\). Then a random variable \\(X\\) is defined as a function</p> \\[ X: \\Omega \\to \\mathbb{R}^d. \\] <p>This means that for every outcome \\(\\omega \\in \\Omega\\), the random variable assigns a specific point \\(X(\\omega) \\in \\mathbb{R}^d\\).</p> <p>For the function \\(X\\) to be meaningful in a probabilistic context, it must be measurable. In simple terms, this measurability condition ensures that we can properly assign probabilities to sets of values in \\(\\mathbb{R}^d\\) (such as intervals or more general Borel sets). It guarantees that the events defined by the values of \\(X\\) are well-behaved with respect to the probability measure on \\(\\Omega\\).</p> <p>Thus, in Euclidean space, a random variable is essentially a tool that transforms abstract outcomes into concrete numerical or vector quantities that we can analyze using familiar concepts from calculus and linear algebra.</p>"},{"location":"book/chapter1_Introduction/1.4statistics/#62-61-pdf-probability-density-function","title":"6.2 6.1 \u6982\u7387\u5bc6\u5ea6\u51fd\u6570(PDF, Probability Density Function)","text":"<ul> <li> <p>\u5982\u679c\u968f\u673a\u53d8\u91cf\u662f\u8fde\u7eed\u578b\u968f\u673a\u53d8\u91cf(\u5982\u6b63\u6001\u5206\u5e03),\u5176\u5206\u5e03\u53ef\u4ee5\u7528\u6982\u7387\u5bc6\u5ea6\u51fd\u6570 \\(f_X(x)\\) \u8868\u793a\u3002</p> </li> <li> <p>\u4f8b\u5982\uff0c\u5bf9\u4e8e\u6b63\u6001\u5206\u5e03:</p> </li> </ul> \\[  X \\sim \\mathcal{N}(\\mu, \\sigma^2) \\] <p>\u6216</p> \\[  f_X(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}} \\] <p>\u8868\u793a \\(X\\) \u670d\u4ece\u5747\u503c\u4e3a \\(\\mu\\)\u3001\u65b9\u5dee\u4e3a \\(\\sigma^2\\) \u7684\u6b63\u6001\u5206\u5e03\u3002</p>"},{"location":"book/chapter1_Introduction/1.4statistics/#63-62-pmf-probability-mass-function","title":"6.3 6.2. \u6982\u7387\u8d28\u91cf\u51fd\u6570(PMF, Probability Mass Function)","text":"<ul> <li> <p>\u5982\u679c\u968f\u673a\u53d8\u91cf\u662f\u79bb\u6563\u578b\u968f\u673a\u53d8\u91cf\uff0c\u5176\u5206\u5e03\u7528\u6982\u7387\u8d28\u91cf\u51fd\u6570 \\(\\(P(X = x)\\)\\) \u8868\u793a\u3002</p> </li> <li> <p>\u4f8b\u5982\uff0c\u5bf9\u4e8e\u4e00\u4e2a\u79bb\u6563\u578b\u53d8\u91cf \\(X\\) \u7684\u4f2f\u52aa\u5229\u5206\u5e03\uff1a</p> </li> </ul> \\[  P(X = x) = p^x (1-p)^{1-x}, \\quad x \\in \\{0, 1\\} \\]"},{"location":"book/chapter1_Introduction/1.4statistics/#64-63-cdf-cumulative-distribution-function","title":"6.4 6.3. **\u7d2f\u79ef\u5206\u5e03\u51fd\u6570(CDF, Cumulative Distribution Function)","text":"<ul> <li>\u7d2f\u79ef\u5206\u5e03\u51fd\u6570\u8868\u793a\u968f\u673a\u53d8\u91cf\u5c0f\u4e8e\u7b49\u4e8e\u67d0\u4e2a\u503c\u7684\u6982\u7387\uff1a</li> </ul> \\[  F_X(x) = P(X \\leq x) \\] <ul> <li>\u5b83\u9002\u7528\u4e8e\u8fde\u7eed\u578b\u548c\u79bb\u6563\u578b\u968f\u673a\u53d8\u91cf\u3002</li> </ul>"},{"location":"book/chapter1_Introduction/1.4statistics/#65-64","title":"6.5 6.4. \u5206\u5e03\u7b26\u53f7\u8868\u793a","text":"<ul> <li>\u5728\u7b80\u5316\u573a\u666f\u4e2d\uff0c\u53ef\u4ee5\u76f4\u63a5\u7528\u7b26\u53f7 \\(\\sim\\) \u8868\u793a\u968f\u673a\u53d8\u91cf\u7684\u5206\u5e03\u7c7b\u578b\u3002\u4f8b\u5982\uff1a</li> <li>\\(X \\sim \\mathcal{N}(\\mu, \\sigma^2)\\)\uff1a\u6b63\u6001\u5206\u5e03\u3002</li> <li>\\(X \\sim \\text{Bernoulli}(p)\\)\uff1a\u4f2f\u52aa\u5229\u5206\u5e03\u3002</li> <li>\\(X \\sim \\text{Uniform}(a, b)\\)\uff1a\u5747\u5300\u5206\u5e03\u3002</li> </ul> <p>\u6216\u8005\u66f4\u8fdb\u4e00\u6b65, \u53ef\u4ee5\u8868\u793a\u4e3a\uff1a\\(\\mathcal{N}(\\mathbf{X}; \\mu, \\Sigma)\\), \\(\\mathcal{N}\\) \u662f \"Normal\"\uff08\u6b63\u6001\u5206\u5e03\uff09\u7684\u9996\u5b57\u6bcd\uff0c\u7528\u4e8e\u8868\u660e\u5206\u5e03\u7684\u7c7b\u578b\u3002 \u8fd9\u662f\u4e00\u79cd\u8bb0\u53f7\u60ef\u4f8b\uff0c\u7528\u6765\u7b80\u6d01\u5730\u8868\u793a\u591a\u5143\u6b63\u6001\u5206\u5e03:</p> <ul> <li> <p>\u7b2c\u4e00\u90e8\u5206 \\(\\mathbf{X}\\) \u662f\u968f\u673a\u53d8\u91cf\u3002</p> </li> <li> <p>\u7b2c\u4e8c\u90e8\u5206 \\(0\\) \u548c \\(\\mathbf{I}\\) \u5206\u522b\u8868\u793a\u5747\u503c\u5411\u91cf\u548c\u534f\u65b9\u5dee\u77e9\u9635\u3002</p> </li> </ul>"},{"location":"book/chapter1_Introduction/1.4statistics/#66-65","title":"6.6 6.5. \u8054\u5408\u5206\u5e03\u4e0e\u6761\u4ef6\u5206\u5e03","text":"<ul> <li>\u5982\u679c\u6709\u591a\u4e2a\u968f\u673a\u53d8\u91cf\uff0c\u53ef\u4ee5\u7528\u8054\u5408\u5206\u5e03\u6216\u6761\u4ef6\u5206\u5e03\u6765\u63cf\u8ff0\u5b83\u4eec\u7684\u5173\u7cfb\uff1a</li> <li> <p>\u8054\u5408\u5206\u5e03\uff1a\\(P(X, Y)\\) \u6216 \\(f_{X, Y}(x, y)\\)\u3002</p> </li> <li> <p>\u6761\u4ef6\u5206\u5e03\uff1a\\(P(X | Y)\\) \u8868\u793a\u5728 \\(Y\\) \u5df2\u77e5\u7684\u6761\u4ef6\u4e0b\uff0c\\(X\\) \u7684\u5206\u5e03\u3002</p> </li> </ul>"},{"location":"book/chapter1_Introduction/1.4statistics/#7-7-markov","title":"7. 7. Markov\u94fe","text":"<p>Markov\u94fe \uff08Markov Chain\uff09\u662f\u4e00\u4e2a\u6ee1\u8db3 Markov\u6027 \uff08\u6216\u79f0\u4e3a\u201c\u65e0\u540e\u6548\u6027\u201d\uff09\u7684\u968f\u673a\u8fc7\u7a0b\u3002\u7b80\u5355\u6765\u8bf4\uff0cMarkov\u6027\u6307\u7684\u662f\uff1a\u672a\u6765\u7684\u72b6\u6001\u53ea\u4e0e\u5f53\u524d\u7684\u72b6\u6001\u6709\u5173\uff0c\u800c\u4e0e\u8fc7\u53bb\u7684\u72b6\u6001\u65e0\u5173\u3002</p>"},{"location":"book/chapter1_Introduction/1.4statistics/#71-71-markov","title":"7.1 7.1 Markov\u94fe\u7684\u6570\u5b66\u5b9a\u4e49","text":"<p>\u8bbe \\(X_t\\) \u8868\u793a\u4e00\u4e2a\u968f\u673a\u8fc7\u7a0b\u5728\u65f6\u95f4 \\(t\\) \u65f6\u7684\u72b6\u6001\u3002\u5982\u679c\u5bf9\u4e8e\u4efb\u610f\u7684 \\(t\\) \u548c\u72b6\u6001\u5e8f\u5217 \\(x_0, x_1, \\ldots, x_t\\)\uff0c\u6ee1\u8db3\u6761\u4ef6\uff1a</p> \\[  P(X_{t+1} = x_{t+1} \\mid X_t = x_t, X_{t-1} = x_{t-1}, \\ldots, X_0 = x_0) = P(X_{t+1} = x_{t+1} \\mid X_t = x_t) \\] <p>\u5373\uff0c\u7ed9\u5b9a\u5f53\u524d\u72b6\u6001 \\(X_t\\)\uff0c\u672a\u6765\u72b6\u6001 \\(X_{t+1}\\) \u7684\u5206\u5e03\u4e0e\u8fc7\u53bb\u7684\u72b6\u6001 \\(X_{t-1}, X_{t-2}, \\ldots\\) \u65e0\u5173\uff0c\u90a3\u4e48\u8fd9\u4e2a\u968f\u673a\u8fc7\u7a0b\u5c31\u662f\u4e00\u4e2aMarkov\u8fc7\u7a0b \u3002\u5982\u679c\u72b6\u6001\u7a7a\u95f4\u662f\u79bb\u6563\u7684\uff0c\u5e76\u4e14\u65f6\u95f4\u4e5f\u662f\u79bb\u6563\u7684\uff0c\u8fd9\u4e2a\u8fc7\u7a0b\u79f0\u4e3a\u79bb\u6563\u65f6\u95f4Markov\u94fe \uff08Discrete-Time Markov Chain, DTMC\uff09\u3002</p>"},{"location":"book/chapter1_Introduction/1.4statistics/#72-72-markov","title":"7.2 7.2 Markov\u94fe\u7684\u8981\u7d20","text":"<ol> <li> <p>\u72b6\u6001\u7a7a\u95f4  (\\(S\\)) Markov\u94fe\u53ef\u4ee5\u5904\u4e8e\u7684\u6240\u6709\u53ef\u80fd\u72b6\u6001\u7684\u96c6\u5408\u3002\u72b6\u6001\u7a7a\u95f4\u53ef\u4ee5\u662f\u6709\u9650\u7684\uff0c\u4e5f\u53ef\u4ee5\u662f\u65e0\u9650\u7684\u3002</p> </li> <li> <p>\u8f6c\u79fb\u6982\u7387 \u4ece\u5f53\u524d\u72b6\u6001\u8f6c\u79fb\u5230\u4e0b\u4e00\u4e2a\u72b6\u6001\u7684\u6982\u7387\u3002\u901a\u5e38\u7528 *\u8f6c\u79fb\u6982\u7387* \u4ece\u5f53\u524d\u72b6\u6001\u8f6c\u79fb\u5230\u4e0b\u4e00\u4e2a\u72b6\u6001\u7684\u6982\u7387\u3002\u901a\u5e38\u7528 \u8f6c\u79fb\u6982\u7387\u77e9\u9635 \\(P\\)  \u8868\u793a\uff1a$  P_{ij} = P(X_{t+1} = j \\mid X_t = i) $ \u8fd9\u91cc \\(P_{ij}\\) \u8868\u793a\u4ece\u72b6\u6001 \\(i\\) \u8f6c\u79fb\u5230\u72b6\u6001 \\(j\\) \u7684\u6982\u7387\u3002</p> </li> <li> <p>\u521d\u59cb\u72b6\u6001\u5206\u5e03 \u6307\u968f\u673a\u8fc7\u7a0b\u5728 \\(t = 0\\) \u65f6\u5404\u4e2a\u72b6\u6001\u7684\u6982\u7387\u5206\u5e03\uff0c\u8bb0\u4e3a \\(\\pi_0\\)\u3002</p> </li> </ol>"},{"location":"book/chapter1_Introduction/1.4statistics/#73-73-markov","title":"7.3 7.3 Markov\u94fe\u7684\u6027\u8d28","text":"<ol> <li> <p>\u65e0\u540e\u6548\u6027\uff08Markov\u6027\uff09 \uff1a\u672a\u6765\u7684\u72b6\u6001\u53ea\u4f9d\u8d56\u4e8e\u5f53\u524d\u72b6\u6001\uff0c\u4e0e\u8fc7\u53bb\u72b6\u6001\u65e0\u5173\u3002</p> </li> <li> <p>\u72b6\u6001\u8f6c\u79fb\u7684\u6982\u7387\u5206\u5e03\u56fa\u5b9a \uff1a\u8f6c\u79fb\u6982\u7387\u77e9\u9635 \\(P\\) \u901a\u5e38\u662f\u65f6\u95f4\u4e0d\u53d8\u7684\u3002</p> </li> <li> <p>n\u6b65\u8f6c\u79fb\u6982\u7387 \uff1a\u7ecf\u8fc7 \\(n\\) \u6b65\u4ece\u72b6\u6001 \\(i\\) \u8f6c\u79fb\u5230\u72b6\u6001 \\(j\\) \u7684\u6982\u7387\u53ef\u7528\u77e9\u9635\u5e42\u8868\u793a\uff1a</p> </li> </ol> \\[  P^{(n)}_{ij} = P(X_{t+n} = j \\mid X_t = i) \\]"},{"location":"book/chapter1_Introduction/1.4statistics/#74-73","title":"7.4 7.3 \u5178\u578b\u5e94\u7528","text":"<ul> <li> <p>\u81ea\u7136\u8bed\u8a00\u5904\u7406 \uff1a\u5982\u8bed\u8a00\u6a21\u578b\u4e2d\u7528Markov\u94fe\u9884\u6d4b\u4e0b\u4e00\u4e2a\u8bcd\u3002</p> </li> <li> <p>\u91d1\u878d\u5efa\u6a21 \uff1a\u80a1\u7968\u4ef7\u683c\u6216\u7ecf\u6d4e\u6307\u6807\u7684\u52a8\u6001\u5efa\u6a21\u3002</p> </li> <li> <p>\u7f51\u7edc\u5206\u6790 \uff1a\u5982PageRank\u7b97\u6cd5\uff0c\u7528Markov\u94fe\u5206\u6790\u7f51\u9875\u8df3\u8f6c\u3002</p> </li> <li> <p>\u751f\u7269\u4fe1\u606f\u5b66 \uff1a\u57fa\u56e0\u5e8f\u5217\u5206\u6790\u3002</p> </li> </ul>"},{"location":"book/chapter1_Introduction/1.4statistics/#75-74-markov","title":"7.5 7.4 \u4e0d\u540c\u5f62\u5f0f\u7684Markov\u94fe","text":"<p>Markov\u94fe\u4e2d\u7684\u201c\u72b6\u6001\u8f6c\u79fb\u7684\u6982\u7387\u5206\u5e03\u56fa\u5b9a \u201d\u5e76\u4e0d\u662f\u4e00\u4e2a\u5fc5\u987b\u6761\u4ef6\uff0c\u800c\u662f\u9488\u5bf9\u9f50\u6b21Markov\u94fe \uff08Homogeneous Markov Chain\uff09\u7684\u5047\u8bbe\u3002\u5b9e\u9645\u4e0a\uff0cMarkov\u94fe\u4e5f\u6709\u4ee5\u4e0b\u60c5\u51b5\uff1a</p> <p>1. \u9f50\u6b21Markov\u94fe\uff08Homogeneous Markov Chain\uff09 \u8fd9\u662f\u6700\u5e38\u89c1\u7684\u60c5\u51b5\uff0c\u8f6c\u79fb\u6982\u7387\u77e9\u9635 \\(P\\) \u4e0d\u968f\u65f6\u95f4\u53d8\u5316 \uff0c\u5373\u5bf9\u4e8e\u4efb\u610f\u65f6\u95f4 \\(t\\)\uff1a$  P(X_{t+1} = j \\mid X_t = i) = P_{ij}, \\quad \\text{(\u6052\u5b9a)}\u3002 $</p> <p>\u8fd9\u79cd\u5047\u8bbe\u7b80\u5316\u4e86\u5206\u6790\uff0c\u4e14\u5728\u5f88\u591a\u5b9e\u9645\u95ee\u9898\u4e2d\u662f\u5408\u7406\u7684\uff0c\u6bd4\u5982PageRank\u7b97\u6cd5\u3001\u5929\u6c14\u6a21\u578b\u7b49\u3002</p> <p>2. \u975e\u9f50\u6b21Markov\u94fe\uff08Non-Homogeneous Markov Chain\uff09 \u5728\u4e00\u4e9b\u573a\u666f\u4e0b\uff0c\u8f6c\u79fb\u6982\u7387\u53ef\u80fd\u968f\u65f6\u95f4\u53d8\u5316 \uff0c\u5373\uff1a$  P(X_{t+1} = j \\mid X_t = i) = P_{ij}^{(t)}\uff0c \\quad \\text{(\u968f \\( t \\) \u53d8\u5316)}\u3002 $ \u8fd9\u610f\u5473\u7740\u72b6\u6001\u4ece \\(i\\) \u8f6c\u79fb\u5230 \\(j\\) \u7684\u6982\u7387\u4f9d\u8d56\u4e8e\u65f6\u95f4 \\(t\\)\u3002\u8fd9\u79cd\u60c5\u51b5\u901a\u5e38\u7528\u4e8e\u4ee5\u4e0b\u60c5\u666f\uff1a</p> <ul> <li> <p>\u5b63\u8282\u6027\u53d8\u5316 \uff1a\u6bd4\u5982\u5929\u6c14\u6a21\u578b\uff0c\u590f\u5b63\u7684\u5929\u6c14\u8f6c\u79fb\u6982\u7387\u4e0d\u540c\u4e8e\u51ac\u5b63\u3002</p> </li> <li> <p>\u52a8\u6001\u7cfb\u7edf \uff1a\u6bd4\u5982\u91d1\u878d\u5e02\u573a\uff0c\u5176\u72b6\u6001\u8f6c\u79fb\u53ef\u80fd\u968f\u65f6\u95f4\u6216\u5916\u90e8\u4e8b\u4ef6\u8c03\u6574\u3002</p> </li> </ul> <p>3. \u5176\u4ed6\u6269\u5c55\u5f62\u5f0f \u9664\u4e86\u4ee5\u4e0a\u4e24\u79cd\uff0c\u8fd8\u53ef\u4ee5\u6709\u66f4\u590d\u6742\u7684Markov\u94fe\u5f62\u5f0f\uff1a</p> <ol> <li> <p>\u534aMarkov\u8fc7\u7a0b\uff08Semi-Markov Process\uff09 \uff1a\u5141\u8bb8\u5728\u6bcf\u4e2a\u72b6\u6001\u505c\u7559\u7684\u65f6\u95f4\u4e0d\u662f\u56fa\u5b9a\u7684\uff0c\u4e5f\u4e0d\u662f\u6307\u6570\u5206\u5e03\u3002</p> </li> <li> <p>\u9ad8\u9636Markov\u94fe\uff08Higher-Order Markov Chain\uff09 \uff1a\u672a\u6765\u72b6\u6001\u4f9d\u8d56\u4e8e\u591a\u4e2a\u5386\u53f2\u72b6\u6001\uff08\u4e0d\u4ec5\u662f\u4e0a\u4e00\u4e2a\u72b6\u6001\uff09\uff0c\u5982\uff1a</p> </li> </ol> \\[  P(X_{t+1} \\mid X_t, X_{t-1}, \\ldots, X_{t-k})\u3002 \\]"},{"location":"book/chapter1_Introduction/1.4statistics/#8-8-monte-carlo-estimate","title":"8. 8 Monte Carlo estimate","text":"<p>Monte Carlo estimate  \u662f\u4e00\u79cd\u5229\u7528\u968f\u673a\u62bd\u6837\u65b9\u6cd5\u6765\u8fd1\u4f3c\u8ba1\u7b97\u590d\u6742\u95ee\u9898\u7684\u6570\u503c\u89e3\u7684\u7edf\u8ba1\u6280\u672f\u3002\u5b83\u5e7f\u6cdb\u5e94\u7528\u4e8e\u6570\u5b66\u3001\u7269\u7406\u3001\u91d1\u878d\u3001\u5de5\u7a0b\u7b49\u9886\u57df\uff0c\u5c24\u5176\u662f\u90a3\u4e9b\u89e3\u6790\u89e3\u96be\u4ee5\u83b7\u5f97\u7684\u95ee\u9898\u3002</p>"},{"location":"book/chapter1_Introduction/1.4statistics/#81-81","title":"8.1 8.1 \u57fa\u672c\u539f\u7406","text":"<p>Monte Carlo \u65b9\u6cd5\u57fa\u4e8e\u4ee5\u4e0b\u6838\u5fc3\u601d\u60f3\uff1a</p> <ol> <li> <p>\u4f7f\u7528\u968f\u673a\u6570\u751f\u6210\u4e00\u7cfb\u5217\u6837\u672c\u3002</p> </li> <li> <p>\u6839\u636e\u8fd9\u4e9b\u6837\u672c\uff0c\u8ba1\u7b97\u4e00\u4e2a\u51fd\u6570\u6216\u7cfb\u7edf\u7684\u5e73\u5747\u503c\u3002</p> </li> <li> <p>\u4f7f\u7528\u5927\u6570\u5b9a\u5f8b\u548c\u4e2d\u5fc3\u6781\u9650\u5b9a\u7406\uff0c\u6765\u786e\u4fdd\u901a\u8fc7\u5927\u91cf\u968f\u673a\u6837\u672c\u7684\u5e73\u5747\u503c\u53ef\u4ee5\u903c\u8fd1\u771f\u5b9e\u503c\u3002</p> </li> </ol> <p>\u7b80\u5355\u6765\u8bf4\uff0cMonte Carlo \u65b9\u6cd5\u901a\u8fc7\u591a\u6b21\u6a21\u62df\u548c\u7edf\u8ba1\u5206\u6790\uff0c\u6765\u4f30\u8ba1\u67d0\u4e9b\u590d\u6742\u95ee\u9898\u7684\u89e3\u3002</p>"},{"location":"book/chapter1_Introduction/1.4statistics/#82-82-monte-carlo-estimate","title":"8.2 8.2 Monte Carlo estimate \u7684\u6b65\u9aa4","text":"<p>\u4ee5\u4f30\u8ba1\u79ef\u5206 \\(\\int_a^b f(x) dx\\) \u4e3a\u4f8b\uff1a</p> <ol> <li> <p>\u5728\u533a\u95f4 \\([a, b]\\) \u5185\u751f\u6210 \\(N\\) \u4e2a\u968f\u673a\u6837\u672c \\(x_1, x_2, \\ldots, x_N\\)\u3002</p> </li> <li> <p>\u8ba1\u7b97 \\(f(x)\\) \u7684\u503c\u5728\u8fd9\u4e9b\u6837\u672c\u70b9\u4e0a\u7684\u5e73\u5747\u503c\uff1a$ \\text{\u5e73\u5747\u503c} = \\frac{1}{N} \\sum_{i=1}^N f(x_i)$</p> </li> <li> <p>\u7528\u4ee5\u4e0b\u516c\u5f0f\u4f30\u8ba1\u79ef\u5206\u503c\uff1a\\(\\int_a^b f(x) dx \\approx (b-a) \\cdot \\text{\u5e73\u5747\u503c}\\)</p> </li> </ol> <p>\u5bf9\u4e8e\u591a\u7ef4\u79ef\u5206\u3001\u6982\u7387\u5206\u5e03\u8ba1\u7b97\u6216\u590d\u6742\u7269\u7406\u7cfb\u7edf\u6a21\u62df\uff0cMonte Carlo \u65b9\u6cd5\u53ef\u4ee5\u901a\u8fc7\u7c7b\u4f3c\u7684\u65b9\u5f0f\u8fdb\u884c\u6269\u5c55\u3002</p>"},{"location":"book/chapter1_Introduction/1.4statistics/#83-83-monte-carlo-estimate","title":"8.3 8.3 Monte Carlo estimate \u7684\u5178\u578b\u5e94\u7528","text":"<ol> <li> <p>\u8ba1\u7b97\u590d\u6742\u79ef\u5206:  \u7528\u4e8e\u89e3\u51b3\u4f20\u7edf\u6570\u503c\u79ef\u5206\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u7684\u9ad8\u7ef4\u79ef\u5206\u95ee\u9898\u3002</p> </li> <li> <p>\u6a21\u62df\u968f\u673a\u8fc7\u7a0b:  \u6a21\u62df\u80a1\u7968\u4ef7\u683c\u8def\u5f84\uff08\u5982 Black-Scholes \u6a21\u578b\uff09\u3001\u7c92\u5b50\u8fd0\u52a8\u3001\u961f\u5217\u6392\u961f\u7b49\u95ee\u9898\u3002</p> </li> <li> <p>\u6982\u7387\u4f30\u8ba1:  \u4f30\u8ba1\u4e8b\u4ef6\u53d1\u751f\u7684\u6982\u7387\uff0c\u4f8b\u5982\u5728\u7edf\u8ba1\u7269\u7406\u4e2d\u6a21\u62df\u7cfb\u7edf\u7684\u72b6\u6001\u5206\u5e03\u3002</p> </li> <li> <p>\u4f18\u5316\u95ee\u9898:  \u5728\u673a\u5668\u5b66\u4e60\u4e2d\uff0c\u7528 Monte Carlo \u65b9\u6cd5\u4f18\u5316\u53c2\u6570\u6216\u6a21\u578b\u6027\u80fd\u3002</p> </li> </ol>"},{"location":"book/chapter1_Introduction/1.4statistics/#84-84","title":"8.4 8.4 \u4f18\u70b9\u4e0e\u7f3a\u70b9","text":""},{"location":"book/chapter1_Introduction/1.4statistics/#841-841","title":"8.4.1 8.4.1 \u4f18\u70b9","text":"<ul> <li> <p>\u901a\u7528\u6027\u5f3a:  \u53ef\u4ee5\u5e94\u7528\u4e8e\u9ad8\u7ef4\u3001\u590d\u6742\u7684\u95ee\u9898\u3002</p> </li> <li> <p>\u6613\u4e8e\u5b9e\u73b0:  \u4e0d\u4f9d\u8d56\u95ee\u9898\u7684\u5177\u4f53\u5f62\u5f0f\uff0c\u53ea\u9700\u8981\u751f\u6210\u968f\u673a\u6837\u672c\u5e76\u8ba1\u7b97\u5e73\u5747\u503c\u3002</p> </li> <li> <p>\u6e10\u8fdb\u6536\u655b\uff1a  \u968f\u7740\u6837\u672c\u6570\u91cf\u589e\u52a0\uff0c\u4f30\u8ba1\u503c\u4f1a\u9010\u6e10\u6536\u655b\u5230\u771f\u5b9e\u503c\u3002</p> </li> </ul>"},{"location":"book/chapter1_Introduction/1.4statistics/#842-842","title":"8.4.2 8.4.2 \u7f3a\u70b9","text":"<ul> <li> <p>\u6548\u7387\u8f83\u4f4e\uff1a  \u6536\u655b\u901f\u5ea6\u8f83\u6162\uff0c\u901a\u5e38\u9700\u8981\u5927\u91cf\u6837\u672c\u6765\u8fbe\u5230\u9ad8\u7cbe\u5ea6\u3002</p> </li> <li> <p>\u4f9d\u8d56\u968f\u673a\u6570\u8d28\u91cf\uff1a  \u751f\u6210\u9ad8\u8d28\u91cf\u7684\u968f\u673a\u6837\u672c\u5bf9\u7ed3\u679c\u81f3\u5173\u91cd\u8981\u3002</p> </li> <li> <p>\u9ad8\u7ef4\u95ee\u9898\u7684\u6837\u672c\u6548\u7387\u4f4e\uff1a  \u9ad8\u7ef4\u95ee\u9898\u4e2d\u7684\u201c\u7ef4\u5ea6\u707e\u96be\u201d\u4f1a\u663e\u8457\u589e\u52a0\u6240\u9700\u6837\u672c\u6570\u91cf\u3002</p> </li> </ul>"},{"location":"book/chapter1_Introduction/1.4statistics/#85-85","title":"8.5 8.5 \u76f4\u89c2\u4f8b\u5b50","text":"<p>Monte Carlo estimate  \u662f\u4e00\u79cd\u5229\u7528\u968f\u673a\u62bd\u6837\u65b9\u6cd5\u6765\u8fd1\u4f3c\u8ba1\u7b97\u590d\u6742\u95ee\u9898\u7684\u6570\u503c\u89e3\u7684\u7edf\u8ba1\u6280\u672f\u3002\u5b83\u5e7f\u6cdb\u5e94\u7528\u4e8e\u6570\u5b66\u3001\u7269\u7406\u3001\u91d1\u878d\u3001\u5de5\u7a0b\u7b49\u9886\u57df\uff0c\u5c24\u5176\u662f\u90a3\u4e9b\u89e3\u6790\u89e3\u96be\u4ee5\u83b7\u5f97\u7684\u95ee\u9898\u3002</p>"},{"location":"book/chapter1_Introduction/1.4statistics/#9-9entropykl-divergenceelbo","title":"9. 9.Entropy,KL divergence,ELBO","text":""},{"location":"book/chapter1_Introduction/1.4statistics/#91-91-entropy","title":"9.1 9.1 \u71b5(Entropy)","text":"<p>\u71b5\u8861\u91cf\u5206\u5e03\u7684\u5e73\u5747\u4e0d\u786e\u5b9a\u6027\u3002 \u79ef\u5206\u5f62\u5f0f \u5bf9\u4e8e\u8fde\u7eed\u5206\u5e03 \\(p(x)\\)\uff0c\u71b5\u7684\u79ef\u5206\u5f62\u5f0f\u4e3a\uff1a</p> \\[  H(X) = -\\int p(x) \\log p(x) \\, dx \\] <p>\u671f\u671b\u5f62\u5f0f \u71b5\u4e5f\u53ef\u4ee5\u8868\u793a\u4e3a\u968f\u673a\u53d8\u91cf \\(X\\) \u7684\u4fe1\u606f\u91cf\u7684\u671f\u671b\uff1a</p> \\[  H(X) = -\\mathbb{E}_{X \\sim p(x)}[\\log p(X)] \\] <p>\u5176\u4e2d \\(\\mathbb{E}_{X \\sim p(x)}\\) \u8868\u793a\u5173\u4e8e\u5206\u5e03 \\(p(x)\\) \u7684\u671f\u671b\u3002</p>"},{"location":"book/chapter1_Introduction/1.4statistics/#92-92klkl-divergence","title":"9.2 9.2KL\u6563\u5ea6\uff08KL Divergence","text":"<p>KL\u6563\u5ea6\u8861\u91cf\u4e24\u4e2a\u5206\u5e03\u4e4b\u95f4\u7684\u5dee\u5f02\u3002 \u79ef\u5206\u5f62\u5f0f \u5bf9\u4e8e\u8fde\u7eed\u5206\u5e03 \\(p(x)\\) \u548c \\(q(x)\\)\uff0cKL\u6563\u5ea6\u7684\u79ef\u5206\u5f62\u5f0f\u4e3a\uff1a</p> \\[  D_{\\text{KL}}(P \\| Q) = \\int p(x) \\log \\frac{p(x)}{q(x)} \\, dx \\] <p>\u671f\u671b\u5f62\u5f0f KL\u6563\u5ea6\u53ef\u4ee5\u5199\u4e3a\u5173\u4e8e\u5206\u5e03 \\(p(x)\\) \u7684\u5bf9\u6570\u6bd4\u503c\u7684\u671f\u671b\uff1a</p> \\[  D_{\\text{KL}}(P \\| Q) = \\mathbb{E}_{X \\sim p(x)} \\left[ \\log \\frac{p(X)}{q(X)} \\right] \\]"},{"location":"book/chapter1_Introduction/1.4statistics/#93-93-evidence-lower-bound-elbo","title":"9.3 9.3. \u8bc1\u636e\u4e0b\u754c\uff08Evidence Lower Bound, ELBO)","text":"<p>ELBO \u662f\u5728\u53d8\u5206\u63a8\u65ad\u4e2d\u7528\u6765\u4f18\u5316\u540e\u9a8c\u5206\u5e03\u7684\u76ee\u6807\u51fd\u6570\u3002</p> <p>\u79ef\u5206\u5f62\u5f0f ELBO \u7684\u79ef\u5206\u5f62\u5f0f\u4e3a\uff1a</p> \\[  \\mathcal{L}(q) = \\int q(z) \\log p(\\mathcal{D} \\mid z) \\, dz - \\int q(z) \\log \\frac{q(z)}{p(z)} \\, dz \\] <p>\u671f\u671b\u5f62\u5f0f \u5c06\u79ef\u5206\u5f62\u5f0f\u6539\u5199\u4e3a\u5173\u4e8e \\(\\(q(z)\\)\\) \u7684\u671f\u671b\uff0c\u5f97\u5230\uff1a</p> \\[  \\mathcal{L}(q) = \\mathbb{E}_{z \\sim q(z)}[\\log p(\\mathcal{D} \\mid z)] - D_{\\text{KL}}(q(z) \\| p(z)) \\] <p>\u5206\u89e3\u4e3a\u5bf9\u6570\u4f3c\u7136 \u8fb9\u9645\u5bf9\u6570\u4f3c\u7136\u53ef\u4ee5\u5206\u89e3\u4e3a ELBO \u548c KL \u6563\u5ea6\uff1a</p> \\[  \\log p(\\mathcal{D}) = \\mathcal{L}(q) + D_{\\text{KL}}(q(z) \\| p(z \\mid \\mathcal{D})) \\] <p>\u5176\u4e2d\uff1a</p> \\[\\mathcal{L}(q) = \\mathbb{E}_{z \\sim q(z)}[\\log p(\\mathcal{D}, z) - \\log q(z)]\\] <p>\u603b\u7ed3</p> \u6982\u5ff5 \u79ef\u5206\u5f62\u5f0f \u671f\u671b\u5f62\u5f0f \u71b5 \\(H(X)\\) \\(-\\int p(x) \\log p(x)\\) \\(-\\mathbb{E}_{X \\sim p(x)}[\\log p(X)]\\) KL\u6563\u5ea6 \\({\\text{KL}}(P \\| Q)\\) \\(\\int p(x) \\log \\frac{p(x)}{q(x)} \\, dx\\) \\(\\mathbb{E}_{X \\sim p(x)} \\left[ \\log \\frac{p(X)}{q(X)} \\right]\\) ELBO \\(\\mathcal{L}(q)\\) \\(\\int q(z) \\log p(\\mathcal{D} \\mid z) \\, dz - \\int q(z) \\log \\frac{q(z)}{p(z)}\\) $\\mathbb{E}{z \\sim q(z)}[\\log p(\\mathcal{D} \\mid z)] - D(q(z) | p(z)) $} <p></p>"},{"location":"book/chapter1_Introduction/1.4statistics/#931-931-elbo","title":"9.3.1 9.3.1 ELBO","text":"<p>\u8bc1\u660e</p> \\[  \\mathcal{L}(x, \\theta, q) = \\log p_\\theta(x) - D_{\\text{KL}}(q_\\phi(z|x) \\| p_\\theta(z|x)).\\\\ =\\mathbb{E}_{z \\sim q_\\phi} [\\log p_\\theta(x, z)] + H(q_\\phi). \\] <p>\u63a8\u5bfc\u6b65\u9aa4</p> <ol> <li>KL \u6563\u5ea6\u5b9a\u4e49 \uff1a \u7531 KL \u6563\u5ea6\u7684\u5b9a\u4e49\uff1a</li> </ol> \\[  D_{\\text{KL}}(q_\\phi(z|x) \\| p_\\theta(z|x)) = \\mathbb{E}_{z \\sim q_\\phi} \\left[ \\log \\frac{q_\\phi(z|x)}{p_\\theta(z|x)} \\right]. \\] <p>\u5c06\u5176\u4ee3\u5165\u516c\u5f0f\uff1a</p> \\[  \\mathcal{L}(x, \\theta, q) = \\log p_\\theta(x) - \\mathbb{E}_{z \\sim q_\\phi} \\left[ \\log \\frac{q_\\phi(z|x)}{p_\\theta(z|x)} \\right]. \\] <ol> <li>\u8d1d\u53f6\u65af\u516c\u5f0f\u66ff\u6362 \\(p_\\theta(z|x)\\) :</li> </ol> <p>\u6839\u636e\u8d1d\u53f6\u65af\u516c\u5f0f\uff1a</p> \\[  p_\\theta(z|x) = \\frac{p_\\theta(x, z)}{p_\\theta(x)}. \\] <p>\u5c06\u5176\u4ee3\u5165\uff1a</p> \\[  \\mathcal{L}(x, \\theta, q) = \\log p_\\theta(x) - \\mathbb{E}_{z \\sim q_\\phi} \\left[ \\log \\frac{q_\\phi(z|x)}{p_\\theta(x, z) / p_\\theta(x)} \\right]. \\] <p>\u7b80\u5316\u5206\u6bcd\u4e2d\u7684\u5206\u6570\uff1a</p> \\[  \\mathcal{L}(x, \\theta, q) = \\log p_\\theta(x) - \\mathbb{E}_{z \\sim q_\\phi} \\left[ \\log \\left( q_\\phi(z|x) \\cdot \\frac{p_\\theta(x)}{p_\\theta(x, z)} \\right) \\right]. \\] <ol> <li>\u5206\u89e3\u5bf9\u6570\u9879 \uff1a \u5c55\u5f00\u5bf9\u6570\u9879\uff1a</li> </ol> \\[  \\mathcal{L}(x, \\theta, q) = \\log p_\\theta(x) - \\mathbb{E}_{z \\sim q_\\phi} \\left[ \\log q_\\phi(z|x) + \\log p_\\theta(x) - \\log p_\\theta(x, z) \\right]. \\] <p>\u5c06\u671f\u671b\u5c55\u5f00\uff1a</p> \\[  \\mathcal{L}(x, \\theta, q) = \\log p_\\theta(x) - \\mathbb{E}_{z \\sim q_\\phi} [\\log q_\\phi(z|x)] - \\mathbb{E}_{z \\sim q_\\phi} [\\log p_\\theta(x)] + \\mathbb{E}_{z \\sim q_\\phi} [\\log p_\\theta(x, z)]. \\] <p>\u6ce8\u610f\u5230 \\(\\log p_\\theta(x)\\) \u662f\u5e38\u6570\uff0c\u53ef\u4ee5\u63d0\u5230\u671f\u671b\u5916\u90e8\uff1a</p> \\[  \\mathcal{L}(x, \\theta, q) = \\mathbb{E}_{z \\sim q_\\phi} [\\log p_\\theta(x, z)] - \\mathbb{E}_{z \\sim q_\\phi} [\\log q_\\phi(z|x)]. \\] <ol> <li>\u71b5\u7684\u5b9a\u4e49\u66ff\u6362 \uff1a</li> </ol> <p>\u6839\u636e\u71b5\u7684\u5b9a\u4e49\uff1a</p> \\[  H(q_\\phi) = -\\mathbb{E}_{z \\sim q_\\phi} [\\log q_\\phi(z|x)]. \\] <p>\u5c06\u5176\u4ee3\u5165\uff1a</p> \\[  \\mathcal{L}(x, \\theta, q) = \\mathbb{E}_{z \\sim q_\\phi} [\\log p_\\theta(x, z)] + H(q_\\phi). \\]"},{"location":"book/chapter1_Introduction/1.4statistics/#10-reference","title":"10. Reference","text":"<p>[1] Book: Deep Learning, Ian Goodfellow, Yoshua Bengio, Aaron Courville</p>"},{"location":"book/chapter1_Introduction/tutorials/","title":"Tutorials on generative AI","text":""},{"location":"book/chapter1_Introduction/tutorials/#1-comprehensive-tutorials-on-generative-ai","title":"1. Comprehensive Tutorials on generative AI","text":"<ul> <li>Tutorial on Diffusion Models for Imaging and Vision Introduced the VAE, DDPM, Score Matching, SDE and Langevin and Fokker-Planck Equations</li> </ul>"},{"location":"book/chapter1_Introduction/tutorials/#2-energy-based-models","title":"2. energy based models","text":"<ul> <li>energy-based models with contrastive divergence explanation</li> </ul>"},{"location":"book/chapter2_generation_theory/generative_model_category/","title":"Generative Category","text":"<p>In this article, we will list the main categories of generative models from different perspectives.</p>"},{"location":"book/chapter2_generation_theory/generative_model_category/#1-main-categories","title":"1. Main Categories","text":"<ul> <li>Variational Autoencoder (VAE)</li> <li>Generative Adversarial Network (GAN)</li> <li>Discrete Diffusion Models</li> <li>Continuous Diffusion Models</li> <li>Energy/Score Based Generative Models</li> <li>Normalizing Flow (NF)</li> <li>Continuous Normalizing Flow (CNF)</li> <li>Flow Matching (FM)</li> <li>RL-Augmented Generative Models</li> <li>Optical Physics</li> </ul>"},{"location":"book/chapter2_generation_theory/generative_model_category/#_1","title":"Generative Model Category","text":"<p>\u8fde\u7eed\u5f52\u4e00\u5316\u6d41\uff08CNF\uff09\uff1a CNF \u7684\u8bad\u7ec3\u76ee\u6807\u662f\u6700\u5927\u5316\u6a21\u578b\u751f\u6210\u6570\u636e\u7684\u5bf9\u6570\u4f3c\u7136\uff0c\u5373\u901a\u8fc7\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\uff08MLE\uff09\u6765\u4f18\u5316\u6a21\u578b\u53c2\u6570\u3002\u5177\u4f53\u800c\u8a00\uff0cCNF \u901a\u8fc7\u5b9a\u4e49\u4e00\u4e2a\u65f6\u95f4\u76f8\u5173\u7684\u5411\u91cf\u573a\uff0c\u4f7f\u6570\u636e\u4ece\u521d\u59cb\u5206\u5e03\uff08\u5982\u9ad8\u65af\u5206\u5e03\uff09\u5e73\u6ed1\u5730\u53d8\u6362\u5230\u76ee\u6807\u5206\u5e03\uff08\u5982\u771f\u5b9e\u6570\u636e\u5206\u5e03\uff09\uff0c\u7136\u540e\u901a\u8fc7\u6570\u503c\u6c42\u89e3\u5e38\u5fae\u5206\u65b9\u7a0b\uff08ODE\uff09\u4ee5\u8bc4\u4f30\u6a21\u578b\u751f\u6210\u6570\u636e\u7684\u5bf9\u6570\u4f3c\u7136\u3002\u7136\u540e\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u8d1f\u5bf9\u6570\u4f3c\u7136\u635f\u5931\u51fd\u6570\uff0c\u4f18\u5316\u6a21\u578b\u53c2\u6570\uff0c\u4f7f\u751f\u6210\u7684\u6570\u636e\u5c3d\u53ef\u80fd\u63a5\u8fd1\u771f\u5b9e\u6570\u636e\u7684\u5206\u5e03\u3002 YMSHICI.COM</p> <p>\u6d41\u5339\u914d\uff08Flow Matching\uff0cFM\uff09\uff1a FM \u7684\u8bad\u7ec3\u76ee\u6807\u662f\u5b66\u4e60\u4e00\u4e2a\u65f6\u95f4\u76f8\u5173\u7684\u5411\u91cf\u573a\uff0c\u4f7f\u5176\u80fd\u591f\u5339\u914d\u4ece\u521d\u59cb\u5206\u5e03\u5230\u76ee\u6807\u5206\u5e03\u7684\u6982\u7387\u6d41\u7684\u52a8\u6001\u7279\u6027\u3002\u5177\u4f53\u800c\u8a00\uff0cFM \u901a\u8fc7\u5b9a\u4e49\u4e00\u4e2a\u53c2\u8003\u6982\u7387\u8def\u5f84\uff0c\u5e76\u4f18\u5316\u4e00\u4e2a\u5339\u914d\u635f\u5931\u51fd\u6570\uff0c\u8be5\u635f\u5931\u51fd\u6570\u8861\u91cf\u6a21\u578b\u9884\u6d4b\u7684\u5411\u91cf\u573a\u4e0e\u771f\u5b9e\u5411\u91cf\u573a\u4e4b\u95f4\u7684\u5dee\u5f02\u3002\u901a\u8fc7\u6700\u5c0f\u5316\u8be5\u635f\u5931\uff0c\u6a21\u578b\u5b66\u4e60\u5230\u4e00\u4e2a\u5411\u91cf\u573a\uff0c\u4f7f\u5f97\u4ece\u521d\u59cb\u5206\u5e03\u5230\u76ee\u6807\u5206\u5e03\u7684\u53d8\u6362\u8fc7\u7a0b\u4e2d\u7684\u901f\u5ea6\u573a\u6700\u5c0f\u5316\u4e0e\u53c2\u8003\u8def\u5f84\u7684\u5dee\u5f02\u3002 BILIBILI.COM \u4e3b\u8981\u533a\u522b\uff1a</p> <ul> <li> <p>\u635f\u5931\u51fd\u6570\uff1a CNF \u91c7\u7528\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\uff0c\u76f4\u63a5\u5bf9\u6570\u636e\u7684\u5bf9\u6570\u4f3c\u7136\u8fdb\u884c\u4f18\u5316\uff1b\u800c FM \u901a\u8fc7\u6700\u5c0f\u5316\u6a21\u578b\u5411\u91cf\u573a\u4e0e\u53c2\u8003\u8def\u5f84\u5411\u91cf\u573a\u4e4b\u95f4\u7684\u5dee\u5f02\u6765\u8bad\u7ec3\u6a21\u578b\u3002</p> </li> <li> <p>\u8bad\u7ec3\u8fc7\u7a0b\uff1a CNF \u9700\u8981\u6570\u503c\u6c42\u89e3 ODE\uff0c\u5e76\u8ba1\u7b97\u96c5\u53ef\u6bd4\u884c\u5217\u5f0f\u7684\u5bf9\u6570\u884c\u5217\u5f0f\uff0c\u8fd9\u53ef\u80fd\u5e26\u6765\u8f83\u9ad8\u7684\u8ba1\u7b97\u6210\u672c\uff1b\u800c FM \u901a\u8fc7\u5339\u914d\u901f\u5ea6\u573a\uff0c\u907f\u514d\u4e86\u5bf9 ODE \u7684\u6570\u503c\u6c42\u89e3\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86\u8bad\u7ec3\u6548\u7387\u3002</p> </li> </ul> <p>\u7efc\u4e0a\uff0c\u867d\u7136 CNF \u548c FM \u90fd\u65e8\u5728\u5c06\u521d\u59cb\u5206\u5e03\u8f6c\u6362\u4e3a\u76ee\u6807\u5206\u5e03\uff0c\u4f46\u5b83\u4eec\u5728\u8bad\u7ec3\u76ee\u6807\u548c\u65b9\u6cd5\u4e0a\u6709\u6240\u4e0d\u540c\u3002CNF \u4fa7\u91cd\u4e8e\u76f4\u63a5\u4f18\u5316\u6570\u636e\u7684\u5bf9\u6570\u4f3c\u7136\uff0c\u800c FM \u5219\u4fa7\u91cd\u4e8e\u5b66\u4e60\u4e00\u4e2a\u5411\u91cf\u573a\uff0c\u4f7f\u5176\u4e0e\u53c2\u8003\u7684\u6982\u7387\u6d41\u8def\u5f84\u76f8\u5339\u914d\u3002</p> <p>\u6e90 </p>"},{"location":"book/chapter2_generation_theory/manifold_hypothesis/","title":"The Manifold Hypothesis: Why High-Dimensional Data Isn't as Complex as It Seems","text":""},{"location":"book/chapter2_generation_theory/manifold_hypothesis/#1-introduction","title":"1. Introduction","text":"<p>The manifold hypothesis is a cornerstone concept in machine learning, particularly for understanding and generating complex data like images, text, and sensor signals. It posits that real-world high-dimensional data (e.g., a 256x256 RGB image with 196,608 pixels) doesn\u2019t randomly fill its ambient space. Instead, it concentrates on low-dimensional manifolds\u2014geometric structures governed by far fewer underlying factors (e.g., pose, lighting, identity). This blog explores the implications, challenges, and applications of this hypothesis in modern AI.</p>"},{"location":"book/chapter2_generation_theory/manifold_hypothesis/#2-core-concepts","title":"2. Core Concepts","text":""},{"location":"book/chapter2_generation_theory/manifold_hypothesis/#21-1-intrinsic-vs-extrinsic-dimensionality","title":"2.1 1. Intrinsic vs. Extrinsic Dimensionality","text":"<ul> <li>Extrinsic Dimensionality: The raw dimension of the data space (e.g., 196,608 for a 256x256 image).</li> <li>Intrinsic Dimensionality: The true dimension of the manifold capturing meaningful variations (often ~10-100 for images).    Example: A facial image dataset\u2019s intrinsic factors might include facial expression, angle, and lighting\u2014not individual pixels.</li> </ul>"},{"location":"book/chapter2_generation_theory/manifold_hypothesis/#22-2-curse-of-dimensionality","title":"2.2 2. Curse of Dimensionality","text":"<p>High-dimensional spaces are sparse, making tasks like sampling and interpolation inefficient. The manifold hypothesis sidesteps this by focusing on the data-rich, low-dimensional subspace.</p>"},{"location":"book/chapter2_generation_theory/manifold_hypothesis/#23-3-nonlinear-structure","title":"2.3 3. Nonlinear Structure","text":"<p>Manifolds are rarely linear. They can be twisted, folded, or disconnected (e.g., distinct classes in images), requiring models to learn complex mappings between latent and ambient spaces.</p>"},{"location":"book/chapter2_generation_theory/manifold_hypothesis/#3-implications-for-machine-learning","title":"3. Implications for Machine Learning","text":""},{"location":"book/chapter2_generation_theory/manifold_hypothesis/#31-1-generative-models","title":"3.1 1. Generative Models","text":"<p>Models like GANs, VAEs, and diffusion models implicitly approximate the data manifold by mapping a low-dimensional latent space to the high-dimensional data space. - GANs: Generate images by sampling latent vectors and projecting them onto the manifold. - Diffusion Models: Gradually perturb data with noise to bridge the manifold and ambient space, enabling stable training.</p>"},{"location":"book/chapter2_generation_theory/manifold_hypothesis/#32-2-score-based-models-challenges","title":"3.2 2. Score-Based Models &amp; Challenges","text":"<p>Score-based models (e.g., diffusion models) estimate gradients (\\(\\nabla_x \\log p_{\\text{data}}(x)\\)) to generate data. However, the manifold hypothesis introduces two key issues: - Undefined Scores: Gradients are computed in the ambient space but are undefined on low-dimensional manifolds. - Inconsistent Estimation: Score matching objectives require data to span the full ambient space, failing when confined to a manifold.</p> <p>Solutions: - Noise Perturbation: Adding small noise (\\(\\mathcal{N}(0, 0.0001)\\)) \"thickens\" the manifold, stabilizing training (see Figure 1).</p>"},{"location":"book/chapter2_generation_theory/manifold_hypothesis/#33-3-dimensionality-reduction-representation-learning","title":"3.3 3. Dimensionality Reduction &amp; Representation Learning","text":"<ul> <li>Autoencoders and t-SNE compress data into manifold-aligned latent spaces.</li> <li>Disentanglement: Unsupervised methods isolate latent factors (e.g., shape vs. texture) to control generation.</li> </ul>"},{"location":"book/chapter2_generation_theory/manifold_hypothesis/#4-challenges-trade-offs","title":"4. Challenges &amp; Trade-offs","text":""},{"location":"book/chapter2_generation_theory/manifold_hypothesis/#41-1-complex-manifold-topology","title":"4.1 1. Complex Manifold Topology","text":"<ul> <li>Disconnected manifolds (e.g., MNIST digits) or \"holes\" complicate modeling.</li> <li>Example: A model trained on cats and dogs may struggle to interpolate between classes.</li> </ul>"},{"location":"book/chapter2_generation_theory/manifold_hypothesis/#42-2-noise-perturbation-trade-offs","title":"4.2 2. Noise Perturbation Trade-offs","text":"<ul> <li>Too little noise: Fails to resolve manifold inconsistencies.</li> <li>Too much noise: Corrupts data structure, harming generation quality.</li> </ul>"},{"location":"book/chapter2_generation_theory/manifold_hypothesis/#43-3-approximation-errors","title":"4.3 3. Approximation Errors","text":"<p>Poorly learned manifolds lead to artifacts (e.g., GAN-generated faces with distorted eyes).</p>"},{"location":"book/chapter2_generation_theory/manifold_hypothesis/#5-applications-beyond-images","title":"5. Applications Beyond Images","text":""},{"location":"book/chapter2_generation_theory/manifold_hypothesis/#51-1-natural-language-processing-nlp","title":"5.1 1. Natural Language Processing (NLP)","text":"<p>Word embeddings (e.g., Word2Vec) project language onto semantic manifolds, where similar words cluster.</p>"},{"location":"book/chapter2_generation_theory/manifold_hypothesis/#52-2-sensor-data","title":"5.2 2. Sensor Data","text":"<p>EEG signals and other time-series data lie on low-dimensional manifolds tied to physiological states.</p>"},{"location":"book/chapter2_generation_theory/manifold_hypothesis/#53-3-robotics","title":"5.3 3. Robotics","text":"<p>Control policies for joint angles or motion trajectories operate on manifolds.</p>"},{"location":"book/chapter2_generation_theory/manifold_hypothesis/#6-future-directions","title":"6. Future Directions","text":"<ol> <li>Manifold-Aware Architectures: Developing models that explicitly respect manifold geometry.</li> <li>Theoretical Guarantees: Formalizing consistency conditions for score-based methods on manifolds.</li> <li>Cross-Domain Manifold Learning: Unifying manifolds across modalities (e.g., image-text pairs).</li> </ol>"},{"location":"book/chapter2_generation_theory/manifold_hypothesis/#7-conclusion","title":"7. Conclusion","text":"<p>The manifold hypothesis is more than a theoretical curiosity\u2014it\u2019s a practical framework for tackling high-dimensional data. By exploiting low-dimensional structure, models achieve efficiency, realism, and interpretability. Yet, challenges like nonlinearity, topology, and noise trade-offs remind us that the \"simple\" low-dimensional story is anything but trivial. As generative AI advances, understanding manifolds will remain central to bridging the gap between raw data and meaningful intelligence.</p>"},{"location":"book/chapter2_generation_theory/mle/","title":"\u6700\u5927\u4f3c\u7136\u4f30\u8ba1","text":""},{"location":"book/chapter2_generation_theory/mle/#1","title":"1. \u751f\u6210\u6a21\u578b\u53ef\u4ee5\u6839\u636e\u5176\u76ee\u6807\u548c\u65b9\u6cd5\u5206\u7c7b","text":"\u6a21\u578b\u7c7b\u522b \u76ee\u6807 \u5178\u578b\u6a21\u578b \u5e94\u7528\u9886\u57df GAN \u6700\u5c0f\u5206\u5e03\u8ddd\u79bb GAN DCGAN\u3001StyleGAN\u3001BigGAN \u56fe\u50cf\u751f\u6210 \u9690\u53d8\u91cf\u6a21\u578b \u6700\u5927\u5316\u5bf9\u6570\u4f3c\u7136 VAE, PixelVAE \u56fe\u50cf\u751f\u6210\u3001\u5e8f\u5217\u751f\u6210 \u6982\u7387\u5bc6\u5ea6\u4f30\u8ba1 \u6700\u5927\u5316\u5bf9\u6570\u4f3c\u7136 Normalizing Flow, Energy-Based Models \u5bc6\u5ea6\u4f30\u8ba1\u3001\u56fe\u50cf\u751f\u6210 \u9010\u6b65\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u6a21\u578b \u9010\u6b65\u6700\u5927\u5316\u5bf9\u6570\u4f3c\u7136 DDPM\u3001Latent Diffusion Models (LDM) \u56fe\u50cf\u751f\u6210\u3001\u8865\u5168\u3001\u8d85\u5206\u8fa8\u7387 \u81ea\u56de\u5f52\u6a21\u578b \u6700\u5927\u5316\u6761\u4ef6\u5bf9\u6570\u4f3c\u7136 \u81ea\u56de\u5f52\u6a21\u578b \u56fe\u50cf\u751f\u6210\u3001\u8865\u5168\u3001\u8d85\u5206\u8fa8\u7387 \u51e0\u4f55/\u7269\u7406\u7ea6\u675f\u6a21\u578b \u6700\u5c0f\u5316\u91cd\u5efa\u8bef\u5dee NeRF, DeepSDF \u4e09\u7ef4\u5efa\u6a21\u3001\u89c6\u70b9\u5408\u6210 \u89c4\u5219/\u7edf\u8ba1\u751f\u6210\u6a21\u578b \u57fa\u4e8e\u89c4\u5219\u6216\u7ecf\u9a8c Procedural Generation, SMOTE \u6570\u636e\u589e\u5f3a\u3001\u751f\u6210\u7eb9\u7406 \u79bb\u6563\u751f\u6210\u6a21\u578b \u79bb\u6563\u6700\u5927\u4f3c\u7136\u4f30\u8ba1 GPT, Transformer \u6587\u672c\u751f\u6210\u3001\u4ee3\u7801\u751f\u6210 \u7a00\u758f/\u538b\u7f29\u751f\u6210\u6a21\u578b \u7a00\u758f\u8868\u793a\u6216\u538b\u7f29\u540e\u91cd\u5efa Sparse Coding, Autoencoders \u7279\u5f81\u63d0\u53d6\u3001\u6570\u636e\u538b\u7f29 \u6df7\u5408\u751f\u6210\u6a21\u578b \u7ed3\u5408\u591a\u4e2a\u751f\u6210\u76ee\u6807 VAE-GAN, Diffusion-GAN \u56fe\u50cf\u751f\u6210\u3001\u9ad8\u8d28\u91cf\u6570\u636e\u751f\u6210 <p>\u4e3b\u8981\u751f\u6210\u4efb\u52a1\u4f7f\u7528\u7684\u65b9\u6cd5</p> \u6570\u636e\u7c7b\u578b \u5e38\u7528\u65b9\u6cd5 \u7279\u70b9 \u5178\u578b\u6a21\u578b \u56fe\u50cf\u751f\u6210 GAN\u3001\u6269\u6563\u6a21\u578b\u3001VAE\u3001\u81ea\u56de\u5f52\u6a21\u578b \u751f\u6210\u8d28\u91cf\u9ad8\uff0c\u9002\u5408\u5355\u5e27\u56fe\u50cf\u751f\u6210\uff0c\u591a\u6837\u6027\u548c\u63a7\u5236\u6027\u89c6\u6a21\u578b\u800c\u5b9a StyleGAN\u3001DDPM\u3001PixelCNN \u8bed\u97f3\u751f\u6210 \u81ea\u56de\u5f52\u6a21\u578b\u3001\u8c31\u56fe\u751f\u6210\u3001GAN\u3001\u6269\u6563\u6a21\u578b \u9ad8\u4fdd\u771f\u8bed\u97f3\u751f\u6210\uff0c\u5e38\u7ed3\u5408\u58f0\u7801\u5668\u5b8c\u6210\u7aef\u5230\u7aef\u751f\u6210 WaveNet\u3001Tacotron\u3001HiFi-GAN\u3001DiffWave \u89c6\u9891\u751f\u6210 GAN\u3001\u81ea\u56de\u5f52\u6a21\u578b\u3001\u6269\u6563\u6a21\u578b\u3001\u6df7\u5408\u6a21\u578b \u89c6\u9891\u751f\u6210\u9700\u8981\u8003\u8651\u65f6\u95f4\u4e00\u81f4\u6027\uff0c\u6a21\u578b\u66f4\u590d\u6742\uff0c\u751f\u6210\u8d28\u91cf\u4f9d\u8d56\u4e8e\u65f6\u95f4\u548c\u7a7a\u95f4\u7684\u5efa\u6a21\u80fd\u529b MoCoGAN\u3001VideoGPT\u3001Video Diffusion Models <p>\u63a5\u4e0b\u6765\u6211\u4eec\u4e3b\u8981\u4ecb\u7ecd\u5728\u6700\u5c0f\u8ddd\u79bb\u5206\u5e03\u548c\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u7684\u6846\u67b6\u4e0b\uff0c\u600e\u4e48\u7edf\u4e00\u89e3\u91ca\u4e0d\u540c\u7684\u751f\u6210\u6a21\u578b\u3002\u540c\u65f6\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u662f\u6700\u5c0f\u5206\u5e03\u8ddd\u79bb\u7684\u4e00\u79cd\u7279\u4f8b\uff0c\u6211\u4eec\u5176\u5b9e\u53ef\u4ee5\u5728\u201d\u6700\u5c0f\u8ddd\u79bb\u5206\u5e03\u201c\u8fd9\u4e2a\u7edf\u4e00\u7684\u6846\u67b6\u4e0b\u6765\u89e3\u91ca\u751f\u6210\u65b9\u6cd5\u7684\u539f\u7406\u3002</p> <p>\u8bb0\u4f4f\u8fd9\u4e2a\u516c\u5f0f\uff0c\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u7684\u8868\u8fbe\u5f0f</p> \\[  \\int_{x\\sim p_{\\text {data }}} p_{\\text {data }}(x) \\log p_{\\theta}(x) d x \\] <p>\u4ece\u79bb\u6563\u7684\u89d2\u5ea6\uff0c\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u8868\u793a\u4e3a</p> \\[  \\sum_{x\\sim p_{\\text {data }}}  \\log p_{\\theta}(x) \\]"},{"location":"book/chapter2_generation_theory/mle/#2-1-mlp","title":"2. \u5b9a\u74061. MLP \u662f\u6700\u5c0f\u5316\u5206\u5e03\u5dee\u5f02\u7684\u7279\u5b9a\u5f62\u5f0f","text":"<p>\u8bc1\u660e: \u5148\u8bf4\u660e\u7ed3\u8bba\uff1a\u4e24\u4e2a\u5206\u5e03\u95f4\u7684\u201c\u8ddd\u79bb\u201d\u53ef\u4ee5\u7528\u4e0d\u540c\u7684\u6307\u6807\u6765\u8861\u91cf\uff08\u5982 KL \u6563\u5ea6\u3001Jensen-Shannon \u6563\u5ea6\u3001Wasserstein \u8ddd\u79bb\u7b49\uff09\u3002MLE \u7684\u76ee\u6807\u662f\u6700\u5c0f\u5316 KL \u6563\u5ea6\uff1a</p> \\[ D_{\\text{KL}}(p_{\\text{data}} || p_\\theta) \\] <p>\u56e0\u6b64\uff0cMLE \u53ef\u4ee5\u88ab\u8ba4\u4e3a\u662f\u4ee5 KL \u6563\u5ea6  \u4f5c\u4e3a\u8ddd\u79bb\u8861\u91cf\u6807\u51c6\u7684\u7279\u4f8b\u3002 \u4e0b\u9762\u6211\u4eec\u53ea\u8981\u8bc1\u660eMLP\u76ee\u6807\u7b49\u4ef7\u4e8e\u4f18\u5316KL\u6563\u5ea6\u5c31\u884c\u3002</p> <p>\u5176\u4e2d</p> \\[D_{\\mathrm{KL}}\\left(p_{\\text {data }} \\| p_\\theta\\right)=\\int p_{\\text {data }}(x) \\log \\frac{p_{\\text {data }}(x)}{p_\\theta(x)} d x\\] <p>\u5c55\u5f00\u4e3a</p> \\[D_{\\mathrm{KL}}\\left(p_{\\text {data }} \\| p_\\theta\\right)=\\int p_{\\text {data }}(x) \\log p_{\\text {data }}(x) d x-\\int p_{\\text {data }}(x) \\log p_\\theta(x) d x\\] <p>\u7b2c\u4e00\u9879\u548c\\(\\theta\\) \u4e5f\u5c31\u662f\u6a21\u578b\u65e0\u5173\uff0c\u56e0\u6b64\u53ef\u4ee5\u5ffd\u7565\u3002\u7b2c\u4e8c\u9879\u548c\\(\\theta\\)\u6709\u5173\uff0c\u56e0\u6b64\u53ef\u4ee5\u770b\u6210KL\u7684\u76ee\u6807\u3002</p> <p>\u53e6\u5916MLE\u7684\u539f\u59cb\u5b9a\u4e49\u4e3a</p> \\[ \\theta^*=\\arg \\max_{\\theta} L_{\\theta}  \\\\ == \\arg\\max_{\\theta} E_{x \\sim p_{\\text {data }}}[\\log p_{\\theta}(x)]\\\\ = \\arg\\min_{\\theta} - \\int p_{\\text {data }}(x) \\log p_{\\theta}(x) d x \\] <p>\u4ece\u8fd9\u4e2a\u89d2\u5ea6\u4ece\u65b0\u4e0d\u540c\u7684\u751f\u6210\u6a21\u578b\uff0c\u5305\u62ecVAE, GAN, Diffusion\u7b49\u7b49\uff0c\u5b83\u4eec\u7684\u76ee\u6807\u90fd\u662f\u6700\u5c0f\u5316\u751f\u6210\u5206\u5e03\u548c\u539f\u59cb\u6570\u636e\u5206\u5e03\u7684\u5dee\u5f02(\u8ddd\u79bb)\u7684\u6700\u5c0f\u5316\u3002</p>"},{"location":"book/chapter2_generation_theory/mle/#3-2gan","title":"3. \u5b9a\u74062\uff1agan\u7684\u4f18\u5316\u76ee\u6807\u7b49\u4ef7\u6700\u5c0f\u5316\u5206\u5e03\u8ddd\u79bb","text":"<p>GAN\u7684\u76ee\u7684\u662f\u6700\u5c0f\u5316\u5206\u5e03\u5dee\u5f02\uff0c\u5176\u4e2dvanila GAN\u7684\u76ee\u7684\u662f\u6700\u5c0f\u5316\u4e24\u4e2a\u5206\u5e03\u4e4b\u95f4\u7684JSD\u6563\u5ea6, WGAN\u7684\u76ee\u7684\u662f\u6700\u5c0f\u5316\u8fde\u4e2a\u5206\u5e03\u4e4b\u524d\u7684Wasserstein\u8ddd\u79bb</p> <p>\u8bc1\u660e\uff1a</p> <p>1. Vanilla GAN \u7684\u4f18\u5316\u76ee\u6807\u4e0e Jensen-Shannon \u6563\u5ea6</p> <p>1.1 GAN \u7684\u4f18\u5316\u76ee\u6807</p> <p>GAN \u7684\u76ee\u6807\u51fd\u6570\u7531\u751f\u6210\u5668 \\(G\\) \u548c\u5224\u522b\u5668 \\(D\\) \u7684\u5bf9\u6297\u535a\u5f08\u7ec4\u6210\uff1a</p> \\[  \\min_G \\max_D \\mathbb{E}_{x \\sim p_{\\text{data}}} [\\log D(x)] + \\mathbb{E}_{z \\sim p(z)} [\\log (1 - D(G(z)))] \\] <p>\u5176\u4e2d\uff1a</p> <ul> <li> <p>\\(p_{\\text{data}}(x)\\)\uff1a\u771f\u5b9e\u6570\u636e\u5206\u5e03\u3002</p> </li> <li> <p>\\(p_\\theta(x) = G(z)\\)\uff1a\u751f\u6210\u5206\u5e03\u3002</p> </li> </ul> <p>1.2 \u5224\u522b\u5668\u7684\u4f18\u5316</p> <p>\u5bf9\u4e8e\u56fa\u5b9a\u7684\u751f\u6210\u5668 \\(G\\)\uff0c\u5224\u522b\u5668 \\(D\\) \u7684\u76ee\u6807\u662f\u6700\u5927\u5316\uff1a</p> \\[  \\mathcal{L}(D) = \\mathbb{E}_{x \\sim p_{\\text{data}}} [\\log D(x)] + \\mathbb{E}_{x \\sim p_\\theta} [\\log (1 - D(x))] \\] <p>\u4f18\u5316 \\(D(x)\\)\uff1a</p> <p>\u5047\u8bbe \\(D(x)\\) \u8f93\u51fa\u7684\u503c\u662f \\(D(x) \\in [0, 1]\\)\uff0c\u5bf9\u5176\u6c42\u5bfc\u5e76\u627e\u5230\u6700\u4f18\u89e3</p> \\[ D^*(x) = \\frac{p_{\\text{data}}(x)}{p_{\\text{data}}(x) + p_\\theta(x)} \\] <p>\u6b64\u65f6\u6700\u4f18\u5224\u522b\u5668 \\(D^*(x)\\) \u8868\u793a\u8f93\u5165\u6837\u672c\u6765\u81ea\u771f\u5b9e\u5206\u5e03\u7684\u6982\u7387\u3002</p> <p>1.3 \u5c06\u6700\u4f18\u5224\u522b\u5668\u4ee3\u5165\u635f\u5931</p> <p>\u5c06 \\(D^*(x)\\) \u4ee3\u5165 GAN \u7684\u76ee\u6807\u51fd\u6570\uff0c\u5f97\u5230\u751f\u6210\u5668\u7684\u4f18\u5316\u76ee\u6807\uff1a</p> \\[  \\min_G \\max_D \\mathcal{L}(D) = \\mathbb{E}*{x \\sim p*{\\text{data}}} \\left[\\log \\frac{p_{\\text{data}}(x)}{p_{\\text{data}}(x) + p_\\theta(x)} \\right] + \\mathbb{E}*{x \\sim p*\\theta} \\left[\\log \\frac{p_\\theta(x)}{p_{\\text{data}}(x) + p_\\theta(x)} \\right] \\] <p>\u5316\u7b80\uff1a</p> \\[  \\mathcal{L}(G) = -\\log(4) + 2 \\cdot D_{\\text{JS}}(p_{\\text{data}} || p_\\theta) \\] <p>\u5176\u4e2d \\(D_{\\text{JS}}\\) \u662f Jensen-Shannon \u6563\u5ea6 \uff0c\u5b9a\u4e49\u4e3a\uff1a</p> \\[  D_{\\text{JS}}(p_{\\text{data}} || p_\\theta) = \\frac{1}{2} D_{\\text{KL}}(p_{\\text{data}} || m) + \\frac{1}{2} D_{\\text{KL}}(p_\\theta || m) \\] <p>\\(m = \\frac{1}{2}(p_{\\text{data}} + p_\\theta)\\)\u3002\u7ed3\u8bba\uff1a Vanilla GAN \u7684\u4f18\u5316\u76ee\u6807\u662f\u6700\u5c0f\u5316\u751f\u6210\u5206\u5e03\u548c\u6570\u636e\u5206\u5e03\u4e4b\u95f4\u7684 Jensen-Shannon \u6563\u5ea6\u3002</p> <p>2. WGAN \u7684\u4f18\u5316\u76ee\u6807\u4e0e Wasserstein \u8ddd\u79bb 2.1 WGAN \u7684\u76ee\u6807\u51fd\u6570</p> <p>WGAN \u7684\u76ee\u6807\u51fd\u6570\u662f\uff1a</p> \\[  \\mathcal{L}(G, D) = \\min_G \\max_{D \\in \\text{Lip-1}} \\mathbb{E}_{x \\sim p_{\\text{data}}} [D(x)] - \\mathbb{E}_{x \\sim p_\\theta} [D(x)] \\] <p>2.1 \u7ea6\u675f\u6761\u4ef6\uff1a</p> <ul> <li> <p>\u5224\u522b\u5668 \\(D(x)\\) \u4e0d\u518d\u8f93\u51fa\u6982\u7387\uff0c\u800c\u662f\u6807\u91cf\u503c\u3002</p> </li> <li> <p>\\(D(x)\\) \u662f 1-Lipschitz \u8fde\u7eed\u51fd\u6570\uff0c\u5373\u6ee1\u8db3 \\(|D(x_1) - D(x_2)| \\leq \\|x_1 - x_2\\|\\)\u3002</p> </li> </ul> <p>2.2 Wasserstein \u8ddd\u79bb\u5b9a\u4e49 Wasserstein \u8ddd\u79bb\uff08\\(W_1\\) \u8ddd\u79bb\uff09\u5b9a\u4e49\u4e3a\uff1a</p> \\[  W_1(p_{\\text{data}}, p_\\theta) = \\inf_{\\gamma \\in \\Pi(p_{\\text{data}}, p_\\theta)} \\mathbb{E}_{(x, y) \\sim \\gamma} [\\|x - y\\|] \\] <p>\u5176\u4e2d \\(\\Pi(p_{\\text{data}}, p_\\theta)\\) \u662f\u6240\u6709\u4f7f\u8fb9\u7f18\u5206\u5e03\u4e3a \\(p_{\\text{data}}\\) \u548c \\(p_\\theta\\) \u7684\u8054\u5408\u5206\u5e03\u3002 \u6839\u636e Kantorovich-Rubinstein \u5bf9\u5076\u6027\uff0cWasserstein \u8ddd\u79bb\u53ef\u4ee5\u91cd\u5199\u4e3a\uff1a</p> \\[  W_1(p_{\\text{data}}, p_\\theta) = \\sup_{\\|D\\|_L \\leq 1} \\mathbb{E}_{x \\sim p_{\\text{data}}} [D(x)] - \\mathbb{E}_{x \\sim p_\\theta} [D(x)] \\] <p>3. \u603b\u7ed3</p> <ul> <li> <p>Vanilla GAN\uff1a  \u5224\u522b\u5668 \\(D\\) \u8f93\u51fa\u7684\u662f\u6982\u7387\uff0c\u4f18\u5316\u76ee\u6807\u662f\u6700\u5c0f\u5316\u751f\u6210\u5206\u5e03\u548c\u771f\u5b9e\u5206\u5e03\u7684 Jensen-Shannon \u6563\u5ea6\uff08JSD\uff09\u3002</p> </li> <li> <p>WGAN\uff1a  \u5224\u522b\u5668 \\(D\\) \u8f93\u51fa\u7684\u662f\u6807\u91cf\u503c\uff0c\u4f18\u5316\u76ee\u6807\u662f\u6700\u5c0f\u5316\u751f\u6210\u5206\u5e03\u548c\u771f\u5b9e\u5206\u5e03\u7684 Wasserstein \u8ddd\u79bb\uff08\\(W_1\\)\uff09\u3002</p> </li> <li> <p>\u4e24\u8005\u7684\u672c\u8d28\uff1a  \u90fd\u5728\u901a\u8fc7\u4e0d\u540c\u7684\u5206\u5e03\u5dee\u5f02\u5ea6\u91cf\u6307\u6807\u4f18\u5316\u751f\u6210\u5206\u5e03 \\(p_\\theta(x)\\) \u903c\u8fd1\u771f\u5b9e\u6570\u636e\u5206\u5e03 \\(p_{\\text{data}}(x)\\)\u3002</p> </li> </ul> <p>4. \u5907\u6ce8</p> <p>\u5728wgan \u4e2d\u4e3a\u4ec0\u4e48\u51fa\u73b0\u4e86Lipschitz \u6761\u4ef6\u3002\u8fd9\u662f\u56e0\u4e3a Kantorovich-Rubinstein \u5bf9\u5076\u6027\u8981\u6c42\u76ee\u6807\u51fd\u6570 \\(\ud835\udc53(\ud835\udc65)\\) \u662f 1-Lipschitz \u51fd\u6570\u3002\u5982\u679c\u6ca1\u6709\u8fd9\u4e2a\u6761\u4ef6\uff0cWasserstein \u8ddd\u79bb\u65e0\u6cd5\u901a\u8fc7\u5bf9\u5076\u5f62\u5f0f\u8ba1\u7b97\u3002 \u5728 WGAN \u4e2d\uff0c\u5224\u522b\u5668 D(x) \u5b9e\u9645\u4e0a\u662f f(x) \u7684\u5b9e\u73b0\uff0c\u56e0\u6b64\u9700\u8981\u6ee1\u8db3 Lipschitz \u8fde\u7eed\u6027\uff0c\u4fdd\u8bc1\u4f18\u5316\u76ee\u6807\u4e0e Wasserstein \u8ddd\u79bb\u7684\u6570\u5b66\u5b9a\u4e49\u4e00\u81f4\u3002</p> <p>\u4ece\u53e6\u5916\u4e00\u4e2a\u89d2\u5ea6\u8bf4\u660e\uff1a\u5224\u522b\u5668\\(D\\)\u7684\u4f5c\u7528\u53ef\u80fd\u4e0d\u4e00\u81f4\uff0c\u4f46\u662fD\u7684loss \u90fd\u8868\u793a\u4e86\u4e24\u4e2a\u5206\u5e03\u4e4b\u95f4\u7684\u8ddd\u79bb\uff0c\u5206\u522b\u662fJSD \u6563\u5ea6\u548cWasserstein \u8ddd\u79bb\u3002\u4f18\u5316\\(D\\) \u7684\u4f5c\u7528\u53ca\u65f6\u8ba9\u8fd9\u4e2aLoss \u5c3d\u91cf\u51c6\u786e\u6a21\u62df\u51fa\u4e24\u4e2a\u5206\u5e03\u4e4b\u95f4\u7684\u8ddd\u79bb\u3002\u5982\u679c\u628a\u8fd9\u4e2aloss \\(L_\\theta(x,y)\\) \u4f5c\u4e3a\u4e00\u4e2a\u51fd\u6570\u770b\u5f85,\u5b83\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5b66\u4e60\u7684\u5c31\u662f\u4e24\u4e2a\u5206\u5e03\u4e4b\u95f4\u7684\u8ddd\u79bb\u7684\u8fd1\u4f3c\u3002</p> <p>\u5f53\u7136\u5728\u4e0a\u9762\u7684\u5206\u6790\u4e2d\uff0c\u6211\u4eec\u662f\u77e5\u9053\u4e86GAN\u7684\u5b9e\u73b0\uff0c\u7136\u540e\u8bc1\u660e\u4e86\u5b83\u7684\u4f5c\u7528\u3002</p> <p>\u7406\u8bba\u4e0a\u6211\u4eec\u8861\u91cf\u4e24\u4e2a\u5206\u5e03\u4e4b\u95f4\u7684\u8ddd\u79bb\u6709\u4e0d\u540c\u7684\u9009\u62e9\uff0c\u90a3\u5728\"GAN\"\u7684\u8bbe\u8ba1\u4e2d\uff0c\u6211\u4eec\u5c31\u53ef\u4ee5\u6839\u636e\u4e0d\u540c\u7684\u8ddd\u79bb\u9009\u62e9\u53ef\u4ee5\u8ba9\u6211\u4eec\u53bb\u8bbe\u8ba1\u4e0d\u540c\u7684D\u548cD\u7684loss\u3002</p> <p>\u90a3\u4e48\u5047\u8bbe\u6211\u4eec\u60f3\u8981\u7528KL \u6563\u5ea6\u53bb\u8861\u91cf\u4e24\u4e2a\u5206\u5e03\u4e4b\u95f4\u7684\u8ddd\u79bb\uff0c\u90a3\u662f\u4e0d\u662f\u53ef\u4ee5\u8bbe\u8ba1\u51fa\u76f8\u5e94\u7684loss\u3002 \u7b54\u6848\u662f\u80af\u5b9a\u7684\uff0c</p> <p>\u6211\u4eec\u53ef\u4ee5\u63a8\u5bfc\u51fa\u5bf9\u7279\u5b9a\u6563\u5ea6\u7684\u4f18\u5316\u8fd1\u4f3c\u4e8e \\(\\min _\\theta \\max _\\omega F(\\theta, \\omega)=\\mathbb{E}_{x \\sim P}\\left[T_\\omega(x)\\right]-\\mathbb{E}_{x \\sim Q_\\theta}\\left[f^*\\left(T_\\omega(x)\\right)\\right]\\).</p> <p>\u4ece\u800cKL\u6563\u5ea6\u5bf9\u5e94\u7684loss \u5219\u4e3a</p> \\[E_{x\\sim P}\\left[\\log D(x)\\right]-E_{x\\sim Q_\\theta}\\left[\\log D(x)\\right]\\] <p>\u53c2\u8003\u8fd9\u4e2a\u8bba\u6587 https://arxiv.org/pdf/1606.00709 \u4e86\u89e3\u66f4\u591a\u6563\u5ea6\u5bf9\u5e94\u7684loss</p>"},{"location":"book/chapter2_generation_theory/mle/#31","title":"3.1 \u5e7f\u6cdb\u542b\u4e49\u4e0a\u7684\u5206\u5e03\u4e4b\u95f4\u7684\u8861\u91cf\u8bbe\u8ba1","text":"\u8ddd\u79bb\u8861\u91cf\u65b9\u6cd5 GAN \u7c7b\u578b \u4f18\u52bf \u52a3\u52bf \u8bba\u6587\u94fe\u63a5 Jensen-Shannon \u6563\u5ea6 Vanilla GAN \u7406\u8bba\u57fa\u7840\u6e05\u6670\uff0c\u76ee\u6807\u660e\u786e \u68af\u5ea6\u6d88\u5931\uff0c\u6a21\u5f0f\u5d29\u6e83 Generative Adversarial Nets Wasserstein \u8ddd\u79bb WGAN \u66f4\u7a33\u5b9a\u7684\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u6709\u610f\u4e49\u7684\u68af\u5ea6 \u8ba1\u7b97\u4ee3\u4ef7\u9ad8\uff0c\u9700\u5f3a\u5236 Lipschitz \u6761\u4ef6 Wasserstein GAN f-\u6563\u5ea6 f-GAN \u7075\u6d3b\u7684\u6563\u5ea6\u9009\u62e9\uff0c\u9002\u5e94\u4e0d\u540c\u4efb\u52a1\u9700\u6c42 \u9700\u9009\u62e9\u5408\u9002\u7684 f-\u6563\u5ea6 f-GAN: Training Generative Neural Samplers using Variational Divergence Minimization MMD\uff08\u6700\u5927\u5747\u503c\u5dee\u5f02\uff09 MMD-GAN \u6838\u51fd\u6570\u7075\u6d3b\uff0c\u9ad8\u7ef4\u6570\u636e\u8868\u73b0\u4f18\u8d8a \u6838\u51fd\u6570\u9009\u62e9\u5f71\u54cd\u6027\u80fd MMD GAN: Towards Deeper Understanding of Moment Matching Network Sliced Wasserstein \u8ddd\u79bb Sliced-WGAN \u6539\u5584\u9ad8\u7ef4\u6570\u636e\u7684\u8bad\u7ec3\u7a33\u5b9a\u6027 \u9700\u8981\u9009\u62e9\u9002\u5f53\u7684\u6295\u5f71\u65b9\u5411 Max-Sliced Wasserstein Distance and Its Use for GANs Sobolev \u8ddd\u79bb Sobolev GAN \u653e\u5bbd Lipschitz \u6761\u4ef6\uff0c\u63d0\u9ad8\u8bad\u7ec3\u7075\u6d3b\u6027 \u7406\u8bba\u590d\u6742\u6027\u589e\u52a0 Towards Generalized Implementation of Wasserstein Distance in GANs"},{"location":"book/chapter2_generation_theory/mle/#4-3-vae","title":"4. \u5b9a\u74063: VAE \u662f\u5bf9\u6700\u5927\u4f3c\u7136\u7684\u4f18\u5316","text":"<p>\u8bc1\u660e</p> <ol> <li>\u8fde\u7eed\u5206\u5e03\u7684\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u76ee\u6807</li> </ol> <p>\u5bf9\u4e8e\u89c2\u6d4b\u6570\u636e\u7684\u6982\u7387\u5206\u5e03 \\(p_{\\text{data}}(x)\\)\uff0c\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u7684\u76ee\u6807\u662f\u6700\u5927\u5316\u6570\u636e\u5206\u5e03\u4e0b\u6a21\u578b \\(p_\\theta(x)\\) \u7684\u5bf9\u6570\u4f3c\u7136\uff1a</p> \\[  \\int_{x \\sim p_{\\text{data}}} p_{\\text{data}}(x) \\log p_\\theta(x) \\, dx \\] <p>\u8fd9\u91cc\u6211\u4eec\u9700\u8981\u627e\u5230\u4e00\u79cd\u529e\u6cd5\u53bb\u8868\u8fbe\u6216\u8005\u8fd1\u4f3c \\(p_\\theta(x)\\)\u3002 \u8fd9\u662f\u5173\u952e\u7684\u4e00\u90e8\u5206\u3002 \u5bf9\u4e8e\u9690\u53d8\u91cf\u751f\u6210\u6a21\u578b\u800c\u8a00\uff0c\u4f1a\u6709\u4e00\u4e2a\\(z\\) \u548c\\(X\\)\u7684\u5bf9\u5e94\u5173\u7cfb\uff0c</p> <p>\u6211\u4eec\u53ef\u4ee5\u5199\u6210 \\(p_\\theta(x) = \\int p_\\theta(x, z) \\, dz\\) \u5305\u542b\u5bf9\u9690\u53d8\u91cf \\(z\\) \u7684\u79ef\u5206\u3002\u518d\u5bf9\\(z\\) \u505a\u4e00\u4e9b\u5047\u8bbe\uff0c\u53ef\u80fd\u5c31\u4f1a\u7b80\u5316\u6c42\u89e3\u7684\u8fc7\u7a0b\u3002</p> <ol> <li>\u91cd\u5199\u8fb9\u7f18\u4f3c\u7136</li> </ol> <p>\u5bf9\u4e8e\u5355\u4e2a\u6570\u636e\u70b9 \\(x\\)\uff0c\u89c2\u6d4b\u6570\u636e\u7684\u8fb9\u7f18\u5bf9\u6570\u4f3c\u7136\u53ef\u4ee5\u5199\u4e3a\uff1a</p> \\[  \\log p_\\theta(x) = \\log \\int p_\\theta(x, z) \\, dz \\] <p>\u5229\u7528\u8054\u5408\u5206\u5e03\u7684\u5206\u89e3 \\(p_\\theta(x, z) = p_\\theta(x \\mid z) p(z)\\)\uff0c\u6211\u4eec\u6709\uff1a</p> \\[  \\log p_\\theta(x) = \\log \\int p_\\theta(x \\mid z) p(z) \\, dz \\] <p>\u76f4\u63a5\u4f18\u5316\u8fd9\u4e2a\u76ee\u6807\u901a\u5e38\u5f88\u56f0\u96be\uff0c\u56e0\u4e3a\u79ef\u5206 \\(\\int p_\\theta(x \\mid z)p(z) dz\\) \u5bf9\u4e8e\u9ad8\u7ef4 \\(z\\) \u4e0d\u53ef\u89e3\u6790\u3002</p> <ol> <li>\u5f15\u5165\u53d8\u5206\u5206\u5e03 \\(q_\\phi(z \\mid x)\\)\u4e3a\u4e86\u89e3\u51b3\u79ef\u5206\u4e0d\u53ef\u89e3\u6790\u7684\u95ee\u9898</li> </ol> <p>\u5f15\u5165\u4e00\u4e2a\u8fd1\u4f3c\u540e\u9a8c\u5206\u5e03 \\(q_\\phi(z \\mid x)\\)\uff0c\u7528\u4e8e\u8fd1\u4f3c\u771f\u5b9e\u540e\u9a8c \\(p_\\theta(z \\mid x)\\)\u3002\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u4ee5\u4e0b\u5206\u89e3\u91cd\u65b0\u8868\u793a \\(\\log p_\\theta(x)\\)\uff1a</p> \\[  \\log p_\\theta(x) = \\mathbb{E}_{q_\\phi(z \\mid x)} \\left[ \\log \\frac{p_\\theta(x, z)}{q_\\phi(z \\mid x)} \\right] + \\mathrm{KL}(q_\\phi(z \\mid x) \\| p_\\theta(z \\mid x)) \\] <p>\u8bc1\u660e\u7ec6\u8282\u8bf7\u770b ELBP\u8bc1\u660e\u3002ELBO\u4e5f\u53ef\u4ee5\u7531\u51f8\u51fd\u6570\u7684\u6027\u8d28\u5229\u7528 Jensen's inequality\u76f4\u63a5\u63a8\u5bfc\u51fa\u4e0d\u7b49\u5f0f(https://en.wikipedia.org/wiki/Evidence_lower_bound).</p> <p>\u5176\u4e2d\uff1a</p> <ul> <li> <p>\u7b2c\u4e00\u9879\u662f\u53d8\u5206\u4e0b\u754c\uff08Evidence Lower Bound, ELBO)),\u6211\u4eec\u53ef\u4ee5\u4f18\u5316\u5b83\u6765\u95f4\u63a5\u4f18\u5316 \\(\\log p_\\theta(x)\\)\u3002</p> </li> <li> <p>\u7b2c\u4e8c\u9879\u662f KL \u6563\u5ea6\uff0c\u8868\u793a\u8fd1\u4f3c\u540e\u9a8c \\(q_\\phi(z \\mid x)\\) \u4e0e\u771f\u5b9e\u540e\u9a8c \\(p_\\theta(z \\mid x)\\) \u7684\u5dee\u8ddd\u3002</p> </li> </ul> <p>\u7531\u4e8e KL \u6563\u5ea6\u603b\u662f\u975e\u8d1f\uff1a\\(\\mathrm{KL}(q_\\phi(z \\mid x) \\| p_\\theta(z \\mid x)) \\geq 0\\)\uff0c\u6240\u4ee5\uff1a\\(\\log p_\\theta(x) \\geq \\mathcal{L}(\\theta, \\phi; x)\\), \u5176\u4e2d\\(L\\) \u8868\u793a\u53d8\u5206\u4e0b\u754c,\u4e5f\u5c31\u662f ELBO\uff0c\u4e3a\u4e0a\u5f0f\u7684\u7b2c\u4e00\u9879\u3002</p> <ol> <li>. \u53d8\u5206\u4e0b\u754c\uff08ELBO, \u8bbe\u4e3a $ \\mathcal{L}$\uff09\u7684\u5206\u89e3</li> </ol> <p>\u53d8\u5206\u4e0b\u754c\u7684\u5177\u4f53\u5f62\u5f0f\u4e3a\uff1a</p> \\[  \\mathcal{L}(\\theta, \\phi; x) = \\mathbb{E}_{q_\\phi(z \\mid x)} \\left[ \\log p_\\theta(x, z) - \\log q_\\phi(z \\mid x) \\right] \\] <p>\u8fdb\u4e00\u6b65\u5206\u89e3\u8054\u5408\u6982\u7387 \\(p_\\theta(x, z) = p_\\theta(x \\mid z)p(z)\\)\uff0c\u5f97\u5230\uff1a</p> \\[  \\mathcal{L}(\\theta, \\phi; x) = \\mathbb{E}_{q_\\phi(z \\mid x)} \\left[ \\log p_\\theta(x \\mid z) \\right] - \\mathrm{KL}(q_\\phi(z \\mid x) \\| p(z)) \\] <p>\u7b2c\u4e00\u9879 \\(\\mathbb{E}_{q_\\phi(z \\mid x)} [\\log p_\\theta(x \\mid z)]\\)\uff1a\u91cd\u6784\u8bef\u5dee\uff08Reconstruction Error\uff09\uff0c\u9f13\u52b1\u751f\u6210\u5668\u80fd\u591f\u751f\u6210\u63a5\u8fd1\u771f\u5b9e\u6570\u636e \\(x\\) \u7684\u5206\u5e03\u3002 \u8fd9\u4e2a\u6ca1\u6cd5\u76f4\u63a5\u8ba1\u7b97\u3002\u5982\u679c\u7528\u8499\u7279\u5361\u6d1b\u91c7\u6837\u7684\u8bdd\uff0c\u4e5f\u9700\u8981\u6709 \\(p_\\theta(z|x)\\)\u7684\u503c\uff0c\u4f46\u662f\u8fd9\u4e2a\u503c\u4e5f\u662f\u4e0d\u53ef\u89e3\u6790\u7684\u3002 \u56e0\u6b64\u5728\u539f\u59cb\u7684\u8bba\u6587\u91cc\uff0c\u5047\u8bbe \\(p_\\theta(z|x)\\)\u662f\u4e00\u4e2a\u9ad8\u65af\u5206\u5e03\uff0c\u8fd9\u6837\u5c31\u53ef\u4ee5\u8ba1\u7b97\u3002</p> <p>\u5982\u679c\u6211\u4eec\u5047\u8bbe \\(p_\\theta(x|z)\\) \u662f\u9ad8\u65af\u5206\u5e03\uff1a</p> \\[ p_\\theta(x|z) = \\mathcal{N}(\\hat{x}, \\sigma^2 I) \\] <p>\u5176\u4e2d \\(\\hat{x}\\) \u662f\u89e3\u7801\u5668\u751f\u6210\u7684\u5747\u503c\uff0c\\(\\sigma^2\\) \u662f\u56fa\u5b9a\u65b9\u5dee\u3002 \u5bf9\u6570\u4f3c\u7136\u5c55\u5f00\uff1a</p> \\[ \\begin{aligned} \\log p_\\theta(x|z) &amp;= \\log \\mathcal{N}(x; \\hat{x}, \\sigma^2 I)\\\\   &amp;= -\\frac{1}{2} \\left( \\frac{\\|x - \\hat{x}\\|^2}{\\sigma^2} + d \\log(2\\pi\\sigma^2) \\right), \\end{aligned} \\] <p>\u5176\u4e2d \\(d\\) \u662f \\(x\\) \u7684\u7ef4\u5ea6\u3002</p> <p>\u91cd\u6784\u8bef\u5dee\u7b49\u4ef7\u4e8e\u8d1f\u5bf9\u6570\u4f3c\u7136\uff0c\u5ffd\u7565\u5e38\u6570\u9879\u540e\u4e3a\uff1a</p> \\[ \\mathbb{E}_{q_\\phi(z|x)}[-\\log p_\\theta(x|z)] \\propto \\mathbb{E}_{q_\\phi(z|x)}[\\|x - \\hat{x}\\|^2]. \\] <ol> <li>\u91cd\u5efa\u8bef\u5dee\u7b80\u5316\u4e3a \\(|x - \\hat{x}|\\)\u5728\u5177\u4f53\u5b9e\u73b0\u4e2d\uff0c\u901a\u5e38\u5047\u8bbe\u65b9\u5dee \\(\\sigma^2 = 1\\) \u4e14\u91cd\u5efa\u8bef\u5dee\u4ec5\u8003\u8651\u5747\u503c\u4f30\u8ba1\uff0c\u6b64\u65f6\uff1a</li> </ol> \\[ \\mathbb{E}_{q_\\phi(z|x)}[\\|x - \\hat{x}\\|^2] \\approx \\|x - \\hat{x}\\|^2, \\] <p>\u5bf9\u5e94\u7684\u5dee\u9879\u4e3a \\(|x - \\hat{x}|\\) \u6216\u5176\u5e73\u65b9\u5f62\u5f0f\u3002</p> <p>\u5f53\u7136\u5982\u679c\u6211\u4eec\u5047\u8bbe \\(p_\\theta(x|z)\\) \u662f\u5c5e\u4e8e\u5176\u4ed6\u5206\u5e03\uff0c\u90a3\u5c31\u4f1a\u5bfc\u51fa\u4e0d\u540c\u7684\u91cd\u6784\u8bef\u5dee\u3002\u66f4\u8fdb\u4e00\u6b65\uff0c\u5bf9\u4e8e\u4efb\u610f\u4e00\u4e2a\u91cd\u5efa\u5dee\u7684\u5ea6\u91cf\uff0c\u5176\u5b9e\u90fd\u5bf9\u5e94\u7740\u4e00\u4e2a\\(p_\\theta(x|z)\\), \u8fd9\u4e2a\u53ef\u4ee5\u7531\u5ea6\u91cf\u51fd\u6570\u53bb\u6784\u5efa\u4e00\u4e2a\u5bc6\u5ea6\u51fd\u6570\u3002 \u5177\u4f53\uff0c\u67e5\u770b VAE: introduction</p> <ul> <li> <p>\u7b2c\u4e8c\u9879 \\(\\mathrm{KL}(q_\\phi(z \\mid x) \\| p(z))\\)\uff1a\u6b63\u5219\u5316\u9879\uff0c\u7ea6\u675f \\(q_\\phi(z \\mid x)\\) \u7684\u5206\u5e03\u63a5\u8fd1\u5148\u9a8c \\(p(z)\\)\u3002</p> </li> <li> <p>\u6700\u7ec8\u5f62\u5f0f\uff08VAE \u635f\u5931\u51fd\u6570\uff09 \u4e3a\u4e86\u4f18\u5316\u4e0a\u8ff0\u76ee\u6807\uff0c\u6211\u4eec\u9700\u8981\u8fdb\u884c\u91c7\u6837 \\(z \\sim q_\\phi(z \\mid x)\\)\u3002\u4e3a\u4e86\u89e3\u51b3\u91c7\u6837\u8fc7\u7a0b\u4e2d\u4e0d\u53ef\u5fae\u7684\u95ee\u9898\uff0c\u4f7f\u7528 \u91cd\u53c2\u6570\u5316\u6280\u5de7\uff08Reparameterization Trick\uff09 \uff1a\u5c06 \\(q_\\phi(z \\mid x)\\) \u5b9a\u4e49\u4e3a\u9ad8\u65af\u5206\u5e03 \\(\\mathcal{N}(\\mu_\\phi(x), \\sigma_\\phi(x)^2)\\)\uff0c\u901a\u8fc7\u5982\u4e0b\u65b9\u5f0f\u91c7\u6837\uff1a</p> </li> </ul> \\[ z = \\mu_\\phi(x) + \\sigma_\\phi(x) \\odot \\epsilon, \\quad \\epsilon \\sim \\mathcal{N}(0, I) \\] <p>\u6700\u7ec8\uff0cVAE \u7684\u635f\u5931\u51fd\u6570\u53ef\u4ee5\u8868\u793a\u4e3a\uff1a</p> \\[  \\mathcal{L}(\\theta, \\phi; x) = \\mathbb{E}_{z \\sim q_\\phi(z \\mid x)} [\\log p_\\theta(x \\mid z)] - \\mathrm{KL}(q_\\phi(z \\mid x) \\| p(z)) \\] <p>\u8fd9\u5bf9\u5e94\u4e8e\uff1a</p> <ol> <li> <p>\u91cd\u6784\u8bef\u5dee \uff1a\u901a\u8fc7\u751f\u6210\u5206\u5e03 \\(p_\\theta(x \\mid z)\\) \u5b66\u4e60\u5982\u4f55\u751f\u6210\u6570\u636e\u3002</p> </li> <li> <p>KL \u6563\u5ea6\u6b63\u5219\u5316 \uff1a\u7ea6\u675f\u6f5c\u53d8\u91cf\u5206\u5e03\u3002</p> </li> </ol> <p>\u4f18\u5316\u8be5\u76ee\u6807\uff0c\u5373\u5b9e\u73b0\u4ece\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u5230 VAE \u7684\u8f6c\u5316\u3002</p> <p>\u4ece\u8fd9\u91cc\u6211\u4eec\u4e5f\u80fd\u770b\u5230\uff0cVAE\u548c\u901a\u5e38\u7684\u795e\u7ecf\u7f51\u7edc\u6784\u9020\u4e0d\u4e00\u6837\uff0c\u5b83\u9884\u6d4b\u7684\u65f6\u4e00\u4e2a\u5206\u5e03\uff0c\u4e0d\u7ba1\u7f16\u7801\u5668\u8fd8\u662f\u89e3\u7801\u5668\uff0c\u9884\u6d4b\u7684\u90fd\u662f\u4e00\u4e2a\u5206\u5e03\u3002\u66f4\u7cbe\u786e\u5f97\u6765\u8bf4\uff0c\u6700\u521d\u7684VAE \u7f16\u7801\u5668\u9884\u6d4b\u7684\u65f6\u9ad8\u65af\u5206\u5e03\u7684mean \u548cvariance\uff0c \u89e3\u7801\u5668\u9884\u6d4b\u7684\u65f6\u9ad8\u65af\u5206\u5e03\u7684mean\u3002\u4f46\u5728\u5b9e\u9645\u5e94\u7528\u65f6\uff0c\u6211\u4eec\u4f7f\u7528VAE \u8fdb\u884c\u91cd\u5efa\u65f6\uff0c\u76f4\u63a5\u4f7f\u7528\u7684\u5c31\u662f\u8fd9\u4e2amean\uff0c\u56e0\u6b64\u5ffd\u7565\u6389\u4e86\u5176\u5b9edecoder \u4e5f\u662f\u672c\u8d28\u4e0a\u9884\u6d4b\u7684\u662fmean.</p> <p>\u5b9e\u9645\u7684VAE\u8fc7\u7a0b </p> <p>\u5bf9\u4e8eVAE\u800c\u8a00\uff0c\u7b2c\u4e00\u9879\u7684\u8ba1\u7b97\u662f\u7b49\u4ef7\u4e8e\u91cd\u5efaloss \u7684\uff0c\u5173\u952e\u662f\u7b2c\u4e8c\u9879\u9700\u8981\u600e\u4e48\u8bbe\u8ba1\u3002\u4e0d\u540c\u7684\u8bbe\u8ba1\u53ef\u80fd\u5c31\u4ee5\u4e3a\u7740\u4e0d\u540c\u7684\u65b9\u6cd5\u3002</p> <p>\u8fd9\u91cc\u6211\u4eec\u5217\u4e3e\u4e86\u4e00\u7cfb\u5217\u5bf9\u7b2c\u4e8c\u9879\u8ba1\u7b97\u7684\u6539\u8fdb\u65b9\u6cd5</p> \u65b9\u6cd5 \u63cf\u8ff0 \u4f18\u70b9 \u7f3a\u70b9 \u9002\u7528\u573a\u666f \u6807\u51c6\u9ad8\u65af VAE \u5047\u8bbe \\(q_\\phi(z \\mid x)\\)\u4e3a\u9ad8\u65af\u5206\u5e03\uff0c\u7f16\u7801\u5668\u8f93\u51fa\u5747\u503c\u548c\u65b9\u5dee\u3002 \u7b80\u5355\u9ad8\u6548\uff0c\u53ef\u89e3\u6790\u8ba1\u7b97 KL \u6563\u5ea6\u3002 \u8868\u8fbe\u80fd\u529b\u6709\u9650\uff0c\u65e0\u6cd5\u5904\u7406\u590d\u6742\u5206\u5e03\u3002 \u5e38\u89c4\u4efb\u52a1\uff0c\u6570\u636e\u5206\u5e03\u7b80\u5355\u3002 \u9ad8\u65af\u6df7\u5408 VAE \u5047\u8bbe \\(q_\\phi(z \\mid x)\\) \u662f\u6df7\u5408\u9ad8\u65af\u5206\u5e03\uff08\u591a\u4e2a\u9ad8\u65af\u6210\u5206\uff09\u3002 \u80fd\u591f\u6355\u6349\u591a\u6a21\u6001\u5206\u5e03\uff0c\u66f4\u9002\u5408\u590d\u6742\u6570\u636e\u5206\u5e03\u3002 \u589e\u52a0\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u9700\u8981\u4f30\u8ba1\u66f4\u591a\u53c2\u6570\u3002 \u591a\u6a21\u6001\u6570\u636e\u5efa\u6a21\uff0c\u4f8b\u5982\u805a\u7c7b\u6216\u5206\u7c7b\u4efb\u52a1\u3002 \u6b63\u6001\u5316\u6d41 VAE \u7528\u4e00\u7cfb\u5217\u53ef\u9006\u53d8\u6362\u6784\u9020 \\(q_\\phi(z \\mid x)\\)\uff0c\u63d0\u9ad8\u540e\u9a8c\u5206\u5e03\u7684\u7075\u6d3b\u6027\u3002 \u540e\u9a8c\u5206\u5e03\u66f4\u7075\u6d3b\uff0c\u9002\u5408\u590d\u6742\u5206\u5e03\u5efa\u6a21\u3002 \u589e\u52a0\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u9700\u8981\u8bbe\u8ba1\u5408\u7406\u7684\u6d41\u6a21\u578b\u3002 \u9ad8\u7ef4\u590d\u6742\u5206\u5e03\u7684\u8868\u793a\u548c\u5efa\u6a21\u3002 \u79bb\u6563 VAE \u5047\u8bbe\u6f5c\u53d8\u91cf\u662f\u79bb\u6563\u53d8\u91cf\uff0c\u7528 Gumbel-Softmax \u6280\u5de7\u5b9e\u73b0\u53ef\u5fae\u4f18\u5316\u3002 \u9002\u5408\u79bb\u6563\u6f5c\u53d8\u91cf\u7a7a\u95f4\uff08\u5982\u5206\u7c7b\u6216\u6587\u672c\u751f\u6210\uff09\u3002 \u65e0\u6cd5\u6355\u6349\u8fde\u7eed\u5206\u5e03\u7684\u7ec6\u8282\uff0c\u5bf9\u6e29\u5ea6\u53c2\u6570\\(\\tau\\)\u654f\u611f\u3002 \u79bb\u6563\u6570\u636e\u751f\u6210\u6216\u5206\u7c7b\u4efb\u52a1\u3002 \u80fd\u91cf\u6a21\u578b VAE \u7528\u80fd\u91cf\u51fd\u6570\u5b9a\u4e49 \\(q_\\phi(z \\mid x)\\),\u5982\\(q_\\phi(z \\mid x) \\propto \\exp(-E_\\phi(x, z))\\)\uff0c\u5e76\u901a\u8fc7 MCMC \u91c7\u6837\u3002 \u975e\u53c2\u6570\u5316\uff0c\u80fd\u591f\u7075\u6d3b\u5efa\u6a21\u590d\u6742\u5206\u5e03\u3002 \u91c7\u6837\u6548\u7387\u8f83\u4f4e\uff0c\u8ba1\u7b97\u6210\u672c\u8f83\u9ad8\u3002 \u9ad8\u5ea6\u590d\u6742\u6216\u672a\u77e5\u5206\u5e03\u5efa\u6a21\u3002 \u5bf9\u6297\u5f0f VAE (AAE) \u7528 GAN \u7684\u5bf9\u6297\u5b66\u4e60\u66ff\u4ee3 KL \u6563\u5ea6\u6b63\u5219\u5316\uff0c\u5224\u522b\u5668\u7528\u4e8e\u5339\u914d \\(q_\\phi(z)\\) \u548c \\(p(z)\\)\u3002 \u4e0d\u9700\u8981\u663e\u5f0f\u8ba1\u7b97 KL \u6563\u5ea6\uff0c\u9002\u5408\u590d\u6742\u5206\u5e03\u3002 \u5bf9\u6297\u8bad\u7ec3\u53ef\u80fd\u4e0d\u7a33\u5b9a\uff0c\u9700\u8981\u7cbe\u5fc3\u8c03\u8bd5\u3002 \u590d\u6742\u6570\u636e\u5206\u5e03\u751f\u6210\u4efb\u52a1\u3002 \u03b2-VAE \u5728 VAE \u635f\u5931\u4e2d\u589e\u52a0 KL \u6563\u5ea6\u7684\u6743\u91cd \\(1\\beta &gt; 1\\)\uff0c\u5f3a\u8c03\u6f5c\u53d8\u91cf\u7684\u538b\u7f29\u6027\u548c\u89e3\u8026\u6027\u3002 \u63d0\u9ad8\u6f5c\u53d8\u91cf\u7684\u8868\u793a\u8d28\u91cf\uff0c\u66f4\u9002\u5408\u8868\u5f81\u5b66\u4e60\u4efb\u52a1\u3002 \u53ef\u80fd\u5bfc\u81f4\u91cd\u6784\u6027\u80fd\u4e0b\u964d\uff0c\u5e73\u8861\u91cd\u6784\u548c\u6b63\u5219\u5316\u8f83\u96be\u3002 \u8868\u5f81\u5b66\u4e60\uff0c\u7279\u5f81\u89e3\u8026\uff08\u5982\u751f\u6210 disentangled \u8868\u793a\uff09\u3002 \u5c42\u6b21\u5316 VAE \u5f15\u5165\u591a\u4e2a\u5c42\u6b21\u7684\u6f5c\u53d8\u91cf\uff0c\u4f8b\u5982 $z_1 \\sim q_\\phi(z_1 \\mid x), z_2 \\sim q_\\phi(z_2 \\mid z_1) $\uff0c\u6355\u6349\u5206\u5e03\u7684\u5c42\u6b21\u7279\u6027\u3002 \u80fd\u591f\u66f4\u597d\u5730\u8868\u793a\u590d\u6742\u6570\u636e\u5206\u5e03\u7684\u5c42\u6b21\u5173\u7cfb\u3002 \u589e\u52a0\u6a21\u578b\u590d\u6742\u5ea6\uff0c\u8bad\u7ec3\u66f4\u56f0\u96be\u3002 \u9ad8\u7ef4\u590d\u6742\u6570\u636e\uff0c\u4f8b\u5982\u56fe\u50cf\u6216\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1\u3002 <p>\u603b\u7ed3</p> <p>\u5bf9\u4e8eVAE\uff0c\u76f4\u89c2\u4e0a\u770b\uff0c\u56e0\u4e3a\u76f4\u63a5\u4f30\u8ba1 \\(p_\\theta(x)\\) \u662f\u6bd4\u8f83\u56f0\u96be\u7684\uff0c\u56e0\u6b64\u5f15\u5165\u5206\u5e03 \\(q_\\phi(z)\\)\uff0c\u6839\u636e \\(p_\\theta(x) = \\int_z p_\\theta(x, z) \\, dz= \\int_z p_\\theta(x|z) p(z) \\, dz\\) \u6765\u8ba1\u7b97 \\(p_\\theta(x)\\)\u3002</p> <p>\u6211\u4eec\u53ef\u4ee5\u9009\u4e00\u4e2a\\(p(z)\\) \u6bd4\u8f83\u597d\u8ba1\u7b97\u7684\u5206\u5e03\u6765\u7b80\u5316\u95ee\u9898\u3002\u5230\u8fd9\u4e00\u6b65\uff0c\u4ecd\u7136\u6ca1\u6709\u529e\u6cd5\u8ba1\u7b97\u3002\u56e0\u6b64\u8bba\u6587\u91cc\u6709\u4e24\u4e2a\u6bd4\u8f83\u91cd\u8981\u7684\u5047\u8bbe\uff0c</p> <ol> <li>\\(q_\\phi(z|x)\\) \u670d\u4ece\u6b63\u6001\u5206\u5e03</li> <li>\\(p_\\theta(x|z)\\) \u670d\u4ece\u6b63\u6001\u5206\u5e03</li> </ol> <p>\u6839\u636e\u8fd9\u4e24\u4e2a\u5047\u8bbe\u4ece\u800c\u4f7f\u5f97loss \u53ef\u4ee5\u8ba1\u7b97\u3002\u7b2c2\u4e2a\u5047\u8bbe\u53ef\u4ee5\u7406\u89e3\u6210\uff0c\u6211\u4eec\u6ca1\u6709\u529e\u6cd5\u5047\u8bbe \\(p_\\theta(x)\\) \u670d\u4ece\u6b63\u6001\u5206\u5e03\uff0c\u56e0\u6b64\u5f31\u5316\u4e00\u4e0b\u6761\u4ef6, \u90a3 \\(p_\\theta(x)\\) \u76f8\u5f53\u4e8e\u6df7\u5408\u9ad8\u65af\u5206\u5e03\uff08\u79bb\u6563\u548c\u7684\u6781\u9650\u5f62\u5f0f),\u4ece\u8fd9\u4e2a\u5f62\u5f0f\u4e0a\u8fd9\u4e2a\u5047\u8bbe\u662f\u5b58\u5728\u5408\u7406\u6027\u7684\uff0c\u6700\u7ec8\u7684\u5206\u5e03\u4e5f\u662f\u80fd\u6ee1\u8db3\u591a\u6837\u6027\u7684\u8981\u6c42\u3002</p> <p>\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u8fd9\u91ccVAE \u90fd\u662f\u5728\u6781\u5927\u4f3c\u7136\u4f30\u8ba1\u7684\u60c5\u51b5\u4e0b\u8fdb\u884c\u63a8\u5bfc\u7684\u3002\u4f46\u662f\u8861\u91cf\u4e24\u4e2a\u5206\u5e03\u7684\u8ddd\u79bb\u4e5f\u53ef\u4ee5\u7528\u5176\u4ed6\u7684\u5ea6\u91cf\u3002 \u53ef\u4ee5\u53c2\u8003</p> <ul> <li> <p>(Wasserstein AE) https://arxiv.org/pdf/1711.01558</p> </li> <li> <p>(GW-AE) https://arxiv.org/pdf/2209.07007</p> </li> </ul> <p>\u5bf9\u4e8e\u4e0d\u540c\u7684\u5047\u8bbe\u6761\u4ef6\uff0c\u53ef\u4ee5\u5f97\u51fa\u4e0d\u540c\u7684\u5b9e\u73b0\u65b9\u6848\u3002</p>"},{"location":"book/chapter2_generation_theory/mle/#5-normalize-flow-nf","title":"5. normalize flow \uff08NF\uff09","text":"<p>\u5982\u679c\u6620\u5c04\u662f\u53ef\u9006\u7684\uff0c\u90a3\u4e48\u6211\u4eec\u5c31\u53ef\u4ee5\u76f4\u63a5\u8ba1\u7b97\u51fa\u751f\u6210\u6837\u672c\u7684\u5bc6\u5ea6\u51fd\u6570(\u5206\u5e03), \u8fd9\u4e2a\u65f6\u5019\u76f4\u63a5\u4f18\u5316\u6700\u5927\u4f3c\u7136\u5c31\u884c\u4e86\u3002 </p> <p>\u5f52\u4e00\u5316\u6d41\uff08Normalizing Flow\uff09\u662f\u4e00\u79cd\u6982\u7387\u5bc6\u5ea6\u4f30\u8ba1\u65b9\u6cd5\uff0c\u5176\u6838\u5fc3\u601d\u60f3\u662f\u901a\u8fc7\u4e00\u7cfb\u5217\u53ef\u9006\u7684\u53d8\u6362\uff0c\u5c06\u4e00\u4e2a\u590d\u6742\u5206\u5e03\u6620\u5c04\u5230\u4e00\u4e2a\u7b80\u5355\u5206\u5e03\uff08\u901a\u5e38\u662f\u6807\u51c6\u6b63\u6001\u5206\u5e03\uff09\uff0c\u8fd9\u4e9b\u53d8\u6362\u662f\u7531\u5177\u6709\u53ef\u5fae\u53c2\u6570\u7684\u51fd\u6570\u5b9a\u4e49\u7684\uff0c\u56e0\u6b64\u53ef\u4ee5\u901a\u8fc7\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u5bf9\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3\u3002\u4ee5\u4e0b\u662f\u4ece\u6700\u5927\u4f3c\u7136\u7684\u89d2\u5ea6\u8be6\u7ec6\u89e3\u91ca\u5f52\u4e00\u5316\u6d41\u7684\u539f\u7406\uff1a</p>"},{"location":"book/chapter2_generation_theory/mle/#51","title":"5.1 \u6700\u5927\u4f3c\u7136\u4f30\u8ba1","text":"<ol> <li>\u76ee\u6807\uff1a\u901a\u8fc7\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u590d\u6742\u5206\u5e03\u7684\u6982\u7387\u5bc6\u5ea6 \u7ed9\u5b9a\u4e00\u4e2a\u6570\u636e\u96c6 \\(\\{x_1, x_2, \\dots, x_N\\}\\)\uff0c\u6211\u4eec\u5e0c\u671b\u62df\u5408\u4e00\u4e2a\u6982\u7387\u5206\u5e03 \\(p_X(x)\\) \u6765\u63cf\u8ff0\u6570\u636e\u7684\u751f\u6210\u8fc7\u7a0b\u3002\u901a\u8fc7\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\uff08MLE)),\u76ee\u6807\u662f\u6700\u5927\u5316\u6a21\u578b\u5206\u5e03\u5bf9\u6570\u636e\u7684\u5bf9\u6570\u4f3c\u7136\uff1a\\(\\mathcal{L} = \\sum_{i=1}^N \\log p_X(x_i)\\).</li> </ol> <p>\u7531\u4e8e\u76f4\u63a5\u5efa\u6a21 \\(p_X(x)\\) \u53ef\u80fd\u975e\u5e38\u590d\u6742\uff0c\u5f52\u4e00\u5316\u6d41\u901a\u8fc7\u53d8\u6362\u5c06\u590d\u6742\u5206\u5e03 \\(p_X(x)\\) \u6620\u5c04\u5230\u4e00\u4e2a\u7b80\u5355\u7684\u5206\u5e03\uff08\u5982\u6b63\u6001\u5206\u5e03\uff09\u3002</p> <ol> <li>\u53ef\u9006\u53d8\u6362\u4e0e\u53d8\u5316\u516c\u5f0f \u5f52\u4e00\u5316\u6d41\u5047\u8bbe\u6570\u636e \\(x\\) \u53ef\u4ee5\u901a\u8fc7\u4e00\u7cfb\u5217\u53ef\u9006\u53d8\u6362 \\(f\\) \u4ece\u4e00\u4e2a\u7b80\u5355\u7684\u5206\u5e03 \\(p_Z(z)\\) \u4e2d\u751f\u6210\uff1a</li> </ol> \\[  x = f(z), \\quad z = f^{-1}(x), \\] <p>\u5176\u4e2d \\(z\\) \u662f\u6f5c\u5728\u7a7a\u95f4\u4e2d\u7684\u8868\u793a\uff0c\u5176\u6982\u7387\u5bc6\u5ea6\u4e3a \\(p_Z(z)\\)\u3002\u6839\u636e\u6982\u7387\u53d8\u5316\u516c\u5f0f\uff0c\\(x\\) \u7684\u6982\u7387\u5bc6\u5ea6\u53ef\u4ee5\u901a\u8fc7\u53d8\u6362\u7684\u96c5\u53ef\u6bd4\u884c\u5217\u5f0f\u8ba1\u7b97\u4e3a\uff1a</p> \\[  p_X(x) = p_Z(z) \\left| \\det \\frac{\\partial f^{-1}}{\\partial x} \\right|, \\] <p>\u6216\u8005\u7b49\u4ef7\u5730\uff1a</p> \\[  \\log p_X(x) = \\log p_Z(z) - \\log \\left| \\det \\frac{\\partial f(x)}{\\partial x} \\right|. \\] <p>\u8fd9\u91cc \\(\\det \\frac{\\partial f(x)}{\\partial x}\\) \u662f\u53d8\u6362 \\(f\\) \u7684\u96c5\u53ef\u6bd4\u77e9\u9635\u7684\u884c\u5217\u5f0f\u3002</p> <ol> <li>\u6700\u5927\u4f3c\u7136\u4f30\u8ba1 \u4e3a\u4e86\u6700\u5927\u5316\u5bf9\u6570\u4f3c\u7136 \\(\\mathcal{L}\\)\uff0c\u9700\u8981\u8ba1\u7b97\u6bcf\u4e2a\u6570\u636e\u70b9 \\(x\\) \u7684\u5bf9\u6570\u5bc6\u5ea6\uff1a</li> <li> <p>\u8ba1\u7b97\u6f5c\u5728\u53d8\u91cf \\(z\\)\uff1a \u5229\u7528 \\(z = f^{-1}(x)\\)\uff0c\u5c06\u8f93\u5165\u6570\u636e \\(x\\) \u6620\u5c04\u5230\u6f5c\u5728\u7a7a\u95f4\u3002</p> </li> <li> <p>\u8ba1\u7b97\u7b80\u5355\u5206\u5e03 \\(p_Z(z)\\)\uff1a \u7b80\u5355\u5206\u5e03\u901a\u5e38\u9009\u62e9\u4e3a\u6807\u51c6\u6b63\u6001\u5206\u5e03 \\(\\mathcal{N}(0, I)\\)\uff0c\u56e0\u6b64 \\(\\log p_Z(z)\\) \u53ef\u4ee5\u76f4\u63a5\u901a\u8fc7 \\(z\\) \u7684\u503c\u8ba1\u7b97\u3002</p> </li> <li> <p>\u8ba1\u7b97\u96c5\u53ef\u6bd4\u884c\u5217\u5f0f\uff1a \u53d8\u6362 \\(f(x)\\) \u5fc5\u987b\u8bbe\u8ba1\u6210\u6613\u4e8e\u8ba1\u7b97\u5176\u96c5\u53ef\u6bd4\u884c\u5217\u5f0f \\(\\det \\frac{\\partial f(x)}{\\partial x}\\)\u3002</p> </li> </ol> <p>\u6700\u7ec8\uff0c\u901a\u8fc7\u4f18\u5316\u53c2\u6570\uff0c\u6700\u5927\u5316\u4ee5\u4e0b\u5bf9\u6570\u4f3c\u7136\uff1a</p> \\[  \\log p_X(x) = \\log p_Z(f^{-1}(x)) - \\log \\left| \\det \\frac{\\partial f(x)}{\\partial x} \\right|. \\] <ol> <li> <p>\u8bbe\u8ba1\u5f52\u4e00\u5316\u6d41\u7684\u53d8\u6362 \u4e3a\u4e86\u6709\u6548\u8bad\u7ec3\u5f52\u4e00\u5316\u6d41\uff0c\u53d8\u6362 \\(f\\) \u901a\u5e38\u9700\u8981\u6ee1\u8db3\u4ee5\u4e0b\u8981\u6c42\uff1a</p> </li> <li> <p>\u53ef\u9006\u6027 \uff1a\u786e\u4fdd \\(f\\) \u548c \\(f^{-1}\\) \u6613\u4e8e\u8ba1\u7b97\u3002</p> </li> <li> <p>\u96c5\u53ef\u6bd4\u884c\u5217\u5f0f\u9ad8\u6548\u8ba1\u7b97 \uff1a\u4f7f\u5f97 \\(\\det \\frac{\\partial f(x)}{\\partial x}\\) \u7684\u8ba1\u7b97\u6210\u672c\u8f83\u4f4e\u3002</p> </li> </ol> <p>\u5e38\u7528\u7684\u53d8\u6362\u5305\u62ec\uff1a</p> <ol> <li> <p>Affine Coupling Layer \uff1a\u53ea\u5bf9\u90e8\u5206\u53d8\u91cf\u8fdb\u884c\u53d8\u6362\uff0c\u7b80\u5316\u96c5\u53ef\u6bd4\u884c\u5217\u5f0f\u7684\u8ba1\u7b97\u3002</p> </li> <li> <p>Spline Flows \uff1a\u57fa\u4e8e\u5206\u6bb5\u51fd\u6570\u7684\u6d41\uff0c\u80fd\u591f\u6355\u83b7\u66f4\u591a\u590d\u6742\u6027\u3002</p> </li> <li> <p>RealNVP  \u548c Glow \uff1a\u5229\u7528\u7279\u5b9a\u7684\u7ed3\u6784\u8bbe\u8ba1\u9ad8\u6548\u7684\u53d8\u6362\u3002</p> </li> </ol>"},{"location":"book/chapter2_generation_theory/mle/#52-loss","title":"5.2 Loss \u7684\u516c\u5f0f\u76f4\u89c2\u62c6\u89e3","text":"<p>\u5728\u5f52\u4e00\u5316\u6d41\u4e2d\uff0c\u5bf9\u6570\u4f3c\u7136\u53ef\u4ee5\u5199\u4e3a\uff1a</p> \\[  \\log p_X(x) = \\log p_Z(f^{-1}(x)) - \\log \\left| \\det \\frac{\\partial f(x)}{\\partial x} \\right|. \\] <p>\u8bad\u7ec3\u7684\u76ee\u6807\u662f\u6700\u5927\u5316\u8fd9\u4e2a\u5bf9\u6570\u4f3c\u7136 \uff0c\u5373\u6700\u5c0f\u5316\u8d1f\u5bf9\u6570\u4f3c\u7136\uff08Negative Log-Likelihood, NLL\uff09\uff1a</p> \\[  \\text{Loss} = -\\mathbb{E}_{x \\sim p_X} \\left[ \\log p_Z(f^{-1}(x)) - \\log \\left| \\det \\frac{\\partial f(x)}{\\partial x} \\right| \\right]. \\] <p>\u4ece\u76f4\u89c2\u89d2\u5ea6\uff0cLoss \u7684\u4e24\u4e2a\u90e8\u5206\u53ef\u4ee5\u7406\u89e3\u4e3a\uff1a</p> <ol> <li> <p>\u6f5c\u5728\u7a7a\u95f4\u7684\u8d1f\u5bf9\u6570\u5bc6\u5ea6 \uff08\\(-\\log p_Z(f^{-1}(x))\\)\uff09\uff1a</p> </li> <li> <p>\u8fd9\u4e2a\u9879\u8868\u793a\u6570\u636e\u70b9 \\(x\\) \u6620\u5c04\u5230\u6f5c\u5728\u7a7a\u95f4\u7684\u70b9 \\(z = f^{-1}(x)\\) \u5728\u7b80\u5355\u5206\u5e03 \\(p_Z(z)\\) \u4e0a\u7684\u6982\u7387\u5bc6\u5ea6\u3002</p> </li> <li> <p>\u76f4\u89c2\u4e0a\uff0c\u8d8a\u9ad8\u7684\u5bc6\u5ea6\u8868\u793a \\(x\\) \u88ab\u6a21\u578b\u89e3\u91ca\u5f97\u8d8a\u597d\uff0cLoss \u8d8a\u5c0f\u3002</p> </li> <li> <p>\u76ee\u6807\u662f\u8ba9\u6570\u636e\u70b9 \\(z\\) \u66f4\u63a5\u8fd1\u7b80\u5355\u5206\u5e03\u7684\u9ad8\u5bc6\u5ea6\u533a\u57df\uff08\u5982\u6807\u51c6\u6b63\u6001\u5206\u5e03\u7684\u4e2d\u5fc3\uff09\u3002</p> </li> <li> <p>\u53d8\u6362\u590d\u6742\u6027\u7684\u4ee3\u4ef7 \uff08\\(-\\log \\left| \\det \\frac{\\partial f(x)}{\\partial x} \\right|\\)\uff09\uff1a</p> </li> <li> <p>\u8fd9\u4e2a\u9879\u91cf\u5316\u4e86\u53d8\u6362 \\(f\\) \u7684\u590d\u6742\u6027\uff0c\u7279\u522b\u662f\u53d8\u6362\u5982\u4f55\u62c9\u4f38\u6216\u538b\u7f29\u7a7a\u95f4\u3002</p> </li> <li> <p>\u76f4\u89c2\u4e0a\uff0c\u5982\u679c\u53d8\u6362\u9700\u8981\u5bf9\u6570\u636e\u8fdb\u884c\u5927\u8303\u56f4\u7684\u626d\u66f2\u6216\u62c9\u4f38\u6765\u5339\u914d\u6570\u636e\u5206\u5e03\uff0c\u96c5\u53ef\u6bd4\u884c\u5217\u5f0f\u4f1a\u8f83\u5927\uff0c\u5bfc\u81f4\u8fd9\u4e2a\u9879\u7684\u503c\u589e\u52a0\uff0c\u4ece\u800c\u635f\u5931\u589e\u5927\u3002</p> </li> <li> <p>\u76ee\u6807\u662f\u8ba9\u53d8\u6362 \\(f\\) \u5c3d\u91cf\u7b80\u5355\uff0c\u540c\u65f6\u80fd\u6709\u6548\u5339\u914d\u6570\u636e\u5206\u5e03\u3002</p> </li> </ol>"},{"location":"book/chapter2_generation_theory/mle/#53","title":"5.3 \u7528\u65e5\u5e38\u6bd4\u55bb\u76f4\u89c2\u7406\u89e3","text":"<p>\u53ef\u4ee5\u5c06 Loss \u7684\u4e24\u4e2a\u90e8\u5206\u7c7b\u6bd4\u4e3a\uff1a</p> <ol> <li> <p>\u9002\u914d\u6570\u636e\u7684\u8fc7\u7a0b \uff1a</p> </li> <li> <p>\u60f3\u8c61\u4f60\u6709\u4e00\u5757\u5e03\uff08\u7b80\u5355\u5206\u5e03\uff09\uff0c\u9700\u8981\u5c06\u5b83\u62c9\u4f38\u548c\u6298\u53e0\uff08\u53d8\u6362\uff09\u4ee5\u5b8c\u5168\u8986\u76d6\u4e00\u4e2a\u590d\u6742\u7684\u5730\u5f62\uff08\u6570\u636e\u5206\u5e03\uff09\u3002</p> </li> <li> <p>\u5e03\u7684\u6bcf\u4e2a\u90e8\u5206\u8d8a\u63a5\u8fd1\u76ee\u6807\u5730\u5f62\u7684\u5b9e\u9645\u5f62\u72b6\uff08\u5373\u6982\u7387\u5bc6\u5ea6\u9ad8\u7684\u533a\u57df\uff09\uff0c\u5c31\u8bf4\u660e\u4f60\u8d8a\u8d34\u5408\u76ee\u6807\uff0c\u7b2c\u4e00\u9879\u7684 Loss \u8d8a\u5c0f\u3002</p> </li> <li> <p>\u62c9\u4f38\u5e03\u7684\u590d\u6742\u6027 \uff1a</p> </li> <li> <p>\u5982\u679c\u9700\u8981\u5bf9\u5e03\u8fdb\u884c\u975e\u5e38\u590d\u6742\u7684\u53d8\u5f62\uff0c\u5e03\u4f1a\u53d8\u5f97\u66f4\u7d27\u6216\u66f4\u677e\uff08\u5bf9\u5e94\u96c5\u53ef\u6bd4\u884c\u5217\u5f0f\u7684\u53d8\u5316\uff09\uff0c\u8fd9\u4f1a\u589e\u52a0\u7b2c\u4e8c\u9879\u7684 Loss\u3002</p> </li> </ol> <p>\u6700\u7ec8\uff0cLoss \u5c31\u662f\u8fd9\u4e24\u8005\u7684\u52a0\u6743\u603b\u6210\u672c\uff1a\u65e2\u5e0c\u671b\u5e03\u80fd\u5f88\u597d\u5730\u8986\u76d6\u5730\u5f62\uff0c\u53c8\u5e0c\u671b\u53d8\u5f62\u7684\u8fc7\u7a0b\u4e0d\u8981\u8fc7\u4e8e\u590d\u6742\u3002</p> <p>\u5b9e\u9645\u5b9e\u73b0\u7684\u65f6\u5019\uff0cnormalize flow \u53ef\u4ee5\u8bbe\u8ba1\u4e3a\u53ef\u9006\u6620\u5c04\u7684\u590d\u5408\u3002</p>"},{"location":"book/chapter2_generation_theory/mle/#6-diffusion-model","title":"6. Diffusion Model","text":"<p>\u6211\u4eec\u4e5f\u53ef\u4ee5\u4ece\u6700\u5927\u4f3c\u7136\u7684\u89d2\u5ea6\u63a8\u5230\u51fa Diffusion model \u7684\u4f18\u5316\u76ee\u6807\u3002\u7c7b\u4f3c\u4e8eVAE\uff0c\u4e0d\u8fc7\u8fd9\u91cc\u7684\\(z\\) \u8981\u770b\u505a\u4e3a \\(X_{1:T}\\), \\(x\\) \u4e3a \\(X_0\\)\u3002\u540c\u6837\u5229\u7528\u53d8\u5206\u5f97\u5230ELBO.</p> <p>1. \u6700\u5927\u4f3c\u7136\u76ee\u6807</p> <p>\u6700\u5927\u5316\u6570\u636e\u5206\u5e03\u7684\u5bf9\u6570\u4f3c\u7136 \\(\\log p_\\theta(x_0)\\)\u3002\u6839\u636e\u53d8\u5206\u539f\u7406\uff0c\u5f15\u5165\u4e2d\u95f4\u53d8\u91cf \\(x_{1:T}\\)\uff0c\u5f97\u5230\uff1a</p> \\[  \\log p_\\theta(x_0) = \\log \\int p_\\theta(x_0, x_{1:T}) \\, dx_{1:T}. \\] <p>\u901a\u8fc7\u5f15\u5165\u5206\u5e03 \\(q(x_{1:T} \\mid x_0)\\)\uff0c\u5229\u7528\u5bf9\u6570\u5206\u89e3\uff1a</p> \\[  \\log p_\\theta(x_0) = \\mathbb{E}_{q(x_{1:T} \\mid x_0)} \\left[ \\log \\frac{p_\\theta(x_0, x_{1:T})}{q(x_{1:T} \\mid x_0)} \\right] + D_{\\text{KL}}(q(x_{1:T} \\mid x_0) \\| p_\\theta(x_{1:T} \\mid x_0)). \\] <p>\u7531\u4e8e KL \u6563\u5ea6\u975e\u8d1f\uff0c\u5f97\u5230\u53d8\u5206\u4e0b\u754c\uff08ELBO\uff09\uff1a</p> \\[  \\log p_\\theta(x_0) \\geq \\mathbb{E}_{q(x_{1:T} \\mid x_0)} \\left[ \\log \\frac{p_\\theta(x_0, x_{1:T})}{q(x_{1:T} \\mid x_0)} \\right]. \\] <p>2. \u8054\u5408\u5206\u5e03\u5206\u89e3</p> <p>\u6a21\u578b\u7684\u8054\u5408\u5206\u5e03 \\(p_\\theta(x_0, x_{1:T})\\) \u548c\u6269\u6563\u8fc7\u7a0b \\(q(x_{1:T} \\mid x_0)\\) \u5206\u522b\u8868\u793a\u4e3a\uff1a</p> \\[  p_\\theta(x_0, x_{1:T}) = p(x_T) \\prod_{t=1}^T p_\\theta(x_{t-1} \\mid x_t), \\] \\[  q(x_{1:T} \\mid x_0) = \\prod_{t=1}^T q(x_t \\mid x_{t-1}), \\] <p>\u4ee3\u5165 ELBO\uff1a</p> \\[  \\log p_\\theta(x_0) \\geq \\mathbb{E}*{q(x*{1:T} \\mid x_0)} \\left[ \\log \\frac{p(x_T) \\prod_{t=1}^T p_\\theta(x_{t-1} \\mid x_t)}{\\prod_{t=1}^T q(x_t \\mid x_{t-1})} \\right]. \\] <p>3. \u5206\u89e3\u548c\u7b80\u5316</p> <p>\u5c06\u5bf9\u6570\u5c55\u5f00\uff1a</p> \\[  \\log p_\\theta(x_0) \\geq \\mathbb{E}*{q(x*{1:T} \\mid x_0)} \\Bigg[ \\log p(x_T) + \\sum_{t=1}^T \\log p_\\theta(x_{t-1} \\mid x_t) - \\sum_{t=1}^T \\log q(x_t \\mid x_{t-1}) \\Bigg]. \\] <p>\u6ce8\u610f \\(q(x_t \\mid x_{t-1})\\) \u662f\u6269\u6563\u8fc7\u7a0b\u7684\u5df2\u77e5\u9ad8\u65af\u5206\u5e03\uff0c\u4e0b\u4e00\u6b65\u5c06\u91cd\u70b9\u5206\u6790\u3002</p> <p>4. \u9010\u6b65\u8c03\u6574\u5206\u5e03\u9879</p> <p>\u7531\u4e8e \\(q(x_{1:T} \\mid x_0)\\) \u662f\u5df2\u77e5\u7684\u52a0\u566a\u8fc7\u7a0b\uff0c\u6211\u4eec\u53ef\u4ee5\u5229\u7528\u6761\u4ef6\u5206\u5e03 \\(q(x_{t-1} \\mid x_t, x_0)\\) \u6765\u66ff\u4ee3\u76f4\u63a5\u7684 \\(q(x_t \\mid x_{t-1})\\)\u3002\u901a\u8fc7 \\(q(x_{t-1} \\mid x_t, x_0) \\cdot q(x_t \\mid x_0)\\) \u7684\u5173\u7cfb\uff1a</p> \\[  \\mathbb{E}_{q(x_{1:T} \\mid x_0)} \\Bigg[ \\sum_{t=1}^T \\log \\frac{p_\\theta(x_{t-1} \\mid x_t)}{q(x_t \\mid x_{t-1})} \\Bigg] = \\mathbb{E}_{q(x_{1:T} \\mid x_0)} \\Bigg[ \\log \\frac{p_\\theta(x_{t-1} \\mid x_t)}{q(x_{t-1} \\mid x_t, x_0)} \\Bigg]. \\] <p>\u4e8e\u662f\uff0c\u76ee\u6807\u5206\u89e3\u4e3a\u4ee5\u4e0b\u51e0\u90e8\u5206\uff1a</p> <ol> <li>\u91cd\u5efa\u8bef\u5dee\uff08Reconstruction Term\uff09\uff1a</li> </ol> \\[  \\mathbb{E}_{q(x_{1:T} \\mid x_0)} \\Big[ \\log p_\\theta(x_0 \\mid x_1) \\Big]. \\] <ol> <li>\u5148\u9a8c\u5339\u914d\u8bef\u5dee\uff08Prior Matching Term\uff09\uff1a</li> </ol> \\[  \\mathbb{E}_{q(x_T \\mid x_0)} \\Big[ \\log p(x_T) - \\log q(x_T \\mid x_0) \\Big] = -D_{\\text{KL}}(q(x_T \\mid x_0) \\| p(x_T)). \\] <ol> <li>\u53bb\u566a\u8bef\u5dee\uff08Denoising Matching Term\uff09\uff1a</li> </ol> \\[  \\sum_{t=2}^T \\mathbb{E}_{q(x_t \\mid x_0)} \\Big[ D_{\\text{KL}}(q(x_{t-1} \\mid x_t, x_0) \\| p_\\theta(x_{t-1} \\mid x_t)) \\Big]. \\] <p>5. \u6700\u7ec8\u635f\u5931\u51fd\u6570</p> <p>\u6700\u7ec8\u635f\u5931\u51fd\u6570\u4e3a\uff1a</p> \\[  \\mathcal{L} = \\mathbb{E}_{q(x_{1:T} \\mid x_0)} \\Big[ \\underbrace{-\\log p_\\theta(x_0 \\mid x_1)}_{\\text{\u91cd\u5efa\u8bef\u5dee}} + \\underbrace{D_{\\text{KL}}(q(x_T \\mid x_0) \\| p(x_T))}_{\\text{\u5148\u9a8c\u5339\u914d\u8bef\u5dee}} + \\underbrace{\\sum_{t=2}^T D_{\\text{KL}}(q(x_{t-1} \\mid x_t, x_0) \\| p_\\theta(x_{t-1} \\mid x_t))}_{\\text{\u53bb\u566a\u8bef\u5dee}} \\Big]. \\] <p>6. \u7b80\u5316\u4e0e\u4f18\u5316</p> <p>\u901a\u8fc7\u5047\u8bbe \\(p_\\theta(x_{t-1} \\mid x_t)\\) \u548c \\(q(x_{t-1} \\mid x_t, x_0)\\) \u90fd\u662f\u9ad8\u65af\u5206\u5e03\uff0c\u8fdb\u4e00\u6b65\u4f18\u5316\u53bb\u566a\u8bef\u5dee\uff1a</p> \\[  \\mathcal{L}_{\\text{DDPM}} = \\mathbb{E}_{x_0, \\epsilon, t} \\Big[ \\| \\epsilon - \\epsilon_\\theta(x_t, t) \\|^2 \\Big]. \\]"},{"location":"book/chapter2_generation_theory/mle/#7","title":"7. \u81ea\u56de\u5f52\u6a21\u578b","text":"<ol> <li>\u56fe\u7247\u8868\u793a\u4e0e\u6700\u5927\u4f3c\u7136\u76ee\u6807</li> </ol> <p>\u5bf9\u4e8e\u4e00\u5f20\u56fe\u7247 \\(\\(\\mathbf{x}\\)\\)\uff0c\u6211\u4eec\u53ef\u4ee5\u5c06\u5176\u8868\u793a\u4e3a\u50cf\u7d20\u503c\u7684\u5e8f\u5217\uff1a</p> \\[  \\mathbf{x} = (x_1, x_2, \\ldots, x_T) \\] <p>\u5176\u4e2d \\(T\\) \u662f\u56fe\u7247\u50cf\u7d20\u7684\u603b\u6570\u3002\u751f\u6210\u56fe\u7247\u7684\u76ee\u6807\u662f\u6700\u5927\u5316\u56fe\u7247\u5728\u6a21\u578b\u4e0b\u7684\u6982\u7387\uff1a</p> \\[  P(\\mathbf{x}|\\theta) = P(x_1, x_2, \\ldots, x_T|\\theta) \\] <p>\u8fd9\u91cc\uff0c\\(\\theta\\) \u662f\u6a21\u578b\u7684\u53c2\u6570\u3002</p> <ol> <li>\u81ea\u56de\u5f52\u5206\u89e3 \u6839\u636e\u6982\u7387\u7684\u94fe\u5f0f\u89c4\u5219\uff0c\u56fe\u7247\u7684\u8054\u5408\u6982\u7387\u53ef\u4ee5\u5206\u89e3\u4e3a\u6bcf\u4e2a\u50cf\u7d20\u7684\u6761\u4ef6\u6982\u7387\u7684\u4e58\u79ef\uff1a</li> </ol> \\[  P(\\mathbf{x}|\\theta) = \\prod_{t=1}^T P(x_t | x_1, x_2, \\ldots, x_{t-1}, \\theta) \\] <p>\u8fd9\u8868\u793a\u5f53\u524d\u50cf\u7d20 \\(x_t\\) \u7684\u751f\u6210\u4f9d\u8d56\u4e8e\u4e4b\u524d\u751f\u6210\u7684\u50cf\u7d20\u503c\u3002</p> <ol> <li>\u5bf9\u6570\u4f3c\u7136\u51fd\u6570</li> </ol> <p>\u7531\u4e8e\u76f4\u63a5\u4f18\u5316\u6982\u7387\u5b58\u5728\u6570\u503c\u4e0d\u7a33\u5b9a\u6027\uff0c\u6211\u4eec\u4f7f\u7528\u5bf9\u6570\u5f62\u5f0f\uff1a</p> \\[  \\log P(\\mathbf{x}|\\theta) = \\sum_{t=1}^T \\log P(x_t | x_1, x_2, \\ldots, x_{t-1}, \\theta) \\] <ol> <li>\u8d1f\u5bf9\u6570\u4f3c\u7136\u4f5c\u4e3a\u635f\u5931\u51fd\u6570</li> </ol> <p>\u4e3a\u4e86\u8fdb\u884c\u6700\u5c0f\u5316\u4f18\u5316\uff0c\u8f6c\u5316\u4e3a\u8d1f\u5bf9\u6570\u4f3c\u7136\u5f62\u5f0f\uff1a</p> \\[  \\mathcal{L}(\\theta) = - \\log P(\\mathbf{x}|\\theta) = - \\sum_{t=1}^T \\log P(x_t | x_1, x_2, \\ldots, x_{t-1}, \\theta) \\] <p>\u8fd9\u5c31\u662f\u81ea\u56de\u5f52\u751f\u6210\u6a21\u578b\u7684\u635f\u5931\u51fd\u6570\u3002</p> <ol> <li>\u50cf\u7d20\u5206\u5e03\u5efa\u6a21</li> </ol> <p>\u4e3a\u4e86\u8ba1\u7b97\u6761\u4ef6\u6982\u7387 \\(\\(P(x_t | x_1, x_2, \\ldots, x_{t-1}, \\theta)\\)\\)\uff0c\u9700\u8981\u5bf9\u50cf\u7d20\u503c\u7684\u5206\u5e03\u8fdb\u884c\u5efa\u6a21\u3002\u5e38\u89c1\u7684\u9009\u62e9\u5305\u62ec\uff1a</p> <ol> <li> <p>\u79bb\u6563\u50cf\u7d20\u503c</p> <p>\u5982\u679c\u50cf\u7d20\u503c\u662f\u79bb\u6563\u7684\uff08\u5982 \\([0, 255]\\) \u7684\u6574\u6570\u503c)),\u6761\u4ef6\u6982\u7387 \\(P(x_t|\\cdot)\\) \u53ef\u4ee5\u901a\u8fc7\u5206\u7c7b\u5668\uff08\u5982 softmax \u8f93\u51fa\u5c42\uff09\u5efa\u6a21\uff1a</p> \\[ P(x_t | x_1, x_2, \\ldots, x_{t-1}, \\theta) = \\text{Softmax}(f_\\theta(x_1, x_2, \\ldots, x_{t-1})) \\] <p>\u6b64\u65f6\uff0c\u635f\u5931\u51fd\u6570\u53ef\u4ee5\u5177\u4f53\u5316\u4e3a\u4ea4\u53c9\u71b5\u635f\u5931\uff1a</p> \\[ \\mathcal{L}(\\theta) = - \\sum_{t=1}^T \\log P(x_t | x_1, x_2, \\ldots, x_{t-1}, \\theta) \\] </li> <li> <p>\u8fde\u7eed\u50cf\u7d20\u503c</p> <p>\u5982\u679c\u50cf\u7d20\u503c\u662f\u8fde\u7eed\u7684\uff08\u5982\u5f52\u4e00\u5316\u5230 \\([0, 1]\\) \u7684\u6d6e\u70b9\u6570)),\u901a\u5e38\u5047\u8bbe\u50cf\u7d20\u503c\u670d\u4ece\u67d0\u79cd\u6982\u7387\u5206\u5e03\uff08\u5982\u9ad8\u65af\u5206\u5e03\uff09\uff1a</p> \\[ P(x_t | x_1, x_2, \\ldots, x_{t-1}, \\theta) = \\mathcal{N}(x_t | \\mu_\\theta, \\sigma_\\theta) \\] <p>\u5176\u4e2d \\(\\mu_\\theta\\) \u548c \\(\\sigma_\\theta\\) \u662f\u6761\u4ef6\u5747\u503c\u548c\u6807\u51c6\u5dee\uff0c\u7531\u6a21\u578b\u9884\u6d4b\u5f97\u5230\u3002\u8d1f\u5bf9\u6570\u4f3c\u7136\u635f\u5931\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\u7b49\u4ef7\u4e8e\u5747\u65b9\u8bef\u5dee\uff08MSE\uff09\uff1a</p> \\[ \\mathcal{L}(\\theta) = \\frac{1}{2} \\sum_{t=1}^T \\left(x_t - \\mu_\\theta(x_1, x_2, \\ldots, x_{t-1})\\right)^2 \\] </li> <li> <p>\u751f\u6210\u56fe\u7247\u7684\u50cf\u7d20\u987a\u5e8f</p> </li> </ol> <p>\u4e3a\u4e86\u5b9a\u4e49\u5e8f\u5217\u751f\u6210\u987a\u5e8f\uff0c\u81ea\u56de\u5f52\u6a21\u578b\u9700\u8981\u660e\u786e\u50cf\u7d20\u7684\u751f\u6210\u65b9\u5f0f\u3002\u5e38\u89c1\u65b9\u6cd5\u5305\u62ec\uff1a</p> <ul> <li>\u884c\u4f18\u5148\u751f\u6210 \uff1a\u9010\u884c\u4ece\u5de6\u5230\u53f3\u3001\u4ece\u4e0a\u5230\u4e0b\u751f\u6210\u50cf\u7d20\u3002</li> <li>\u5757\u4f18\u5148\u751f\u6210 \uff1a\u4ee5\u5757\u7684\u5f62\u5f0f\u751f\u6210\u50cf\u7d20\u3002</li> <li> <p>\u81ea\u5b9a\u4e49\u987a\u5e8f \uff1a\u57fa\u4e8e\u7279\u5b9a\u7684\u6392\u5217\u89c4\u5219\u751f\u6210\u3002 \u987a\u5e8f\u7684\u9009\u62e9\u76f4\u63a5\u5f71\u54cd\u6761\u4ef6\u6982\u7387\u7684\u5efa\u6a21\u65b9\u5f0f\u3002</p> </li> <li> <p>\u603b\u7ed3\uff1a\u81ea\u56de\u5f52\u751f\u6210\u56fe\u7247\u6a21\u578b\u7684\u635f\u5931</p> </li> </ul> <p>\u81ea\u56de\u5f52\u6a21\u578b\u7528\u4e8e\u56fe\u7247\u751f\u6210\u7684\u901a\u7528\u635f\u5931\u51fd\u6570\u4e3a\uff1a</p> \\[  \\mathcal{L}(\\theta) = - \\sum_{t=1}^T \\log P(x_t | x_1, x_2, \\ldots, x_{t-1}, \\theta) \\] <ul> <li> <p>\u5bf9\u4e8e\u79bb\u6563\u50cf\u7d20\uff0c\u4f7f\u7528\u4ea4\u53c9\u71b5\u635f\u5931\u3002</p> </li> <li> <p>\u5bf9\u4e8e\u8fde\u7eed\u50cf\u7d20\uff0c\u901a\u5e38\u4f7f\u7528\u5747\u65b9\u8bef\u5dee\u6216\u8d1f\u5bf9\u6570\u4f3c\u7136\u3002</p> </li> </ul> <p>\u901a\u8fc7\u5bf9\u6bcf\u4e2a\u50cf\u7d20\u7684\u6761\u4ef6\u6982\u7387\u8fdb\u884c\u4f18\u5316\uff0c\u6a21\u578b\u80fd\u591f\u5b66\u4e60\u751f\u6210\u56fe\u7247\u7684\u590d\u6742\u5206\u5e03\u3002</p>"},{"location":"book/chapter2_generation_theory/mle/#8-refenrence","title":"8. Refenrence","text":"<ul> <li>normalize flow</li> <li>Diffusion \u7efc\u8ff0\u9605\u8bfb\u7b14\u8bb0</li> </ul>"},{"location":"book/chapter3_energy_based_model/cd/","title":"\u5bf9\u6bd4\u6563\u5ea6\uff08CD\uff09\u65b9\u6cd5\u8be6\u89e3\uff1a\u4ece\u7406\u8bba\u63a8\u5bfc\u5230\u76f4\u89c2\u7406\u89e3","text":""},{"location":"book/chapter3_energy_based_model/cd/#1","title":"1. \u5f15\u8a00","text":"<p>\u5728\u8bad\u7ec3\u80fd\u91cf\u6a21\u578b\uff08\u5982\u53d7\u9650\u73bb\u5c14\u5179\u66fc\u673a\uff0cRBM\uff09\u65f6\uff0c\u914d\u5206\u51fd\u6570\u7684\u8ba1\u7b97\u4e00\u76f4\u662f\u4e00\u4e2a\u6838\u5fc3\u96be\u9898\u3002\u4f20\u7edf\u7684\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u9700\u8981\u8ba1\u7b97\u914d\u5206\u51fd\u6570\u7684\u68af\u5ea6\uff0c\u4f46\u5728\u9ad8\u7ef4\u7a7a\u95f4\u4e2d\u8fd9\u4e00\u8fc7\u7a0b\u51e0\u4e4e\u4e0d\u53ef\u884c\u3002 2002\u5e74\uff0cGeoffrey Hinton\u63d0\u51fa \u5bf9\u6bd4\u6563\u5ea6\uff08Contrastive Divergence, CD \u65b9\u6cd5\uff0c\u901a\u8fc7\u5de7\u5999\u7684\u8fd1\u4f3c\u7b56\u7565\uff0c\u7ed5\u8fc7\u4e86\u914d\u5206\u51fd\u6570\u7684\u663e\u5f0f\u8ba1\u7b97\uff0c\u6210\u4e3a\u8bad\u7ec3\u80fd\u91cf\u6a21\u578b\u7684\u91cc\u7a0b\u7891\u5f0f\u5de5\u4f5c\u3002 \u672c\u6587\u5c06\u6df1\u5165\u89e3\u6790CD\u7684\u6570\u5b66\u539f\u7406\u3001\u76f4\u89c2\u89e3\u91ca\u53ca\u5176\u5b9e\u9645\u5e94\u7528\u3002</p>"},{"location":"book/chapter3_energy_based_model/cd/#2-1","title":"2. 1.\u95ee\u9898\u80cc\u666f\uff1a\u80fd\u91cf\u6a21\u578b\u4e0e\u914d\u5206\u51fd\u6570","text":"<p>\u80fd\u91cf\u6a21\u578b\u901a\u8fc7\u80fd\u91cf\u51fd\u6570\\(E_\\theta(x)\\)\u5b9a\u4e49\u6982\u7387\u5206\u5e03\uff1a</p> \\[ p_\\theta(x) = \\frac{e^{-E_\\theta(x)}}{Z(\\theta)}, \\quad Z(\\theta) = \\int e^{-E_\\theta(x)} dx, \\] <p>\u5176\u4e2d\\(Z(\\theta)\\)\u662f\u914d\u5206\u51fd\u6570\u3002\u8bad\u7ec3\u76ee\u6807\u662f\u6700\u5927\u5316\u6570\u636e\u7684\u5bf9\u6570\u4f3c\u7136\uff1a</p> \\[ \\mathcal{L}(\\theta) = E_{x\\sim p_{\\text{data}}(x)}[\\log p_\\theta(x_i)] \\] <p>\u914d\u5206\u51fd\u6570\u7684\u68af\u5ea6\u53ef\u901a\u8fc7\u5bf9\u80fd\u91cf\u51fd\u6570\u6c42\u5bfc\u5f97\u5230\uff1a</p> \\[ \\begin{aligned} \\nabla_\\theta \\log Z(\\theta) &amp;= \\frac{1}{Z(\\theta)} \\nabla_\\theta Z(\\theta) \\\\ &amp;= \\frac{1}{Z(\\theta)} \\int \\nabla_\\theta e^{-E_\\theta(x)} dx \\\\ &amp;= \\frac{1}{Z(\\theta)} \\int -e^{-E_\\theta(x)} \\nabla_\\theta E_\\theta(x) dx \\\\ &amp;= -\\mathbb{E}_{p_\\theta(x)} \\left[ \\nabla_\\theta E_\\theta(x) \\right]. \\end{aligned} \\] <p>\u5c06\u5bf9\u6570\u4f3c\u7136\u7684\u68af\u5ea6\u5206\u89e3\u4e3a\u6570\u636e\u9879\u548c\u6a21\u578b\u9879\uff1a</p> \\[ \\begin{aligned} \\nabla_\\theta \\mathcal{L}(\\theta) &amp;= \\mathbb{E}_{p_{\\text{data}}(x)} \\left[ \\nabla_\\theta \\log p_\\theta(x) \\right] \\\\ &amp;= \\mathbb{E}_{p_{\\text{data}}(x)} \\left[ -\\nabla_\\theta E_\\theta(x) - \\nabla_\\theta \\log Z(\\theta) \\right] \\\\ &amp;= -\\mathbb{E}_{p_{\\text{data}}(x)} \\left[ \\nabla_\\theta E_\\theta(x) \\right] + \\mathbb{E}_{p_\\theta(x)} \\left[ \\nabla_\\theta E_\\theta(x) \\right]. \\end{aligned} \\] <p>\u5176\u4e2d\uff1a</p> <ul> <li>\u7b2c\u4e00\u9879\uff1a\u6570\u636e\u5206\u5e03\u7684\u671f\u671b\uff0c\u76f4\u63a5\u8ba1\u7b97\u8bad\u7ec3\u6837\u672c\u7684\u68af\u5ea6\u3002</li> <li>\u7b2c\u4e8c\u9879\uff1a\u6a21\u578b\u5206\u5e03\u7684\u671f\u671b\uff0c\u4f20\u7edf\u65b9\u6cd5\u9700MCMC\u91c7\u6837\uff0cCD\u901a\u8fc7\u77ed\u94fe\u91c7\u6837\u8fd1\u4f3c\u3002</li> </ul> <p>\u68af\u5ea6\u8ba1\u7b97\u96be\u9898\uff1a \u5bf9\u6570\u4f3c\u7136\u7684\u68af\u5ea6\u4e3a\uff1a</p> \\[ \\nabla_\\theta \\mathcal{L}(\\theta) = -\\mathbb{E}_{p_{\\text{data}}} [\\nabla_\\theta E_\\theta(x)] + \\mathbb{E}_{p_\\theta(x)} [\\nabla_\\theta E_\\theta(x)]. \\] <p>\u5176\u4e2d\u7b2c\u4e8c\u9879 \\(\\mathbb{E}_{p_\\theta(x)}[\\cdot]\\) \u9700\u8981\u4ece\u6a21\u578b\u5206\u5e03\u4e2d\u91c7\u6837\uff0c\u4f46\u4f20\u7edfMCMC\u65b9\u6cd5\u56e0\u9ad8\u7ef4\u7a7a\u95f4\u6536\u655b\u6162\u800c\u4e0d\u53ef\u884c\u3002</p>"},{"location":"book/chapter3_energy_based_model/cd/#3-2-cd","title":"3. 2. CD\u7684\u6838\u5fc3\u601d\u60f3","text":""},{"location":"book/chapter3_energy_based_model/cd/#31-21","title":"3.1 2.1. \u76f4\u89c2\u89e3\u91ca","text":"<p>CD\u7684\u6838\u5fc3\u601d\u60f3\u662f\u7528\u5c11\u91cfMCMC\u6b65\u9aa4\u751f\u6210\u8fd1\u4f3c\u6837\u672c\uff0c\u66ff\u4ee3\u4f20\u7edf\u65b9\u6cd5\u4e2d\u7684\u5b8c\u5168\u6536\u655b\u94fe\uff1a</p> <ul> <li>\u4ece\u6570\u636e\u5206\u5e03\u542f\u52a8\u94fe\uff1a\u7528\u8bad\u7ec3\u6837\u672c \\(x_{\\text{data}}\\) \u521d\u59cb\u5316MCMC\u94fe\uff0c\u800c\u975e\u968f\u673a\u566a\u58f0\u3002</li> <li>\u77ed\u94fe\u91c7\u6837\uff1a\u4ec5\u8fd0\u884c \\(k\\) \u6b65\uff08\u901a\u5e38\\(k=1\\)\uff09MCMC\uff08\u5982Gibbs\u91c7\u6837\uff09\u751f\u6210\u8d1f\u6837\u672c \\(x_{\\text{CD_k}}\\)\u3002</li> <li>\u68af\u5ea6\u8fd1\u4f3c\uff1a\u7528 \\(x_{\\text{CD_k}}\\) \u8fd1\u4f3c\u6a21\u578b\u5206\u5e03\u7684\u671f\u671b\uff0c\u8ba1\u7b97\u68af\u5ea6\u66f4\u65b0\u53c2\u6570\u3002</li> </ul> <p>\u4e3a\u4ec0\u4e48\u6709\u6548\uff1f</p> <ul> <li>\u6570\u636e\u5206\u5e03\u9760\u8fd1\u6a21\u578b\u5206\u5e03\uff0c\u77ed\u94fe\u5373\u53ef\u903c\u8fd1\u76ee\u6807\u5206\u5e03\u3002</li> <li>\u907f\u514d\u4e86\u957f\u94feMCMC\u7684\u9ad8\u8ba1\u7b97\u6210\u672c\u3002</li> </ul>"},{"location":"book/chapter3_energy_based_model/cd/#4-3","title":"4. 3. \u6570\u5b66\u63a8\u5bfc","text":""},{"location":"book/chapter3_energy_based_model/cd/#41-31","title":"4.1 3.1  \u76ee\u6807\u51fd\u6570\u4e0e\u68af\u5ea6","text":"<p>\u6700\u5927\u5316\u5bf9\u6570\u4f3c\u7136\u7b49\u4ef7\u4e8e\u6700\u5c0f\u5316KL\u6563\u5ea6\uff1a</p> \\[ D_{\\text{KL}}(p_{\\text{data}} \\| p_\\theta) = \\mathbb{E}_{p_{\\text{data}}} [\\log p_{\\text{data}}(x) - \\log p_\\theta(x)]. \\] <p>\u5176\u68af\u5ea6\u4e3a\uff1a</p> \\[ \\nabla_\\theta D_{\\text{KL}} = -\\mathbb{E}_{p_{\\text{data}}} [\\nabla_\\theta \\log p_\\theta(x)] + \\mathbb{E}_{p_\\theta(x)} [\\nabla_\\theta \\log p_\\theta(x)]. \\]"},{"location":"book/chapter3_energy_based_model/cd/#42-32-cd","title":"4.2 3.2. CD\u7684\u6838\u5fc3\u7b56\u7565","text":"<p>\u76f4\u63a5\u7528\u77ed\u94feMCMC\u91c7\u6837\u8fd1\u4f3c\u6a21\u578b\u5206\u5e03\u7684\u671f\u671b:</p> <p>\u6b65\u9aa4</p> <ul> <li>\u4ece\u8bad\u7ec3\u6570\u636e\u6837\u672c \\(x_{\\text{data}}\\) \u542f\u52a8\u9a6c\u5c14\u53ef\u592b\u94fe\u3002</li> <li>\u8fd0\u884c \\(k\\) \u6b65MCMC\uff08\u5982Gibbs\u91c7\u6837\uff09\u751f\u6210\u6837\u672c \\(x_{\\text{CD_k}}\\)\u3002</li> <li>\u7528\u8fd9\u4e9b\u6837\u672c\u7684\u5747\u503c\u8fd1\u4f3c \\(\\mathbb{E}_{p_\\theta(x)}[\\cdot]\\)\uff0c\u5373\uff1a</li> </ul> \\[ \\mathbb{E}_{p_\\theta(x)} [\\nabla_\\theta E_\\theta(x)] \\approx \\frac{1}{B} \\sum_{i=1}^B \\nabla_\\theta E_\\theta(x_{\\text{CD_k}}^{(i)}). \\]"},{"location":"book/chapter3_energy_based_model/cd/#43-33","title":"4.3 3.3. \u53c2\u6570\u66f4\u65b0\u89c4\u5219\u7684\u7b80\u5316","text":"<p>\u68af\u5ea6\u516c\u5f0f\u7b80\u5316\u4e3a\uff1a</p> \\[ \\nabla_\\theta \\mathcal{L}(\\theta) \\approx -\\mathbb{E}_{p_{\\text{data}}} [\\nabla_\\theta E_\\theta(x)] + \\frac{1}{B} \\sum_{i=1}^B \\nabla_\\theta E_\\theta(x_{\\text{CD_k}}^{(i)}). \\] <p>\u53c2\u6570\u66f4\u65b0\u65b9\u5411\u4e3a\uff1a</p> \\[ \\Delta \\theta \\propto -\\nabla_\\theta E_\\theta(x_{\\text{data}}) + \\nabla_\\theta E_\\theta(x_{\\text{CD_k}}). \\]"},{"location":"book/chapter3_energy_based_model/cd/#44-34","title":"4.4 3.4. \u7b49\u4ef7\u635f\u5931\u51fd\u6570\u7684\u5b9a\u4e49","text":"<p>CD\u7684\u7b49\u4ef7\u635f\u5931\u51fd\u6570\u53ef\u8868\u793a\u4e3a\uff1a</p> \\[ \\mathcal{L}_{\\text{CD}} = \\mathbb{E}_{p_{\\text{data}}} [E_\\theta(x)] - \\mathbb{E}_{p_{\\theta}^{(k)}} [E_\\theta(x)], \\] <p>\u5176\u4e2d\uff1a</p> <ul> <li>\u7b2c\u4e00\u9879\uff1a\u771f\u5b9e\u6570\u636e\u6837\u672c \\( x \\sim p_{\\text{data}} \\) \u7684\u5e73\u5747\u80fd\u91cf\u3002</li> <li>\u7b2c\u4e8c\u9879\uff1a\u4ece\u6570\u636e\u5206\u5e03\u542f\u52a8 \\( k \\) \u6b65MCMC\uff08\u5982Gibbs\u91c7\u6837\uff09\u751f\u6210\u7684\u6837\u672c \\( x_{\\text{CD_k}} \\sim p_{\\theta}^{(k)} \\) \u7684\u5e73\u5747\u80fd\u91cf\u3002</li> <li>\u4f18\u5316\u76ee\u6807\uff1a\u6700\u5c0f\u5316 \\( \\mathcal{L}_{\\text{CD}} \\),\u5373\u964d\u4f4e\u771f\u5b9e\u6570\u636e\u7684\u80fd\u91cf\uff0c\u540c\u65f6\u63d0\u9ad8\u751f\u6210\u6570\u636e\u7684\u80fd\u91cf\u3002</li> <li>\u4f5c\u7528\uff1a\u964d\u4f4e\u771f\u5b9e\u6837\u672c\u7684\u80fd\u91cf\uff0c\u4f7f\u5176\u66f4\u53ef\u80fd\u88ab\u6a21\u578b\u751f\u6210\u3002\u63d0\u9ad8\u751f\u6210\u6837\u672c\u7684\u80fd\u91cf\uff0c\u4f7f\u5176\u8fdc\u79bb\u5f53\u524d\u6a21\u578b\u5206\u5e03\u3002</li> </ul> <p></p>"},{"location":"book/chapter3_energy_based_model/cd/#45-35","title":"4.5 3.5. \u77ed\u94fe\u91c7\u6837\u7684\u5408\u7406\u6027","text":"<ul> <li>\u70ed\u542f\u52a8\uff1a\u4ece\u6570\u636e\u70b9\u542f\u52a8MCMC\u94fe\uff0c\u8d77\u70b9\u9760\u8fd1\u9ad8\u6982\u7387\u533a\u57df\uff0c\u5c11\u91cf\u6b65\u9aa4\u5373\u53ef\u903c\u8fd1\u6a21\u578b\u5206\u5e03\u3002</li> <li>\u5c40\u90e8\u63a2\u7d22\uff1a\u77ed\u94fe\u4e3b\u8981\u8c03\u6574\u6837\u672c\u7684\u5c40\u90e8\u7ed3\u6784\uff08\u5982\u7eb9\u7406\u7ec6\u8282\uff09\uff0c\u800c\u975e\u5168\u5c40\u6a21\u5f0f\u3002</li> </ul>"},{"location":"book/chapter3_energy_based_model/cd/#46-36-mcmc","title":"4.6 3.6. \u4e0e\u4f20\u7edfMCMC\u7684\u5bf9\u6bd4","text":"\u65b9\u6cd5 \u521d\u59cb\u72b6\u6001 \u94fe\u957f \u8ba1\u7b97\u6210\u672c \u4f20\u7edfMCMC \u968f\u673a\u566a\u58f0 \u957f\uff08\u6536\u655b\uff09 \u9ad8 CD \u8bad\u7ec3\u6570\u636e \u77ed\uff08$ k=1 $\uff09 \u4f4e"},{"location":"book/chapter3_energy_based_model/cd/#5-4","title":"5. 4. \u5e94\u7528\u4e0e\u53d8\u79cd","text":""},{"location":"book/chapter3_energy_based_model/cd/#51-41-rbm","title":"5.1 4.1. \u5728RBM\u4e2d\u7684\u5b9e\u73b0","text":"<ul> <li> <p>Gibbs\u91c7\u6837\u6b65\u9aa4\uff1a</p> </li> <li> <p>\u6b63\u5411\u4f20\u64ad\uff1a\u8ba1\u7b97\u9690\u5c42\u6982\u7387 \\(p(h \\mid v_{\\text{data}})\\)\uff0c\u91c7\u6837 \\(h_0\\)\u3002</p> </li> <li> <p>\u53cd\u5411\u91cd\u6784\uff1a\u8ba1\u7b97\u53ef\u89c1\u5c42\u6982\u7387 \\(p(v \\mid h_0)\\)\uff0c\u91c7\u6837 \\(v_1\\)\u3002</p> </li> <li> <p>\u53c2\u6570\u66f4\u65b0:</p> </li> </ul> \\[ \\Delta w_{ij} \\propto v_{\\text{data},i} h_{0,j} - v_{1,i} h_{1,j}. \\]"},{"location":"book/chapter3_energy_based_model/cd/#52-42","title":"5.2 4.2 \u6539\u8fdb\u65b9\u6cd5","text":"<ul> <li>Persistent CD (PCD)\uff1a\u8de8\u6279\u6b21\u4fdd\u7559MCMC\u94fe\u72b6\u6001\uff0c\u63d0\u5347\u91c7\u6837\u6548\u7387\uff08Tijmen Tieleman, 2008\uff09\u3002</li> <li>Fast CD\uff1a\u7ed3\u5408\u52a8\u91cf\u3001\u81ea\u9002\u5e94\u5b66\u4e60\u7387\u52a0\u901f\u8bad\u7ec3\u3002</li> </ul>"},{"location":"book/chapter3_energy_based_model/cd/#6-5","title":"6. 5. \u4f18\u7f3a\u70b9\u5206\u6790","text":""},{"location":"book/chapter3_energy_based_model/cd/#61","title":"6.1 \u4f18\u70b9","text":"<ul> <li>\u9ad8\u6548\uff1a\u907f\u514d\u957f\u94feMCMC\uff0c\u8ba1\u7b97\u6210\u672c\u4f4e\u3002</li> <li>\u5b9e\u7528\uff1a\u5728RBM\u7b49\u6a21\u578b\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u63a8\u52a8\u4e86\u6df1\u5ea6\u5b66\u4e60\u590d\u5174\u3002</li> </ul>"},{"location":"book/chapter3_energy_based_model/cd/#62","title":"6.2 \u7f3a\u70b9","text":"<ul> <li>\u6709\u504f\u4f30\u8ba1\uff1a\u77ed\u94fe\u672a\u6536\u655b\u5230\u5e73\u7a33\u5206\u5e03\uff0c\u68af\u5ea6\u4e0d\u51c6\u786e\u3002</li> <li>\u6a21\u5f0f\u574d\u584c\u98ce\u9669\uff1a\u53ef\u80fd\u9057\u6f0f\u4f4e\u6982\u7387\u533a\u57df\u3002</li> </ul>"},{"location":"book/chapter3_energy_based_model/cd/#7-6","title":"7. 6. \u603b\u7ed3","text":"<p>\u5bf9\u6bd4\u6563\u5ea6\uff08CD\uff09\u901a\u8fc7\u6709\u9650\u6b65MCMC\u91c7\u6837\u548c\u6570\u636e\u5206\u5e03\u70ed\u542f\u52a8\u7684\u7b56\u7565\uff0c\u89e3\u51b3\u4e86\u80fd\u91cf\u6a21\u578b\u8bad\u7ec3\u7684\u914d\u5206\u51fd\u6570\u96be\u9898\u3002\u5c3d\u7ba1\u5b58\u5728\u7406\u8bba\u504f\u5dee\uff0c\u5176\u5b9e\u7528\u6027\u548c\u9ad8\u6548\u6027\u4f7f\u5176\u6210\u4e3a\u751f\u6210\u6a21\u578b\u8bad\u7ec3\u7684\u57fa\u77f3\u4e4b\u4e00\u3002\u4eceRBM\u5230\u73b0\u4ee3\u6df1\u5ea6\u751f\u6210\u6a21\u578b\uff0cCD\u7684\u601d\u60f3\u4ecd\u5728\u6301\u7eed\u5f71\u54cd\u65e0\u76d1\u7763\u5b66\u4e60\u7684\u53d1\u5c55\u3002</p> <p>\u53c2\u8003\u6587\u732e\uff1a Hinton, G. E. (2002). Training products of experts by minimizing contrastive divergence. Neural Computation, 14(8), 1771\u20131800.</p>"},{"location":"book/chapter3_energy_based_model/introduction/","title":"\u80fd\u91cf\u6a21\u578b\uff1a\u7406\u8bba\u4e0e\u5e94\u7528\u5168\u666f\u89e3\u8bfb","text":""},{"location":"book/chapter3_energy_based_model/introduction/#1","title":"1. \u5f15\u8a00","text":"<p>\u80fd\u91cf\u6a21\u578b\uff08Energy-Based Models, EBMs\uff09\u662f\u673a\u5668\u5b66\u4e60\u9886\u57df\u7684\u4e00\u7c7b\u91cd\u8981\u751f\u6210\u6a21\u578b\uff0c\u5176\u6838\u5fc3\u601d\u60f3\u662f\u901a\u8fc7\u80fd\u91cf\u51fd\u6570\u9690\u5f0f\u5b9a\u4e49\u6570\u636e\u5206\u5e03\u3002\u4e0e\u663e\u5f0f\u5efa\u6a21\u6982\u7387\u5bc6\u5ea6\u7684\u6a21\u578b\uff08\u5982\u6807\u51c6\u5316\u6d41\u3001VAE\uff09\u4e0d\u540c\uff0c\u80fd\u91cf\u6a21\u578b\u901a\u8fc7\u201c\u80fd\u91cf\u503c\u201d\u8861\u91cf\u6837\u672c\u7684\u5408\u7406\u6027\uff0c\u4f4e\u80fd\u91cf\u5bf9\u5e94\u9ad8\u6982\u7387\u533a\u57df\u3002\u8fd9\u79cd\u7075\u6d3b\u6027\u4f7f\u5176\u5728\u56fe\u50cf\u751f\u6210\u3001\u591a\u6a21\u6001\u5b66\u4e60\u3001\u79d1\u5b66\u8ba1\u7b97\u7b49\u4efb\u52a1\u4e2d\u5c55\u73b0\u51fa\u72ec\u7279\u4f18\u52bf\u3002 \u672c\u6587\u5c06\u7cfb\u7edf\u89e3\u6790\u80fd\u91cf\u6a21\u578b\u7684\u6570\u5b66\u57fa\u7840\u3001\u6838\u5fc3\u6d41\u6d3e\u3001\u6269\u5c55\u65b9\u6cd5\u53ca\u5176\u4e0e\u4e3b\u6d41\u751f\u6210\u6a21\u578b\uff08\u5982GAN\u3001\u6269\u6563\u6a21\u578b\uff09\u7684\u8054\u7cfb\uff0c\u5e76\u63a2\u8ba8\u5176\u672a\u6765\u53d1\u5c55\u65b9\u5411\u3002</p>"},{"location":"book/chapter3_energy_based_model/introduction/#2-1","title":"2. 1. \u80fd\u91cf\u6a21\u578b\u7684\u57fa\u7840\u7406\u8bba","text":""},{"location":"book/chapter3_energy_based_model/introduction/#21-11","title":"2.1 1.1. \u5b9a\u4e49\u4e0e\u6570\u5b66\u5f62\u5f0f","text":"<p>\u80fd\u91cf\u6a21\u578b\u901a\u8fc7\u80fd\u91cf\u51fd\u6570 \\(E_\\theta(x)\\) \u9690\u5f0f\u5b9a\u4e49\u6982\u7387\u5206\u5e03\uff1a</p> \\[ P_\\theta(x) = \\frac{e^{-E_\\theta(x)}}{Z(\\theta)}, \\quad Z(\\theta) = \\int e^{-E_\\theta(x)} dx \\] <ul> <li>\u80fd\u91cf\u51fd\u6570 \\(E_\\theta(x)\\)\uff1a\u8861\u91cf\u6837\u672c \\(x\\) \u7684\u201c\u4e0d\u5408\u7406\u6027\u201d\uff0c\u901a\u5e38\u7531\u795e\u7ecf\u7f51\u7edc\u53c2\u6570\u5316\u3002</li> <li>\u5f52\u4e00\u5316\u56e0\u5b50 \\(Z(\\theta)\\)\uff1a\u786e\u4fdd\u6982\u7387\u79ef\u5206\u4e3a1\uff0c\u4f46\u5728\u9ad8\u7ef4\u7a7a\u95f4\u4e2d\u96be\u4ee5\u76f4\u63a5\u8ba1\u7b97\u3002</li> </ul> <p>\u7c7b\u6bd4\u7269\u7406\u7cfb\u7edf</p> <ul> <li>\u7269\u7406\u52bf\u80fd\uff1a\u5728\u7269\u7406\u5b66\u4e2d\uff0c\u52bf\u80fd\u8d8a\u4f4e\u7684\u72b6\u6001\u8d8a\u7a33\u5b9a\uff08\u5982\u5c0f\u7403\u5728\u8c37\u5e95\uff09\u3002</li> <li>\u80fd\u91cf\u6a21\u578b\uff1a\u80fd\u91cf\u51fd\u6570E(x) \u626e\u6f14\u7c7b\u4f3c\u52bf\u80fd\u7684\u89d2\u8272\uff0c\u4f4e\u80fd\u91cf\u533a\u57df\u5bf9\u5e94\u6570\u636e\u5206\u5e03\u7684\u9ad8\u6982\u7387\u533a\u57df\uff08\u5373\u771f\u5b9e\u6570\u636e\u96c6\u4e2d\u51fa\u73b0\u53ef\u80fd\u6027\u5927\u7684\u6837\u672c\uff09\u3002</li> </ul> <p>\u80fd\u91cf\u51fd\u6570\u672c\u8d28\u662f\u4e00\u4e2a\u8bc4\u5206\u51fd\u6570\uff1a</p> <ul> <li>\u5bf9\u5408\u7406\u7684\u6837\u672c\uff08\u5982\u8bad\u7ec3\u6570\u636e\uff09\u8d4b\u4e88\u4f4e\u80fd\u91cf\u503c;</li> <li>\u5bf9\u4e0d\u5408\u7406\u7684\u6837\u672c\uff08\u5982\u566a\u58f0\u3001\u5f02\u5e38\u503c\uff09\u8d4b\u4e88\u9ad8\u80fd\u91cf\u503c\u3002</li> </ul> <p>\u793a\u4f8b\uff1a</p> <ul> <li>\u5728\u56fe\u50cf\u751f\u6210\u4efb\u52a1\u4e2d\uff0c\u6e05\u6670\u7684\u56fe\u7247\u80fd\u91cf\u4f4e\uff0c\u6a21\u7cca\u6216\u6df7\u4e71\u7684\u56fe\u7247\u80fd\u91cf\u9ad8;</li> <li>\u5728\u6587\u672c\u751f\u6210\u4e2d\uff0c\u8bed\u6cd5\u6b63\u786e\u7684\u53e5\u5b50\u80fd\u91cf\u4f4e\uff0c\u8bed\u4e49\u77db\u76fe\u7684\u53e5\u5b50\u80fd\u91cf\u9ad8\u3002</li> </ul> <p>\u8fd9\u91cc\u5927\u5bb6\u53ef\u80fd\u4f1a\u6709\u56f0\u60d1\uff0c\u867d\u7136\u5b9a\u4e49\u4e86\u4e00\u4e2a\u80fd\u91cf\uff0c\u4f46\u662f\u8fd9\u4e2a\u80fd\u91cf\u5230\u5e95\u600e\u4e48\u4f7f\u7528\uff1f\u4f7f\u7528\u80fd\u91cf\u6a21\u578b\u6709\u4e24\u4e2a\u6838\u5fc3\u8981\u89e3\u51b3\u7684\u95ee\u9898\uff0c\u4e00\u4e2a\u662f\u5b66\u4e60\u51fa\u80fd\u91cf\u51fd\u6570\u548c\u76ee\u6807\u6570\u636e\u5206\u5e03\u4e00\u81f4\uff0c\u53e6\u5916\u4e00\u4e2a\u662f\u4ece\u80fd\u91cf\u51fd\u6570\u4e2d\u91c7\u6837\u51fa\u6570\u636e\uff0c\u8fd9\u662f\u80fd\u91cf\u6a21\u578b\u7684\u6838\u5fc3\u6311\u6218\u3002\u540e\u7eed\u6211\u4eec\u4f1a\u8bb2\u5230\u600e\u4e48\u5b66\u4e60\u80fd\u91cf\u51fd\u6570\uff0c\u53c8\u600e\u4e48\u4ece\u80fd\u91cf\u51fd\u6570\u4e2d\u91c7\u6837\u3002\u76f4\u89c2\u4e0a\u8bb2\uff0c\u5047\u8bbe\u6211\u4eec\u6709\u4e86\u4e00\u4e2a\u80fd\u91cf\u51fd\u6570\uff0c\u90a3\u91c7\u6837\u610f\u5473\u7740\u6211\u4eec\u6309\u7167\u80fd\u91cf\u51fd\u6570\u7ed9\u51fa\u7684\u5206\u5e03\u6982\u7387\u8fdb\u884c\u91c7\u6837\u3002</p>"},{"location":"book/chapter3_energy_based_model/introduction/#22-12","title":"2.2 1.2. \u6838\u5fc3\u5047\u8bbe\u4e0e\u6761\u4ef6","text":"<ul> <li>\u4f4e\u80fd\u91cf\u5bf9\u5e94\u9ad8\u6982\u7387\uff1a\u771f\u5b9e\u6570\u636e\u6837\u672c\u4f4d\u4e8e\u80fd\u91cf\u51fd\u6570\u7684\u4f4e\u80fd\u533a\u57df\u3002</li> <li>\u6570\u5b66\u6761\u4ef6\uff1a</li> <li>\u53ef\u79ef\u6027\uff1a\u4fdd\u8bc1 \\(Z(\\theta)\\) \u5b58\u5728\uff08\u79ef\u5206\u6536\u655b\uff09\u3002</li> <li>\u53ef\u5fae\u5206\u6027\uff1a\u80fd\u91cf\u51fd\u6570\u9700\u5bf9\u8f93\u5165 \\(x\\) \u548c\u53c2\u6570 \\(\\theta\\) \u53ef\u5bfc\uff0c\u4ee5\u652f\u6301\u68af\u5ea6\u4f18\u5316\u3002</li> <li>\u8bad\u7ec3\u5047\u8bbe\uff1a</li> <li>\u5bf9\u6bd4\u5b66\u4e60\uff1a\u901a\u8fc7\u533a\u5206\u771f\u5b9e\u6837\u672c\uff08\u4f4e\u80fd\u91cf\uff09\u4e0e\u566a\u58f0\u6837\u672c\uff08\u9ad8\u80fd\u91cf\uff09\u4f18\u5316\u80fd\u91cf\u51fd\u6570\u3002</li> <li>\u91c7\u6837\u53ef\u884c\u6027\uff1a\u4f9d\u8d56\u9ad8\u6548\u91c7\u6837\u65b9\u6cd5\uff08\u5982MCMC\uff09\u751f\u6210\u8d1f\u6837\u672c\u3002</li> </ul>"},{"location":"book/chapter3_energy_based_model/introduction/#3-2","title":"3. 2. \u80fd\u91cf\u6a21\u578b\u7684\u6838\u5fc3\u6311\u6218","text":""},{"location":"book/chapter3_energy_based_model/introduction/#31-21-p_textdatax","title":"3.1 2.1. \u4f30\u8ba1\u771f\u5b9e\u6570\u636e\u5206\u5e03 \\(p_{\\text{data}}(x)\\)","text":"<p>\u76f4\u63a5\u8ba1\u7b97\u5f52\u4e00\u5316\u56e0\u5b50 \\(Z(\\theta)\\) \u4e0d\u53ef\u884c\uff0c\u9700\u7ed5\u8fc7\u663e\u5f0f\u79ef\u5206\uff1a</p> <ul> <li>\u5bf9\u6bd4\u6563\u5ea6\uff08CD\uff09\uff1a\u7528\u5c11\u91cfMCMC\u6b65\u9aa4\u751f\u6210\u8d1f\u6837\u672c\uff0c\u5bf9\u6bd4\u4f18\u5316\u80fd\u91cf\u51fd\u6570\uff08\u5982\u53d7\u9650\u73bb\u5c14\u5179\u66fc\u673a\uff09\u3002</li> <li>\u5206\u6570\u5339\u914d\uff08Score Matching\uff09\uff1a\u76f4\u63a5\u5339\u914d\u6570\u636e\u5206\u5e03\u7684\u68af\u5ea6 \\(\\nabla_x \\log p_{\\text{data}}(x)\\)\uff08\u5373\u80fd\u91cf\u51fd\u6570\u7684\u8d1f\u68af\u5ea6\uff09\u3002</li> <li>\u5bf9\u6297\u8bad\u7ec3\uff1a\u5c06\u751f\u6210\u5668\u4f5c\u4e3a\u91c7\u6837\u5668\uff0c\u5224\u522b\u5668\u4f5c\u4e3a\u80fd\u91cf\u51fd\u6570\uff08\u5982EBGAN\uff09\u3002</li> </ul>"},{"location":"book/chapter3_energy_based_model/introduction/#32-22","title":"3.2 2.2. \u9ad8\u6548\u91c7\u6837","text":"<p>\u4ece \\(P_\\theta(x) \\propto e^{-E_\\theta(x)}\\) \u4e2d\u91c7\u6837\u9700\u63a2\u7d22\u4f4e\u80fd\u91cf\u533a\u57df\uff1a</p> <ul> <li>\u9a6c\u5c14\u53ef\u592b\u94fe\u8499\u7279\u5361\u6d1b\uff08MCMC\uff09\uff1a</li> <li>Langevin\u52a8\u529b\u5b66\uff1a\u901a\u8fc7\u68af\u5ea6\u4e0b\u964d\u4e0e\u566a\u58f0\u6270\u52a8\u8fed\u4ee3\u91c7\u6837\uff1a</li> </ul> \\[ x_{t+1} = x_t - \\eta \\nabla_x E_\\theta(x_t) + \\sqrt{2\\eta} \\epsilon_t, \\quad \\epsilon_t \\sim \\mathcal{N}(0, I) \\] <ul> <li>Gibbs\u91c7\u6837\uff1a\u9002\u7528\u4e8e\u5177\u6709\u5c40\u90e8\u4f9d\u8d56\u6027\u7684\u6a21\u578b\uff08\u5982\u73bb\u5c14\u5179\u66fc\u673a\uff09\u3002</li> <li>\u9690\u5f0f\u751f\u6210\u5668\uff1a\u5982GAN\u7684\u751f\u6210\u5668\u76f4\u63a5\u5b66\u4e60\u4ece\u7b80\u5355\u5206\u5e03\u5230\u6570\u636e\u5206\u5e03\u7684\u6620\u5c04\u3002</li> <li>\u6269\u6563\u6a21\u578b\uff1a\u5728\u53bb\u566a\u8fc7\u7a0b\u4e2d\u7ed3\u5408\u80fd\u91cf\u68af\u5ea6\u5f15\u5bfc\u91c7\u6837\u3002</li> </ul> <p>\u91c7\u6837\u65f6\u4e00\u822c\u90fd\u9700\u8981\u80fd\u91cf\u51fd\u6570\u7684\u68af\u5ea6\uff0c\u8fd9\u4e2a\u68af\u5ea6\u6211\u4eec\u4e5f\u53eb\u505a\"score function\", \u662f\u4e00\u4e2a\u5411\u91cf\u573a\uff0c\u8868\u793a\u80fd\u91cf\u53d8\u5316\u7684\u65b9\u5411\u548c\u5f3a\u5ea6\u3002</p>"},{"location":"book/chapter3_energy_based_model/introduction/#4-3-ebm-vs-sbm","title":"4. 3. EBM vs SBM","text":"<ul> <li>\u9884\u6d4b\u80fd\u91cf\u51fd\u6570\u7684\u6a21\u578b, \u6a21\u578b\u8f93\u51fa\u4e00\u4e2a\u6807\u91cf\u503c, \u6211\u4eec\u53eb \"EBM\", energy-based model</li> <li>\u76f4\u63a5\u9884\u6d4bscore function \u7684\u6a21\u578b, \u6a21\u578b\u8f93\u51fa\u4e3a\u4e00\u4e2a\u5411\u91cf\u573a, \u6211\u4eec\u53eb\u505a \"SBM\", score based model</li> </ul>"},{"location":"book/chapter3_energy_based_model/introduction/#5-4","title":"5. 4. \u80fd\u91cf\u6a21\u578b\u7684\u4e3b\u6d41\u6d41\u6d3e","text":""},{"location":"book/chapter3_energy_based_model/introduction/#51-41-contrastive-divergence","title":"5.1 4.1. Contrastive Divergence","text":"<ul> <li> <p>\u6838\u5fc3\uff1a\u6b63\u5e38\u8fed\u4ee3\u6a21\u578b\uff0c\u9700\u8981\u8ba1\u7b97\\(\\theta\\) \u7684\u68af\u5ea6\uff0c\u90a3\u6211\u4eec\u662f\u4e0d\u662f\u53ef\u4ee5\u76f4\u63a5\u8ba1\u7b97\u51fa \\(p_\\theta(x)\\) \u7684\u68af\u5ea6, \u7136\u540e\u6309\u7167\u68af\u5ea6\u65b9\u5411\u53bb\u66f4\u65b0\u68af\u5ea6\u3002 \u6839\u636e\u8fd9\u4e2a\u65b9\u6cd5\u6211\u4eec\u5c31\u5f97\u5230\u4e86\u5bf9\u6bd4\u6563\u5ea6\uff08CD\uff09\u65b9\u6cd5\u3002</p> </li> <li> <p>\u4ee3\u8868\u6a21\u578b\uff1a\u53d7\u9650\u73bb\u5c14\u5179\u66fc\u673a\uff08RBM\uff09\u3001Deep Belief Networks\u3002</p> </li> <li>\u7279\u70b9\uff1a\u8bad\u7ec3\u7a33\u5b9a\uff0c\u4f46MCMC\u91c7\u6837\u6548\u7387\u4f4e\u3002</li> </ul>"},{"location":"book/chapter3_energy_based_model/introduction/#52-42","title":"5.2 4.2. \u5206\u6570\u5339\u914d","text":"<ul> <li>\u6838\u5fc3\uff1a \u76f4\u63a5\u8ba1\u7b97\u4e24\u4e2a\u5206\u5e03\u4e4b\u95f4\u7684\u8ddd\u79bb\u4f1a\u6bd4\u8f83\u96be\uff0c\u4f46\u662f\u8ba1\u7b97\u4e24\u4e2a\u5206\u5e03\u7684\u68af\u5ea6\u7684\u5dee\u5f02\u4f1a\u5bb9\u6613\u4e00\u4e9b\u3002\u540c\u65f6\u5229\u7528\u5206\u90e8\u79ef\u5206\uff0c\u53ef\u4ee5\u7ed5\u8fc7\u539f\u59cb\u5206\u5e03\u7684\u68af\u5ea6\u8ba1\u7b97\u3002\u8fd9\u5c31\u662f\u6240\u8c13\u7684 score matching \u65b9\u6cd5\u3002\u8fd9\u91cc\u7684\u2018score\u2019 \u5c31\u662f\u68af\u5ea6\u3002</li> </ul> \\[  J(\\theta) = \\frac{1}{2} \\mathbb{E}_{p(x)} \\left[ \\| \\nabla_x \\log q_\\theta(x) - \\nabla_x \\log p(x) \\|^2 \\right]. \\] <p>\u5b83\u7b49\u4ef7\u4e8e\u4f18\u5316</p> \\[  \\min_\\theta\\mathbb{E}_{p(x)} \\left[ \\text{trace} \\left( \\nabla_x^2 \\log q_\\theta(x) \\right) + \\frac{1}{2} \\| \\nabla_x \\log q_\\theta(x) \\|^2 \\right]. \\] <p>\u56e0\u4e3a\u4e8c\u9636\u5bfc\u7684\u8ba1\u7b97\u901a\u5e38\u6bd4\u8f83\u590d\u6742\uff0c\u56e0\u6b64\u5728\u8fd9\u4e2a\u65b9\u5411\u4e0a\u4f1a\u6709\u4e0d\u540c\u7684\u5b9e\u8df5\u65b9\u6cd5\uff0c\u5e38\u89c1\u7684\u6709sliced score matching \u548c denosing score matching</p> <ul> <li>\u4ee3\u8868\u6a21\u578b\uff1a\u5e38\u89c1\u7684score matching \u6709 sliced score matching\u548cdenosing score matching</li> <li>\u7279\u70b9\uff1a\u751f\u6210\u8d28\u91cf\u9ad8\uff0c\u4f46\u8ba1\u7b97\u6210\u672c\u5927\u3002</li> </ul>"},{"location":"book/chapter3_energy_based_model/introduction/#53-43","title":"5.3 4.3. \u5bf9\u6297\u8bad\u7ec3\u6d3e","text":"<ul> <li>\u6838\u5fc3\uff1a\u5224\u522b\u5668\u4f5c\u4e3a\u80fd\u91cf\u51fd\u6570\uff0c\u751f\u6210\u5668\u4f5c\u4e3a\u91c7\u6837\u5668\u3002</li> <li>\u4ee3\u8868\u6a21\u578b\uff1aEBGAN\u3001BEGAN\u3002</li> <li>\u7279\u70b9\uff1a\u751f\u6210\u9ad8\u6548\uff0c\u4f46\u6613\u6a21\u5f0f\u5d29\u6e83\u3002</li> </ul>"},{"location":"book/chapter3_energy_based_model/introduction/#54-44","title":"5.4 4.4. \u7ed3\u6784\u5316\u80fd\u91cf\u6a21\u578b","text":"<ul> <li>\u6838\u5fc3\uff1a\u5f15\u5165\u9886\u57df\u77e5\u8bc6\uff08\u5982\u56fe\u7ed3\u6784\u3001\u7269\u7406\u7ea6\u675f\uff09\u8bbe\u8ba1\u80fd\u91cf\u51fd\u6570\u3002</li> <li>\u4ee3\u8868\u6a21\u578b\uff1aGraphEBM\uff08\u5206\u5b50\u751f\u6210\uff09\u3001CRF\uff08\u6761\u4ef6\u968f\u673a\u573a\uff09\u3002</li> <li>\u7279\u70b9\uff1a\u53ef\u89e3\u91ca\u6027\u5f3a\uff0c\u6cdb\u5316\u6027\u5f31\u3002</li> </ul>"},{"location":"book/chapter3_energy_based_model/introduction/#6-5","title":"6. 5.\u80fd\u91cf\u6a21\u578b\u7684\u6269\u5c55\u65b9\u6cd5","text":""},{"location":"book/chapter3_energy_based_model/introduction/#61-51","title":"6.1 5.1. \u6761\u4ef6\u80fd\u91cf\u6a21\u578b","text":"<p>\u901a\u8fc7\u6761\u4ef6\u53d8\u91cf \\(c\\)\uff08\u5982\u6587\u672c\u3001\u6807\u7b7e\uff09\u5efa\u6a21\u6761\u4ef6\u5206\u5e03 \\(p(x \\mid c)\\)\uff1a</p> <ul> <li>\u80fd\u91cf\u51fd\u6570\uff1a\\(E_\\theta(x, c)\\)\uff0c\u6982\u7387\u5206\u5e03\u4e3a</li> </ul> \\[ p(x \\mid c) = \\frac{e^{-E_\\theta(x, c)}}{Z(c)}, \\quad Z(c) = \\int e^{-E_\\theta(x, c)} dx \\] <ul> <li>\u5e94\u7528\u573a\u666f\uff1a\u6587\u672c\u5230\u56fe\u50cf\u751f\u6210\u3001\u53ef\u63a7\u751f\u6210\uff08\u5982DALL\u00b7E 2\uff09\u3002</li> </ul>"},{"location":"book/chapter3_energy_based_model/introduction/#62-52","title":"6.2 5.2. \u9690\u53d8\u91cf\u80fd\u91cf\u6a21\u578b","text":"<p>\u5f15\u5165\u9690\u53d8\u91cf \\(z\\) \u5efa\u6a21\u8054\u5408\u5206\u5e03 \\(p(x, z)\\)\uff0c\u63d0\u5347\u8868\u8fbe\u80fd\u529b\uff1a</p> <ul> <li>\u53d8\u5206\u80fd\u91cf\u6a21\u578b\uff08VAE-EBM\uff09\uff1a\u7ed3\u5408VAE\u7684\u53d8\u5206\u63a8\u65ad\u4e0e\u80fd\u91cf\u51fd\u6570\u7ea6\u675f\u3002</li> </ul> \\[ \\log p(x) \\geq \\mathbb{E}_{q(z|x)} \\left[ -E_\\theta(x, z) - \\log q(z|x) \\right] - \\log Z \\] <ul> <li>\u5bf9\u6297\u5f0f\u9690\u53d8\u91cfEBMs\uff1a\u751f\u6210\u5668 \\(G(z)\\) \u751f\u6210\u6837\u672c\uff0c\u80fd\u91cf\u51fd\u6570 \\(E_\\theta(x)\\) \u5224\u522b\u5408\u7406\u6027\u3002</li> </ul>"},{"location":"book/chapter3_energy_based_model/introduction/#63-53","title":"6.3 5.3. \u80fd\u91cf\u5f15\u5bfc\u7684\u6269\u6563\u6a21\u578b","text":"<p>\u5728\u6269\u6563\u8fc7\u7a0b\u4e2d\u663e\u5f0f\u5f15\u5165\u80fd\u91cf\u51fd\u6570 \\(E_\\theta(x, c)\\)\uff0c\u589e\u5f3a\u751f\u6210\u53ef\u63a7\u6027\uff1a</p> <ul> <li>\u91c7\u6837\u516c\u5f0f\uff1a</li> </ul> \\[ x_{t-1} = \\text{Denoise}(x_t) - \\eta \\nabla_x E_\\theta(x_t, c) \\] <ul> <li>\u5e94\u7528\uff1a\u5206\u5b50\u751f\u6210\u3001\u827a\u672f\u54c1\u98ce\u683c\u8fc1\u79fb\u3002</li> </ul>"},{"location":"book/chapter3_energy_based_model/introduction/#7-6","title":"7. 6. \u80fd\u91cf\u6a21\u578b\u4e0e\u5176\u4ed6\u751f\u6210\u6a21\u578b\u7684\u5173\u7cfb","text":""},{"location":"book/chapter3_energy_based_model/introduction/#71-61-vae","title":"7.1 6.1. VAE\uff1a\u9690\u53d8\u91cf\u80fd\u91cf\u6a21\u578b\u7684\u53d8\u5206\u5b9e\u73b0","text":"<p>VAE\u901a\u8fc7\u9690\u53d8\u91cf \\(z\\) \u5efa\u6a21\u8054\u5408\u5206\u5e03 \\(p(x, z)\\)\uff0c\u5176ELBO\u76ee\u6807\u7b49\u4ef7\u4e8e\u80fd\u91cf\u51fd\u6570\u7684\u53d8\u5206\u4f18\u5316\uff1a</p> \\[ \\text{ELBO} = \\mathbb{E}_{q(z|x)}[\\log p(x|z)] - \\text{KL}(q(z|x) \\| p(z)) \\]"},{"location":"book/chapter3_energy_based_model/introduction/#72-62-gan","title":"7.2 6.2. GAN\uff1a\u5bf9\u6297\u5f0f\u80fd\u91cf\u6a21\u578b","text":"<ul> <li>EBGAN\uff1a\u5224\u522b\u5668 \\(D(x)\\) \u4f5c\u4e3a\u80fd\u91cf\u51fd\u6570\uff0c\u751f\u6210\u5668 \\(G(z)\\) \u6700\u5c0f\u5316 \\(E(G(z))\\)\u3002</li> <li>\u80fd\u91cf\u89c6\u89d2\uff1aGAN\u7684\u5bf9\u6297\u8bad\u7ec3\u9690\u5f0f\u4f18\u5316\u80fd\u91cf\u5206\u5e03\u3002</li> </ul>"},{"location":"book/chapter3_energy_based_model/introduction/#73-63","title":"7.3 6.3. \u6269\u6563\u6a21\u578b\uff1a\u52a8\u6001\u80fd\u91cf\u6a21\u578b","text":"<ul> <li>\u5206\u6570\u5339\u914d\u7b49\u4ef7\u6027\uff1a\u6269\u6563\u6a21\u578b\u5b66\u4e60\u5206\u6570\u51fd\u6570 \\(\\nabla_x \\log p(x)\\)\uff0c\u5373\u80fd\u91cf\u68af\u5ea6 \\(-\\nabla_x E(x)\\)\u3002</li> <li>Langevin\u52a8\u529b\u5b66\uff1a\u6269\u6563\u91c7\u6837\u8fc7\u7a0b\u4e0e\u80fd\u91cf\u6a21\u578b\u7684MCMC\u65b9\u6cd5\u4e00\u81f4\u3002</li> </ul>"},{"location":"book/chapter3_energy_based_model/introduction/#74-64","title":"7.4 6.4. \u6807\u51c6\u5316\u6d41\uff1a\u663e\u5f0f\u5f52\u4e00\u5316\u7684\u7279\u4f8b","text":"<p>\u6807\u51c6\u5316\u6d41\u901a\u8fc7\u53ef\u9006\u53d8\u6362\u663e\u5f0f\u4fdd\u8bc1 \\(Z=1\\)\uff0c\u5176\u80fd\u91cf\u51fd\u6570\u4e3a \\(E(x) = -\\log p(x)\\)\uff0c\u4f46\u751f\u6210\u673a\u5236\uff08\u786e\u5b9a\u6027\u6620\u5c04\uff09\u4e0e\u4f20\u7edfEBMs\u4e0d\u540c\u3002</p>"},{"location":"book/chapter3_energy_based_model/introduction/#8-7","title":"8. 7.\u6311\u6218\u4e0e\u672a\u6765\u65b9\u5411","text":""},{"location":"book/chapter3_energy_based_model/introduction/#81-71","title":"8.1 7.1. \u6838\u5fc3\u6311\u6218","text":"<ul> <li>\u8bad\u7ec3\u7a33\u5b9a\u6027\uff1a\u9690\u53d8\u91cf\u4e0e\u6761\u4ef6\u53d8\u91cf\u7684\u8054\u5408\u4f18\u5316\u6613\u5bfc\u81f4\u6a21\u5f0f\u5d29\u6e83\u3002</li> <li>\u91c7\u6837\u6548\u7387\uff1a\u9ad8\u7ef4\u6570\u636e\u4e0bMCMC\u6536\u655b\u7f13\u6162\u3002</li> <li>\u53ef\u89e3\u91ca\u6027\uff1a\u9690\u53d8\u91cf\u7684\u7269\u7406\u610f\u4e49\u4e0d\u660e\u786e\u3002</li> </ul>"},{"location":"book/chapter3_energy_based_model/introduction/#82-72","title":"8.2 7.2. \u672a\u6765\u8d8b\u52bf","text":"<ul> <li>\u9ad8\u6548\u91c7\u6837\u7b97\u6cd5\uff1a\u6269\u6563\u84b8\u998f\u3001\u5feb\u901fMCMC\u53d8\u4f53\u3002</li> <li>\u591a\u6a21\u6001\u7edf\u4e00\u5efa\u6a21\uff1a\u8de8\u6587\u672c\u3001\u56fe\u50cf\u3001\u8bed\u97f3\u7684\u80fd\u91cf\u51fd\u6570\u8bbe\u8ba1\u3002</li> <li>\u4e0e\u5927\u578b\u6a21\u578b\u7ed3\u5408\uff1a\u5229\u7528LLMs\u63d0\u4f9b\u6761\u4ef6\u4fe1\u53f7\u6216\u9690\u53d8\u91cf\u5148\u9a8c\u3002</li> <li>\u79d1\u5b66\u8ba1\u7b97\u6df1\u5316\uff1a\u5206\u5b50\u52a8\u529b\u5b66\u3001\u6750\u6599\u8bbe\u8ba1\u4e2d\u7684\u80fd\u91cf\u6a21\u578b\u5e94\u7528\u3002</li> </ul>"},{"location":"book/chapter3_energy_based_model/sampling/","title":"Sampling from a Distribution","text":"<p>Understanding the process of sampling is crucial in probability and statistics. Sampling is not merely picking random points in space; it involves generating samples that statistically resemble a given probability distribution. This is essential for tasks such as Monte Carlo simulations, statistical modeling, and machine learning.</p>"},{"location":"book/chapter3_energy_based_model/sampling/#1-key-concepts-in-sampling","title":"1. Key Concepts in Sampling","text":"<ol> <li> <p>Representation of the Distribution: The samples should reflect the underlying probability distribution. For example, if a distribution has a high density in a specific region, more samples should appear in that region.</p> </li> <li> <p>Convergence to the Distribution: As the number of samples increases, the empirical distribution (e.g., a histogram) should converge to the theoretical probability distribution.</p> </li> <li> <p>Applications: Accurate sampling is vital for simulations and models where results depend on how well samples represent the true distribution.</p> </li> </ol> <p></p> <p>That is to say, we want to give higher priority to sample that have higher probability.</p> <p>Next, if given a density function, how to sample it. Unlike the VAE, Gan which directed generated an example. In the energy based model, we only have the probability density function (precisely, we have the unnormalized probability density function), how can we sample from it?</p> <p>Generally, sample from a probability distribution can be done in this way</p> <ol> <li>sample from a uniform distribution</li> <li>map the sample to the inverse of the CDF function</li> </ol> <p>than we obtained the samples that follow the given probability distribution. Here CDF is the cumulative distribution function, that is</p> \\[ CDF(x) = \\int_{-\\infty}^x p(z) \\, dz \\]"},{"location":"book/chapter3_energy_based_model/sampling/#2-sample-from-a-simple-gaussian-distribution","title":"2. sample from a simple gaussian distribution","text":"<p>In python, sample the gussian distribution maybe simple as the following.</p> <pre><code>import torch\nimport torch.distributions as dist\n\n# Sample from a standard normal distribution\nsample = dist.Normal(0, 1).sample()\nprint(sample)\n</code></pre>"},{"location":"book/chapter3_energy_based_model/sampling/#21-transformations-from-uniform-distributions","title":"2.1 Transformations from Uniform Distributions","text":"<p>While Gaussian distributions can be sampled directly, they can also be derived from uniform distributions using transformations like the Box-Muller method:</p> <pre><code>import numpy as np\n\n# Box-Muller transform: sampling normal distribution from uniform\nu1 = np.random.uniform(0, 1)\nu2 = np.random.uniform(0, 1)\nz1 = np.sqrt(-2 * np.log(u1)) * np.cos(2 * np.pi * u2)\nz2 = np.sqrt(-2 * np.log(u1)) * np.sin(2 * np.pi * u2)\nprint(f\"Samples: {z1}, {z2}\")\n</code></pre> <p>This method is efficient because it avoids the need for the inverse CDF, which does not have a closed form for Gaussian distributions.</p>"},{"location":"book/chapter3_energy_based_model/sampling/#22-sampling-from-complex-distributions","title":"2.2 Sampling from Complex Distributions","text":"<p>For complex distributions, especially with unnormalized probability density functions (as in Energy-Based Models), sophisticated methods are needed:</p> <ol> <li>Markov Chain Monte Carlo (MCMC): A broad class of algorithms for sampling from complex distributions.</li> <li>Langevin Dynamics: Combines gradient descent with noise to explore probability spaces.</li> <li>Hamiltonian Monte Carlo (HMC): Uses physical dynamics to efficiently sample from high-dimensional distributions.</li> </ol>"},{"location":"book/chapter3_energy_based_model/sampling/#3-markov-chain-monte-carlo-mcmc","title":"3. Markov Chain Monte Carlo (MCMC)","text":"<p>MCMC is a broad class of algorithms used to draw samples from complex probability distributions, especially when direct sampling or classical numerical integration is difficult. The main idea behind MCMC is:</p> <ol> <li>We want samples from a target distribution Suppose we have a probability distribution \\(\\pi(x)\\) (often given up to a normalization constant, e.g., \\(\\pi(x)\\propto e^{-E(x)}\\)), and we want to estimate expectations like</li> </ol> \\[  \\mathbb{E}_{x\\sim \\pi}[f(x)] \\;=\\; \\int f(x)\\,\\pi(x)\\,dx. \\] <p>In many applications (e.g., Bayesian inference), \\(\\pi\\) may be high\u2010dimensional or have no closed\u2010form normalizing constant, making direct sampling infeasible.</p> <ol> <li> <p>Construct a Markov Chain whose stationary distribution is \\(\\pi\\) MCMC methods build a Markov chain \\(X_0, X_1, X_2,\\dots\\) with a transition rule \\(X_{t+1}\\sim T(\\cdot\\mid X_t)\\). The key is to design \\(T\\) so that if \\(X_t\\) is distributed according to \\(\\pi\\), then \\(X_{t+1}\\) is also distributed according to \\(\\pi\\). Under suitable conditions (ergodicity), the chain then converges to \\(\\pi\\) from a wide range of initial states, and the samples \\(X_0, X_1, \\dots\\) \u201cmix\u201d throughout the support of \\(\\pi\\).</p> </li> <li> <p>Samples from the chain approximate samples from \\(\\pi\\)</p> </li> </ol> <p>If the Markov chain is ergodic and aperiodic, then for large \\(t\\), the distribution of \\(X_t\\) is close to \\(\\pi\\). We can compute empirical averages using \\(\\frac{1}{N}\\sum_{t=1}^N f(X_t)\\) to estimate \\(\\mathbb{E}_{\\pi}[f]\\). The law of large numbers for Markov chains implies that, as \\(N\\to\\infty\\), these empirical averages converge to the true expectation (under mild regularity conditions).</p> <p>Popular MCMC approaches include:</p> <ul> <li> <p>Metropolis\u2013Hastings (MH) : Propose a new sample from a proposal distribution \\(q(\\cdot\\mid X_t)\\) and accept or reject it based on a Metropolis acceptance probability that ensures \\(\\pi\\) is the stationary distribution.</p> </li> <li> <p>Gibbs sampling : Update each component in turn from its conditional distribution, often used when conditionals of \\(\\pi\\) are simpler than the joint.</p> </li> </ul>"},{"location":"book/chapter3_energy_based_model/sampling/#4-hamiltonian-monte-carlo-hmc","title":"4. Hamiltonian Monte Carlo (HMC)","text":"<p>Hamiltonian Monte Carlo (HMC)  is a specialized MCMC method designed to tackle high\u2010dimensional sampling problems more efficiently than basic Metropolis\u2013Hastings or Gibbs sampling, especially when \\(\\pi(x)\\propto e^{-E(x)}\\) for some smooth potential \\(E(x)\\). Its key ingredients:</p> <ol> <li>Incorporate \u201cphysical\u201d dynamics HMC treats the target variable \\(x\\) as a position in a physical system and introduces an auxiliary momentum variable \\(p\\). Together, \\((x,p)\\) evolve according to (fictitious) Hamiltonian dynamics governed by a Hamiltonian function</li> </ol> \\[H(x,p) = E(x) + \\frac{1}{2}p^\\top M^{-1} p\\] <p>where \\(M\\) is a mass matrix (often the identity).</p> <ol> <li>Hamiltonian flow Starting from \\((x,p)\\), HMC simulates the continuous\u2010time Hamiltonian equations:</li> </ol> \\[  \\begin{cases} \\dot{x} \\;=\\; M^{-1} p,\\\\ \\dot{p} \\;=\\; -\\,\\nabla E(x). \\end{cases} \\] <p>These flow equations conserve the Hamiltonian \\(H(x,p)\\). In practice, one discretizes this flow via a symplectic integrator (e.g., leapfrog method), which approximates the true continuous trajectory but still preserves many beneficial geometry properties.</p> <ol> <li> <p>Metropolis correction After simulating the Hamiltonian system for a certain number of leapfrog steps, HMC performs a Metropolis acceptance/rejection step:</p> </li> <li> <p>Propose a new state \\((x^\\star,p^\\star)\\) by integrating from \\((x,p)\\).</p> </li> <li> <p>Accept or reject based on the Metropolis probability involving the change in Hamiltonian:</p> </li> </ol> \\[  \\alpha \\;=\\; \\min\\Bigl(1,\\;\\exp\\bigl[-(H(x^\\star,p^\\star)-H(x,p))\\bigr]\\Bigr). \\] <p>This ensures the Markov chain has \\(\\pi(x)\\cdot\\mathcal{N}(p\\mid 0,M)\\) as its invariant distribution in the extended space.</p> <ol> <li>Efficient exploration Because Hamiltonian trajectories can travel long distances in the state space without random walk behavior, HMC reduces the random walk inefficiency often seen in simpler MCMC methods. This often leads to better mixing and more decorrelated samples, especially in high dimensions.</li> </ol> <p>Summary of HMC steps</p> <ol> <li> <p>Sample momentum \\(p\\sim \\mathcal{N}(0,M)\\) to get \\((x,p)\\).</p> </li> <li> <p>Simulate Hamiltonian flow  with a symplectic integrator (e.g., leapfrog) for a chosen number of steps \\(L\\) and step size \\(\\epsilon\\). This yields a proposal \\((x^\\star, p^\\star)\\).</p> </li> <li> <p>Accept/Reject \\((x^\\star,p^\\star)\\) using the Metropolis probability \\(\\alpha\\). If accepted, set \\(X_{t+1}=x^\\star\\); else remain at \\(X_{t+1}=x\\).</p> </li> <li> <p>Repeat  for many iterations.</p> </li> </ol>"},{"location":"book/chapter3_energy_based_model/sampling/#41-references-further-reading","title":"4.1 References &amp; Further Reading","text":"<ul> <li>MCMC in general :</li> <li> <p>Chib, S. and Greenberg, E. (1995). Understanding the Metropolis\u2013Hastings Algorithm. The American Statistician.</p> </li> <li> <p>Gilks, W. R., Richardson, S., &amp; Spiegelhalter, D. J. (1995). Markov Chain Monte Carlo in Practice. Chapman &amp; Hall.</p> </li> <li> <p>Hamiltonian Monte Carlo :</p> </li> <li> <p>Duane, S., Kennedy, A. D., Pendleton, B. J., &amp; Roweth, D. (1987). Hybrid Monte Carlo. Physics Letters B.</p> </li> <li> <p>Neal, R. M. (2011). MCMC Using Hamiltonian Dynamics. In Handbook of Markov Chain Monte Carlo (eds S. Brooks, et al.).</p> </li> <li> <p>Betancourt, M. (2018). A Conceptual Introduction to Hamiltonian Monte Carlo.</p> </li> </ul> <p>In short, MCMC is the backbone of sampling from complicated distributions when direct sampling is infeasible. Hamiltonian Monte Carlo refines this idea by incorporating physical dynamics to move quickly through the space, often yielding more efficient sampling in high\u2010dimensional problems.</p>"},{"location":"book/chapter3_energy_based_model/sampling/#5-langevin-dynamics","title":"5. Langevin Dynamics","text":""},{"location":"book/chapter3_energy_based_model/sampling/#51-1-definition","title":"5.1 1. Definition","text":"<p>Langevin Dynamics Sampling is a sampling method based on Stochastic Differential Equations (SDE). It is used to sample from high-dimensional probability distributions \\(p(x) \\propto e^{-E(x)}\\). The core idea is to add stochastic noise to the deterministic gradient descent process, ensuring a balance between exploration and exploitation, ultimately achieving the desired distribution.</p>"},{"location":"book/chapter3_energy_based_model/sampling/#52-2-core-principles","title":"5.2 2. Core Principles","text":"<ul> <li> <p>Physical Perspective : Derived from particle motion, where \\(E(x)\\) represents the particle's potential energy (drift term), and random thermal noise (diffusion term) drives its movement.</p> </li> <li> <p>Mathematical Perspective : Designed as a random process to enable samples to converge to the target distribution \\(p(x)\\).</p> </li> <li> <p>Key Components :</p> </li> <li> <p>Gradient Descent : Following the negative gradient of \\(E(x)\\), which guides the particle toward areas of lower energy (higher probability density).</p> </li> <li> <p>Random Noise : Adding stochastic perturbations to prevent the algorithm from getting stuck and ensure sufficient exploration.</p> </li> </ul> <p>One also need to note that the converge to the final target distribution is not depended on the initial status, that means we can sample the initial status from any distribution.</p>"},{"location":"book/chapter3_energy_based_model/sampling/#53-3-discrete-formulation","title":"5.3 3. Discrete Formulation","text":"<p>Continuous Langevin Dynamics</p> \\[  dx_t = -\\nabla E(x_t)dt + \\sqrt{2}dW_t \\] <p>Where:</p> <ul> <li> <p>\\(x_t\\): Position of the particle at time \\(t\\).</p> </li> <li> <p>\\(W_t\\): Standard Wiener process (Brownian motion), satisfying \\(W_t \\sim \\mathcal{N}(0, t)\\).</p> </li> </ul> <p>Discrete Update Rule  (Practical Implementation):</p> \\[  x_{k+1} = x_k - \\epsilon \\nabla E(x_k) + \\sqrt{2\\epsilon} \\xi_k, \\, \\xi_k \\sim \\mathcal{N}(0, I) \\] <p>Where \\(\\epsilon\\) is the step size, controlling the trade-off between convergence speed and accuracy.</p>"},{"location":"book/chapter3_energy_based_model/sampling/#54-4-proof-target-distribution-as-the-stationary-distribution","title":"5.4 4. Proof: Target Distribution as the Stationary Distribution","text":"<p>Goal : Prove that the stationary distribution of Langevin Dynamics is \\(p(x) \\propto e^{-E(x)}\\).</p> <p>Tool : Fokker-Planck Equation (Describes the evolution of probability density under a stochastic process).</p> <ol> <li>\\(p(x)\\) is a stationary solution</li> </ol> <p>According to Fokker-Planck Equation:</p> \\[ \\begin{aligned} \\frac{\\partial p(x, t)}{\\partial t} |_{p(x,t)=p(x)}  &amp;= \\nabla \\cdot \\left( p \\nabla E(x) \\right) + \\nabla^2 p \\\\ &amp; = \\nabla \\cdot ( p \\nabla E + \\nabla p) \\\\ &amp; = \\nabla \\cdot ( p \\nabla E - p \\nabla E)\\\\ &amp; = 0 \\end{aligned} \\] <p>the last second equation comes from</p> \\[ \\nabla p = \\nabla_x \\frac{e^{-E}}{Z}= \\frac{1}{Z} \\nabla e^{-E} = - \\frac{e^-E}{Z} \\nabla E= -p\\nabla E \\] <ol> <li>Prove \\(p(x)\\) is a unique stationary distribution</li> </ol> <p>Define the relative entropy</p> \\[ H(t) = \\int p(x,t) \\log \\frac{p(x,t)}{p(x)} d x \\] <p>where \\(p(x,t)\\) is the density function in time \\(t\\) according to the Langevin Dynamics.</p> <p>Compute its time derivative, we have</p> \\[\\frac{d H}{d t} = - \\int p \\left| \\nabla log \\frac{p(x,t)}{p(x)}\\right|^2 d x \\leq 0\\] <p>This shows \\(p(x,t)\\) decreases monotonically and is zero only when \\(p(x,t) = p(x)\\).</p>"},{"location":"book/chapter3_energy_based_model/sampling/#55-5-application-scenarios","title":"5.5 5. Application Scenarios","text":"<ol> <li> <p>Statistical Sampling : Simulates sampling from high-dimensional distributions.</p> </li> <li> <p>Bayesian Inference : Samples from posterior distributions \\(p(\\theta|D)\\) in Bayesian models.</p> </li> <li> <p>Generative Models : Used in methods like DDPM (Denoising Diffusion Probabilistic Models) for image synthesis.</p> </li> <li> <p>Optimization : Combines stochastic noise with gradient-based optimization (e.g., Stochastic Gradient Langevin Dynamics, SGLD).</p> </li> </ol>"},{"location":"book/chapter3_energy_based_model/sampling/#56-6-implementation-steps-and-hyperparameter-tuning","title":"5.6 6. Implementation Steps and Hyperparameter Tuning","text":"<p>Implementation Process :</p> <ol> <li> <p>Initialization : Start with a random initial point \\(x_0\\).</p> </li> <li> <p>Iterative Updates :</p> </li> </ol> \\[  x_{k+1} = x_k - \\epsilon \\nabla \\log p(x) + \\sqrt{2\\epsilon} \\xi_k \\] <ol> <li>Stopping Criterion : Stop when the algorithm converges or sufficient samples are collected.</li> </ol> <p>Hyperparameter Tuning :</p> <ol> <li> <p>Step Size (\\(\\epsilon\\)) : Should ensure convergence while balancing efficiency and stability (commonly uses an annealing strategy).</p> </li> <li> <p>Noise Level : Increase \\(\\sqrt{2\\epsilon}\\) to improve exploration but avoid excessively large variances.</p> </li> <li> <p>Regularization : Use adaptive methods (e.g., SGLD) to accelerate convergence.</p> </li> </ol> <p>Notes :</p> <ul> <li> <p>May fail for ill-conditioned cases; alternative methods like Metropolis-Hastings or MALA can be used.</p> </li> <li> <p>Works under smoothness assumptions of the target distribution \\(E(x)\\) (requires Lipschitz continuous gradients).</p> </li> </ul>"},{"location":"book/chapter3_energy_based_model/sampling/#57-7-example-code-python-code","title":"5.7 7. Example Code (Python Code)","text":"<pre><code>import numpy as np\n\ndef langevin_sampling(grad_log_p, x0, epsilon, n_steps):\n    samples = [x0]\n    x = x0.copy()\n    for _ in range(n_steps):\n        noise = np.random.randn(*x.shape) * np.sqrt(2 * epsilon)\n        x += -epsilon * grad_log_p(x) + noise\n        samples.append(x)\n    return np.array(samples)\n\n# Example: Sampling from \\( p(x) \\propto e^{-x^2/2}, \\, \\text{grad_log_p}(x) = -x \\)\ngrad_log_p = lambda x: -x  # Gradient of log-p(x)\nsamples = langevin_sampling(grad_log_p, x0=np.random.randn(), epsilon=0.01, n_steps=1000)\n</code></pre> <ul> <li>Code <code>experiment/langevin_dynamics_simulation.ipynb</code> </li> </ul>"},{"location":"book/chapter3_energy_based_model/sampling/#58-8-comparison-with-other-sampling-methods","title":"5.8 8. Comparison with Other Sampling Methods","text":"Method Requires Gradients Accept/Reject Step Applicable Scenarios Metropolis-Hastings No Yes General-purpose, less efficient HMC (Hamiltonian MC) Yes Yes High efficiency for correlated distributions Langevin Dynamics Yes (Pure SDE) No Efficient for high-dimensional sampling"},{"location":"book/chapter3_energy_based_model/sampling/#59-conclusion","title":"5.9 Conclusion","text":"<p>Langevin Dynamics Sampling introduces stochasticity guided by gradients, enabling efficient sampling from high-dimensional distributions. It is a powerful tool in generative modeling, Bayesian inference, and optimization algorithms. The theoretical guarantee relies on the Fokker-Planck Equation ensuring the target distribution, while practical tuning of step size and noise level balances convergence and efficiency.</p> <p>This simulation starts from a uniform distribution and converges to a Gaussian mixture, illustrating the effectiveness of Langevin dynamics in sampling from complex distributions.</p>"},{"location":"book/chapter3_energy_based_model/sampling/#6-alternative-sampling-dynamics","title":"6. Alternative Sampling Dynamics","text":"<p>A question is that, why should we sample from \\(p(x)\\) should follow LD ? Is there any other way?</p> <p>He we introduce various stochastic differential equations (SDEs) designed to generate the steady-state distribution \\(p(x) \\propto e^{-E(x)}\\). By learning the appropriate potential \\(E(x)\\), these SDE-based methods can model the target distribution, making them suitable for generative tasks, optimization, and more. Below are common dynamics and SDE models:</p>"},{"location":"book/chapter3_energy_based_model/sampling/#61-1-underdamped-langevin-dynamics","title":"6.1 1. Underdamped Langevin Dynamics","text":"<p>Definition :</p> <p>Introduces momentum \\(v\\), modeling the dynamics of particles in a potential field. The equations are:</p> \\[  dx = v dt, \\quad dv = -\\eta v dt - \\nabla E(x) dt + \\sqrt{2\\eta} dW_v, \\] <p>where \\(\\eta &gt; 0\\) is the friction coefficient.</p> <p>Features :</p> <ul> <li> <p>Momentum introduces inertia, counteracting the \"random walk\" effect of overdamped Langevin dynamics.</p> </li> <li> <p>Converges to the stationary distribution \\(p(x) \\propto e^{-E(x)}\\).</p> </li> </ul> <p>Applications :</p> <ul> <li> <p>Sampling methods like Hamiltonian Monte Carlo (HMC).</p> </li> <li> <p>Simulating particle dynamics in physical systems.</p> </li> </ul>"},{"location":"book/chapter3_energy_based_model/sampling/#62-2-regularized-x-sde","title":"6.2 2. Regularized X-SDE","text":"<p>Definition :</p> <p>For a smooth potential \\(E(x)\\), introduces regularization terms. The SDE is:</p> \\[ dx = b(x) dt + g(x) dW_x, \\] <p>where \\(p(x) \\propto e^{-E(x)}\\).</p> <p>In the Regularized X-SDE  framework, the drift term \\(b(x)\\) and diffusion term \\(g(x)\\) are typically designed based on the energy function \\(E(x)\\) to ensure that the process samples from the desired probability distribution \\(p(x) \\propto e^{-E(x)}\\). Their relationships are as follows:</p>"},{"location":"book/chapter3_energy_based_model/sampling/#621-21-drift-term-bx","title":"6.2.1 2.1. Drift Term \\(b(x)\\)","text":"<ul> <li> <p>The drift term \\(b(x)\\) represents the deterministic component that drives the system towards lower-energy regions.</p> </li> <li> <p>In standard Langevin Dynamics , the drift is given by:</p> </li> </ul> \\[  b(x) = -\\nabla E(x) \\] <ul> <li>However, in Regularized X-SDE , \\(b(x)\\) can be modified to incorporate additional prior knowledge, regularization, or auxiliary variables to improve sampling efficiency.</li> </ul>"},{"location":"book/chapter3_energy_based_model/sampling/#622-22-diffusion-term-gx","title":"6.2.2 2.2. Diffusion Term \\(g(x)\\)","text":"<ul> <li> <p>The diffusion term \\(g(x)\\) controls the stochasticity of the process.</p> </li> <li> <p>In standard Langevin Dynamics, the noise term follows:</p> </li> </ul> \\[  g(x) = \\sqrt{2} I \\] <p>where \\(I\\) is the identity matrix.</p> <ul> <li>In Regularized X-SDE , \\(g(x)\\) can be spatially varying, meaning:</li> </ul> \\[  g(x) = g(x) \\] <p>where \\(g(x)\\) is a function that may depend on the energy landscape \\(E(x)\\), allowing for adaptive noise scaling .</p>"},{"location":"book/chapter3_energy_based_model/sampling/#63-23-generalized-regularized-x-sde-form","title":"6.3 2.3. Generalized Regularized X-SDE Form","text":"<p>A common form of the Regularized X-SDE  is</p> \\[  dx = -\\nabla E(x) dt + g(x) dW_x \\] <p>where:</p> <ul> <li> <p>\\(-\\nabla E(x)\\) ensures the process moves towards lower-energy regions.</p> </li> <li> <p>\\(g(x)\\) can be tuned to balance exploration and exploitation, helping to escape local minima.</p> </li> </ul>"},{"location":"book/chapter3_energy_based_model/sampling/#64-24-practical-adjustments","title":"6.4 2.4. Practical Adjustments","text":"<ul> <li>Preconditioned Langevin Dynamics (PLD): \\(b(x)\\) is modified as:</li> </ul> \\[  b(x) = - M(x) \\nabla E(x) \\] <p>where \\(M(x)\\) is a preconditioning matrix, improving convergence speed.</p> <ul> <li>Adaptive Noise Scaling: \\(g(x)\\) can be chosen to control the amount of stochasticity, improving mixing properties.</li> </ul> <p>There are few main popular choise of \\(g(x)\\),</p>"},{"location":"book/chapter3_energy_based_model/sampling/#641-241-constant-diffusion-standard-langevin-dynamics","title":"6.4.1 2.4.1 Constant Diffusion (Standard Langevin Dynamics)","text":"\\[g(x) = \\sqrt(2)I\\]"},{"location":"book/chapter3_energy_based_model/sampling/#642-242-preconditioned-diffusion","title":"6.4.2 2.4.2 Preconditioned Diffusion","text":"\\[ g(x) = \\sqrt{2P(x)}\\] <p>where \\(P(x)\\) is a preconditioning matrix (positive definite). Some choices of \\(P(x)\\)</p> <ul> <li>Diagonal Preconditioning \\(P(x) = \\text{diag} (\\gamma_1, \\gamma_2, ...,\\gamma_d)\\) depends on the local curvature of \\(E(x)\\)</li> <li>Inverse Hession Approximation: \\(P(x) \\approx \\left( \\nabla^2 E(x) + \\epsilon I \\right)^{-1}\\),(helps navigate high-curvature regions).</li> </ul>"},{"location":"book/chapter3_energy_based_model/sampling/#643-243-energy-based-diffusion-gradient-magnitude-scaling","title":"6.4.3 2.4.3  Energy-Based Diffusion (Gradient Magnitude Scaling)","text":"\\[  g(x) = \\alpha \\cdot (1 + \\|\\nabla E(x)\\|^\\beta) \\] <p>where \\(\\alpha\\) and \\(\\beta\\) are hyperparameters.</p> <ul> <li> <p>Intuition:  Increases noise in high-energy regions, encouraging exploration.</p> </li> <li> <p>Use Case:  Helps escape local minima in multi-modal distributions.</p> </li> </ul>"},{"location":"book/chapter3_energy_based_model/sampling/#644-244-annealed-langevin-dynamics-temperature-based-diffusion","title":"6.4.4 2.4.4 Annealed Langevin Dynamics (Temperature-Based Diffusion)","text":"\\[ g(x) = \\sqrt{2 T(x)} \\] <p>where \\(T(x)\\) is a temperature schedule such as:</p> \\[ T(x) = \\frac{T_0}{1 + \\lambda t} \\] <ul> <li> <p>Effect:  Decreases noise over time, allowing for exploration in early iterations and exploitation in later iterations.</p> </li> <li> <p>Use Case:  Useful in Bayesian inference and generative modeling.</p> </li> </ul>"},{"location":"book/chapter3_energy_based_model/sampling/#645-245-score-based-sde-diffusion-models","title":"6.4.5 2.4.5. Score-Based SDE (Diffusion Models)","text":"\\[ g(x) = \\sigma(t) \\] <p>where \\(\\(\\sigma(t)\\)\\) follows a decreasing function, such as:</p> \\[  \\sigma(t) = \\sigma_{\\max} \\left( \\frac{t}{T} \\right)^{\\gamma} \\] <ul> <li>Use Case:  Used in diffusion models for generative modeling.</li> </ul> <p>Summary Table</p> Term Standard Langevin Dynamics Regularized X-SDE b(x) \\(-\\nabla E(x)\\) Can include regularization, preconditioning \\(g(x)\\) \\(\\sqrt{2} I\\) Adaptive function \\(b(x)\\), may depend on xxx"},{"location":"book/chapter3_energy_based_model/sampling/#65-3-time-reversal-sde-reverse-diffusion-process","title":"6.5 3. Time-Reversal SDE (Reverse Diffusion Process)","text":"<p>Definition :</p> <p>Given a forward SDE:</p> \\[  dx = f(x, t) dt + g(x) dW_x, \\] <p>the reverse-time SDE has the form:</p> \\[  dx_r = f(x, t) - g(x)^2 \\nabla \\log p(x, t) + g(x) dW_x, \\] <p>where \\(p(x, t)\\) is the time-dependent probability density.</p> <p>Applications :</p> <ul> <li> <p>Generative models (e.g., DDPM, score-based models).</p> </li> <li> <p>Denoising diffusion models for approximating \\(\\log p(x)\\).</p> </li> </ul> <p>In this method, we need to construct a path that maps from the original data distribution to some easy distribution, and then use the revserse process (as defined in the SDE) to sample from target data distribution.</p>"},{"location":"book/chapter3_energy_based_model/sampling/#66-4-preconditioned-langevin-dynamics","title":"6.6 4. Preconditioned Langevin Dynamics","text":"<p>Definition :</p> <p>Introduces a preconditioning matrix \\(P(x)\\) to accelerate convergence which is a special case of regularized X-SDE. The SDE is:</p> \\[  dx = -P(x) \\nabla E(x) dt + \\sqrt{2P(x)} dW_x, \\] <p>where \\(P(x)\\) is symmetric and positive definite.</p> <p>Features :</p> <ul> <li> <p>Efficient sampling when \\(P(x)\\) adapts to the geometry of \\(E(x)\\).</p> </li> <li> <p>Extends to include Riemannian manifold-based methods.</p> </li> </ul> <p>Preconditioned SDE (or Preconditioned Langevin Dynamics) is used to improve sampling efficiency  and convergence speed  in stochastic optimization and generative modeling. The main idea is to introduce a preconditioning matrix \\(P(x)\\)  that adapts the sampling dynamics to the local geometry of the energy function \\(E(x)\\). This helps navigate complex landscapes more effectively, especially when different directions in the space have different scales of variation.</p> <p>Where Does the Idea Come From? The idea comes from natural gradient methods  and Riemannian manifold-based optimization , where the metric tensor  is used to adapt learning rates per dimension. In standard Langevin dynamics:</p> \\[ dx = -\\nabla E(x) dt + \\sqrt{2} dW_x \\] <ul> <li> <p>The step size in each direction is uniform , which can lead to slow mixing if the energy landscape has anisotropic (different scaling in different directions) curvature.</p> </li> <li> <p>In high-dimensional spaces, some directions have strong gradients, while others are almost flat, causing inefficient exploration. By introducing \\(P(x)\\) , we scale the gradient and noise adaptively:</p> </li> </ul> \\[ dx = -P(x) \\nabla E(x) dt + \\sqrt{2P(x)} dW_x \\] <p>where \\(P(x)\\) is a positive definite symmetric matrix that scales updates differently in each direction .</p> <p>Usage and Simple Example</p> <p>Let\u2019s consider a simple case where:</p> \\[  P(x) = \\text{diag}(p_1, p_2, ..., p_n) \\] <p>This means that we scale each coordinate independently .</p> <p>Example: Sampling from an Anisotropic Gaussian</p> <p>Consider an energy function for a Gaussian distribution:</p> \\[  E(x) = \\frac{1}{2} x^T A x \\] <p>where \\(A\\) is a diagonal matrix:</p> \\[ A = \\begin{bmatrix} 10 &amp; 0 \\\\ 0 &amp; 1 \\end{bmatrix} \\] <p>This means:</p> <ul> <li> <p>The first dimension has stronger curvature  (steeper gradient).</p> </li> <li> <p>The second dimension has weaker curvature  (flatter gradient).</p> </li> </ul> <p>Using standard Langevin dynamics:</p> \\[ dx = -A x dt + \\sqrt{2} dW_x \\] <ul> <li> <p>The first component moves very slowly due to large gradients.</p> </li> <li> <p>The second component moves faster, leading to inefficient exploration.</p> </li> </ul> <p>Applying Preconditioning</p> <p>Now, we apply a preconditioner:</p> \\[ P(x) = A^{-1} = \\begin{bmatrix} 0.1 &amp; 0 \\\\ 0 &amp; 1 \\end{bmatrix} \\] <p>which leads to:</p> \\[ dx = - P(x) A x dt + \\sqrt{2P(x)} dW_x \\] <p>Since \\(P(x) A = I\\), the dynamics become:</p> \\[ dx = - x dt + \\sqrt{2P(x)} dW_x \\] <p>which normalizes the scales in all directions , making the sampling more efficient</p>"},{"location":"book/chapter3_energy_based_model/sampling/#67-summary-of-sde-models","title":"6.7 Summary of SDE Models","text":"SDE Type Core Concept Advantages Applications General Langevin Dynamics Basic diffusion model Theoretical clarity Generative modeling Underdamped Langevin Dynamics Adds momentum Faster convergence Sampling, optimization Preconditioned Langevin Dynamics Preconditioning matrix for geometry Accelerates convergence Bayesian inference Coupled SDE-ODE Balance of stochastic/deterministic Stable dynamics Scientific computing Reverse-Time SDE Diffusion process reversal High-quality generation Generative models"},{"location":"book/chapter3_energy_based_model/sampling/#68-learning-objectives","title":"6.8 Learning Objectives","text":"<p>Why do different SDE formulations yield the same equilibrium distribution?</p> <p>Mathematical Tool :</p> <p>Fokker-Planck equation</p> <p>For the SDE \\(dx = b(x) dt + \\sigma(x) dW_x\\), the Fokker-Planck equation is:</p> \\[  \\frac{\\partial p}{\\partial t} = -\\nabla \\cdot (p b) + \\frac{1}{2} \\nabla^2(p \\sigma \\sigma^\\top), \\] <p>where \\(p(x, t)\\) is the probability density, \\(b(x)\\) the drift term, and \\(\\sigma(x)\\) the diffusion term. Stationary solution \\(p(x)\\) satisfies:</p> \\[  \\nabla \\cdot (p b) = \\frac{1}{2} \\nabla^2(p \\sigma \\sigma^\\top). \\] <p>By adjusting \\(b(x)\\) and \\(\\sigma(x)\\), one can achieve the desired stationary distribution.</p>"},{"location":"book/chapter3_energy_based_model/sampling/#69-practical-recommendations","title":"6.9 Practical Recommendations","text":"<ol> <li> <p>Choose the SDE based on your specific problem and computational constraints.</p> </li> <li> <p>For generative tasks, consider time-reversal SDEs or preconditioned Langevin dynamics.</p> </li> <li> <p>When optimizing, balance between exploration (stochastic) and exploitation (deterministic).</p> </li> </ol>"},{"location":"book/chapter3_energy_based_model/sampling/#7-details-of-annealed-langevin-dynamics-sampling","title":"7. Details of Annealed Langevin Dynamics Sampling","text":""},{"location":"book/chapter3_energy_based_model/sampling/#71-1-definition","title":"7.1 1. Definition","text":"<p>Annealed Langevin Dynamics Sampling is a stochastic sampling method that incorporates temperature annealing. It enhances the system's ability to explore the target space, balancing between exploration (searching globally) and exploitation (refining locally).</p>"},{"location":"book/chapter3_energy_based_model/sampling/#72-2-core-principles","title":"7.2 2. Core Principles","text":"<ul> <li> <p>Annealing : Introduces a temperature schedule \\(T(t)\\), which controls the degree of randomness (higher temperatures lead to larger noise, encouraging exploration; lower temperatures reduce noise for refined optimization).</p> </li> <li> <p>Stationary Distribution : Gradually transitions the sampling distribution towards the target distribution \\(p(x) \\propto e^{-E(x)}\\) by reducing the temperature.</p> </li> </ul>"},{"location":"book/chapter3_energy_based_model/sampling/#73-3-mathematical-formulation-and-derivation","title":"7.3 3. Mathematical Formulation and Derivation","text":"<p>The dynamic form of Annealed Langevin Dynamics is:</p> \\[  dx_t = -\\nabla U(x_t) dt + \\sqrt{2 T(t)} dW_t, \\] <p>where:</p> <ul> <li> <p>\\(T(t)\\): Temperature schedule (e.g., exponential decay \\(T(t) = T_0 e^{-\\beta t}\\), or other schedules like polynomial decay \\(T_k = T_0 / (1 + k)\\)).</p> </li> <li> <p>Noise term: \\(\\sqrt{2 T(t)} dW_t\\) ensures randomness at each step.</p> </li> </ul> <p>The discrete iteration formula becomes:</p> \\[  x_{k+1} = x_k - \\epsilon \\nabla U(x_k) + \\sqrt{2 \\epsilon T_k} \\xi_k, \\quad \\xi_k \\sim \\mathcal{N}(0, I), \\] <p>where \\(\\epsilon\\) is the step size, and \\(\\xi_k\\) is Gaussian noise.</p>"},{"location":"book/chapter3_energy_based_model/sampling/#74-4-temperature-scheduling-design","title":"7.4 4. Temperature Scheduling Design","text":"<ul> <li> <p>Exponential Decay : \\(T_k = T_0 \\cdot \\gamma^k\\), where \\(0 &lt; \\gamma &lt; 1\\).</p> </li> <li> <p>Polynomial Decay : \\(T_k = T_0 / (1 + k)^\\alpha\\), where \\(\\alpha &gt; 0\\).</p> </li> <li> <p>Adaptive Scheduling : Adjust \\(T_k\\) based on the sampling performance (e.g., adaptively reduce noise if the acceptance rate decreases).</p> </li> </ul> <p>Key parameters:</p> <ul> <li> <p>Initial Temperature \\(T_0\\) : Chosen high enough to explore the search space widely.</p> </li> <li> <p>Final Temperature : Chosen low enough to focus on the target distribution.</p> </li> <li> <p>Step Size \\(\\epsilon\\) : Adjusted to balance accuracy and computational cost.</p> </li> </ul>"},{"location":"book/chapter3_energy_based_model/sampling/#75-5-theoretical-analysis","title":"7.5 5. Theoretical Analysis","text":"<p>In the presence of temperature \\(T\\), the stationary distribution of Langevin Dynamics becomes:</p> \\[  p_T(x) \\propto e^{-E(x)/T}. \\] <p>As \\(T \\to 0\\), the distribution transitions to \\(p(x) \\propto e^{-E(x)}\\) (i.e., the target distribution).</p> <p>Convergence Analysis :</p> <ul> <li> <p>Exploration : High temperatures help explore distant regions of the space.</p> </li> <li> <p>Exploitation : Gradual cooling refines the search towards the target distribution.</p> </li> </ul>"},{"location":"book/chapter3_energy_based_model/sampling/#76-6-applications","title":"7.6 6. Applications","text":"<ul> <li> <p>Generative Models : Used in training and optimization tasks for high-dimensional data.</p> </li> <li> <p>Non-Convex Optimization : Combines annealing and dynamics for escaping local minima.</p> </li> </ul>"},{"location":"book/chapter3_energy_based_model/sampling/#77-7-practical-steps","title":"7.7 7. Practical Steps","text":"<ol> <li> <p>Initialization :</p> </li> <li> <p>Set the initial temperature \\(T_0\\), annealing schedule, step size \\(\\epsilon\\), and random initialization of \\(x_0\\).</p> </li> <li> <p>Iteration :</p> </li> <li> <p>Compute \\(\\nabla U(x_k)\\).</p> </li> <li> <p>Update \\(T_k\\) based on the annealing schedule.</p> </li> <li> <p>Perform the update:</p> </li> </ol> \\[  x_{k+1} = x_k - \\epsilon \\nabla U(x_k) + \\sqrt{2 \\epsilon T_k} \\xi_k. \\] <ol> <li> <p>Convergence :</p> </li> <li> <p>Stop when the temperature reaches a specified threshold or convergence criteria are met.</p> </li> </ol> <p>Python Code Example :</p> <pre><code>import numpy as np\n\ndef annealed_langevin(grad_U, x0, T0, epsilon, n_steps, schedule='exponential', gamma=0.99):\n    x = x0.copy()\n    samples = [x0]\n    T = T0\n    for k in range(n_steps):\n        if schedule == 'exponential':\n            T = T0 * gamma ** k\n        elif schedule == 'polynomial':\n            T = T0 / (1 + k)\n        noise = np.random.randn(x.shape) * np.sqrt(2 * epsilon * T)\n        x = x - epsilon * grad_E(x) + noise\n        samples.append(x)\n    return np.array(samples)\n</code></pre>"},{"location":"book/chapter3_energy_based_model/sampling/#78-8-comparison-with-other-methods","title":"7.8 8. Comparison with Other Methods","text":"Method Annealing Strategy Noise Term Suitable Scenarios Standard Langevin Dynamics None Yes Single-mode stationary distributions Annealed Langevin Dynamics Yes Yes Multi-modal distributions, generative models Simulated Annealing Yes No Combinatorial optimization, discrete space Hamiltonian Monte Carlo (HMC) None No High-dimensional, parametric distributions"},{"location":"book/chapter3_energy_based_model/sampling/#79-9-advanced-extensions","title":"7.9 9. Advanced Extensions","text":"<ul> <li> <p>SGLD with Annealing : Combines stochastic gradient Langevin dynamics with annealing for large-scale datasets.</p> </li> <li> <p>Adaptive Annealing : Dynamically adjusts the annealing schedule based on feedback (e.g., acceptance rate, energy variance).</p> </li> </ul>"},{"location":"book/chapter3_energy_based_model/sampling/#710-10-key-considerations","title":"7.10 10. Key Considerations","text":"<ul> <li> <p>Temperature Schedule : Improper schedules (e.g., too rapid cooling) may lead to poor convergence.</p> </li> <li> <p>Step Size Selection : Balances convergence speed with numerical stability.</p> </li> </ul>"},{"location":"book/chapter3_energy_based_model/score_function/","title":"Score Function","text":"<p>In the context of the energy based model, we have the two types of score function:</p> <ol> <li> <p>Stein's score function</p> \\[\\tag{1} s_\\theta(x) \\overset{\\text{def}}{=} \\nabla_x \\log p_\\theta(x). \\] </li> <li> <p>ordinary score function</p> \\[ \\tag{2} s_x(\\theta) \\overset{\\text{def}}{=} \\nabla_\\theta \\log p_\\theta(x). \\] </li> </ol> <p>In the context of Langevin dynamics and the underlying Fokker-Planck equation, a key component is the gradient of the log-likelihood function \\(\\nabla_x \\log p(x)\\), which is called ordinary score function in equation (2).</p> <p>On the other hand, the derivative of the log density with respect to the sample variable \\(x\\) is called Stein's score function in equation (1).</p> <p>Despite the naming conventions, in diffusion literature, Stein's score function is often simply referred to as the score function, and we will adopt this terminology here.</p> <p>In the context of contrastive divergence (CD), the ordinary score function is used to directly calculate the derivative of \\(p_\\theta\\) and update the network parameters.</p> <p>In score matching methods, Stein's score function is employed, where the loss is defined as the divergence between the gradient of the learned score function and the true gradient of the log-likelihood function.</p> <p>Suppose \\(p_\\theta\\) is a mixture of two Gaussian distributions in one and two dimensions. We can visualize the score function of \\(p_\\theta\\) in the following figures:</p> <p></p> <p></p> <p>In two dimensions, the score function can be visualized as a vector field of the log-likelihood function. The arrow direction represents the gradient, and the arrow length indicates the gradient's magnitude. By employing Langevin dynamics, we can randomly choose a point and follow the arrows to sample from the log-likelihood function, ultimately tracing the trajectory of Langevin dynamics. In physics, the score function is analogous to \"drift,\" indicating how diffusion particles should flow towards the lowest energy state.</p>"},{"location":"book/chapter3_energy_based_model/score_function/#1-reference","title":"1. Reference","text":"<ul> <li>code about the score function of gaussian mixture: experiment/score_function_gaussian.ipynb</li> </ul>"},{"location":"book/chapter3_energy_based_model/score_matching/","title":"Score matching","text":"<p>Score Matching \u662f\u4e00\u79cd\u4f30\u8ba1\u6982\u7387\u5206\u5e03\u7684\u5bc6\u5ea6\u6a21\u578b\u7684\u65b9\u6cd5\uff0c\u6700\u65e9\u7531 Aapo Hyv\u00e4rinen \u5728 2005 \u5e74\u63d0\u51fa\u3002\u5b83\u7684\u4e3b\u8981\u76ee\u6807\u662f\u901a\u8fc7\u76f4\u63a5\u62df\u5408\u6570\u636e\u7684\u6982\u7387\u5bc6\u5ea6\u68af\u5ea6\uff08\u4e5f\u79f0\u4e3a score function\uff09\u6765\u907f\u514d\u5bf9\u5f52\u4e00\u5316\u56e0\u5b50\uff08partition function\uff09\u7684\u663e\u5f0f\u8ba1\u7b97\u3002\u4ee5\u4e0b\u662f\u5bf9 Score Matching \u65b9\u6cd5\u7684\u603b\u7ed3\uff1a</p> <p>\u6838\u5fc3\u601d\u60f3</p> <ul> <li> <p>\u8bbe \\(p(x)\\) \u662f\u6570\u636e\u7684\u771f\u5b9e\u5206\u5e03\uff0c\u6a21\u578b\u5206\u5e03\u4e3a \\(q_\\theta(x)\\)\u3002</p> </li> <li> <p>Score Matching \u7684\u76ee\u6807\u662f\u4f7f\u6a21\u578b\u7684 score function \\(\\nabla_x \\log q_\\theta(x)\\) \u5c3d\u53ef\u80fd\u63a5\u8fd1\u6570\u636e\u5206\u5e03\u7684 score function \\(\\nabla_x \\log p(x)\\)</p> </li> <li> <p>\u6362\u53e5\u8bdd\u8bf4\uff0c\u4f18\u5316\u76ee\u6807\u662f\u6700\u5c0f\u5316\u4ee5\u4e0b\u76ee\u6807\u51fd\u6570\uff1a</p> </li> </ul> \\[  J(\\theta) = \\frac{1}{2} \\mathbb{E}_{p(x)} \\left[ \\| \\nabla_x \\log q_\\theta(x) - \\nabla_x \\log p(x) \\|^2 \\right]. \\] <p>\u603b\u4f53\u6765\u8bf4\uff0c\u5728EBM\u548cSBM (energy based model and score based model) \u4e2d,score matching \u90fd\u53ef\u4ee5\u4f7f\u7528\u3002\u5728EBM\u4e2d\uff0c\u51fd\u6570\u662f\u4e00\u4e2a\u6807\u91cf\uff0c\u8868\u793a\u80fd\u91cf\uff0c\u80fd\u91cf\u4f4e\u7684\u5730\u65b9\u8868\u793a\u6982\u7387\u9ad8\uff0c\u7a33\u5b9a\u533a\u57df\u3002\u5728SBM\u4e2d\uff0c\u51fd\u6570\u662f\u4e00\u4e2a\u5411\u91cf\uff0c\u8868\u793a score function\uff0cscore \u8868\u793a\u80fd\u91cf\u6216\u8005\u5bc6\u5ea6\u53d8\u5316\u7684\u5267\u70c8\u7a0b\u5ea6\u548c\u65b9\u5411\uff0c\u968f\u7740score \u7684\u8d1f\u65b9\u5411\uff0c\u4f1a\u5230\u8fbe\u80fd\u91cf\u4f4e\u7684\u533a\u57df\u3002score matching \u5728\u8fd9\u4e24\u79cd\u6a21\u578b\u4e2d\u90fd\u6709\u81ea\u7136\u7684\u6269\u5c55\uff0c\u5373\u53ef\u4ee5\u62df\u5408\u975e\u5e38\u590d\u6742\u7684density function\u6216\u8005\u5176score function\u3002</p> <p>\u5bf9\u4e8escore matching, \u5b83\u4e5f\u6709\u4e0d\u540c\u7684\u5b9e\u73b0\u65b9\u6cd5\u3002</p> <ul> <li>explicite score matching</li> <li>sliced score matching</li> <li>denosing score matching</li> </ul>"},{"location":"book/chapter3_energy_based_model/score_matching/#1-explicit-score-matching","title":"1. Explicit Score-Matching","text":""},{"location":"book/chapter3_energy_based_model/score_matching/#11-esm","title":"1.1 \u663e\u5f0f\u5206\u6570\u5339\u914d\uff08ESM\uff09\u7684\u76f4\u89c2\u601d\u60f3","text":"<p>ESM \u7684\u6838\u5fc3\u76ee\u6807\u662f\u8bad\u7ec3\u4e00\u4e2a\u6a21\u578b $ s_\\theta(x) $\uff0c\u4f7f\u5176\u9884\u6d4b\u7684\u68af\u5ea6\u5c3d\u53ef\u80fd\u63a5\u8fd1\u771f\u5b9e\u7684 score function\u3002\u4e3a\u6b64\uff0cESM \u76f4\u63a5\u5b9a\u4e49\u4e00\u4e2a\u635f\u5931\u51fd\u6570\uff1a</p> \\[ \\mathcal{L}(\\theta) = \\mathbb{E}_{x \\sim p(x)} \\left[ \\| s_\\theta(x) - \\nabla_x \\log p(x) \\|^2 \\right] \\] <p>\u4f46\u95ee\u9898\u5728\u4e8e\uff1a\u771f\u5b9e\u5206\u5e03 \\(p(x)\\) \u672a\u77e5\uff0c\u56e0\u6b64\u65e0\u6cd5\u76f4\u63a5\u8ba1\u7b97\u771f\u5b9e\u7684\u68af\u5ea6\u3002 \u89e3\u51b3\u65b9\u6848\uff1a\u5148\u7528 \u6838\u5bc6\u5ea6\u4f30\u8ba1\uff08KDE\uff09 \u8fd1\u4f3c \\(p(x)\\)\uff0c\u518d\u7528 KDE \u7684\u7ed3\u679c\u8bad\u7ec3\u6a21\u578b\u3002</p>"},{"location":"book/chapter3_energy_based_model/score_matching/#12-step-1kde","title":"1.2 Step 1\uff1a\u7528\u6838\u5bc6\u5ea6\u4f30\u8ba1\uff08KDE\uff09\u8fd1\u4f3c\u6570\u636e\u5206\u5e03","text":"<p>KDE \u662f\u4e00\u79cd\u975e\u53c2\u6570\u65b9\u6cd5\uff0c\u901a\u8fc7\u6570\u636e\u70b9\u5468\u56f4\u7684\u201c\u5e73\u6ed1\u5c0f\u5c71\u4e18\u201d\uff08\u6838\u51fd\u6570\uff09\u53e0\u52a0\u6765\u4f30\u8ba1\u5206\u5e03\u3002\u4f8b\u5982\uff0c\u5bf9\u4e8e\u6570\u636e\u70b9 $ {x_1, x_2, ..., x_N} $\uff0cKDE \u7684\u516c\u5f0f\u4e3a\uff1a</p> \\[ \\hat{p}(x) = \\frac{1}{N} \\sum_{i=1}^N K_h(x - x_i) \\] <p>\u5176\u4e2d $ K_h $ \u662f\u6838\u51fd\u6570\uff08\u5982\u9ad8\u65af\u6838\uff09\uff0c$ h $ \u662f\u63a7\u5236\u5e73\u6ed1\u5ea6\u7684\u5e26\u5bbd\u53c2\u6570\u3002</p> <p>\u9ad8\u65af\u6838\u7684\u76f4\u89c2\u89e3\u91ca\uff1a\u6bcf\u4e2a\u6570\u636e\u70b9 $ x_i $ \u5468\u56f4\u751f\u6210\u4e00\u4e2a\u949f\u5f62\u66f2\u7ebf\uff0c\u6240\u6709\u66f2\u7ebf\u53e0\u52a0\u5f62\u6210\u6574\u4f53\u5206\u5e03\u3002</p>"},{"location":"book/chapter3_energy_based_model/score_matching/#13-step-2-kde","title":"1.3 Step 2\uff1a\u8ba1\u7b97 KDE \u7684\u68af\u5ea6","text":"<p>\u4e3a\u4e86\u5f97\u5230 score function\uff0c\u9700\u8ba1\u7b97 $ \\nabla_x \\log \\hat{p}(x) $\u3002\u4ee5\u9ad8\u65af\u6838\u4e3a\u4f8b\uff1a</p> <ol> <li>\u8ba1\u7b97\u68af\u5ea6\u7684\u5206\u5b50\u90e8\u5206\uff1a</li> </ol> \\[ \\nabla_x \\hat{p}(x) = \\frac{1}{N} \\sum_{i=1}^N K_h(x - x_i) \\cdot \\left(-\\frac{x - x_i}{h^2}\\right) \\] <ol> <li>\u8ba1\u7b97\u68af\u5ea6\uff1a</li> </ol> \\[ \\nabla_x \\log \\hat{p}(x) = \\frac{\\nabla_x \\hat{p}(x)}{\\hat{p}(x)} \\] <p>\u7269\u7406\u610f\u4e49\uff1a\u68af\u5ea6\u65b9\u5411\u6307\u5411\u5468\u56f4\u6570\u636e\u70b9\u7684\u52a0\u6743\u5e73\u5747\u4f4d\u7f6e\u3002</p>"},{"location":"book/chapter3_energy_based_model/score_matching/#14-step-3","title":"1.4 Step 3\uff1a\u8bad\u7ec3\u6a21\u578b\u62df\u5408\u68af\u5ea6","text":"<p>\u5b9a\u4e49\u4e00\u4e2a\u6a21\u578b\uff08\u5982\u795e\u7ecf\u7f51\u7edc\uff09 $ s_\\theta(x) $\uff0c\u8f93\u5165\u6570\u636e\u70b9 $ x $\uff0c\u8f93\u51fa\u9884\u6d4b\u7684\u68af\u5ea6\u3002\u635f\u5931\u51fd\u6570\u4e3a\uff1a</p> \\[ \\mathcal{L}(\\theta) \\approx \\frac{1}{N} \\sum_{i=1}^N \\| s_\\theta(x_i) - \\nabla_x \\log \\hat{p}(x_i) \\|^2 \\] <p>\u8bad\u7ec3\u8fc7\u7a0b\uff1a</p> <ol> <li>\u5bf9\u6bcf\u4e2a\u6570\u636e\u70b9 $ x_i $\uff0c\u7528 KDE \u8ba1\u7b97\u5176\u68af\u5ea6 $ \\nabla_x \\log \\hat{p}(x_i) $\u3002</li> <li>\u7528\u68af\u5ea6\u4e0b\u964d\u6cd5\u4f18\u5316\u6a21\u578b\u53c2\u6570 $ \\theta $\uff0c\u4f7f\u9884\u6d4b\u503c\u903c\u8fd1 KDE \u7684\u68af\u5ea6\u3002</li> </ol>"},{"location":"book/chapter3_energy_based_model/score_matching/#15","title":"1.5 \u4e3a\u4ec0\u4e48\u9700\u8981\u6539\u8fdb\uff1f","text":"<p>\u5c3d\u7ba1\u65b9\u6cd5\u76f4\u89c2\uff0c\u4f46\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a</p> <ol> <li>\u7ef4\u5ea6\u707e\u96be\uff1aKDE \u5728\u9ad8\u7ef4\u6570\u636e\u4e2d\u6548\u679c\u5dee\uff08\u8ba1\u7b97\u91cf\u5927\u4e14\u4f30\u8ba1\u4e0d\u51c6\uff09\u3002</li> <li>\u8ba1\u7b97\u6548\u7387\uff1a\u6bcf\u4e2a\u70b9\u7684\u68af\u5ea6\u8ba1\u7b97\u9700\u904d\u5386\u6240\u6709\u6570\u636e\uff0c\u590d\u6742\u5ea6\u4e3a $ O(N) $\u3002</li> </ol>"},{"location":"book/chapter3_energy_based_model/score_matching/#16","title":"1.6 \u6539\u8fdb\u65b9\u6848","text":"<ol> <li> <p>\u53bb\u566a\u5206\u6570\u5339\u914d\uff08DSM\uff09\uff1a    \u76f4\u63a5\u5411\u6570\u636e\u6dfb\u52a0\u566a\u58f0\uff08\u5982\u9ad8\u65af\u566a\u58f0\uff09\uff0c\u5229\u7528\u566a\u58f0\u5206\u5e03\u7684\u5df2\u77e5\u68af\u5ea6\u95f4\u63a5\u8bad\u7ec3\u6a21\u578b\uff0c\u907f\u514d\u663e\u5f0f\u8ba1\u7b97 $ p(x) $\u3002</p> </li> <li> <p>\u964d\u7ef4\u9884\u5904\u7406\uff1a    \u5bf9\u9ad8\u7ef4\u6570\u636e\u4f7f\u7528 PCA \u6216\u81ea\u7f16\u7801\u5668\u964d\u7ef4\uff0c\u518d\u5728\u4f4e\u7ef4\u7a7a\u95f4\u5e94\u7528 KDE\u3002</p> </li> <li> <p>Mini-batch \u4f18\u5316\uff1a    \u6bcf\u6b21\u968f\u673a\u91c7\u6837\u90e8\u5206\u6570\u636e\u8ba1\u7b97\u68af\u5ea6\uff0c\u51cf\u5c11\u8ba1\u7b97\u91cf\u3002</p> </li> </ol>"},{"location":"book/chapter3_energy_based_model/score_matching/#17","title":"1.7 \u603b\u7ed3\u4e0e\u9002\u7528\u573a\u666f","text":"<ul> <li>\u9002\u7528\u573a\u666f\uff1a\u4f4e\u7ef4\u6570\u636e\u5206\u5e03\u4f30\u8ba1\u3001\u751f\u6210\u6a21\u578b\u9884\u8bad\u7ec3\u3001\u5c0f\u89c4\u6a21\u6570\u636e\u5206\u6790\u3002</li> <li>\u4f18\u52bf\uff1a\u65e0\u9700\u5047\u8bbe\u6570\u636e\u5206\u5e03\u5f62\u5f0f\uff0c\u76f4\u63a5\u901a\u8fc7\u6570\u636e\u5b66\u4e60\u68af\u5ea6\u3002</li> <li>\u5c40\u9650\u6027\uff1a\u9ad8\u7ef4\u6570\u636e\u6548\u679c\u53d7\u9650\uff0c\u9700\u7ed3\u5408 DSM \u6216\u964d\u7ef4\u6280\u672f\u3002</li> </ul> <p>\u901a\u8fc7 KDE \u4e0e\u663e\u5f0f\u5206\u6570\u5339\u914d\u7684\u7ed3\u5408\uff0c\u6211\u4eec\u80fd\u591f\u4ece\u6709\u9650\u7684\u6570\u636e\u4e2d\u201c\u611f\u77e5\u201d\u6982\u7387\u5206\u5e03\u7684\u53d8\u5316\u65b9\u5411\uff0c\u4e3a\u540e\u7eed\u751f\u6210\u6a21\u578b\u6216\u5f02\u5e38\u68c0\u6d4b\u4efb\u52a1\u5960\u5b9a\u57fa\u7840\u3002\u5c3d\u7ba1\u5b58\u5728\u6311\u6218\uff0c\u8fd9\u4e00\u65b9\u6cd5\u5728\u4f4e\u7ef4\u573a\u666f\u4e2d\u4ecd\u662f\u4e00\u4e2a\u7b80\u6d01\u800c\u5f3a\u5927\u7684\u5de5\u5177\u3002</p>"},{"location":"book/chapter3_energy_based_model/score_matching/#18","title":"1.8 \u5b9e\u9a8c","text":"<p>\u6211\u4eec\u7528\u4e00\u4e2a\u4e8c\u7ef4\u7684\u6df7\u5408\u9ad8\u65af\u5206\u5e03\u8fdb\u884c\u5b9e\u9a8c\u3002</p> <pre><code>def generate_data(num_samples=1000):\n    # \u751f\u6210\u4e24\u4e2a\u9ad8\u65af\u5206\u5e03\u7684\u6df7\u5408\u6570\u636e\n    mean1 = [2, 2]\n    cov1 = [[1, 0.5], [0.5, 1]]\n    data1 = np.random.multivariate_normal(mean1, cov1, num_samples//2)\n\n    mean2 = [-2, -2]\n    cov2 = [[1, -0.5], [-0.5, 1]]\n    data2 = np.random.multivariate_normal(mean2, cov2, num_samples//2)\n\n    return np.vstack([data1, data2])\n</code></pre> <p>\u6839\u636e\u4ee5\u4e0a\u7684\u6df7\u5408\u9ad8\u65af\u5206\u5e03\u751f\u6210\u7684\u6570\u636e\u3002  \u7136\u540e\u6211\u4eec\u8fdb\u884cKDE\uff0c\u7136\u540e\u5229\u7528KDE\u53bb\u4f30\u8ba1\u68af\u5ea6\u3002\u6700\u540e\u5f97\u5230\u9884\u6d4b\u7ed3\u679c\u548c\u771f\u5b9e\u68af\u5ea6\u7684\u53ef\u89c6\u5316\u3002</p> <p></p> <p>\u53ef\u4ee5\u770b\u5230\u6700\u7ec8\u5728\u9ad8\u6982\u7387\u533a\u57df\uff0c\u5206\u5e03\u662f\u6bd4\u8f83\u76f8\u4f3c\u7684\uff0c\u4f46\u662f\u5728\u4f4e\u6982\u7387\u533a\u57df\uff0c\u5206\u5e03\u76f8\u5dee\u8f83\u5927\u3002\u8fd9\u4e2a\u539f\u56e0\u4e3b\u8981\u662f\u56e0\u4e3a\u4f4e\u6982\u7387\u533a\u57df\u7684\u6570\u636e\u91cf\u8f83\u5c11\uff0cKDE \u4f30\u8ba1\u7684\u68af\u5ea6\u53ef\u80fd\u4f1a\u53d7\u5230\u5927\u91cf\u566a\u58f0\u7684\u5f71\u54cd\u3002 \u540c\u65f6\u6a21\u578b\u5b66\u51fa\u6765\u7684\u5206\u5e03\u6bd4KDE\u548c\u539f\u59cb\u5206\u5e03\u66f4\u52a0\u63a5\u8fd1\u3002</p>"},{"location":"book/chapter3_energy_based_model/score_matching/#2-implicit-score-matching","title":"2. Implicit Score Matching","text":""},{"location":"book/chapter3_energy_based_model/score_matching/#21-fisher","title":"2.1 \u4eceFisher\u6563\u5ea6\u5230\u9690\u5f0f\u5206\u6570\u5339\u914d\u7684\u63a8\u5bfc","text":""},{"location":"book/chapter3_energy_based_model/score_matching/#22-1-fisher","title":"2.2 1. \u5b9a\u4e49Fisher\u6563\u5ea6","text":"<p>Fisher\u6563\u5ea6\u8861\u91cf\u4e24\u4e2a\u6982\u7387\u5206\u5e03 $ p(\\mathbf{x}) $ \u548c $ q(\\mathbf{x}; \\theta) $ \u7684\u5206\u6570\u5dee\u5f02\uff1a</p> \\[ D_F(p \\parallel q) = \\mathbb{E}_{p(\\mathbf{x})} \\left[ \\| \\nabla_{\\mathbf{x}} \\log p(\\mathbf{x}) - \\nabla_{\\mathbf{x}} \\log q(\\mathbf{x}; \\theta) \\|^2 \\right]. \\]"},{"location":"book/chapter3_energy_based_model/score_matching/#23-2","title":"2.3 2. \u5c55\u5f00\u5e73\u65b9\u9879","text":"<p>\u5c06\u5e73\u65b9\u9879\u5c55\u5f00\u4e3a\u4e09\u90e8\u5206\uff1a</p> \\[ D_F = \\underbrace{\\mathbb{E}_{p} \\left[ \\| \\nabla \\log p \\|^2 \\right]}_{T_1} - 2 \\underbrace{\\mathbb{E}_{p} \\left[ (\\nabla \\log p)^\\top (\\nabla \\log q) \\right]}_{T_2} + \\underbrace{\\mathbb{E}_{p} \\left[ \\| \\nabla \\log q \\|^2 \\right]}_{T_3}. \\]"},{"location":"book/chapter3_energy_based_model/score_matching/#24-3-t_2","title":"2.4 3. \u5904\u7406\u4ea4\u53c9\u9879 $ T_2 $","text":"<p>\u4ea4\u53c9\u9879</p> \\[ T_2 = -2 \\mathbb{E}_{p} \\left[ (\\nabla \\log p)^\\top (\\nabla \\log q) \\right] \\] <p>\u5305\u542b\u672a\u77e5\u7684 \\(\\nabla \\log p\\)\uff0c\u9700\u901a\u8fc7\u5206\u90e8\u79ef\u5206\u6d88\u9664\u4f9d\u8d56\u3002</p>"},{"location":"book/chapter3_energy_based_model/score_matching/#241","title":"2.4.1 \u5206\u91cf\u4e3a\u6807\u91cf\u7684\u63a8\u5bfc","text":"<p>\u5bf9\u6bcf\u4e2a\u7ef4\u5ea6 $ x_i $ \u5355\u72ec\u5904\u7406\uff1a</p> \\[ T_2 = -2 \\sum_{i=1}^d \\mathbb{E}_{p} \\left[ \\partial_i \\log p \\cdot \\partial_i \\log q \\right]. \\] <p>\u5e94\u7528\u5206\u90e8\u79ef\u5206\u516c\u5f0f\uff1a</p> \\[ \\int p(\\mathbf{x}) \\partial_i \\log p \\cdot \\partial_i \\log q \\, d\\mathbf{x} = -\\int p(\\mathbf{x}) \\partial_i^2 \\log q \\, d\\mathbf{x}. \\] <p>\u5173\u952e\u5047\u8bbe\uff1a\u6982\u7387\u5bc6\u5ea6\u5728\u8fb9\u754c\u5904\u8870\u51cf\u81f3\u96f6\uff0c\u5373\uff1a</p> \\[ \\left. p(\\mathbf{x}) \\partial_i \\log q \\right|_{x_i \\to \\pm\\infty} = 0. \\]"},{"location":"book/chapter3_energy_based_model/score_matching/#242","title":"2.4.2 \u5408\u5e76\u6240\u6709\u7ef4\u5ea6","text":"<p>\u5bf9\u6bcf\u4e2a\u5206\u91cf\u79ef\u5206\u540e\u6c42\u548c\uff1a</p> \\[ T_2 = 2 \\sum_{i=1}^d \\mathbb{E}_{p} \\left[ \\partial_i^2 \\log q \\right] = 2 \\mathbb{E}_{p} \\left[ \\text{tr}(\\nabla_{\\mathbf{x}}^2 \\log q) \\right], \\] <p>\u5176\u4e2d \\(\\text{tr}(\\nabla_{\\mathbf{x}}^2 \\log q)\\) \u8868\u793aHessian\u77e9\u9635\u7684\u8ff9\u3002</p>"},{"location":"book/chapter3_energy_based_model/score_matching/#25-4-fisher","title":"2.5 4. \u91cd\u7ec4Fisher\u6563\u5ea6","text":"<p>\u5c06 \\(T_1, T_2, T_3\\) \u4ee3\u5165\u539f\u5f0f\uff1a</p> \\[ D_F = \\mathbb{E}_{p} \\left[ \\| \\nabla \\log p \\|^2 \\right] + \\mathbb{E}_{p} \\left[ \\| \\nabla \\log q \\|^2 + 2 \\, \\text{tr}(\\nabla^2 \\log q) \\right]. \\] <p>\u5ffd\u7565\u5e38\u6570\u9879 \\(\\mathbb{E}_{p} \\left[ \\| \\nabla \\log p \\|^2 \\right]\\)\uff0c\u4f18\u5316\u76ee\u6807\u7b80\u5316\u4e3a\uff1a</p> \\[ \\min_{\\theta} \\mathbb{E}_{p} \\left[ \\| \\nabla \\log q \\|^2 + 2 \\, \\text{tr}(\\nabla^2 \\log q) \\right]. \\]"},{"location":"book/chapter3_energy_based_model/score_matching/#26-5","title":"2.6 5. \u6807\u51c6\u5316\u76ee\u6807\u51fd\u6570","text":"<p>\u5f15\u5165\u7f29\u653e\u56e0\u5b50 \\(\\frac{1}{2}\\)\uff0c\u5f97\u5230\u9690\u5f0f\u5206\u6570\u5339\u914d\u76ee\u6807\u51fd\u6570\uff1a</p> \\[ J(\\theta) = \\mathbb{E}_{p(\\mathbf{x})} \\left[ \\frac{1}{2} \\| \\nabla_{\\mathbf{x}} \\log q(\\mathbf{x}; \\theta) \\|^2 + \\text{tr}(\\nabla_{\\mathbf{x}}^2 \\log q(\\mathbf{x}; \\theta)) \\right]. \\]"},{"location":"book/chapter3_energy_based_model/score_matching/#27-6","title":"2.7 6. \u9690\u5f0f\u6027\u5206\u6790","text":"<ul> <li>\u663e\u5f0f\u5339\u914d\u9879\uff1a\\(\\frac{1}{2} \\| \\nabla \\log q \\|^2\\) \u76f4\u63a5\u7ea6\u675f\u5206\u6570\u6a21\u957f\u3002</li> <li>\u9690\u5f0f\u6b63\u5219\u9879\uff1a\\(\\text{tr}(\\nabla^2 \\log q)\\) \u901a\u8fc7\u4e8c\u9636\u5bfc\u6570\u9690\u5f0f\u7ea6\u675f\u5206\u6570\u65b9\u5411\uff0c\u907f\u514d\u4f9d\u8d56 \\(\\nabla \\log p\\)\u3002</li> </ul>"},{"location":"book/chapter3_energy_based_model/score_matching/#271-7","title":"2.7.1 7. \u6700\u7ec8\u5f62\u5f0f","text":"<p>\u9690\u5f0f\u5206\u6570\u5339\u914d\u7684\u76ee\u6807\u51fd\u6570\u4e3a\uff1a</p> \\[ \\boxed{J(\\theta) = \\mathbb{E}_{p(\\mathbf{x})} \\left[ \\frac{1}{2} \\| \\nabla_{\\mathbf{x}} \\log q(\\mathbf{x}; \\theta) \\|^2 + \\text{tr}(\\nabla_{\\mathbf{x}}^2 \\log q(\\mathbf{x}; \\theta)) \\right]}. \\] <p>\u5f53\u7136\u5982\u679c\u6211\u4eec\u53ea\u5173\u6ce8score function \u672c\u8eab\uff0c\u800c\u4e0d\u9700\u8981\u77e5\u9053\u539f\u59cb\u7684density function \u6216\u8005\u8bf4energy function, \u90a3\u4e48\u95ee\u9898\u5c31\u7b80\u5316\u4e86\uff0c\u5c31\u4e0d\u6d89\u53ca\u5230\u4e8c\u9636\u5bfc\u4e86\u3002</p> <p>Let \\(s_\\theta(x) = \\nabla_{\\mathbf{x}} \\log q(\\mathbf{x}; \\theta)\\) be score function.</p> <p>The implicit score matching loss can be approximated by Monte Carlo:</p> \\[ J_{\\text{ISM}}(\\theta) \\approx \\frac{1}{M} \\sum_{m=1}^{M} \\sum_{i} \\left( \\partial_i \\mathbf{s}_{\\theta}(\\mathbf{x}^{(m)}) + \\frac{1}{2} \\| \\mathbf{s}_{\\theta}(\\mathbf{x}^{(m)}) \\|^2 \\right), \\] <p>where \\(\\partial_i \\mathbf{s}_{\\theta}(\\mathbf{x}^{(m)}) = \\frac{\\partial}{\\partial x_i} [\\mathbf{s}_{\\theta}(\\mathbf{x})]_i = \\frac{\\partial^2}{\\partial x_i^2} \\log p(\\mathbf{x})\\). If the model for the score function is realized by a deep neural network, the trace operator can be difficult to compute, hence making the implicit score matching not scalable [40].</p> <p>Refenrence</p> <ul> <li>Aapo Hyv\u00a8arinen. Estimation of non-normalized statistical models by score matching. Journal of Machine Learning Research (JMLR), 6(24):695\u2013709, 2005. https://jmlr.org/papers/volume6/ hyvarinen05a/hyvarinen05a.pdf</li> </ul>"},{"location":"book/chapter3_energy_based_model/score_matching/#28-experiment","title":"2.8 experiment","text":"<p>We use a mixture of guassian distribution for testing. But the results is not good.</p> <p> </p> <p>It turns out that the derivative maganitude is near 0, but the trace is almost - 0.0004.</p> <ul> <li>optimizatioin 1 add regularization of \\(E_x p_\\theta(x)\\). Still not work, almost constant </li> <li>optimization 2 output energy function not the \\(p_\\theta\\), that is without a exponention.</li> </ul>"},{"location":"book/chapter3_energy_based_model/score_matching/#3-siced-score-matching","title":"3. Siced score matching","text":"<ul> <li>optimization3 Finally, it is because that the network used ReLU, which is not enough for modeling the complex density function. Here we change to Swish function instead. Now the iteration is much more stable and output the correct estimation of the ground truth density function (un-normalized)</li> </ul>"},{"location":"book/chapter3_energy_based_model/score_matching/#31","title":"3.1 \u6838\u5fc3\u601d\u60f3","text":"<p>Sliced Score Matching\uff08\u5207\u7247\u5206\u6570\u5339\u914d\uff09 \u662f\u4e00\u79cd\u7528\u4e8e\u9ad8\u6548\u4f30\u8ba1\u6570\u636e\u5206\u5e03\u68af\u5ea6\uff08score function\uff09\u7684\u65b9\u6cd5\uff0c\u4e3b\u8981\u9488\u5bf9\u9ad8\u7ef4\u6570\u636e\u573a\u666f\u8bbe\u8ba1\u3002\u5176\u6838\u5fc3\u521b\u65b0\u5728\u4e8e\u901a\u8fc7\u968f\u673a\u6295\u5f71\u6280\u672f\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u907f\u514d\u76f4\u63a5\u8ba1\u7b97\u9ad8\u7ef4Jacobian\u77e9\u9635\u7684\u8ff9\uff08Trace\uff09\uff0c\u4ece\u800c\u89e3\u51b3\u4f20\u7edfImplicit Score Matching\u7684\u53ef\u6269\u5c55\u6027\u95ee\u9898\u3002</p> <p>\u76f4\u89c2\u7684\u8bf4\uff0c\u5c31\u662f\u5728\u4efb\u4f55\u7684\u6295\u5f71\u7a7a\u95f4\uff0c\u4e24\u4e2afunction \u80fd\u591f\u8fd1\u4f3c\uff0c\u90a3\u4e48\u539f\u672c\u7684\u4e24\u4e2afunction \u4e5f\u5fc5\u7136\u8fd1\u4f3c\u3002\u8fd9\u662f\u4e00\u79cd\u6bd4\u8f83\u91cd\u8981\u7684\u601d\u60f3\uff0c\u53ef\u4ee5\u5728\u5176\u4ed6\u7684\u95ee\u9898\u4e2d\u501f\u9274\u3002\u540c\u6837\u7684\u8fd8\u6709\uff0c\u5982\u679c\u4e24\u4e2afunction \u7684\u68af\u5ea6\u5904\u5904\u76f8\u7b49\uff0c\u90a3\u4e48\u8fd9\u4e24\u4e2afunction \u4e5f\u76f8\u7b49\uff08\u5dee\u4e00\u4e2aconstant), \u8fd9\u4e9b\u90fd\u662f\u4e00\u79cd\u8f6c\u5316\u95ee\u9898\u7684\u6280\u5de7\uff0c\u503c\u5f97\u5b66\u4e60\u3002</p>"},{"location":"book/chapter3_energy_based_model/score_matching/#32","title":"3.2 \u6570\u5b66\u5b9a\u4e49","text":"<p>1. Fisher \u6563\u5ea6\u7684\u5b9a\u4e49 Fisher \u6563\u5ea6\u8861\u91cf\u771f\u5b9e\u5206\u5e03 \\(p(x)\\) \u4e0e\u6a21\u578b\u5206\u5e03 \\(q_\\theta(x)\\) \u7684 score function \u4e4b\u95f4\u7684\u5dee\u5f02\uff1a</p> \\[ \\mathcal{D}_{\\text{Fisher}}(p \\| q_\\theta) = \\mathbb{E}_{p(x)} \\left[ \\| \\nabla_x \\log p(x) - \\nabla_x \\log q_\\theta(x) \\|^2 \\right]. \\] <p>\u6700\u5c0f\u5316 Fisher \u6563\u5ea6\u7b49\u4ef7\u4e8e\u8ba9\u6a21\u578b score \\(\\nabla_x \\log q_\\theta(x)\\) \u903c\u8fd1\u771f\u5b9e score \\(\\nabla_x \\log p(x)\\)\u3002</p> <p>\u901a\u8fc7 Stein \u6052\u7b49\u5f0f\uff0cISM \u5c06 Fisher \u6563\u5ea6\u8f6c\u5316\u4e3a\u4ee5\u4e0b\u76ee\u6807\u51fd\u6570\uff1a</p> \\[ J_{\\text{ISM}}(\\theta) = \\mathbb{E}_{p(x)} \\left[ \\operatorname{Tr}(\\nabla_x \\mathbf{s}_\\theta(x)) + \\frac{1}{2} \\| \\mathbf{s}_\\theta(x) \\|^2 \\right], \\] <p>\u5176\u4e2d \\(\\mathbf{s}_\\theta(x)\\) \u662f\u6a21\u578b\u9884\u6d4b\u7684 score function\u3002</p> <p>\u5173\u952e\u7b49\u5f0f\uff1a\u5f53 \\(\\mathbf{s}_\\theta(x) = \\nabla_x \\log p_\\theta(x)\\) \u65f6\uff0cISM \u635f\u5931\u8fbe\u5230\u6700\u5c0f\u503c\uff0c\u6b64\u65f6 \\(\\mathcal{D}_{\\text{Fisher}} = 0\\)\u3002</p> <p>3. Sliced Score Matching \u7684\u52a8\u673a ISM \u7684\u74f6\u9888\u5728\u4e8e\u8ba1\u7b97 Jacobian \u77e9\u9635\u7684\u8ff9 \\(\\operatorname{Tr}(\\nabla_x \\mathbf{s}_\\theta(x))\\)\uff0c\u5176\u590d\u6742\u5ea6\u4e3a \\(O(d^2)\\)\uff08\\(d\\) \u4e3a\u6570\u636e\u7ef4\u5ea6\uff09\u3002 \u6838\u5fc3\u601d\u60f3\uff1a\u5229\u7528\u968f\u673a\u6295\u5f71\u6280\u672f\u5c06\u8ff9\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\u964d\u81f3 \\(O(d)\\)\u3002</p> <p>4. \u968f\u673a\u6295\u5f71\u8fd1\u4f3c\u8ff9</p> <p>\u6839\u636e Hutchinson \u8ff9\u4f30\u8ba1\u5668\uff0c\u4efb\u610f\u77e9\u9635 \\(A \\in \\mathbb{R}^{d \\times d}\\) \u7684\u8ff9\u53ef\u8868\u793a\u4e3a\uff1a</p> \\[ \\operatorname{Tr}(A) = \\mathbb{E}_{\\mathbf{v} \\sim \\mathcal{N}(0, I)} \\left[ \\mathbf{v}^\\top A \\mathbf{v} \\right], \\] <p>\u5176\u4e2d $ \\mathbf{v} $ \u4e3a\u6807\u51c6\u6b63\u6001\u5206\u5e03\u7684\u968f\u673a\u5411\u91cf\u3002 \u5c06\u6b64\u6280\u672f\u5e94\u7528\u4e8e ISM \u7684\u8ff9\u9879\uff1a</p> \\[ \\operatorname{Tr}(\\nabla_x \\mathbf{s}_\\theta(x)) = \\mathbb{E}_{\\mathbf{v}} \\left[ \\mathbf{v}^\\top \\nabla_x \\mathbf{s}_\\theta(x) \\mathbf{v} \\right]. \\] <p>5. Sliced Score Matching \u7684\u76ee\u6807\u51fd\u6570</p> <p>\u5c06 ISM \u7684\u8ff9\u9879\u66ff\u6362\u4e3a\u968f\u673a\u6295\u5f71\u8fd1\u4f3c\uff0c\u5f97\u5230 SSM \u7684\u76ee\u6807\u51fd\u6570\uff1a</p> \\[ J_{\\text{SSM}}(\\theta) = \\mathbb{E}_{p(x)} \\mathbb{E}_{\\mathbf{v}} \\left[ \\mathbf{v}^\\top \\nabla_x \\mathbf{s}_\\theta(x) \\mathbf{v} + \\frac{1}{2} \\| \\mathbf{s}_\\theta(x) \\|^2 \\right]. \\] <p>\u8499\u7279\u5361\u6d1b\u8fd1\u4f3c\uff1a\u901a\u8fc7\u91c7\u6837\u5c11\u91cf\u6295\u5f71\u65b9\u5411 $ {\\mathbf{v}k}^K $ \u4f30\u8ba1\u671f\u671b\u503c\uff1a</p> \\[ J_{\\text{SSM}}(\\theta) \\approx \\frac{1}{N} \\sum_{i=1}^N \\left[ \\frac{1}{K} \\sum_{k=1}^K \\mathbf{v}_k^\\top \\nabla_x \\mathbf{s}_\\theta(x_i) \\mathbf{v}_k + \\frac{1}{2} \\| \\mathbf{s}_\\theta(x_i) \\|^2 \\right]. \\] <p>6. \u7b49\u4ef7\u6027\u8bc1\u660e</p> <p>\u5f53\u6295\u5f71\u65b9\u5411\u6570\u91cf $K \\to \\infty $ \u65f6\uff0cSSM \u4e0e ISM \u7684\u76ee\u6807\u51fd\u6570\u7b49\u4ef7\uff1a</p> \\[ \\lim_{K \\to \\infty} J_{\\text{SSM}}(\\theta) = J_{\\text{ISM}}(\\theta). \\] <p>\u56e0\u6b64\uff0cSSM \u662f ISM \u7684\u9ad8\u6548\u8fd1\u4f3c\uff0c\u4e14\u5728\u4f18\u5316\u8fc7\u7a0b\u4e2d\u7b49\u4ef7\u4e8e\u6700\u5c0f\u5316 Fisher \u6563\u5ea6\u3002</p> <p>7. \u603b\u7ed3</p> <ul> <li>\u4ece Fisher \u6563\u5ea6\u5230 SSM \u7684\u63a8\u5bfc\u8def\u5f84\uff1a</li> </ul> \\[ \\mathcal{D}_{\\text{Fisher}} \\xrightarrow{\\text{Stein \u6052\u7b49\u5f0f}} J_{\\text{ISM}} \\xrightarrow{\\text{\u968f\u673a\u6295\u5f71\u8fd1\u4f3c}} J_{\\text{SSM}}. \\] <ul> <li>SSM \u7684\u4f18\u52bf\uff1a\u5c06\u8ba1\u7b97\u590d\u6742\u5ea6\u4ece \\(O(d^2)\\) \u964d\u4f4e\u81f3 \\(O(Kd)\\)\uff0c\u9002\u7528\u4e8e\u9ad8\u7ef4\u6570\u636e\uff08\u5982\u56fe\u50cf\u3001\u6587\u672c\uff09\u3002</li> <li> <p>\u9002\u7528\u573a\u666f\uff1a\u751f\u6210\u6a21\u578b\uff08\u5982\u6269\u6563\u6a21\u578b\uff09\u3001\u65e0\u9700\u663e\u5f0f\u6982\u7387\u5bc6\u5ea6\u7684\u68af\u5ea6\u4f30\u8ba1\u3002</p> </li> <li> <p>\u57fa\u7840\u516c\u5f0f \u4e0e\u4f20\u7edfImplicit Score Matching\u7684\u635f\u5931\u51fd\u6570\u7c7b\u4f3c\uff0c\u4f46\u5f15\u5165\u968f\u673a\u6295\u5f71\u5411\u91cf $ \\mathbf{v} $\uff1a</p> </li> </ul> \\[ J_{\\text{SSM}}(\\theta) = \\mathbb{E}_{p(\\mathbf{x})} \\mathbb{E}_{\\mathbf{v} \\sim \\mathcal{N}(0,I)} \\left[ \\mathbf{v}^\\top \\nabla_{\\mathbf{x}} \\mathbf{s}_\\theta(\\mathbf{x}) \\mathbf{v} + \\frac{1}{2} \\| \\mathbf{s}_\\theta(\\mathbf{x}) \\|^2 \\right], \\] <p>\u5176\u4e2d\uff1a</p> <ul> <li> <p>\\(\\mathbf{v}\\) \u662f\u670d\u4ece\u6807\u51c6\u6b63\u6001\u5206\u5e03\u7684\u968f\u673a\u5411\u91cf\u3002</p> </li> <li> <p>\\(\\mathbf{v}^\\top \\nabla_{\\mathbf{x}} \\mathbf{s}_\\theta(\\mathbf{x}) \\mathbf{v}\\) \u8868\u793aJacobian\u77e9\u9635\u5728\u968f\u673a\u65b9\u5411 \\(\\mathbf{v}\\) \u4e0a\u7684\u6295\u5f71\u3002</p> </li> <li> <p>\u5173\u952e\u7b80\u5316    \u901a\u8fc7\u968f\u673a\u6295\u5f71\uff0c\u5c06\u8ba1\u7b97\u5168Jacobian\u77e9\u9635\u7684\u8ff9 \\(\\operatorname{Tr}(\\nabla_{\\mathbf{x}}\\mathbf{s}_\\theta(\\mathbf{x}))\\) \u8f6c\u5316\u4e3a\uff1a</p> </li> </ul> \\[ \\operatorname{Tr}(\\nabla_{\\mathbf{x}}\\mathbf{s}_\\theta(\\mathbf{x})) = \\mathbb{E}_{\\mathbf{v}} \\left[ \\mathbf{v}^\\top \\nabla_{\\mathbf{x}} \\mathbf{s}_\\theta(\\mathbf{x}) \\mathbf{v} \\right]. \\]"},{"location":"book/chapter3_energy_based_model/score_matching/#33-complexity-analysis","title":"3.3 Complexity Analysis","text":"<p>Consider the case</p> \\[ \\operatorname{Tr}(\\nabla_{x} \\nabla_x \\log p_\\theta (x) )) = \\mathbb{E}_{\\mathbf{v}} \\left[ \\mathbf{v}^\\top \\nabla_{x} \\nabla_x \\log p_\\theta(x) \\mathbf{v} \\right]. \\]"},{"location":"book/chapter3_energy_based_model/score_matching/#331-gradient-computation","title":"3.3.1 Gradient Computation","text":"<p>For a scalar function \\(f: \\mathbb{R}^n \\to \\mathbb{R}\\), reverse-mode AD (backpropagation) computes all partial derivatives \\(\\frac{\\partial f}{\\partial x_1}, \\ldots, \\frac{\\partial f}{\\partial x_n}\\) in a single backward pass. Its cost is on the same order as one or two forward evaluations of \\(f\\). We denote this by \\(\\mathbf{C}_\\nabla\\). Thus:</p> \\[ \\text{Cost of computing } \\nabla f(x) \\;\\approx\\; O(\\mathbf{C}_\\nabla). \\] <p>Key note: Requesting a single partial \\(\\frac{\\partial f}{\\partial x[i]}\\) doesn\u2019t save much computation in practice; the backward pass still traverses the entire graph.</p>"},{"location":"book/chapter3_energy_based_model/score_matching/#332-hessian-trace-computation","title":"3.3.2 Hessian Trace Computation","text":"<p>The Hessian \\(\\nabla^2 f(x)\\) is an \\(n \\times n\\) matrix. Its trace is</p> \\[ \\mathrm{trace}(\\nabla^2 f(x)) \\;=\\; \\sum_{i=1}^n \\frac{\\partial^2 f}{\\partial x_i^2}. \\] <p>A standard AD procedure to get each diagonal entry \\(\\frac{\\partial^2 f}{\\partial x_i^2}\\) involves one forward-mode pass (perturbing only \\(x_i\\)) plus one reverse-mode pass. Doing this for all \\(n\\) coordinates requires roughly \\(n\\) times the gradient cost:</p> \\[ \\text{Cost of computing } \\mathrm{trace}(\\nabla^2 f) \\;\\approx\\; O\\bigl(n \\times \\mathbf{C}_\\nabla\\bigr). \\]"},{"location":"book/chapter3_energy_based_model/score_matching/#333-hessian-vector-product-computation","title":"3.3.3 Hessian Vector Product Computation","text":"<p>To calculate the \\(v^TH\\cdot v\\), we have</p> <ol> <li>Calculate \\(\\nabla f(x)\\) from the backward and keep the graph</li> <li>Calculate the product \\(\\nabla f(x) v\\), which is a scalar, and then do another backward to get its derivative \\(\\nabla \\bigl[\\nabla f(x)\\cdot v\\bigr]\\)</li> <li>Calcualte \\(v^T \\nabla \\bigl[\\nabla f(x)\\cdot v\\bigr]\\) which can be ignored compared with the computation with the first two steps</li> </ol> <p>Hence, totally, the computation of \\(v^TH\\cdot v\\) is around \\(2\\times \\mathbf{C}_\\nabla\\).</p> <p>Below is a coordinate\u2010level proof that</p> \\[ \\nabla \\bigl[\\nabla f(x)\\cdot v\\bigr] \\;=\\; \\nabla^2 f(x)\\,v, \\] <p>which justifies the standard PyTorch implementation for the Hessian\u2013vector product:</p>"},{"location":"book/chapter3_energy_based_model/score_matching/#4-statement","title":"4. Statement","text":"<p>Let \\(f:\\mathbb{R}^n \\to \\mathbb{R}\\) be twice continuously differentiable, and let \\(v \\in \\mathbb{R}^n\\). Define the scalar function</p> \\[ g(x)\\;=\\;\\nabla f(x)\\,\\cdot\\,v \\;=\\; \\sum_{i=1}^n \\frac{\\partial f}{\\partial x_i}(x)\\,v_i. \\] <p>Then</p> \\[ \\nabla g(x) \\;=\\; \\nabla^2 f(x)\\,v. \\] <p>In other words, if \\(H = \\nabla^2 f(x)\\) is the Hessian of \\(f\\) at \\(x\\), then</p> \\[ \\frac{\\partial}{\\partial x_j} \\bigl[\\nabla f(x)\\cdot v\\bigr] \\;=\\; \\bigl(H\\,v\\bigr)_j \\quad \\text{for each }j=1,\\dots,n. \\]"},{"location":"book/chapter3_energy_based_model/score_matching/#5-coordinatelevel-proof","title":"5. Coordinate\u2010Level Proof","text":"<ol> <li>Expand the definition of \\(g(x)\\):</li> </ol> \\[ g(x)\\;=\\;  \\nabla f(x)\\,\\cdot\\,v  \\;=\\;  \\sum_{i=1}^n  \\frac{\\partial f}{\\partial x_i}(x)\\,v_i. \\] <ol> <li>Compute the partial derivative w.r.t. \\(x_j\\):</li> </ol> \\[ \\frac{\\partial g}{\\partial x_j}(x) \\;=\\; \\frac{\\partial}{\\partial x_j} \\Bigl[\\,   \\sum_{i=1}^n   \\frac{\\partial f}{\\partial x_i}(x)\\,v_i \\Bigr]. \\] <ol> <li>Bring the partial derivative inside the sum (assuming sufficient smoothness of \\(f\\)):</li> </ol> \\[ \\frac{\\partial g}{\\partial x_j}(x)\\;=\\;\\sum_{i=1}^n v_i\\,\\frac{\\partial}{\\partial x_j} \\Bigl(\\frac{\\partial f}{\\partial x_i}(x)\\Bigr). \\] <ol> <li>Recognize the second partial derivative:</li> </ol> \\[ \\frac{\\partial}{\\partial x_j}\\Bigl(\\frac{\\partial f}{\\partial x_i}(x)\\Bigr)\\;=\\;   \\frac{\\partial^2 f}{\\partial x_j \\,\\partial x_i}(x). \\] <p>If \\(f\\) is \\(C^2\\) and the Hessian is symmetric, \\(\\partial^2 f/\\partial x_j \\partial x_i = \\partial^2 f/\\partial x_i \\partial x_j\\). Then</p> \\[ \\frac{\\partial g}{\\partial x_j}(x) \\;=\\;\\sum_{i=1}^nv_i\\,\\frac{\\partial^2 f}{\\partial x_i \\,\\partial x_j}(x). \\] <ol> <li>Interpret as the \\(j\\)-th component of \\(H\\,v\\):</li> <li>The matrix \\(H = \\bigl[\\frac{\\partial^2 f}{\\partial x_i \\,\\partial x_j}(x)\\bigr]\\) is \\(n\\times n\\).</li> <li> <p>The product \\((H\\,v)_j\\) is</p> \\[ (H\\,v)_j \\;=\\; \\sum_{i=1}^n \\frac{\\partial^2 f}{\\partial x_j\\,\\partial x_i}(x)\\;v_i, \\] <p>which, by symmetry of second derivatives, equals  \\(\\sum_{i=1}^n v_i \\,\\frac{\\partial^2 f}{\\partial x_i\\,\\partial x_j}(x)\\).</p> </li> </ol> <p>Therefore,</p> \\[ \\frac{\\partial g}{\\partial x_j}(x) \\;=\\; (H\\,v)_j, \\quad \\forall\\,j. \\] <p>Hence, \\(\\nabla g(x) = H\\,v = \\nabla^2 f(x)\\,v\\).</p>"},{"location":"book/chapter3_energy_based_model/score_matching/#51-4-summary","title":"5.1 4. Summary","text":"<ul> <li>Full Gradient: One reverse-mode pass yields \\(\\nabla f(x)\\) at cost \\(\\mathbf{C}_\\nabla\\).</li> <li>Hessian Trace: Exact computation requires about \\(n+1\\) times that cost.</li> <li>Hessin vector product: Requires about \\(2\\) times of the cost of gradient.</li> <li>Single Partial vs. Full Gradient: In reverse-mode AD for scalar outputs, both cost nearly the same. that is <code>grad(f,x)</code> has almost the same complexity of <code>grad(f,x[i])</code>.</li> </ul> <p>See the code here</p> <pre><code>def gradient(f, x):\n    \"\"\"\n    Compute the gradient of the scalar function f w.r.t. x.\n\n    f: a scalar PyTorch tensor (the output of some function of x)\n    x: a PyTorch tensor of shape (n,) with requires_grad=True\n    \"\"\"\n    # create_graph=True allows further differentiation\n    grad_f = torch.autograd.grad(f, x, create_graph=True)[0]\n    return grad_f\n\ndef hessian_trace(f, x):\n    \"\"\"\n    Compute the trace of the Hessian of the scalar function f w.r.t. x.\n    i.e., sum(d^2 f / d x_i^2).\n\n    f: scalar value (output of some function of x)\n    x: torch.tensor shape (n,), requires_grad=True\n    \"\"\"\n    # First get the gradient. We need create_graph=True so we can differentiate again.\n    grad_f = torch.autograd.grad(f, x, create_graph=True)[0]\n\n    # Sum of second derivatives w.r.t each x[i]\n    # We'll accumulate each d(grad_f[i]) / d x[i].\n    trace_val = 0.0\n    for i in range(x.numel()):\n        # grad of grad_f[i] w.r.t x gives a vector; we take [i] component\n        second_deriv_i = torch.autograd.grad(grad_f[i], x, retain_graph=True)[0][i]\n        trace_val += second_deriv_i\n\n    return trace_val\n\ndef hvp(f, x, v):\n    \"\"\"\n    Compute Hessian-vector product H * v, where H = \u2207^2 f(x).\n    f: \u6807\u91cf\uff0c\u7f51\u7edc/\u51fd\u6570\u5bf9 x \u7684\u8f93\u51fa\n    x: \u53c2\u6570\u6216\u8f93\u5165\u5411\u91cf (requires_grad=True)\n    v: \u4e00\u4e2a\u548c x \u5f62\u72b6\u76f8\u540c\u7684\u5411\u91cf\uff0c\u7528\u4f5c\u65b9\u5411\n    \"\"\"\n    # \u7b2c\u4e00\u6b65\uff1a\u6c42\u4e00\u9636\u68af\u5ea6\uff0c\u4fdd\u7559\u8ba1\u7b97\u56fe\n    grad_f = torch.autograd.grad(f, x, create_graph=True)[0]\n    # grad_f \u662f\u548c x \u540c shape \u7684\u5f20\u91cf\n\n    # \u7b2c\u4e8c\u6b65\uff1a\u5bf9 (grad_f \u548c v \u7684\u5185\u79ef) \u518d\u6c42\u4e00\u6b21\u68af\u5ea6\n    # \u8fd9\u76f8\u5f53\u4e8e\u5bf9 g(x)^T * v \u505a\u4e00\u6b21 backprop\uff0c\u5f97\u51fa H*v\n    hv = torch.autograd.grad(grad_f @ v, x)[0]\n    return hv\n</code></pre> <p>References</p> <ul> <li>A. Griewank &amp; A. Walther, Evaluating Derivatives.</li> <li>B. A. Pearlmutter, Fast Exact Multiplication by the Hessian, 1994.</li> <li>Hutchinson, A Stochastic Estimator of the Trace, 1990.</li> </ul>"},{"location":"book/chapter3_energy_based_model/score_matching/#52","title":"5.2 \u5bf9\u6bd4\u5176\u4ed6\u65b9\u6cd5","text":"\u65b9\u6cd5 \u8ba1\u7b97\u590d\u6742\u5ea6 \u4e3b\u8981\u6311\u6218 Explicit Score Matching \\(O(d)\\) \u4f9d\u8d56\u771f\u5b9escore function\uff0c\u901a\u5e38\u672a\u77e5 Implicit Score Matching \\(O(d^2)\\) \u8ba1\u7b97Jacobian\u8ff9\u7684\u9ad8\u590d\u6742\u5ea6 Sliced Score Matching \\(O(d)\\) \u9700\u5e73\u8861\u6295\u5f71\u65b9\u5411\u6570\u91cf\u4e0e\u4f30\u8ba1\u7cbe\u5ea6"},{"location":"book/chapter3_energy_based_model/score_matching/#521","title":"5.2.1 \u4ee3\u7801\u5b9e\u73b0\uff08\u4f2a\u4ee3\u7801\uff09","text":"<pre><code>import torch\n\ndef sliced_score_matching_loss(model, data, num_projections=10):\n    \"\"\"\n    model: \u9884\u6d4bscore function\u7684\u795e\u7ecf\u7f51\u7edc\n    data: \u8f93\u5165\u6570\u636e\u6837\u672c\n    num_projections: \u968f\u673a\u6295\u5f71\u65b9\u5411\u7684\u6570\u91cf\n    \"\"\"\n    scores = model(data)  # \u6a21\u578b\u9884\u6d4b\u7684score [batch_size, d]\n    loss = 0.5 * torch.mean(torch.sum(scores**2, dim=1))  # 1/2 ||s_\u03b8(x)||^2\n\n    for _ in range(num_projections):\n        v = torch.randn_like(data)  # \u968f\u673a\u6295\u5f71\u5411\u91cf [batch_size, d]\n        v.requires_grad_(True)\n\n        # \u8ba1\u7b97 v^T \u2207s_\u03b8(x) v\n        v_scores = torch.sum(v * scores, dim=1)  # [batch_size]\n        jvp = torch.autograd.grad(\n            outputs=v_scores, inputs=data,\n            grad_outputs=torch.ones_like(v_scores),\n            create_graph=True\n        )[0]  # \u2207(v^T s_\u03b8(x)) = v^T \u2207s_\u03b8(x)\n        trace_estimate = torch.sum(v * jvp, dim=1)  # v^T \u2207s_\u03b8(x) v\n\n        loss += torch.mean(trace_estimate) / num_projections\n\n    return loss\n</code></pre>"},{"location":"book/chapter3_energy_based_model/score_matching/#53-experiment","title":"5.3 experiment","text":"<p>We also tried with the mixture og gaussian distribution, it performs well.</p> <p></p> <p>See notebook on  experiment/implicit_score_matching.ipynb.</p>"},{"location":"book/chapter3_energy_based_model/score_matching/#6-denoising-score-matching","title":"6. Denoising Score Matching","text":"<p>Generative models aim to learn the underlying distribution of data, allowing us to generate new samples. Denoising Score Matching (DSM) is a powerful technique in this domain, leveraging noise to simplify training. In this blog, we'll break down DSM's intuition, math, training, and sampling, and extend it to multi-scale and continuous noise settings. We\u2019ll emphasize why each step matters and how the pieces connect.</p>"},{"location":"book/chapter3_energy_based_model/score_matching/#61-1-intuition-why-add-noise","title":"6.1 1. Intuition: Why Add Noise?","text":""},{"location":"book/chapter3_energy_based_model/score_matching/#611-what-is-a-score","title":"6.1.1 What is a \"Score\"?","text":"<p>The score of a probability distribution \\(p(x)\\) is its gradient of the log-density:</p> \\[ \\nabla_x \\log p(x)\\] <p>Imagine you\u2019re hiking on a landscape where valleys represent regions of high data density (e.g., realistic images). The score tells you the direction to move uphill toward higher density (i.e., toward realistic data).</p>"},{"location":"book/chapter3_energy_based_model/score_matching/#612-why-traditional-score-matching-fails","title":"6.1.2 Why Traditional Score Matching Fails","text":"<p>For high-dimensional data (e.g., images), most of the space is empty\u2014data lies on a thin \"manifold.\" Traditional score matching struggles because:</p> <ol> <li>Computational cost: Estimating gradients in high dimensions is expensive.</li> <li>Sparse signals: The score is undefined or noisy in empty regions far from the data manifold.</li> </ol>"},{"location":"book/chapter3_energy_based_model/score_matching/#613-the-noise-solution","title":"6.1.3 The Noise Solution","text":"<p>By adding Gaussian noise to data points, we \"smooth\" the distribution, filling empty regions with a blurry haze of noisy data. This makes the score easier to estimate everywhere. Think of it like turning a spiky mountain range into rolling hills\u2014easier to navigate!</p> <p>Key Insight: Instead of learning \\(\\nabla_x \\log p(x)\\) directly (hard!), learn to denoise perturbed data. The denoising direction aligns with the score of the noise-augmented distribution.</p>"},{"location":"book/chapter3_energy_based_model/score_matching/#62-2-derivation-connecting-noise-to-the-score","title":"6.2 2. Derivation: Connecting Noise to the Score","text":""},{"location":"book/chapter3_energy_based_model/score_matching/#621-step-1-define-the-noisy-distribution","title":"6.2.1 Step 1: Define the Noisy Distribution","text":"<p>Corrupt a data point \\(x\\) with Gaussian noise:</p> \\[ \\tilde{x} = x + \\epsilon, \\quad \\epsilon \\sim \\mathcal{N}(0, \\sigma^2 I) \\] <p>The conditional distribution is:</p> \\[ q(\\tilde{x}|x) = \\mathcal{N}(x, \\sigma^2 I) \\] <p>thus,</p> \\[ q_\\sigma(\\tilde{\\mathbf{x}}) = \\int q(\\tilde{\\mathbf{x}} \\mid \\mathbf{x}) p_{\\text{data}}(\\mathbf{x}) \\, d\\mathbf{x}, \\] <p>where \\(q(\\tilde{\\mathbf{x}} \\mid \\mathbf{x}) = \\mathcal{N}(\\tilde{\\mathbf{x}}; \\mathbf{x}, \\sigma^2 \\mathbf{I})\\) is a Gaussian distribution centered at \\(\\mathbf{x}\\) with variance \\(\\sigma^2\\). This represents a convolution of \\(p_{\\text{data}}(\\mathbf{x})\\) with a Gaussian kernel.</p>"},{"location":"book/chapter3_energy_based_model/score_matching/#622-1-small-noise-sigma-to-0","title":"6.2.2 1. Small Noise \\(\\sigma \\to 0\\)","text":"<ul> <li>Behavior of \\(q(\\tilde{\\mathbf{x}} \\mid \\mathbf{x})\\):</li> </ul> <p>The Gaussian becomes a Dirac delta function:</p> \\[ q_\\sigma(\\tilde{\\mathbf{x}} \\mid \\mathbf{x}) \\to \\delta(\\tilde{\\mathbf{x}} - \\mathbf{x}). \\] <ul> <li>Effect on \\(q(\\tilde{\\mathbf{x}})\\):</li> </ul> <p>The integral simplifies to \\(p_{\\text{data}}(\\tilde{\\mathbf{x}})\\), preserving the original distribution:</p> \\[ q_\\sigma(\\tilde{\\mathbf{x}}) \\approx p_{\\text{data}}(\\tilde{\\mathbf{x}}). \\] <ul> <li>Interpretation: Minimal blurring; the perturbed distribution matches the original data distribution.</li> </ul>"},{"location":"book/chapter3_energy_based_model/score_matching/#623-2-moderate-noise-sigma-0","title":"6.2.3 2. Moderate Noise \\(\\sigma &gt; 0\\)","text":"<ul> <li> <p>Behavior of \\(q(\\tilde{\\mathbf{x}} \\mid \\mathbf{x})\\):   The Gaussian acts as a smoothing kernel with width proportional to \\(\\sigma\\).</p> </li> <li> <p>Effect on \\(q(\\tilde{\\mathbf{x}})\\):   The convolution introduces controlled blurring, creating a smoothed version of \\(p_{\\text{data}}(\\mathbf{x})\\). Fine details are averaged, but the global structure remains recognizable.</p> </li> <li> <p>Interpretation: Useful for regularization or generating \"softened\" data samples.</p> </li> </ul>"},{"location":"book/chapter3_energy_based_model/score_matching/#624-3-large-noise-sigma-to-infty","title":"6.2.4 3. Large Noise \\(\\sigma \\to \\infty\\)","text":"<ul> <li> <p>Behavior of \\(q_\\sigma(\\tilde{\\mathbf{x}} \\mid \\mathbf{x})\\):   The Gaussian becomes extremely wide and flat, approximating a uniform distribution over the domain.</p> </li> <li> <p>Effect on \\(q_\\sigma(\\tilde{\\mathbf{x}})\\):</p> </li> </ul> <p>The integral averages \\(p_{\\text{data}}(\\mathbf{x})\\) over a large region, erasing fine structure. If \\(p_{\\text{data}}(\\mathbf{x})\\) is bounded, \\(q(\\tilde{\\mathbf{x}})\\) approaches a uniform distribution; otherwise, it becomes a broad Gaussian.</p> <ul> <li>Interpretation: Severe distortion; the original distribution is lost.</li> </ul>"},{"location":"book/chapter3_energy_based_model/score_matching/#625-step-2-score-of-the-noisy-distribution","title":"6.2.5 Step 2: Score of the Noisy Distribution","text":"<p>The score of \\(q(\\tilde{x}|x)\\) is:</p> \\[\\nabla_{\\tilde{x}} \\log q(\\tilde{x}|x) = \\frac{x - \\tilde{x}}{\\sigma^2}\\] <p>Why?</p> <p>For a Gaussian \\(\\mathcal{N}(x, \\sigma^2 I)\\), the gradient of the log-density with respect to \\(\\tilde{x}\\) points toward the mean \\(x\\). The term \\((x - \\tilde{x})/\\sigma^2\\) is the \"denoising direction\" that corrects \\(\\tilde{x}\\) back to \\(x\\).</p>"},{"location":"book/chapter3_energy_based_model/score_matching/#626-step-3-the-dsm-objective","title":"6.2.6 Step 3: The DSM Objective","text":"<p>Train a model \\(s_\\theta(\\tilde{x})\\) to match this score:</p> \\[ J(\\theta) = \\mathbb{E}_{q(\\tilde{x},x)}\\left[ \\| s_\\theta(\\tilde{x}) - \\frac{x - \\tilde{x}}{\\sigma^2} \\|^2 \\right] \\] <p>Why This Works:</p> <p>Minimizing this loss forces \\(s_\\theta(\\tilde{x})\\) to approximate \\(\\nabla_{\\tilde{x}} \\log q(\\tilde{x})\\), the score of the marginal noisy distribution \\(q(\\tilde{x}) = \\int q(\\tilde{x}|x)p_{\\text{data}}(x)dx\\),  which has been proved in the above section. As illustrated above, this is equivalent to learning the score of the true data distribution \\(p_{\\text{data}}(x)\\) as \\(\\sigma \\to 0\\).</p>"},{"location":"book/chapter3_energy_based_model/score_matching/#63-3-training-process-step-by-step","title":"6.3 3. Training Process: Step-by-Step","text":""},{"location":"book/chapter3_energy_based_model/score_matching/#631-step-1-add-noise-to-data","title":"6.3.1 Step 1: Add Noise to Data","text":"<p>For each clean data point \\(x\\), generate a noisy version:</p> \\[ \\tilde{x} = x + \\epsilon, \\quad \\epsilon \\sim \\mathcal{N}(0, \\sigma^2 I) \\] <p>Why Add Noise?</p> <ul> <li>Creates \"easier\" training examples by spreading data into empty regions.</li> <li>Teaches the model to handle perturbations, improving robustness.</li> </ul>"},{"location":"book/chapter3_energy_based_model/score_matching/#632-step-2-compute-the-loss","title":"6.3.2 Step 2: Compute the Loss","text":"<p>The DSM loss simplifies to:</p> \\[ \\mathcal{L} = \\frac{1}{N} \\sum_{i=1}^N \\| s_\\theta(\\tilde{x}_i) - \\frac{x_i - \\tilde{x}_i}{\\sigma^2} \\|^2 \\] <p>Interpretation:</p> <p>The model learns to predict the vector \\((x_i - \\tilde{x}_i)/\\sigma^2\\), which points from the noisy sample \\(\\tilde{x}_i\\) back to the clean \\(x_i\\). This is equivalent to estimating the score of the noisy distribution.</p>"},{"location":"book/chapter3_energy_based_model/score_matching/#633-step-3-gradient-descent","title":"6.3.3 Step 3: Gradient Descent","text":"<p>Update model parameters \\(\\theta\\) to minimize \\(\\mathcal{L}\\).</p> <p></p> <p>Practical Tip:</p> <p>Scale the loss by $ \\sigma^2 $ to balance learning across noise levels (critical for multi-scale training).</p> <p>\u591a\u5c3a\u5ea6 sigmas (\u03c3 schedules)</p> <ul> <li> <p>\u4e3a\u4e86\u589e\u5f3a\u6a21\u578b\u7684\u9c81\u68d2\u6027\uff0c\u53ef\u4ee5\u4e3a\u566a\u58f0\u8bbe\u7f6e\u4e00\u7cfb\u5217\u503c\uff0c\u4ece\u8f83\u5c0f\u7684\u566a\u58f0\u5230\u8f83\u5927\u7684\u566a\u58f0\uff0c\u5f62\u6210\u4e00\u4e2a\u566a\u58f0\u5c3a\u5ea6 \u3002</p> </li> <li> <p>\u516c\u5f0f : \u901a\u5e38\u6784\u9020\u4e00\u4e2a\u5bf9\u6570\u95f4\u9694\u7684\u5e8f\u5217\uff0c\u4f8b\u5982\uff1a</p> </li> </ul> \\[ \\sigma_i = \\sigma_{\\text{min}} \\times \\left(\\frac{\\sigma_{\\text{max}}}{\\sigma_{\\text{min}}}\\right)^{i / (N-1)} \\] <pre><code>- `\u03c3_min`: \u6700\u5c0f\u566a\u58f0\u5f3a\u5ea6\u3002\n\n- `\u03c3_max`: \u6700\u5927\u566a\u58f0\u5f3a\u5ea6\u3002\n\n- `N`: \u566a\u58f0\u5c3a\u5ea6\u7684\u6570\u91cf\u3002\n</code></pre> <ul> <li>\u5e38\u7528\u8bbe\u7f6e :</li> <li> <p>\u5bf9\u4e8e\u56fe\u50cf\u6570\u636e\uff0c<code>\u03c3_min</code> \u901a\u5e38\u662f <code>0.01</code> \u6216 <code>0.05</code>\u3002</p> </li> <li> <p><code>\u03c3_max</code> \u901a\u5e38\u53d6 <code>0.5</code> \u6216 <code>1.0</code>\u3002</p> </li> <li> <p><code>N</code> \u7684\u5178\u578b\u503c\u4e3a <code>10</code> \u5230 <code>50</code>\u3002</p> </li> <li> <p>\u4f18\u70b9 : \u591a\u5c3a\u5ea6\u566a\u58f0\u66f4\u9002\u5408\u590d\u6742\u5206\u5e03\uff0c\u53ef\u4ee5\u5efa\u6a21\u4ece\u4f4e\u566a\u58f0\u5230\u9ad8\u566a\u58f0\u7684\u5404\u79cd\u60c5\u51b5\u3002</p> </li> <li> <p>\u7f3a\u70b9 : \u8bad\u7ec3\u548c\u5b9e\u73b0\u66f4\u590d\u6742\uff0c\u9700\u8981\u52a8\u6001\u8c03\u6574\u566a\u58f0\u6c34\u5e73\u3002</p> </li> </ul>"},{"location":"book/chapter3_energy_based_model/score_matching/#64-4-sampling-with-langevin-dynamics","title":"6.4 4. Sampling with Langevin Dynamics","text":"<p>Once trained, we use Langevin dynamics to generate samples by \"walking\" along the learned score.</p>"},{"location":"book/chapter3_energy_based_model/score_matching/#641-the-update-rule","title":"6.4.1 The Update Rule","text":"\\[ x_{t+1} = x_t + \\epsilon \\cdot s_\\theta(x_t) + \\sqrt{2\\epsilon} \\cdot z_t, \\quad z_t \\sim \\mathcal{N}(0, I)\\] <p>Breaking It Down:</p> <ol> <li>Score term \\(\\epsilon \\cdot s_\\theta(x_t)\\): Guides \\(x_t\\) toward high-density regions (denoising).</li> <li>Noise term \\(\\sqrt{2\\epsilon} \\cdot z_t\\): Adds randomness to escape local minima and explore the distribution.</li> </ol> <p>Why This Works: Langevin dynamics is a Markov Chain Monte Carlo (MCMC) method that uses the score to perform gradient ascent on \\(\\log p(x)\\). The noise ensures ergodicity, allowing the chain to converge to the true distribution.</p>"},{"location":"book/chapter3_energy_based_model/score_matching/#642-analogy","title":"6.4.2 Analogy","text":"<p>Imagine rolling a marble on a bumpy surface (the data landscape). The score tilts the surface to guide the marble toward valleys (data points), while the noise gives it occasional kicks to explore new areas.</p>"},{"location":"book/chapter3_energy_based_model/score_matching/#65-5-multi-scale-noise-training","title":"6.5 5. Multi-Scale Noise Training","text":""},{"location":"book/chapter3_energy_based_model/score_matching/#651-why-multiple-noise-scales","title":"6.5.1 Why Multiple Noise Scales?","text":"<p>Key Challenges in Training SBMs/EBMs</p> <ul> <li>Undefined Score Function Off the Data Manifold : Under the manifold hypothesis, data resides on a low-dimensional manifold embedded in a high-dimensional ambient space. The score function $ \\nabla_x \\log p(x) $, which requires gradients to be defined everywhere in the ambient space, becomes ill-defined outside the manifold.</li> </ul> <p>Problem: Score estimation fails in regions irrelevant to the data, destabilizing training and generation.</p> <p>Implication: Score estimation fails in regions irrelevant to the data, destabilizing training and generation.</p> <ul> <li>Sparse Data in Low-Density Regions</li> </ul> <p>Problem: Real-world datasets often lack sufficient samples in low-density areas (e.g., transitions between classes or rare features). This sparsity makes it difficult to reliably estimate the score function in these regions.</p> <p>Implication: Poor score approximation leads to artifacts, mode collapse, or unrealistic interpolations.</p> <ul> <li>Degradation of Mixing Distribution Coefficients</li> </ul> <p>Problem: In near-zero density regions (e.g., far from the manifold), the coefficients (weights) of the mixing distribution\u2014used to model complex data\u2014vanish or become negligible.</p> <p>Implication: The model loses expressive power in these regions, exacerbating mode collapse and limiting diversity in generated samples.</p> <p>We use multi-scale noise pertubation could help address these challenges.</p> <p>Real-world data (e.g., images) has structure at multiple resolutions:</p> <ul> <li>Low noise (small \\(\\sigma\\)): Captures fine details (e.g., textures).</li> <li>High noise (large \\(\\sigma\\)): Captures coarse structure (e.g., shapes).</li> </ul> <p>Training with a single \\(\\sigma\\) limits the model\u2019s ability to generalize across scales.</p>"},{"location":"book/chapter3_energy_based_model/score_matching/#652-training-process","title":"6.5.2 Training Process","text":"<ol> <li>Noise Sampling: For each batch, randomly pick \\(\\sigma_i\\) from a set \\(\\{\\sigma_1, ..., \\sigma_L\\}\\).</li> <li>Loss Adjustment: Scale the loss by \\(\\sigma_i^2\\) to prevent larger \\(\\sigma\\) from dominating:</li> </ol> \\[ \\mathcal{L} = \\frac{1}{L} \\sum_{i=1}^L \\mathbb{E}\\left[ \\sigma_i^2 \\| s_\\theta(\\tilde{x}, \\sigma_i) - \\frac{x - \\tilde{x}}{\\sigma_i^2} \\|^2 \\right] \\]"},{"location":"book/chapter3_energy_based_model/score_matching/#653-sampling","title":"6.5.3 Sampling","text":"<p>Use a decreasing sequence \\(\\sigma_1 &gt; \\sigma_2 &gt; ... &gt; \\sigma_L\\) during Langevin dynamics:</p> <ol> <li>Start with high noise to capture coarse structure.</li> <li>Gradually reduce noise to refine details.</li> </ol> <p>Analogy: Like sketching a painting\u2014first outline shapes (high noise), then add details (low noise).</p>"},{"location":"book/chapter3_energy_based_model/score_matching/#66-6-continuous-noise-levels","title":"6.6 6. Continuous Noise Levels","text":""},{"location":"book/chapter3_energy_based_model/score_matching/#661-why-go-continuous","title":"6.6.1 Why Go Continuous?","text":"<p>Discrete noise scales are rigid and computationally costly for large \\(L\\). A continuous approach:</p> <ul> <li>Smoothly interpolates between noise levels.</li> <li>Connects to differential equations for efficient sampling.</li> </ul>"},{"location":"book/chapter3_energy_based_model/score_matching/#662-training","title":"6.6.2 Training","text":"<ol> <li> <p>Noise Sampling: Sample \\(t \\sim \\mathcal{U}(0,1)\\), compute \\(\\sigma(t)\\) (e.g., \\(\\sigma(t) = \\sigma_{\\text{min}} + t(\\sigma_{\\text{max}} - \\sigma_{\\text{min}})\\)).</p> </li> <li> <p>Condition the Model: Feed \\(t\\) to \\(s_\\theta\\) via time embeddings (e.g., sinusoidal features).</p> </li> </ol>"},{"location":"book/chapter3_energy_based_model/score_matching/#663-sampling-with-stochastic-differential-equations-sdes","title":"6.6.3 Sampling with Stochastic Differential Equations (SDEs)","text":"<p>The continuous noise process can be described as an SDE:</p> \\[ dx = s_\\theta(x, t) dt + \\sqrt{2\\sigma(t)} dw \\] <p>Intuition: This generalizes Langevin dynamics to infinitesimal steps. The term \\(s_\\theta(x,t)dt\\) is the deterministic drift (denoising), and \\(\\sqrt{2\\sigma(t)}dw\\) is stochastic diffusion (noise).</p> <p>Solving the SDE: Use numerical solvers like Euler-Maruyama:</p> \\[ x_{t+1} = x_t + s_\\theta(x_t, t) \\Delta t + \\sqrt{2\\sigma(t) \\Delta t} \\, z_t \\] <p>This is equivalent to Langevin dynamics with time-dependent noise.</p>"},{"location":"book/chapter3_energy_based_model/score_matching/#67-7-why-does-dsm-work-a-unified-view","title":"6.7 7. Why Does DSM Work? A Unified View","text":"<ol> <li>Avoids Density Estimation: Models gradients instead of \\(p(x)\\), bypassing normalization constraints.</li> <li>Exploits Noise: Smoothens the data manifold, making score estimation tractable.</li> <li>Connects to Diffusion Models: DSM is the backbone of diffusion models (e.g., DDPM, Score-SDE), where noise addition/removal is formalized across timesteps.</li> </ol> <p>Comparison to GANs/VAEs:</p> <ul> <li>No adversarial training: More stable than GANs.</li> <li>No latent space bottlenecks: Richer expressivity than VAEs.</li> </ul>"},{"location":"book/chapter3_energy_based_model/score_matching/#68-conclusion","title":"6.8 Conclusion","text":"<p>Denoising Score Matching elegantly bridges noise and geometry to learn data distributions. By progressively corrupting and denoising data, it captures multi-scale structure and enables efficient sampling via SDEs. This framework powers cutting-edge generative models, offering flexibility, stability, and scalability.</p> <p>Further Reading:</p> <ul> <li>Score Matching (Hyv\u00e4rinen, 2005)</li> <li>Denoising Score Matching (Vincent, 2011)</li> <li>Score-Based SDEs (Song et al., 2021)</li> <li>Generative Modeling by Estimating Gradients of the Data Distribution (YangSong, 2019)</li> </ul>"},{"location":"book/chapter5_GAN/vq_gan/","title":"Understanding VQ-GAN: A Powerful Approach to High-Quality Image Synthesis","text":""},{"location":"book/chapter5_GAN/vq_gan/#1-introduction","title":"1. Introduction","text":"<p>Vector Quantized Generative Adversarial Network (VQ-GAN) is an advanced generative model that builds upon VQ-VAE by incorporating adversarial training and perceptual loss. This allows it to generate high-resolution, photo-realistic images while maintaining compact and meaningful latent representations. In this blog, we will explore how VQ-GAN works, why it surpasses VQ-VAE, and its key insights.</p>"},{"location":"book/chapter5_GAN/vq_gan/#2-why-vq-gan","title":"2. Why VQ-GAN?","text":""},{"location":"book/chapter5_GAN/vq_gan/#21-limitations-of-vq-vae","title":"2.1 Limitations of VQ-VAE","text":"<p>VQ-VAE efficiently compresses data into a discrete latent space but has several drawbacks:</p> <ul> <li>Blurred reconstructions: The decoder in VQ-VAE often produces oversmoothed images due to reliance on mean squared error (MSE) loss.</li> <li>Lack of fine details: It does not explicitly optimize for perceptual quality, causing small textures and details to be lost.</li> <li>Autoregressive bottleneck: Many implementations rely on autoregressive priors (e.g., PixelCNN), which are computationally expensive.</li> </ul>"},{"location":"book/chapter5_GAN/vq_gan/#22-vq-gans-improvements","title":"2.2 VQ-GAN's Improvements","text":"<p> VQ-GAN enhances VQ-VAE with the following key features:</p> <ul> <li>Adversarial training: By introducing a discriminator (GAN-style training), VQ-GAN produces sharper and more realistic images.</li> <li>Perceptual loss: Instead of relying solely on MSE, it uses perceptual loss (from a pre-trained network) to improve visual fidelity.</li> <li>Efficient Latent Representations: Unlike PixelCNN priors, VQ-GAN leverages transformers for improved context modeling, leading to faster and more efficient generation.</li> </ul>"},{"location":"book/chapter5_GAN/vq_gan/#3-how-vq-gan-works","title":"3. How VQ-GAN Works","text":""},{"location":"book/chapter5_GAN/vq_gan/#31-quantization-process-similar-to-vq-vae","title":"3.1 Quantization Process (Similar to VQ-VAE)","text":"<ul> <li>The input image is encoded into a latent space using a convolutional encoder.</li> <li>The encoded features are discretized using a vector quantization (VQ) layer, mapping each feature to a learned codebook entry.</li> <li>The decoder reconstructs the image from the quantized representation.</li> </ul>"},{"location":"book/chapter5_GAN/vq_gan/#32-adversarial-training","title":"3.2 Adversarial Training","text":"<ul> <li>A discriminator is introduced, following the GAN framework, to distinguish real images from generated ones.</li> <li>The generator (decoder) is trained to fool the discriminator, improving image sharpness and realism.</li> </ul>"},{"location":"book/chapter5_GAN/vq_gan/#33-perceptual-reconstruction-loss","title":"3.3 Perceptual &amp; Reconstruction Loss","text":"<ul> <li>Instead of purely optimizing for pixel-wise loss (MSE), VQ-GAN incorporates a perceptual loss computed using a pre-trained deep network (e.g., VGG) to ensure structural coherence.</li> <li>The final objective function combines:</li> <li>Reconstruction loss (ensuring faithful reconstructions)</li> <li>GAN loss (encouraging realism)</li> <li>Perceptual loss (maintaining perceptual consistency)</li> </ul>"},{"location":"book/chapter5_GAN/vq_gan/#34-loss-function-comparison-vq-vae-vs-vq-gan","title":"3.4 Loss Function Comparison: VQ-VAE vs. VQ-GAN","text":""},{"location":"book/chapter5_GAN/vq_gan/#341-vq-vae-loss-function","title":"3.4.1 VQ-VAE Loss Function","text":"\\[ L_{VQ-VAE} = \\| x - \\hat{x} \\|^2 + \\| sg(E(x)) - z \\|^2 + \\beta \\| sg(z) - E(x) \\|^2 \\] <p>Where:</p> <ul> <li>\\( x \\) is the input image, \\( \\hat{x} \\) is the reconstructed image.</li> <li>\\( E(x) \\) is the encoder output.</li> <li>\\( z \\) is the quantized latent vector.</li> <li>The first term represents the reconstruction loss, while the second and third terms encourage commitment to the learned codebook.</li> </ul>"},{"location":"book/chapter5_GAN/vq_gan/#342-vq-gan-loss-function","title":"3.4.2 VQ-GAN Loss Function","text":"\\[ L_{VQ-GAN} = L_{VQ-VAE} + \\lambda L_{GAN} \\] <p>The additional GAN loss is defined as</p> \\[ L_{GAN}(\\{E, G, \\mathcal{Z}\\}, D) = \\mathbb{E}[\\log D(x) + \\log(1 - D(G(z_q(x))))] \\] <p>where:</p> <ul> <li>\\( z_q(x) \\) is the quantized latent representation of the input \\( x \\).</li> <li>\\( G(z_q(x)) \\) represents the reconstructed/generated image from the quantized latent representation.</li> <li>\\( D(x) \\) is the discriminator's probability that the real image \\( x \\) is real.</li> <li>\\( D(G(z_q(x))) \\) is the discriminator's probability that the generated image is real.</li> </ul> <p>The adaptive weight \\(\\lambda\\)</p> \\[ \\lambda = \\frac{\\nabla_{G_L} [\\mathcal{L}_{rec}]}{\\nabla_{G_L} [\\mathcal{L}_{GAN}] + \\delta} \\] <p>This formula describes the computation of the adaptive weight \\( \\lambda \\), which balances the perceptual reconstruction loss and the adversarial loss.</p> <p>Moreover, to enhance perceptual quality, the reconstruction loss is replaced with the perceptual loss.</p> <p>The perceptual reconstruction loss in VQ-GAN is designed to improve the quality of generated images by ensuring they preserve high-level semantic features from the original input. Instead of relying solely on pixel-wise losses like MSE (which often lead to blurriness), perceptual loss leverages a pre-trained deep network (such as VGG) to compare feature activations between the original and reconstructed images.</p> <p>Perceptual Reconstruction Loss Formula</p> \\[ \\mathcal{L}_{rec} = \\mathbb{E}_{x \\sim p(x)} \\left[ \\| x - G(z_q(x)) \\|^2 + \\sum_{l} \\lambda_l \\| \\phi_l(x) - \\phi_l(G(z_q(x))) \\|^2 \\right] \\] <p>Where:</p> <ul> <li>\\( x \\) is the original image.</li> <li>\\( G(z_q(x)) \\) is the reconstructed/generated image from the quantized latent representation.</li> <li>\\( \\| x - G(z_q(x)) \\|^2 \\) is the pixel-wise reconstruction loss (MSE).</li> <li>\\( \\phi_l(\\cdot) \\) represents the feature maps extracted from the \\( l \\)-th layer of a pre-trained deep network (e.g., VGG-19).</li> <li>\\( \\lambda_l \\) is a weighting factor for each feature layer contribution.</li> <li>The second term ensures that the generated image maintains perceptual similarity to the original image in feature space rather than just pixel space.</li> </ul> <p>This loss helps VQ-GAN produce sharper and more visually appealing images compared to traditional autoencoders.</p> <p>By integrating adversarial and perceptual losses, VQ-GAN improves image sharpness and realism compared to VQ-VAE.</p>"},{"location":"book/chapter5_GAN/vq_gan/#35-transformer-based-prior","title":"3.5 Transformer-based Prior","text":"<ul> <li>Unlike VQ-VAE, which often relies on PixelCNN priors, VQ-GAN uses transformers to model long-range dependencies in the latent space.</li> <li>This allows for more coherent and meaningful latent space representation, enhancing image synthesis quality.</li> </ul>"},{"location":"book/chapter5_GAN/vq_gan/#351-sliding-attention-window","title":"3.5.1 Sliding Attention Window","text":"<ul> <li>Instead of computing self-attention across the entire sequence, a fixed-size attention window is used.</li> <li>The attention window slides across the sequence, allowing each token to attend only to nearby tokens while gradually incorporating long-range dependencies.</li> <li>This reduces computational complexity from O(N\u00b2) to O(NW), where \\( W \\) is the window size.</li> <li>Sliding window attention ensures that local consistency is preserved while enabling efficient global information flow.</li> </ul>"},{"location":"book/chapter5_GAN/vq_gan/#352-training-process-for-autoregressive-token-prediction","title":"3.5.2 Training Process for Autoregressive Token Prediction","text":"<p>The Transformer models the probability distribution over latent tokens autoregressively:</p> \\[ p(z_q) = \\prod_{i} p(z_i | z_{&lt;i}, c) \\] <p>where \\( c \\) represents optional conditioning information.</p> <p>The loss function for training the Transformer is:</p> \\[ L_{trans} = - \\sum_{i=1}^{N} \\log p_{\\theta} (z_i | z_{&lt;i}, c) \\] <p>This ensures that the Transformer learns to predict the next token in the sequence given previous tokens and any conditional information.</p>"},{"location":"book/chapter5_GAN/vq_gan/#353-conditional-transformer-training","title":"3.5.3 Conditional Transformer Training","text":"<p>The Transformer can be trained to perform conditional inference using different types of conditioning signals:</p>"},{"location":"book/chapter5_GAN/vq_gan/#3531-class-conditional-generation","title":"3.5.3.1 Class-Conditional Generation","text":"<ul> <li>A class label is embedded and concatenated with latent tokens:   $$   {c, z_1, z_2, ..., z_N}   $$</li> <li>The Transformer learns to generate latent tokens consistent with the given class label.</li> </ul>"},{"location":"book/chapter5_GAN/vq_gan/#3532-text-to-image-generation","title":"3.5.3.2 Text-to-Image Generation","text":"<ul> <li>Text embeddings (from CLIP or other models) are used as conditional inputs:</li> </ul> <p>$$   c = \\text{CLIP}(text)   $$</p> <ul> <li>The Transformer generates latent tokens aligned with the text prompt.</li> </ul>"},{"location":"book/chapter5_GAN/vq_gan/#3533-segmentation-or-sketch-based-generation","title":"3.5.3.3 Segmentation or Sketch-Based Generation","text":"<ul> <li>Segmentation maps or sketches are encoded into feature embeddings and used as conditions:   $$   c = E_{seg}(segmentation) \\quad \\text{or} \\quad c = E_{sketch}(sketch)   $$</li> <li>The Transformer learns to generate latent tokens that conform to the provided structure.</li> </ul>"},{"location":"book/chapter5_GAN/vq_gan/#3534-image-inpainting-partial-image-completion","title":"3.5.3.4 Image Inpainting (Partial Image Completion)","text":"<ul> <li>Missing tokens are inferred while attending to known pixels:   $$   p(z_q | c) = \\prod_{i=1}^{N} p(z_i | z_{&lt;i}, c)   $$</li> <li>The model fills in missing details using masked attention.</li> </ul>"},{"location":"book/chapter5_GAN/vq_gan/#354-inference-process-unconditional-conditional-generation","title":"3.5.4 Inference Process: Unconditional &amp; Conditional Generation","text":""},{"location":"book/chapter5_GAN/vq_gan/#3541-unconditional-generation","title":"3.5.4.1 Unconditional Generation","text":"<ul> <li>The Transformer randomly initializes the first token \\( z_0 \\) and generates the rest autoregressively:</li> </ul> <p>$$   z_1 \\sim p(z_1 | z_0), \\quad z_2 \\sim p(z_2 | z_0, z_1), ..., z_N \\sim p(z_N | z_{&lt;N})   $$</p> <ul> <li>The latent tokens are reshaped into a 2D grid and decoded into an image.</li> </ul>"},{"location":"book/chapter5_GAN/vq_gan/#3542-conditional-generation","title":"3.5.4.2 Conditional Generation","text":"<ul> <li>The Transformer incorporates conditioning signals (class, text, segmentation, sketch, or partial images) to guide latent token prediction:   $$   p(z_q | c) = \\prod_{i=1}^{N} p(z_i | z_{&lt;i}, c)   $$</li> <li>The final latent tokens are decoded into an image consistent with the condition.</li> </ul>"},{"location":"book/chapter5_GAN/vq_gan/#4-conditioned-synthesis-with-vq-gan","title":"4. Conditioned Synthesis with VQ-GAN","text":"<ul> <li>Text-to-Image Synthesis: By combining VQ-GAN with CLIP or transformers, it can generate images conditioned on text descriptions, making it suitable for creative AI applications.</li> <li>Class-Conditional Image Generation: By feeding class labels into the latent space alongside encoded images, VQ-GAN can generate class-specific images.</li> <li>Image-to-Image Translation: VQ-GAN can be conditioned on specific inputs (such as edge maps, sketches, or low-resolution images) to generate high-fidelity versions.</li> <li>Latent Code Conditioning: Fine-tuning the learned codebook enables the model to generate samples conditioned on specific feature embeddings, allowing user-defined controls over the generation process.</li> </ul>"},{"location":"book/chapter5_GAN/vq_gan/#5-key-insights","title":"5. Key Insights","text":"<ul> <li> <p>Balance Between Compression &amp; Fidelity VQ-GAN achieves high compression rates while retaining fine details, unlike traditional autoencoders that tend to over-smooth outputs.</p> </li> <li> <p>GANs Improve High-Frequency Details The adversarial loss significantly enhances the reconstruction of textures, details, and structures, leading to more realistic images compared to VQ-VAE.</p> </li> <li> <p>Transformers as a Strong Prior Replacing autoregressive models like PixelCNN with transformers allows VQ-GAN to generate images more efficiently and with greater coherence.</p> </li> <li> <p>Versatile Applications VQ-GAN is widely used in:</p> </li> <li> <p>High-resolution image synthesis</p> </li> <li>Text-to-image generation (when combined with CLIP or transformers)</li> <li>Neural compression (efficient latent representation for storage and transmission)</li> <li>Creative AI applications (e.g., AI-driven art)</li> </ul>"},{"location":"book/chapter5_GAN/vq_gan/#6-codes","title":"6. Codes","text":""},{"location":"book/chapter5_GAN/vq_gan/#61-vectorquantizer","title":"6.1 VectorQuantizer","text":"<pre><code>class VectorQuantizer(nn.Module):\n    def __init__(self, n_e, e_dim, beta):\n        super(VectorQuantizer, self).__init__()\n        self.n_e = n_e\n        self.e_dim = e_dim\n        self.beta = beta\n\n        self.embedding = nn.Embedding(self.n_e, self.e_dim)\n        self.embedding.weight.data.uniform_(-1.0 / self.n_e, 1.0 / self.n_e)\n\n\n    def forward(self, z):\n        z = z.permute(0, 2, 3, 1).contiguous()\n        z_flattened = z.view(-1, self.e_dim)\n        # distances from z to embeddings e_j (z - e)^2 = z^2 + e^2 - 2 e * z\n\n        d = torch.sum(z_flattened ** 2, dim=1, keepdim=True) + \\\n            torch.sum(self.embedding.weight**2, dim=1) - 2 * \\\n            torch.matmul(z_flattened, self.embedding.weight.t())\n\n        # find closest encodings\n        min_encoding_indices = torch.argmin(d, dim=1).unsqueeze(1)\n\n        min_encodings = torch.zeros(\n            min_encoding_indices.shape[0], self.n_e).to(z)\n        min_encodings.scatter_(1, min_encoding_indices, 1)\n\n        z_q = torch.matmul(min_encodings, self.embedding.weight).view(z.shape)\n\n        # compute loss for embedding\n        loss = torch.mean((z_q.detach()-z)**2) + self.beta * \\\n            torch.mean((z_q - z.detach()) ** 2)\n\n        # preserve gradients\n        z_q = z + (z_q - z).detach()\n\n        # perplexity\n        e_mean = torch.mean(min_encodings, dim=0)\n        perplexity = torch.exp(-torch.sum(e_mean * torch.log(e_mean + 1e-10)))\n\n        # reshape back to match original input shape\n        z_q = z_q.permute(0, 3, 1, 2).contiguous()\n\n        return z_q, loss, (perplexity, min_encodings, min_encoding_indices)\n</code></pre> <p>Here we can see how we copy the gradient from \\(z_e\\) to \\(z_q\\).</p>"},{"location":"book/chapter5_GAN/vq_gan/#7-conclusion","title":"7. Conclusion","text":"<p>VQ-GAN represents a significant leap over VQ-VAE by combining vector quantization, GANs, and transformers to achieve superior image synthesis. It maintains high compression efficiency while ensuring visually compelling results. With applications in generative art, neural compression, and AI-powered creativity, VQ-GAN is a pivotal model in modern generative AI research.</p>"},{"location":"book/chapter5_GAN/3.1from_gan_to_stylegan/paper/","title":"From GAN to PGGAN: Some Base GAN model Introduction","text":""},{"location":"book/chapter5_GAN/3.1from_gan_to_stylegan/paper/#1-2014gan-generative-adversarial-networks","title":"1. [2014]GAN : Generative Adversarial Networks","text":"<p>GANs (Generative Adversarial Networks) are based on an adversarial process framework. In this framework, there are two networks that work in opposition: a generator and a discriminator. This can be compared to a scenario where one team (generator) tries to produce counterfeit items without being detected, while the other team (discriminator) acts like law enforcement trying to detect the fakes. Overall Introduction</p> <ul> <li> <p>Base model structure    Image Source: Semi Engineering - GAN Knowledge Center</p> </li> <li> <p>The model works through two independent learning models: a Generative Model and a Discriminative Model, which learn through adversarial training to produce high-quality outputs.</p> <ul> <li>Generative Model,short as \\(G\\)\uff1a</li> <li>Takes random noise \\(z\\) as input -&gt; Generates images \\(G(z)\\)</li> <li>Aims to create images that look real enough to fool \\(D\\)</li> <li>Discriminative Model, short as \\(D\\),is a binary classifier:</li> <li>Takes an image x as input -&gt; Output \\(D(x)\\), representing the probability that \\(x\\) is a real image<ul> <li>\\(D(x)=1\\) means 100% confidence it's real</li> <li>\\(D(x)=0\\) means it's definitely fake</li> </ul> </li> </ul> </li> <li> <p>Adversarial training: The optimization process is a minimax game, with the goal of reaching Nash equilibrium</p> </li> <li> <p>The generator tries to minimize the probability of the discriminator detecting fake samples     The discriminator tries to maximize its ability to distinguish between real and fake samples</p> </li> </ul>"},{"location":"book/chapter5_GAN/3.1from_gan_to_stylegan/paper/#11-loss-function","title":"1.1 Loss function:","text":"<p>\\(\\(V(D,G) = \\underset{D}{\\max} {\\underbrace{\\mathbb{E}_{x \\sim p_{data}(x)}[\\log D(x)] + \\mathbb{E}_{z \\sim p_z(z)}[\\log(1-D(G(z)))]}_{\\text{Discriminator Loss}:L_D}} +\\underset{G}{\\min} {\\underbrace{\\mathbb{E}_{z \\sim p_z(z)}[\\log(1-D(G(z)))]}_{\\text{Generator Loss: }L_G}}\\)\\)</p> <p>Where:   - \\(p_{data}(x)\\) is the real data distribution   - \\(p_z(z)\\) is the noise distribution   - \\(G(z)\\) is generator mapping from noise to synthetic data   - \\(D(x)\\) is the discriminator's estimate of the probability that \\(x\\) is real</p> <p>overall training process:    Image Source: Goodfellow et al., \"Generative Adversarial Networks\" (2014) arXiv:1406.2661</p> <ul> <li> <p>In GAN training, we iterate the Discriminator (\\(D\\)) \\(K\\) times before updating the Generator (\\(G\\)) once\uff1a</p> </li> <li> <p>because we need \\(D\\) to be powerful enough to provide accurate feedback for \\(G's\\) improvement</p> </li> <li>This iterative strategy helps maintain training stability and prevent mode collapse, although K needs to be carefully balanced <ul> <li>too large and G can't learn effectively, too small and D's feedback becomes unreliable.</li> </ul> </li> </ul>"},{"location":"book/chapter5_GAN/3.1from_gan_to_stylegan/paper/#12-base-model-structure","title":"1.2 Base model structure","text":"<p>Code reference: https://github.com/eriklindernoren/PyTorch-GAN/blob/master/implementations/gan/gan.py</p> <pre><code>class Generator(nn.Module):\n    def __init__(self):\n        super(Generator, self).__init__()\n\n        def block(in_feat, out_feat, normalize=True):\n            layers = [nn.Linear(in_feat, out_feat)]\n            if normalize:\n                layers.append(nn.BatchNorm1d(out_feat, 0.8))\n            layers.append(nn.LeakyReLU(0.2, inplace=True))\n            return layers\n\n        self.model = nn.Sequential(\n            *block(opt.latent_dim, 128, normalize=False),\n            *block(128, 256),\n            *block(256, 512),\n            *block(512, 1024),\n            nn.Linear(1024, int(np.prod(img_shape))),\n            nn.Tanh()\n        )\n    def forward(self, z):\n        img = self.model(z)\n        img = img.view(img.size(0), *img_shape)\n        return img\n</code></pre> <p><pre><code>class Discriminator(nn.Module):\n    def __init__(self):\n        super(Discriminator, self).__init__()\n        self.model = nn.Sequential(\n            nn.Linear(int(np.prod(img_shape)), 512),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Linear(512, 256),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Linear(256, 1),\n            nn.Sigmoid(),\n        )\n    def forward(self, img):\n        img_flat = img.view(img.size(0), -1)\n        validity = self.model(img_flat)\n        return validity\n</code></pre> Training process and images generated:</p> <p> Image Source: Goodfellow et al., \"Generative Adversarial Networks\" (2014) arXiv:1406.2661</p> <ul> <li>Real data distribution \\(p_{data}\\)(Black dotted line)</li> <li>Generator distribution \\(p_g\\)(Green solid line )</li> <li>Discriminator output \\(D\\)(Blue dashed line)</li> <li>Noise space where \\(z\\) is sampled (Lower horizontal line)</li> <li>Data space \\(x\\)(Upper horizontal line)</li> <li>Generator G's mapping from  \\(z\\) to  \\(x\\) (Arrows connecting lines)</li> </ul> <p>From the picture, we can see the training Evolution (from a to d):</p> <ul> <li> <p>Initial Stage:</p> </li> <li> <p>The generated distribution  \\(p_g\\) (green) differs significantly from the real distribution \\(p_{data}\\) (black)</p> </li> <li> <p>Discriminator \\(D\\)  (blue) attempts to distinguish samples, but performs unstably</p> </li> <li> <p>Discriminator Training: \\(D\\) is trained to reach optimal solution: \\(D^*(x) = \\frac{p_{data}(x)}{p_{data}(x) + p_g(x)}\\)</p> </li> <li> <p>Generator Update:  \\(G\\) updates based on gradients from \\(D\\)</p> </li> <li> <p>Final Convergence: When \\(G\\) and \\(D\\) have sufficient capacity\uff08 \\(p_{data} =p_g\\)), they reach Nash equilibrium</p> </li> </ul> <p> Image Source: Goodfellow et al., \"Generative Adversarial Networks\" (2014) arXiv:1406.2661</p>"},{"location":"book/chapter5_GAN/3.1from_gan_to_stylegan/paper/#2-2014cgan-conditional-generative-adversarial-nets","title":"2. [2014]cGAN: Conditional Generative Adversarial Nets","text":""},{"location":"book/chapter5_GAN/3.1from_gan_to_stylegan/paper/#21-overall-introduction","title":"2.1 Overall Introduction:","text":"<p>Conditional generation Traditional GANs produce samples from random noise but can't control the output features, as they are unsupervised learning.</p> <p>While conditional GANs (cGANs) incorporate conditional information into both the generator and discriminator, enabling control over the output properties. This is achieved through a semi-supervised approach.</p> <p>The cGAN paper only shows its generated results on the MNIST dataset, where simply concatenating label embeddings might have limited impact. However, the core idea of \"guiding the generation process with conditional information\" proposed by cGAN has significantly influenced subsequent generative models. </p> <ul> <li>For example, models like DALL-E and Stable Diffusion, although utilizing different architectures like Diffusion, have adopted the principle of conditional generation: they use text embeddings as conditional information to control image generation.</li> </ul>"},{"location":"book/chapter5_GAN/3.1from_gan_to_stylegan/paper/#22-base-model-structure","title":"2.2 Base model structure","text":"<p> Source: Mirza et al., \"Conditional Generative Adversarial Nets\" (2014) arXiv:1411.1784</p> <p>How to combine the condition into input:</p> <ul> <li> <p>First convert categorical labels into continuous vector representations using nn.Embedding</p> </li> <li> <p><code>self.label_emb = nn.Embedding(opt.n_classes, opt.n_classes)</code></p> </li> <li> <p>Then concatenates torch.cat label embeddings(y) with noise vectors(z) along dimension -1: </p> </li> <li> <p><code>gen_input = torch.cat((self.label_emb(labels), noise), -1)</code></p> </li> <li> <p>Uses this concatenated vector as input to generate images through multiple network layers</p> </li> </ul> <pre><code>class Generator(nn.Module):\n    def __init__(self):\n        super(Generator, self).__init__()\n        self.label_emb = nn.Embedding(opt.n_classes, opt.n_classes)\n        def block(in_feat, out_feat, normalize=True):\n            layers = [nn.Linear(in_feat, out_feat)]\n            if normalize:\n                layers.append(nn.BatchNorm1d(out_feat, 0.8))\n            layers.append(nn.LeakyReLU(0.2, inplace=True))\n            return layers\n\n        self.model = nn.Sequential(\n            *block(opt.latent_dim + opt.n_classes, 128, normalize=False),\n            *block(128, 256),\n            *block(256, 512),\n            *block(512, 1024),\n            nn.Linear(1024, int(np.prod(img_shape))),\n            nn.Tanh()\n        )\n\n    def forward(self, noise, labels):\n        # Concatenate label embedding and image to produce input\n        gen_input = torch.cat((self.label_emb(labels), noise), -1)\n        img = self.model(gen_input)\n        img = img.view(img.size(0), *img_shape)\n        return img\n</code></pre> <p>IN Discriminator:</p> <ul> <li> <p>Flattens input images: </p> <ul> <li><code>img.view(img.size(0), -1)</code></li> </ul> </li> <li> <p>Similarly, processes labels through embedding: <code>self.label_embedding(labels)</code></p> </li> <li> <p>Concatenates flattened images and label embeddings:</p> <ul> <li><code>d_in = torch.cat((img.view(img.size(0), -1), self.label_embedding(labels)), -1)</code></li> </ul> </li> <li> <p>Passes concatenated vector through discriminator network for real/fake classification</p> </li> </ul> <p><pre><code>class Discriminator(nn.Module):\n    def __init__(self):\n        super(Discriminator, self).__init__()\n\n        self.label_embedding = nn.Embedding(opt.n_classes, opt.n_classes)\n\n        self.model = nn.Sequential(\n            nn.Linear(opt.n_classes + int(np.prod(img_shape)), 512),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Linear(512, 512),\n            nn.Dropout(0.4),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Linear(512, 512),\n            nn.Dropout(0.4),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Linear(512, 1),\n        )\n\n    def forward(self, img, labels):\n        # Concatenate label embedding and image to produce input\n        d_in = torch.cat((img.view(img.size(0), -1), self.label_embedding(labels)), -1)\n        validity = self.model(d_in)\n        return validity\n</code></pre> Actually, it's still a Binary Classification Task. The output of cGAN discriminator still maintains GAN's binary output (real/fake). </p> <ul> <li>Doesn't explicitly verify condition-image matching</li> <li>Output is a single scalar through Sigmoid/BCELoss or MSELoss</li> </ul> <p>For example, an input condition: number \"7\". If the generator generates an image that looks like \"3\". Although the discriminator will not directly point out \"this is not 7\", because the label of \"7\" in the training data has never been paired with the image of \"3\". So this wrong match will be identified as \"generated\" by the discriminator.</p>"},{"location":"book/chapter5_GAN/3.1from_gan_to_stylegan/paper/#23-loss-function","title":"2.3 Loss function","text":"\\[\\min_{G} \\max_{D} V(D,G) = \\mathbb{E}_{x \\sim p_{data}(x)}[\\log D(x|y)] + \\mathbb{E}_{z \\sim p_z(z)}[\\log(1 - D(G(z|y)))]\\] <p>Where: \\(\\mathbb{E}\\): Expected value (expectation) \\(\\mathbb{E}_{x \\sim p_{data}(x)}[\\log D(x|y)]\\) : </p> <ul> <li> <p>\\(x \\sim p_{data(x)}\\):  \\(x\\)sampled from real data distribution</p> </li> <li> <p>\\(D(x|y)\\): Discriminator's output for real data  \\(x\\) given condition  \\(y\\)</p> </li> <li> <p>\\(E[\\log D(x|y)]\\) - Discriminator's ability to identify real samples</p> </li> </ul> <p>\\(\\mathbb{E}_{z \\sim p_z(z)}[\\log(1 - D(G(z|y)))]\\) : </p> <ul> <li> <p>\\(z \\sim p_z(z)\\) z sampled from noise distribution</p> </li> <li> <p>\\(G(z|y)\\): Generator's output from noise z given condition y</p> </li> <li> <p>\\(E[log(1 - D(G(z|y)))]\\) - Discriminator's ability to identify fake samples</p> </li> </ul> <p><pre><code>for epoch in range(opt.n_epochs):\n    for i, (imgs, labels) in enumerate(dataloader):\n        batch_size = imgs.shape[0]\n        # Adversarial ground truths\n        valid = Variable(FloatTensor(batch_size, 1).fill_(1.0), requires_grad=False)\n        fake = Variable(FloatTensor(batch_size, 1).fill_(0.0), requires_grad=False)\n        # Configure input\n        real_imgs = Variable(imgs.type(FloatTensor))\n        labels = Variable(labels.type(LongTensor))\n        # -----------------\n        #  Train Generator\n        # -----------------\n        optimizer_G.zero_grad()\n        # Sample noise and labels as generator input\n        z = Variable(FloatTensor(np.random.normal(0, 1, (batch_size, opt.latent_dim))))\n        gen_labels = Variable(LongTensor(np.random.randint(0, opt.n_classes, batch_size)))\n        # Generate a batch of images\n        gen_imgs = generator(z, gen_labels)\n        # Loss measures generator's ability to fool the discriminator\n        validity = discriminator(gen_imgs, gen_labels)\n        g_loss = adversarial_loss(validity, valid)\n        g_loss.backward()\n        optimizer_G.step()\n        # ---------------------\n        #  Train Discriminator\n        # ---------------------\n        optimizer_D.zero_grad()\n        # Loss for real images\n        validity_real = discriminator(real_imgs, labels)\n        d_real_loss = adversarial_loss(validity_real, valid)\n        # Loss for fake images\n        validity_fake = discriminator(gen_imgs.detach(), gen_labels)\n        d_fake_loss = adversarial_loss(validity_fake, fake)\n        # Total discriminator loss\n        d_loss = (d_real_loss + d_fake_loss) / 2\n        d_loss.backward()\n        optimizer_D.step()\n</code></pre> Source: Mirza et al., \"Conditional Generative Adversarial Nets\" (2014) arXiv:1411.1784</p>"},{"location":"book/chapter5_GAN/3.1from_gan_to_stylegan/paper/#3-2015dcgandeep-convolutional-ganunsupervised-representation-learning-with-deep-convolutional-generative-adversarial-networks","title":"3. [2015]DCGAN(Deep Convolutional GAN\uff09\uff1aUnsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks","text":""},{"location":"book/chapter5_GAN/3.1from_gan_to_stylegan/paper/#31-overall-introduction-deep-convolutional-gan","title":"3.1 Overall Introduction:  Deep Convolutional GAN","text":"<p>DCGAN integrates the strengths of Convolutional Neural Networks into GANs with key innovations:</p> <ol> <li> <p>Convolutional Layers: Transposed convolutions in the generator and strided convolutions in the discriminator enhance spatial information retention.</p> </li> <li> <p>Batch Normalization: Used extensively in both parts to improve stability and prevent mode collapse.</p> </li> <li> <p>Activation Functions: The generator uses ReLU with a Tanh final layer, and the discriminator employs LeakyReLU.</p> </li> <li> <p>Starts from 100-dimensional noise z, gradually generating \\(64\u00d764\\) images through multiple convolution layers</p> </li> <li> <p>Feature map progression(CHW): </p> </li> <li> <p>\\(100\\times1\\times1\\)-&gt;\\(1024\\times4\\times4\\) -&gt; \\(512\\times8\\times8\\)-&gt;\\(256\\times16\\times16\\)-&gt;\\(128\\times32\\times32\\)-&gt;\\(3\\times64\\times64\\)</p> </li> </ol>"},{"location":"book/chapter5_GAN/3.1from_gan_to_stylegan/paper/#32-base-model-structure","title":"3.2 Base model structure","text":"<p> Source: Radford et al., \"Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks\" (2016) arXiv:1511.06434</p> <p>About Transposed convolutions:</p> <ul> <li> <p>Input Matrix Expansion: Initially, the input feature map undergoes an expansion by inserting zeros between each element. The number of zeros inserted depends on the stride parameter. </p> </li> <li> <p>Application of the Convolution Kernel: Next, the convolution kernel is applied to the expanded feature map. This process is similar to traditional convolution operations, where the kernel slides over the expanded feature map, computing the dot product with local regions. Unlike regular convolution, this operation results in a larger output feature map because the input has been expanded.</p> </li> <li> <p>Adjustment of Output Size: Finally, the output feature map might be cropped or padded to adjust its dimensions to the desired size. This adjustment depends on the padding parameter, which can either reduce or increase the spatial dimensions of the output</p> </li> </ul>"},{"location":"book/chapter5_GAN/3.1from_gan_to_stylegan/paper/#33-loss-function","title":"3.3 Loss function","text":"<p>Same as GAN objective : \\(\\min_G \\max_D V(D,G) = \\mathbb{E}_{x\\sim p_{data}}[\\log D(x)] + \\mathbb{E}_{z\\sim p_z}[\\log(1-D(G(z)))]\\)</p>"},{"location":"book/chapter5_GAN/3.1from_gan_to_stylegan/paper/#4-2017-wgan-wasserstein-gan","title":"4. [2017] WGAN: Wasserstein GAN","text":""},{"location":"book/chapter5_GAN/3.1from_gan_to_stylegan/paper/#41-overall-introduction","title":"4.1 Overall Introduction:","text":"<p>WGAN introduces Wasserstein distance and Lipschitz constraint  in loss function to \"improve the stability of learning, get rid of problems like mode collapse, and provide meaningful learning curves useful for debugging and hyperparameter searches\". WGAN replaces the JSD with the Wasserstein distance to measure the distribution distance in the original GAN.</p> <ul> <li> <p>If the discriminator is trained too well, the generator's gradients vanish, and the generator's loss cannot decrease </p> </li> <li> <p>If the discriminator is not trained well enough, the generator's gradients become inaccurate, causing it to move erratically. </p> </li> </ul> <p>The discriminator needs to be trained to just the right degree - neither too well nor too poorly - but this balance is very difficult to achieve. Moreover, this optimal balance might even vary at different stages within the same training epoch, which is why GANs are so difficult to train.</p>"},{"location":"book/chapter5_GAN/3.1from_gan_to_stylegan/paper/#42-drawbacks-as-jsd","title":"4.2 Drawbacks as JSD\uff1a","text":""},{"location":"book/chapter5_GAN/3.1from_gan_to_stylegan/paper/#421-gradient-vanishing-problem-training-instability","title":"4.2.1 Gradient Vanishing Problem &amp; training instability","text":"<p>We have introduced above, under an (approximately) optimal discriminator, minimizing the generator's loss is equivalent to minimizing the JS divergence between \\(P_r\\) and \\(P_g\\). Since \\(P_r\\) and \\(P_g\\) almost inevitably have negligible overlap, their JS divergence will always be the constant \\(\\log 2\\), regardless of how far apart they are. This ultimately leads to the generator's gradient (approximately) becoming 0, resulting in gradient vanishing.  Source: Arjovsky et al., \"Wasserstein GAN\" (2017) arXiv:1701.07875</p>"},{"location":"book/chapter5_GAN/3.1from_gan_to_stylegan/paper/#422-model-collapse","title":"4.2.2 Model collapse","text":"<p>Secondly, even the previously mentioned standard KL divergence term has flaws. Because KL divergence is not a symmetric measure, \\(KL(P_g\\|P_r)\\) and \\(KL(P_r\\|P_g)\\) are different.  Taking the former as an example: \\(KL(P_g||P_r) = \\int_x P_g(x)\\log(\\frac{P_g(x)}{P_r(x)})dx\\)</p> <ul> <li> <p>When \\(P_g(x) \\to 0\\) and \\(P_{r}(x) \\to 1\\), \\(P_g(x)\\log\\frac{P_g(x)}{P_{r}(x)} \\to 0\\), contributing nearly 0 to \\(KL(P_g||P_r)\\)</p> </li> <li> <p>When \\(P_g(x) \\to 1\\) and \\(P_{r}(x) \\to 0\\), \\(P_g(x)\\log\\frac{P_g(x)}{P_{r}(x)} \\to +\\infty\\), contributing positively infinite to \\(KL(P_g||P_r)\\)</p> </li> <li> <p>In other words, \\(KL(P_g||P_r)\\) penalizes these two types of errors differently. </p> </li> <li> <p>The first type of error corresponds to \"generator failing to generate real samples\" with small penalty.</p> </li> <li> <p>The second type corresponds to \"generator generating unrealistic samples\" with large penalty. </p> </li> </ul> <p>The first type of error represents a lack of diversity, while the second type represents a lack of accuracy. As a result, the generator would rather generate some repetitive but \"safe\" samples, and is reluctant to generate diverse samples, because one small mistake could lead to the second type of error, resulting in an unacceptable loss. This phenomenon is commonly referred to as mode collapse.</p> <p> Source: Arjovsky et al., \"Wasserstein GAN\" (2017) arXiv:1701.07875</p> <p>Why Wasserstein distance?</p> <p>The superiority of the Wasserstein distance compared to KL divergence and JS divergence lies in its ability to reflect the proximity between two distributions even when they don't overlap. While KL divergence and JS divergence are discontinuous , being either maximum or minimum. The Wasserstein distance is smooth and offers a more natural way to measure distances between distributions.</p> <ol> <li> <p>Training Stability: Provides meaningful gradients even when distributions do not overlap, significantly improving the stability of GAN training.</p> </li> <li> <p>Reduced Mode Collapse: Encourages diversity in generated samples by considering the overall differences between distributions, reducing mode collapse.</p> </li> <li> <p>Intuitive Loss Function: Serves as a loss metric, where a smaller Wasserstein distance indicates closer alignment with the target distribution's statistical properties.</p> </li> <li> <p>Effective GAN Training: WGANs use Wasserstein distance to offer a more stable and effective training process, enhancing the quality and diversity of generated samples.</p> </li> </ol>"},{"location":"book/chapter5_GAN/3.1from_gan_to_stylegan/paper/#43-loss-function","title":"4.3 Loss function","text":"<ol> <li>About Wasserstein Distance (measure distance by estimating the difference between expectation):</li> <li>Mathematical Definition \uff1a\\(W(P,Q) = \\inf_{\\gamma \\in \\Pi(P,Q)} \\mathbb{E}_{(x,y)\\sim \\gamma}[||x-y||]\\)<ul> <li>\\(\\Pi(P_r, P_g)\\) is the set of all possible joint distributions whose marginal distributions are \\(P_r\\) and \\(P_g\\). </li> <li>In other words, for each distribution in \\(\\Pi(P_r, P_g)\\), its marginal distributions are \\(P_r\\) and \\(P_g\\). </li> <li>For each possible joint distribution \\(\\gamma\\),sample \\((x,y) \\sim \\gamma\\) to get a real sample \\(x\\) and a generated sample \\(y\\), and calculate the distance between these samples \\(\\|x-y\\|\\). </li> <li>\\(\\mathbb{E}_{(x,y)\\sim\\gamma}[\\|x-y\\|]\\)calculates the expected value of the sample distance under this joint distribution. The infimum of this expected value among all possible joint distributions \\(\\inf_{\\gamma\\sim\\Pi(P_r,P_g)} \\mathbb{E}_{(x,y)\\sim\\gamma}[\\|x-y\\|]\\) is defined as the Wasserstein distance.</li> <li>Intuitively, \\(\\mathbb{E}_{(x,y)\\sim\\gamma}[\\|x-y\\|]\\) can be understood as the \"cost\" of moving \"\\(P_r\\) pile of earth\" to \" \\(P_g\\) location\" under this \"transport plan\", and \\(W(P_r, P_g)\\) is the \"minimum cost\" under the \"optimal transport plan\", which is why it's called the Earth-Mover distance.</li> </ul> </li> <li>Lipschitz Constraint</li> <li>A function f is called Lipschitz continuous if it satisfies:(\\(|f(x) - f(y)| \\leq C|x - y|\\)\\)<ul> <li>where \\(C\\) is the Lipschitz constant.</li> <li>When inputs x and y are close to each other, their corresponding outputs \\(f(x)\\) and \\(f(y)\\) must also be close. This property ensures smoothness and continuity in the function</li> </ul> </li> <li>As for a discriminator in WGAN, D is constrained to be 1-Lipschitz functions: \\(|D(x) - D(y)| \\leq |x - y|\\)</li> <li>Wasserstein Distance in WGAN:</li> <li>GAN objective function :\\(\\(\\min_{G} \\max_{D} V(D,G) = \\mathbb{E}_{x \\sim p_{data}(x)}[\\log D(x)] + \\mathbb{E}_{z \\sim p_z(z)}[\\log(1 - D(G(z)))]\\)\\)</li> <li>In WGAN, the objective function can be written as:(\\(W(P_r, P_g) = \\sup_{||f||_L \\leq 1} \\mathbb{E}_{x \\sim \\mathbb{P}_r}[D(x)] - \\mathbb{E}_{x \\sim \\mathbb{P}_g}[D(x)]\\)\\)   where \uff1a<ul> <li>D is constrained to be 1-Lipschitz functions.</li> <li>\\(\\mathbb{P}_r\\) represents the distribution of real data (real probability distribution)</li> <li>\\(x\\sim\\mathbb{P}_r\\) means x is sampled from the real data distribution</li> <li>\\(\\mathbb{P}_g\\) represents the distribution of generated data (generated probability distribution)</li> <li>\\({x}\\sim\\mathbb{P}_g\\) means x is sampled from the generator's distribution</li> <li>WGAN tries to minimize the Wasserstein distance between \\(\\mathbb{P}_r\\) and \\(\\mathbb{P}_g\\) </li> <li>\\(||f||_L \\leq 1\\) means that the discriminator D must satisfy the Lipschitz condition.</li> </ul> </li> </ol> <p>how do we get the loss function:</p> <ul> <li>Primal Form (Original Wasserstein Distance):</li> </ul> <p>\\(\\(W(P,Q) = \\inf_{\\gamma \\in \\Pi(P,Q)} \\mathbb{E}_{(x,y)\\sim \\gamma}[||x-y||]\\)\\)</p> <p>where \\(\\Pi(P,Q)\\) is the set of all joint distributions (couplings) whose margins are P and Q.</p> <ul> <li>Kantorovich Duality Theorem:According to the duality Theorem, this problem is equivalent to:</li> </ul> <p>\\(\\(W(P,Q) = \\sup_{f\\in Lip_1} \\left(\\int f\\,dP - \\int f\\,dQ\\right)\\)\\) where \\(Lip_1\\) is the set of 1-Lipschitz functions.</p> <ul> <li>Expectation Form:Converting the integrals to expectations:</li> </ul> \\[W(P,Q) = \\sup_{||f||_L \\leq 1} [\\mathbb{E}_{x\\sim P}[f(x)] - \\mathbb{E}_{x\\sim Q}[f(x)]]\\] <ul> <li>Application to GAN: When P = Pr (real distribution) and Q = Pg (generated distribution):</li> </ul> \\[W(P_r,P_g) = \\sup_{||f||_L \\leq 1} [\\mathbb{E}_{x\\sim P_r}[f(x)] - \\mathbb{E}_{x\\sim P_g}[f(x)]]\\] <ol> <li> <p>Weight Clipping : -&gt; implementation of Lipschitz Constraint in WGAN</p> </li> <li> <p>WGAN forces the discriminator to satisfy the Lipschitz constraint through weight clipping or gradient penalty.</p> </li> <li> <p>After each gradient update, the weights of the critic (discriminator) are clipped to a fixed range [-c, c] </p> </li> <li> <p>In the paper, c = 0.01</p> </li> </ol> <pre><code># \u5728\u6bcf\u6b21\u53c2\u6570\u66f4\u65b0\u540e\u6267\u884c\nfor param in discriminator.parameters():\n    param.data.clamp_(-c, c)  # c\u901a\u5e38\u8bbe\u4e3a0.01\nWeight Clipping -&gt; all weight values are forced to be limited to the range of [-0.01, 0.01].\n</code></pre> <ul> <li> <p>Any value outside this range will be \"clipped\" to the boundary value. </p> </li> <li> <p>This ensures the Lipschitz constraint of the network, but may also lead to limitations in expressiveness.</p> </li> </ul> <p>\"Weight clipping is a clearly terrible way to enforce a Lipschitz constraint.\" -- M. Arjovsky, S. Chintala and L. Bottou, \"Wasserstein Generative Adversarial Networks,\" in International Conference on Machine Learning, 2017, pp. 214-223.</p>"},{"location":"book/chapter5_GAN/3.1from_gan_to_stylegan/paper/#44-training-process-wasserstein-lipschitz-gradient","title":"4.4 Training process -&gt; Wasserstein &amp; Lipschitz  Gradient","text":"<p> Source: Arjovsky et al., \"Wasserstein GAN\" (2017) arXiv:1701.07875</p> <ol> <li>Discriminator  Gradient:</li> </ol> <p>The Wasserstein loss for the Discriminator is:\\(\\(L(w) = \\mathbb{E}_{x \\sim \\mathbb{P}_r}[f_w(x)] - \\mathbb{E}_{z \\sim p(z)}[f_w(g_\\theta(z))]\\)\\) where:</p> <ul> <li> <p>\\(f_w(x)\\) Discriminator evaluates real data samples</p> </li> <li> <p>\\(x\\sim\\mathbb{P}_r\\) means x is sampled from the real data distribution</p> </li> <li> <p>\\(f_w(g_\u03b8(z))\\) Discriminator evaluates generated data samples</p> <ul> <li> <p>\\(z\\) is random noise transformed by generator \\(g_\u03b8\\) </p> </li> <li> <p>\\(g_\u03b8(z)\\) represents the Generator generated samples</p> </li> </ul> </li> </ul> <p>For a batch of size m, the empirical version becomes: \\(\\(L(w) = \\frac{1}{m}\\sum_{i=1}^m f_w(x^{(i)}) - \\frac{1}{m}\\sum_{i=1}^m f_w(g_\\theta(z^{(i)}))\\)\\)</p> <p>Therefore, the gradient with respect to Discriminator parameters w is:</p> \\[\\nabla_w L = \\frac{1}{m}\\sum_{i=1}^m \\nabla_w f_w(x^{(i)}) - \\frac{1}{m}\\sum_{i=1}^m \\nabla_w f_w(g_\\theta(z^{(i)}))\\] <ol> <li>Generator Gradient:</li> </ol> <p>The generator's objective is to minimize:</p> \\[L(\u03b8) = -\\mathbb{E}_{z \\sim p(z)}[f_w(g_\\theta(z))]\\] <p>For a batch of size m, this becomes:</p> \\[L(\u03b8) = -\\frac{1}{m}\\sum_{i=1}^m f_w(g_\\theta(z^{(i)}))\\] <p>The gradient with respect to generator parameters \u03b8 is:</p> \\[\\nabla_\\theta L = -\\frac{1}{m}\\sum_{i=1}^m \\nabla_\\theta f_w(g_\\theta(z^{(i)}))\\] <ul> <li> <p>Line 5: Discriminator gradient computation \\(g_w \u2190 \\nabla_w [\\frac{1}{m}\\sum_{i=1}^m f_w(x^{(i)}) - \\frac{1}{m}\\sum_{i=1}^m f_w(g_\\theta(z^{(i)}))]\\)</p> </li> <li> <p>Line 10: Generator gradient computation \\(g_\\theta \u2190 -\\nabla_\\theta \\frac{1}{m}\\sum_{i=1}^m f_w(g_\\theta(z^{(i)}))\\)</p> </li> </ul> <pre><code>for i, (imgs, _) in enumerate(dataloader):\n        # Configure input\n        real_imgs = Variable(imgs.type(Tensor))\n        # ---------------------\n        #  Train Discriminator\n        # ---------------------\n        optimizer_D.zero_grad()\n        # Sample noise as generator input\n        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], opt.latent_dim))))\n        # Generate a batch of images\n        fake_imgs = generator(z).detach()\n        # Adversarial loss\n        loss_D = -torch.mean(discriminator(real_imgs)) + torch.mean(discriminator(fake_imgs))\n        loss_D.backward()\n        optimizer_D.step()\n        # Clip weights of discriminator\n        for p in discriminator.parameters():\n            p.data.clamp_(-opt.clip_value, opt.clip_value)\n        # Train the generator every n_critic iterations\n        if i % opt.n_critic == 0:\n            # -----------------\n            #  Train Generator\n            # -----------------\n            optimizer_G.zero_grad()\n            # Generate a batch of images\n            gen_imgs = generator(z)\n            # Adversarial loss\n            loss_G = -torch.mean(discriminator(gen_imgs))\n            loss_G.backward()\n            optimizer_G.step()\n</code></pre> <p> Source: Arjovsky et al., \"Wasserstein GAN\" (2017) arXiv:1701.07875</p>"},{"location":"book/chapter5_GAN/3.1from_gan_to_stylegan/paper/#5-2017-wgan-gp-improved-training-of-wasserstein-gans","title":"5. [2017] WGAN-GP: Improved Training of Wasserstein GANs","text":""},{"location":"book/chapter5_GAN/3.1from_gan_to_stylegan/paper/#51-overall-introduction-gradient-penalty","title":"5.1 Overall Introduction:  gradient penalty","text":"<p>WGAN-GP replaces the weight clipping in the original WGAN by adding a gradient penalty term at the random interpolation points between the real and generated data, thereby achieving a more stable training process and better generation effects.</p> <p>Loss function in WGAN:  \\(\\(L = \\sup_{||f||_L \\leq 1} \\mathbb{E}_{x \\sim \\mathbb{P}_r}[D(x)] - \\mathbb{E}_{x \\sim \\mathbb{P}_g}[D(x)]\\)\\)</p> <p>Loss function in WGAN-GP:  \\(\\(L = \\mathbb{E}_{x\\sim P_r}[D(x)] - \\mathbb{E}_{x\\sim P_g}[D(x)] + \\lambda \\mathbb{E}_{\\hat{x}\\sim P_{\\hat{x}}}[(||\\nabla_{\\hat{x}}D(\\hat{x})||_2 - 1)^2]\\)\\)</p> <p>where: - Wasserstein Distance Term :\\(\\mathbb{E}_{x\\sim P_r}[D(x)] - \\mathbb{E}_{x\\sim P_g}[D(x)]\\)</p> <ul> <li> <p>measure distance between real and generated distributions</p> </li> <li> <p>Gradient Penalty Term: \\(\\lambda \\mathbb{E}_{\\hat{x}\\sim P_{\\hat{x}}}[(||\\nabla_{\\hat{x}}D(\\hat{x})||_2 - 1)^2]\\)</p> </li> <li> <p>\u03bb is penalty coefficient (typically 10)</p> </li> <li> <p>Ensures gradient norm is close to 1</p> </li> <li> <p>\\(\\hat{x}\\) is a random interpolation between real samples and generated samples:</p> </li> </ul>"},{"location":"book/chapter5_GAN/3.1from_gan_to_stylegan/paper/#511-drawbacks-as-weight-clipping","title":"5.1.1 Drawbacks as weight-clipping","text":"<p> Source: Gulrajani et al., \"Improved Training of Wasserstein GANs\" (2017) arXiv:1704.00028</p>"},{"location":"book/chapter5_GAN/3.1from_gan_to_stylegan/paper/#5111-capacity-underuse","title":"5.1.1.1 Capacity underuse","text":"<ul> <li> <p>Main Issues:</p> </li> <li> <p>Theoretically, this critic should maintain unit gradient magnitudes everywhere, but when using weight clipping constraints, the critic in WGAN tends to learn overly simplistic functions. </p> </li> <li> <p>Experimental Validation:</p> </li> <li> <p>To verify this, we conducted experiments using the real distribution plus random noise as the generator's output. </p> </li> <li> <p>The results showed that critics with weight clipping indeed overlook the complex features of the data, learning only simple approximations. </p> </li> </ul>"},{"location":"book/chapter5_GAN/3.1from_gan_to_stylegan/paper/#5112-exploding-and-vanishing-gradients","title":"5.1.1.2 Exploding and vanishing gradients","text":"<ul> <li> <p>Main Issues:</p> </li> <li> <p>WGAN faces optimization challenges during training, caused by the interaction between weight constraints and the loss function. If the clipping threshold \\(c\\) is not carefully adjusted, it may lead to either vanishing or exploding gradients.</p> </li> <li> <p>Experimental Validation:</p> </li> <li> <p>Researchers conducted experiments on the Swiss Roll toy dataset using three different clipping thresholds: 0.1, 0.01, and 0.001. With weight clipping:</p> <ul> <li> <p>At \\(c=0.1\\), gradients exhibited exponential growth (red line going up).</p> </li> <li> <p>At \\(c=0.01\\) and \\(c=0.001\\), gradients exhibited exponential decay (purple and green lines going down).</p> </li> </ul> </li> </ul> <p>The two smaller graphs on the right show differences in weight distribution:</p> <ul> <li> <p>The upper graph: Weight clipping pushes weights toward two extreme values.</p> </li> <li> <p>The lower graph: Gradient penalty results in a more normal distribution of weights.</p> </li> </ul>"},{"location":"book/chapter5_GAN/3.1from_gan_to_stylegan/paper/#52-loss-function","title":"5.2 Loss function","text":"<p>Training process:  Source: Gulrajani et al., \"Improved Training of Wasserstein GANs\" (2017) arXiv:1704.00028</p> <p>How does the Gradient Penalty term work in WGAN-GP\uff1f</p> <ol> <li> <p>The loss function of WGAN-GP:  \\(\\min_G \\max_D \\mathbb{E}_{x\\sim P_r}[D(x)] - \\mathbb{E}_{z\\sim P_z}[D(G(z))] + \\lambda \\mathbb{E}_{\\hat{x}\\sim P_{\\hat{x}}}[(||\\nabla_{\\hat{x}}D(\\hat{x})||_2 - 1)^2]\\)</p> </li> <li> <p>The core idea of the Gradient Penalty term is to enforce the 1-Lipschitz constraint on discriminator D across the sample space\uff1a \\(|D(x_1) - D(x_2)| \\leq |x_1 - x_2|\\)</p> </li> <li> <p>The 1-Lipschitz constraint above is equivalent to having the gradient norm of the discriminator not exceeding 1 at any point:  \\(||\\nabla_x D(x)||_2 \\leq 1\\)</p> </li> <li> <p>WGAN-GP enforces the gradient norm to be equal to 1, rather than less than or equal to 1, through the penalty term:\\(\\mathcal{L}_{GP} = \\lambda \\mathbb{E}_{\\hat{x}\\sim P_{\\hat{x}}}[(||\\nabla_{\\hat{x}}D(\\hat{x})||_2 - 1)^2]\\)</p> </li> <li> <p>\\(\\hat{x} = \\epsilon x + (1-\\epsilon)G(z), \\epsilon \\sim U[0,1]\\)</p> <ul> <li> <p>So \\(\\hat{x}\\) is a linear interpolation between data points of the real data distribution \\(P_r\\) and the generated data distribution \\(P_g\\).</p> </li> <li> <p>Why sampling?</p> </li> <li> <p>According to \\(||\\nabla_x D(x)||_2 \\leq 1\\), the optimal critic forms a line between the paired points of the real and generated distributions with a gradient norm of 1. Therefore, as a compromise, the constraint is only enforced along these sampled lines.</p> </li> <li> <p>Easy to implement and worked out in experiments.</p> </li> </ul> </li> </ol> <p>\\(\\hat{x}\\): <pre><code>alpha = torch.rand(real_samples.size(0), 1, 1, 1)\ninterpolates = alpha * real_samples + (1 - alpha) * fake_samples\n</code></pre> \\(\\nabla_{\\hat{x}}D(\\hat{x})\\): <pre><code>#d(x)\nd_interpolates = D(interpolates)  \n# \\nabla_{\\hat{x}}D(\\hat{x}):\ngradients = autograd.grad(\n        outputs=d_interpolates,\n        inputs=interpolates,\n        grad_outputs=torch.ones_like(d_interpolates),\n        create_graph=True\n    )[0]\n</code></pre></p> <p>\\((||\\nabla_{\\hat{x}}D(\\hat{x})||_2 - 1)^2\\):</p> <pre><code>gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n</code></pre> <ol> <li> <p>The regulatory effect of this penalty term is manifested in:</p> </li> <li> <p>When \\(||\\nabla_{\\hat{x}}D(\\hat{x})||_2 &gt; 1\\), showing:</p> <ul> <li> <p>Too Steep Gradients: Discriminators tend to be \"aggressive\" in judging real/fake samples and change too rapidly </p> </li> <li> <p>May lead to training instability:</p> </li> <li> <p>Likely to cause discriminator overfitting</p> </li> <li> <p>Provides too strong gradient signals to the generator</p> </li> </ul> </li> <li> <p>When \\(||\\nabla_{\\hat{x}}D(\\hat{x})||_2 &lt; 1\\), showing:</p> <ul> <li> <p>Too Flat Gradients: The Discriminator tends to be  insensitive to input changes </p> </li> <li> <p>Insufficient Discrimination :  The Discriminator cannot effectively distinguish real/fake samples</p> </li> <li> <p>Vanishing Gradients: Generator might not receive effective training signals</p> </li> </ul> </li> <li> <p>Only when gradient norm  \\(||\\nabla_{\\hat{x}}D(\\hat{x})||_2 = 1\\), the penalty term becomes zero</p> </li> </ol> <pre><code>def compute_gradient_penalty(D, real_samples, fake_samples):\n    # Random interpolation coefficient\n    alpha = torch.rand(real_samples.size(0), 1, 1, 1)\n    # Generate interpolated samples\n    interpolates = alpha * real_samples + (1 - alpha) * fake_samples\n    interpolates.requires_grad_(True)\n    # Compute discriminator output\n    d_interpolates = D(interpolates)  \n    # Compute gradients\n    gradients = autograd.grad(\n        outputs=d_interpolates,\n        inputs=interpolates,\n        grad_outputs=torch.ones_like(d_interpolates),\n        create_graph=True\n    )[0]\n    # Compute gradient penalty\n    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n    return gradient_penalty\n\n# Training loop\nfor epoch in epochs:\n    for real_data in dataloader:\n        # Compute gradient penalty\n        gradient_penalty = compute_gradient_penalty(D, real_data, fake_data)\n        # Discriminator loss\n        d_loss = -torch.mean(D(real_data)) + torch.mean(D(fake_data)) + lambda_gp * gradient_penalty\n</code></pre> <p> Source: Gulrajani et al., \"Improved Training of Wasserstein GANs\" (2017) arXiv:1704.00028</p> <p> Source: Gulrajani et al., \"Improved Training of Wasserstein GANs\" (2017) arXiv:1704.00028</p>"},{"location":"book/chapter5_GAN/3.1from_gan_to_stylegan/paper/#6-2018-pggan-progressive-growing-of-gans-for-improved-quality-stability-and-variation","title":"6. [2018] PGGAN: Progressive Growing of GANs for Improved Quality, Stability, and Variation","text":""},{"location":"book/chapter5_GAN/3.1from_gan_to_stylegan/paper/#61-overall-introduction","title":"6.1 Overall Introduction:","text":"<ol> <li> <p>Progressive Growing</p> </li> <li> <p>Core Idea: Start at low resolution and progressively increase to higher resolutions.</p> </li> <li> <p>Advantages:  More stable training &amp; Higher computational efficiency &amp; Better memory utilization</p> </li> <li> <p>Implementation: Smoothly fade in new layers and synchronous growth of the generator and discriminator</p> </li> <li> <p>Minibatch Standard Deviation </p> </li> <li> <p>Purpose: Increase the diversity of generated images &amp; prevents mode collapse.</p> </li> <li> <p>Implementation: </p> <ul> <li> <p>Introduce a statistical layer late in the discriminator</p> </li> <li> <p>Calculate the standard deviation within a minibatch of samples</p> </li> <li> <p>Concatenate statistical features with the original features</p> </li> </ul> </li> <li> <p>Normalization Strategies</p> </li> <li> <p>Purpose: strategies ensure underlying training stability.</p> </li> <li> <p>Implementation: </p> <ul> <li>Generator: Uses PixelNorm </li> </ul> </li> </ol> <p>The structure of PGGAN laid an important foundation for subsequent work (such as StyleGAN).</p>"},{"location":"book/chapter5_GAN/3.1from_gan_to_stylegan/paper/#62-progressive-growing-of-gans","title":"6.2 PROGRESSIVE GROWING OF GANS","text":"<p> Source: Karras et al., \"Progressive Growing of GANs for Improved Quality, Stability, and Variation\" (2018) arXiv:1710.10196</p> <p> Source: Karras et al., \"Progressive Growing of GANs for Improved Quality, Stability, and Variation\" (2018) arXiv:1710.10196</p> <ul> <li> <p>Each resolution stage has two phases:</p> </li> <li> <p>Fade-in Phase:</p> <ul> <li> <p>The new layer is gradually blended in using alpha parameter</p> </li> <li> <p>Alpha increases linearly from 0 to 1</p> </li> <li> <p>In PGGAN, the growth of the \u03b1 parameter is linear and is controlled by the number of training iterations. This is achieved as follows:</p> </li> </ul> </li> </ul> <pre><code># \u5047\u8bbefade_in_iters\u662ffade-in\u9636\u6bb5\u7684\u603b\u8fed\u4ee3\u6b21\u6570\nfade_in_iters = 600000  # 600k images\n# \u5f53\u524d\u8fed\u4ee3\u6b21\u6570current_iter\nalpha = min(current_iter / fade_in_iters, 1.0)\n\ndef fade_in(self, alpha, upscaled, generated):\n    return torch.tanh(alpha * generated + (1-alpha) * upscaled)\n......\nfinal_upscaled = self.rgb_layers[steps-1](upscaled)\nfinal_out = self.rgb_layers[steps](out)\nreturn self.fade_in(alpha, final_upscaled, final_out)\n</code></pre> <ol> <li> <p>Stabilization Phase: </p> <ul> <li> <p>Train network with new layers fully active</p> </li> <li> <p>Old paths are removed</p> </li> <li> <p>Network stabilizes at new resolution</p> </li> </ul> </li> </ol> <p>Time Allocation:</p> <ul> <li> <p>Fade-in Phase: 600k images</p> </li> <li> <p>Stabilization Phase: 600k images</p> </li> <li> <p>Total per resolution: 1.2M images (600k + 600k)</p> </li> </ul> <p><pre><code>Complete Training Process Example (from 4\u00d74 to 1024\u00d71024):\n4\u00d74:   Only Stabilization     600k images\n8\u00d78:   Fade-in + Stabilization 1.2M images\n16\u00d716: Fade-in + Stabilization 1.2M images\n32\u00d732: Fade-in + Stabilization 1.2M images\n64\u00d764: Fade-in + Stabilization 1.2M images\n128\u00d7128: Fade-in + Stabilization 1.2M images\n256\u00d7256: Fade-in + Stabilization 1.2M images\n512\u00d7512: Fade-in + Stabilization 1.2M images\n1024\u00d71024: Fade-in + Stabilization 1.2M images\n</code></pre> Smooth Layer Transitions: <pre><code>def forward(self, x, alpha):\n    # Old path (lower resolution)\n    old_rgb = self.from_rgb_old(x)\n    old_rgb = self.upsample(old_rgb)\n\n    # New path (higher resolution)\n    new_x = self.upsample(x)\n    new_x = self.conv(new_x)\n    new_rgb = self.to_rgb_new(new_x)\n\n    # Smooth blending\n    return (1 - alpha) * old_rgb + alpha * new_rgb\n</code></pre>   - toRGB: 1\u00d71 convolution to convert features to RGB</p> <ul> <li> <p>fromRGB: 1\u00d71 convolution to convert RGB to features</p> </li> <li> <p>2\u00d7: Upsampling (nearest neighbor)</p> </li> <li> <p>0.5\u00d7: Downsampling (average pooling)</p> </li> </ul>"},{"location":"book/chapter5_GAN/3.1from_gan_to_stylegan/paper/#63-increasing-variation-using-minibatch-standard-deviation","title":"6.3 INCREASING VARIATION USING MINIBATCH STANDARD DEVIATION","text":"<p> Source: Wang et al., \"Citrus Disease Image Generation and Classification Based on Improved FastGAN and EfficientNet-B5\" (2023) Electronics, 12(5), 1232</p> <ol> <li>For each feature and spatial location i, compute standard deviation across the batch:   \\(\\sigma_i(x) = \\sqrt{\\frac{1}{N}\\sum_{k=1}^{N}(x_{ik} - \\mu_i)^2}\\) where:</li> <li> <p>\\(x_{ik}\\) is the feature value for sample k at position i</p> </li> <li> <p>\\(\\mu_i = \\frac{1}{N}\\sum_{k=1}^{N}x_{ik}\\) is the mean across the batch</p> </li> <li> <p>N is the batch size</p> </li> <li> <p>Average the standard deviations across features and spatial dimensions:   \\(\\sigma = \\frac{1}{C \\times H \\times W}\\sum_{i}\\sigma_i(x)\\)</p> </li> </ol> <p>where:</p> <ul> <li>\\(C\\) : channels. \\(H\\): height. \\(W\\) :width</li> </ul> <p>These statistics are then:</p> <ol> <li> <p>Replicated into a \\([1\u00d71\u00d7H\u00d7W]\\) tensor</p> </li> <li> <p>Further replicated N times to match batch size: \\([N\u00d71\u00d7H\u00d7W]\\)</p> </li> <li> <p>Concatenated with original input along channel dimension to get final output of shape \\([N\u00d7(C+1)\u00d7H\u00d7W]\\)</p> </li> </ol> <p><pre><code>def minibatch_stddev_layer(x, group_size=4):\n    N, C, H, W = x.shape\n    G = min(group_size, N)  # \u5206\u7ec4\u5927\u5c0f\n\n    # [NCHW] -&gt; [GMCHW] \u5206\u6210G\u7ec4\n    y = x.reshape(G, -1, C, H, W)\n\n    # \u8ba1\u7b97\u6807\u51c6\u5dee\n    y = torch.sqrt(y.var(0) + 1e-8)  # [-MCHW]\n\n    # \u53d6\u5e73\u5747\u5f97\u5230\u5355\u4e2a\u503c\n    y = y.mean(dim=[0,1,2,3])  # []\n\n    # \u5e7f\u64ad\u56de\u539f\u59cb\u5f62\u72b6\n    y = y.reshape(1, 1, 1, 1)\n    y = y.repeat(N, 1, H, W)  # [N1HW]\n\n    # \u8fde\u63a5\u5230\u8f93\u5165\u7279\u5f81\u56fe\n    return torch.cat([x, y], 1)  # [N(C+1)HW]\n</code></pre> The main advantages of this technique are:</p> <ol> <li>Helps the discriminator identify the statistical characteristics of the generated images</li> <li>Encourages the generator to produce more diverse outputs</li> <li>Helps avoid mode collapse</li> </ol>"},{"location":"book/chapter5_GAN/3.1from_gan_to_stylegan/paper/#64-normalization-in-generator-and-discriminator","title":"6.4 NORMALIZATION IN GENERATOR AND DISCRIMINATOR","text":""},{"location":"book/chapter5_GAN/3.1from_gan_to_stylegan/paper/#641-normalization-in-passed-gan-related-model","title":"6.4.1 Normalization in passed GAN-related-model","text":"GAN model Normalization applied Implementation detail GAN batch normalization Typically employs basic batch normalization in both the generator and discriminator. cGAN batch normalization Typically employs basic batch normalization in both the generator and discriminator. DCGAN batch normalization Generator: BN is used in all layers except the output layer. Discriminator: BN is used in all layers except the input and output layers. WGAN Remove BN in the discriminator Advises against using batch normalization due to its impact on the Lipschitz constraint. Completely removes BN in the discriminator. The generator may use BN, but it is often omitted in practice. WGAN-GP Remove BN in the discriminator Discriminator: Recommends using layer normalization or instance normalization instead of batch normalization. This is because BN introduces correlations between samples, affecting the calculation of the gradient penalty. PGGAN Completely Remove BN and Pixel-wise normalization in the generator and new weight initialization Generator: BN is used in all layers except the output layer. Discriminator: BN is used in all layers except the input and output layers."},{"location":"book/chapter5_GAN/3.1from_gan_to_stylegan/paper/#642-pixelwise-feature-vector-normalization-in-generator","title":"6.4.2 PIXELWISE FEATURE VECTOR NORMALIZATION IN GENERATOR","text":"<p>Applied after each convolutional layer in the generator at each pixel position independently:</p> \\[b_{x,y} = \\frac{a_{x,y}}{\\sqrt{\\frac{1}{N}\\sum_{j=0}^{N-1}(a_{x,y}^j)^2 + \\epsilon}}\\] <p>Where: - \\(\\epsilon = 10^{-8}\\)</p> <ul> <li> <p>\\(a_{x,y} \\text{ is the original feature vector at pixel position } (x,y)\\)</p> </li> <li> <p>\\(b_{x,y} \\text{ is the normalized feature vector at pixel position } (x,y)\\)</p> </li> <li> <p>\\(N \\text{ is the number of feature maps (channels)}\\)</p> </li> <li> <p>\\(\\epsilon = 10^{-8} \\text{ is a small constant to prevent division by zero}\\)</p> </li> <li> <p>\\(\\text{The sum } \\sum_{j=0}^{N-1} \\text{ is taken over all } N \\text{ feature maps for that pixel position}\\)</p> </li> </ul> <p><pre><code>class PixelNorm(nn.Module):\n    def forward(self, x):\n        norm = torch.mean(x ** 2, dim=1, keepdim=True)\n        norm = torch.sqrt(norm + self.epsilon)\n        return x / norm    \n</code></pre> - \\(x ** 2\\):  Calculate the squared values of all features at each pixel \\((a_{x,y}^j)^2\\)</p> <ul> <li> <p><code>torch.mean(..., dim=1)</code>:  Average these squares across all feature maps \\({\\frac{1}{N}\\sum_{j=0}^{N-1}(a_{x,y}^j)^2 }\\)</p> </li> <li> <p>torch.sqrt(... + epsilon): Take the square root of the average (plus \u03b5) \\({\\sqrt{\\frac{1}{N}\\sum_{j=0}^{N-1}(a_{x,y}^j)^2 + \\epsilon}}\\)</p> </li> <li> <p>\\(x / norm\\):  normalization \\(\\frac{a_{x,y}}{\\sqrt{\\frac{1}{N}\\sum_{j=0}^{N-1}(a_{x,y}^j)^2 + \\epsilon}}\\)$</p> </li> </ul>"},{"location":"book/chapter5_GAN/3.1from_gan_to_stylegan/paper/#643-qualized-learning-rate","title":"6.4.3 QUALIZED LEARNING RATE","text":"<p>Problem: In traditional neural network training, parameters of different layers may have different dynamic ranges. When using adaptive optimizers like RMSProp or Adam, they normalize gradient updates based on the standard deviation of parameters. This results in parameters with larger dynamic ranges requiring more time to adjust properly.</p> <p>Specific Implementation:</p> <ol> <li>Traditional Weight Initialization </li> <li> <p>In standard neural networks, weights are typically initialized using methods </p> <ul> <li>like He initialization N(0, sqrt(2/n)), Better suited for ReLU</li> </ul> </li> </ol> <p><pre><code># Standard He initialization (for comparison)\nweight_shape = (out_channels, in_channels, kernel, kernel)\nstd = np.sqrt(2.0 / (in_channels * kernel * kernel))\nweights = np.random.normal(0, std, weight_shape)\n</code></pre>   - This can lead to different layers learning at different rates, causing training instability</p> <ul> <li> <p>The variance of the gradients can differ significantly between layers</p> </li> <li> <p>The Equalized Learning Rate Solution: </p> </li> <li> <p>initialization (happens only once when the model is created):</p> <ul> <li>Instead of using usual standard initialization, weights are initialized from N(0,1)</li> </ul> </li> </ul>"},{"location":"book/chapter5_GAN/3.1from_gan_to_stylegan/paper/#65-equalized-learning-rate-approach","title":"6.5 Equalized learning rate approach","text":"<pre><code>weights = np.random.normal(0, 1.0, weight_shape)\nruntime_coef = std  # Applied during forward pass\n</code></pre> <ul> <li> <p>During training (happens every forward pass): scaling process</p> </li> <li> <p>Each layer's weights are explicitly scaled during runtime by a layer-specific constant </p> </li> <li> <p>The scaling factor is the per-layer normalization constant from He initialization</p> </li> </ul>"},{"location":"book/chapter5_GAN/3.1from_gan_to_stylegan/paper/#651-in-equalizedconv2d","title":"6.5.1 In EqualizedConv2d","text":"<pre><code>self.scale = np.sqrt(2) / np.sqrt(fan_in)  # Calculate He scaling factor\nscaled_weight = self.weight * self.scale    # Apply scaling at runtime\n</code></pre> <ul> <li>This ensures that the dynamic range and learning speed are similar for all weights</li> <li>Standard layers: Apply scaling during initialization<ul> <li>Equalized layers: Apply scaling during each forward pass</li> <li>This ensures the gradient updates remain properly scaled throughout training</li> </ul> </li> </ul> <p>Why It's Useful:</p> <ol> <li> <p>Ensures that all weights have a similar dynamic range.</p> </li> <li> <p>Makes the learning process more balanced, avoiding slow learning for some parameters due to large ranges.</p> </li> <li> <p>Better adapts to c</p> </li> <li> <p>In standard neural networks, weights are typically initialized using methods </p> </li> <li> <p>like He initialization \\(N(0, sqrt(2/n))\\), Better suited for ReLU</p> </li> </ol> <p>RMSProp or Adam, they normalize gradient updates based on the standard deviation of parameters\uff1a</p> <p>RMSprop: \\(\\(\\theta_t = \\theta_{t-1} - \\frac{\\eta}{\\sqrt{v_t + \\epsilon}} g_t\\)\\) Adam:\\(\\(\\theta_t = \\theta_{t-1} - \\frac{\\eta}{\\sqrt{\\hat{v}_t} + \\epsilon} \\hat{m}_t\\)\\)</p> <ol> <li>Standard Deviation Estimation:</li> <li> <p>\\(v_t\\) actually estimates the exponential moving average of squared gradients:\\(v_t = \\beta v_{t-1} + (1-\\beta)g_t^2\\)</p> </li> <li> <p>This accumulated squared gradient \\(v_t\\) is essentially estimating the second moment of the gradient, and its square root \\(\\sqrt v_t\\) approximates the standard deviation of the gradient</p> </li> <li> <p>Normalization Effect:</p> </li> <li> <p>In the update formula, the gradient term (\\(g_t\\) or \\(\u0125_t\\)) is divided by \\(\\sqrt v_t\\)</p> </li> <li> <p>This is equivalent to normalizing the gradient update by the gradient's standard deviation</p> </li> <li> <p>Mathematically equivalent to:\\(\\(\\text{normalized update} = \\frac{g_t}{\\sqrt{v_t + \\epsilon}}\\)\\)</p> </li> <li> <p>Why This Is Standard Deviation Normalization:</p> </li> <li> <p>If a parameter has large gradient variations (high standard deviation), \\(\\sqrt v_t\\) will become larger</p> </li> <li> <p>This will make the actual update step smaller</p> </li> <li> <p>Conversely, if gradient variations are small (low standard deviation), the update step will become larger accordingly</p> </li> <li> <p>This achieves adaptive standard deviation normalization</p> <ul> <li>This is also why EQUALIZED LEARNING RATE solves this problem by explicitly controlling the dynamic range of parameters (\\(\u0175\u1d62 = w\u1d62/c\\)).</li> </ul> </li> </ol> <p>Main Advantages:</p> <ol> <li> <p>Keeps the learning speed consistent for all weights.</p> </li> <li> <p>Avoids the issue of having both too high and too low learning rates at the same time.</p> </li> <li> <p>By dynamically scaling during runtime rather than statically at initialization, it makes the training process more stable.</p> </li> </ol>"},{"location":"book/chapter5_GAN/3.3stylegan/paper/","title":"StyleGAN: A Style-Based Generator Architecture for Generative Adversarial Networks","text":"<p>Paper Link </p>"},{"location":"book/chapter5_GAN/3.3stylegan/paper/#1","title":"1. \u6838\u5fc3\u521b\u65b0","text":"<ol> <li>\u57fa\u4e8e\u98ce\u683c\u7684\u751f\u6210\u5668\u67b6\u6784 </li> <li>\u5c06\u4f20\u7edf\u7684\u8f93\u5165\u5c42\u66ff\u6362\u4e3a\u5e38\u91cf\u8f93\u5165</li> <li>\u901a\u8fc7AdaIN\u5c42\u5c06\u6f5c\u5728\u7f16\u7801\u6ce8\u5165\u5230\u4e0d\u540c\u7684\u5c42\u7ea7</li> <li> <p>\u5b9e\u73b0\u4e86\u5bf9\u4e0d\u540c\u5c3a\u5ea6\u7279\u5f81\u7684\u7cbe\u786e\u63a7\u5236</p> </li> <li> <p>\u4e2d\u95f4\u6f5c\u5728\u7a7a\u95f4W</p> </li> <li>\u5f15\u5165\u6620\u5c04\u7f51\u7edcF\u5c06\u6f5c\u5728\u7a7a\u95f4Z\u6620\u5c04\u5230\u4e2d\u95f4\u6f5c\u5728\u7a7a\u95f4W</li> <li>W\u7a7a\u95f4\u5177\u6709\u66f4\u597d\u7684\u89e3\u8026\u7279\u6027</li> <li> <p>\u652f\u6301\u66f4\u597d\u7684\u7279\u5f81\u6df7\u5408\u548c\u7f16\u8f91\u64cd\u4f5c</p> </li> <li> <p>\u81ea\u9002\u5e94\u5b9e\u4f8b\u5f52\u4e00\u5316(AdaIN)</p> </li> <li>\u901a\u8fc7\u98ce\u683c\u5411\u91cf\u8c03\u5236\u6bcf\u4e2a\u901a\u9053\u7684\u5747\u503c\u548c\u65b9\u5dee</li> <li>\u5b9e\u73b0\u4e86\u5bf9\u7279\u5b9a\u7279\u5f81\u7684\u7cbe\u786e\u63a7\u5236</li> </ol> <pre><code>x = x * (style_split[:, 0] + 1) + style_split[:, 1]\n</code></pre> <ul> <li>\u6bcf\u4e2achannel\u7684feature map\u663e\u5f0f\u8c03\u8282\u65b9\u5dee\u548c\u5747\u503c\uff0c\u8fd9\u4e24\u4e2a\u7edf\u8ba1\u91cf\u8868\u793a\u56fe\u7247\u7684\u98ce\u683c</li> </ul>"},{"location":"book/chapter5_GAN/3.3stylegan/paper/#2","title":"2. \u6280\u672f\u7ec6\u8282","text":"<ol> <li>LOD (Level of Detail) \u8ba1\u7b97:</li> <li>\u76ee\u7684: \u63a7\u5236\u8bad\u7ec3\u671f\u95f4\u7684\u5206\u8fa8\u7387\u7ea7\u522b\uff0c\u652f\u6301\u6e10\u8fdb\u5f0f\u589e\u957f\u3002</li> <li>\u8ba1\u7b97:<ul> <li><code>lod</code> \u57fa\u4e8e\u5df2\u89c1\u56fe\u50cf\u6570\u91cf (<code>seen_img</code>) \u548c\u6bcf\u4e2a\u7ea7\u522b\u7684\u6301\u7eed\u65f6\u95f4 (<code>lod_duration</code>) \u8ba1\u7b97\u3002</li> <li>\u968f\u8bad\u7ec3\u8fdb\u5c55\u800c\u51cf\u5c11\uff0c\u5e73\u6ed1\u8fc7\u6e21\u4e8e\u4e0d\u540c\u5206\u8fa8\u7387\u3002</li> </ul> </li> <li> <p>\u9636\u6bb5:</p> <ul> <li>\u7a33\u5b9a\u9636\u6bb5\uff1a<code>lod</code> \u4fdd\u6301\u4e0d\u53d8\u3002</li> <li>\u8fc7\u6e21\u9636\u6bb5\uff1a<code>lod</code> \u53d6\u5206\u6570\u503c\uff0c\u5e73\u6ed1\u5206\u8fa8\u7387\u53d8\u5316\u3002</li> </ul> </li> <li> <p>\u5408\u6210\u7f51\u7edc (Synthesis Network):</p> </li> <li>\u7ed3\u6784: \u7531\u591a\u4e2a\u5206\u8fa8\u7387\u5c42\u7ec4\u6210\uff0c\u6bcf\u5c42\u5305\u542b\u4e24\u4e2a\u5377\u79ef\u5757\u3002</li> <li>\u5206\u8fa8\u7387\u5c42:<ul> <li>\u521d\u59cb\u5c42: \u5c06\u5e38\u91cf\u8f93\u5165\u8f6c\u6362\u4e3a\u7279\u5f81\u56fe\u3002</li> <li>\u540e\u7eed\u5c42: \u6bcf\u5c42\u5206\u8fa8\u7387\u52a0\u500d\uff0c\u901a\u9053\u51cf\u534a\uff0c\u4fdd\u6301\u53c2\u6570\u4e00\u81f4\u3002</li> </ul> </li> <li> <p>\u5377\u79ef\u5757 (ConvBlock):</p> <ul> <li>\u4e0a\u91c7\u6837: \u4f7f\u7528\u6700\u8fd1\u90bb\u63d2\u503c\u589e\u52a0\u5206\u8fa8\u7387\u3002</li> <li>\u5377\u79ef: \u53d7 PGGAN \u542f\u53d1\u7684\u7f29\u653e\u6743\u91cd\uff0c\u7a33\u5b9a\u8bad\u7ec3\u3002</li> <li>\u566a\u58f0\u6dfb\u52a0: \u7a7a\u95f4\u6216\u901a\u9053\u566a\u58f0\uff0c\u589e\u5f3a\u7ec6\u8282\u591a\u6837\u6027\u3002</li> <li>\u6fc0\u6d3b: LeakyReLU \u9632\u6b62\u795e\u7ecf\u5143\u6b7b\u4ea1\uff0c\u6539\u5584\u68af\u5ea6\u6d41\u52a8\u3002</li> <li>\u5f52\u4e00\u5316: \u5b9e\u4f8b\u5f52\u4e00\u5316\u6807\u51c6\u5316\u7279\u5f81\u56fe\u3002</li> <li>\u98ce\u683c\u5316: \u4f7f\u7528\u5b66\u4e60\u7684\u98ce\u683c\u5411\u91cf\u8c03\u5236\u7279\u5f81\u56fe\uff0c\u8c03\u6574\u6bcf\u4e2a\u7279\u5f81\u56fe\u7684\u5747\u503c\u548c\u65b9\u5dee\u3002</li> </ul> </li> <li> <p>\u98ce\u683c\u8c03\u5236 (Style Modulation):</p> </li> <li>\u8fc7\u7a0b: \u6bcf\u4e2a\u7279\u5f81\u56fe\u901a\u9053\u4f7f\u7528\u98ce\u683c\u5411\u91cf\u8c03\u5236\u3002</li> <li> <p>\u65b9\u7a0b:</p> \\[  x = x \\times (\\text{style\\_split}[:, 0] + 1) + \\text{style\\_split}[:, 1] \\] </li> <li> <p>\u76ee\u7684: \u663e\u5f0f\u8c03\u6574\u7279\u5f81\u56fe\u65b9\u5dee\u548c\u5747\u503c\uff0c\u8868\u793a\u56fe\u7247\u98ce\u683c\u3002</p> </li> <li> <p>\u622a\u65ad\u6280\u5de7 (Truncation Trick):</p> </li> <li>\u76ee\u7684: \u63a7\u5236\u751f\u6210\u56fe\u50cf\u7684\u591a\u6837\u6027\u4e0e\u7a33\u5b9a\u6027\u3002</li> <li> <p>\u8fc7\u7a0b: \u4f7f\u7528\u4e2d\u5fc3\u5e73\u5747\u503c (<code>w_{avg}</code>) \u548c\u7f29\u653e\u56e0\u5b50 (<code>trunc_psi</code>) \u8c03\u6574\u98ce\u683c\u5411\u91cf\u3002\u5b83\u66f4\u76f8\u5f53\u4e8e\u4e00\u4e2a\u7f29\u653e\u64cd\u4f5c\uff0c\u800c\u4e0d\u662f\u4f20\u7edf\u610f\u4e49\u4e0a\u7684\u622a\u65ad\u64cd\u4f5c\u3002</p> </li> <li> <p>\u566a\u58f0\u6ce8\u5165 (Noise Injection):</p> </li> <li>\u7c7b\u578b: \u7a7a\u95f4\u6216\u901a\u9053\u3002</li> <li>\u76ee\u7684: \u4e3a\u7279\u5f81\u56fe\u6dfb\u52a0\u968f\u673a\u53d8\u5316\uff0c\u589e\u5f3a\u7ec6\u8282\u591a\u6837\u6027\u3002</li> </ol>"},{"location":"book/chapter5_GAN/3.3stylegan/paper/#3","title":"3. \u4ee3\u7801\u89e3\u8bfb","text":""},{"location":"book/chapter5_GAN/3.3stylegan/paper/#31-1-generator","title":"3.1 1. Generator","text":"<pre><code>    def forward(self,\n                z,\n                label=None,\n                lod=None,\n                w_moving_decay=0.995,\n                style_mixing_prob=0.9,\n                trunc_psi=None,\n                trunc_layers=None,\n                randomize_noise=False,\n                **_unused_kwargs):\n        mapping_results = self.mapping(z, label) # label \u662f\u7528\u4e8e\u6761\u4ef6\u751f\u6210\u7684\u6807\u7b7e\n        w = mapping_results['w'] #  W\u7a7a\u95f4\n        # w shape : [batch_size, w_space_dim] = [B,512]\n\n        if self.training and w_moving_decay &lt; 1:\n            batch_w_avg = all_gather(w).mean(dim=0)\n            self.truncation.w_avg.copy_(\n                self.truncation.w_avg * w_moving_decay +\n                batch_w_avg * (1 - w_moving_decay))\n            # \u8ba1\u7b97\u4e00\u4e2aW\u7a7a\u95f4\u4e2d\u7684\u4e2d\u5fc3\u70b9,\u7528\u4e8e\u622a\u65ad\u64cd\u4f5c\n        if self.training and style_mixing_prob &gt; 0:\n            new_z = torch.randn_like(z)\n            new_w = self.mapping(new_z, label)['w']\n            lod = self.synthesis.lod.cpu().tolist() if lod is None else lod\n            # \u8fd9\u91cc\u7684 tolist() \u53ef\u80fd\u9020\u6210\u6df7\u6dc6\uff0c\u4f46\u5bf9\u4e8e0\u7ef4tensor\uff08\u6807\u91cftensor\uff09\uff0c\u5b83\u8fd4\u56de\u7684\u662f\u4e00\u4e2a\u6807\u91cf\u503c\u3002\u4f8b\u5982\uff1a\n            # \u6240\u4ee5\u5728\u8fd9\u91cc\uff0clod \u5c31\u662f\u4e00\u4e2a\u6570\u503c\uff0c\u6bd4\u5982 0\u30011\u30012 \u6216\u8005 1.5 \u8fd9\u6837\u7684\u503c\uff0c\u7528\u4e8e\u63a7\u5236\u751f\u6210\u56fe\u50cf\u7684\u5206\u8fa8\u7387\u7ea7\u522b\u3002\u8fd9\u4e2a\u503c\uff1a\n\n            # \u53ef\u4ee5\u662f\u6574\u6570\uff1a\u76f4\u63a5\u5bf9\u5e94\u67d0\u4e2a\u5206\u8fa8\u7387\u7ea7\u522b\n            # \u4e5f\u53ef\u4ee5\u662f\u5c0f\u6570\uff1a\u8868\u793a\u5728\u4e24\u4e2a\u5206\u8fa8\u7387\u7ea7\u522b\u4e4b\u95f4\u8fdb\u884c\u63d2\u503c\n\n            current_layers = self.num_layers - int(lod) * 2\n            if np.random.uniform() &lt; style_mixing_prob:\n                mixing_cutoff = np.random.randint(1, current_layers)\n                # \u524d\u9762\u7684current_layers \u8868\u793a\u5f53\u524d\u7684\u5206\u8fa8\u7387\u7ea7\u522b\n                # \u540e\u9762\u7684 mixing_cutoff \u8868\u793a\u622a\u65ad\u70b9\n                # \u8fd9\u91cc\u7684 np.random.randint(1, current_layers) \u8868\u793a\u968f\u673a\u9009\u62e9\u4e00\u4e2a\u622a\u65ad\u70b9\n\n                w = self.truncation(w)\n                new_w = self.truncation(new_w)\n                w[:, mixing_cutoff:] = new_w[:, mixing_cutoff:]\n                # \u524d\u534a\u90e8\u5206\u7684 W \u7a7a\u95f4\u4e0d\u53d8\uff0c\u540e\u534a\u90e8\u5206\u7684 W \u7a7a\u95f4\u8fdb\u884c\u4e86\u66ff\u6362\n\n        wp = self.truncation(w, trunc_psi, trunc_layers)\n        # wp \u4e5f\u8fdb\u884c\u4e86\u622a\u65ad\u3002\n        # \u5f62\u72b6\u53d8\u5316  \uff1a\n        # \u8f93\u5165 w: [batch_size, w_space_dim] = [B, 512]\n        # \u8f93\u51fa wp: [batch_size, num_layers, w_space_dim] = [B, num_layers, 512]\n        synthesis_results = self.synthesis(wp, lod, randomize_noise)\n\n        return {**mapping_results, **synthesis_results}\n</code></pre> <p>generator \u5206\u6210\u51e0\u4e2a\u6b65\u9aa4</p>"},{"location":"book/chapter5_GAN/3.3stylegan/paper/#311-1-mapping-network","title":"3.1.1 1. \u6620\u5c04\u7f51\u7edc (Mapping Network)","text":"<pre><code>mapping_results = self.mapping(z, label) # label \u662f\u7528\u4e8e\u6761\u4ef6\u751f\u6210\u7684\u6807\u7b7e\nw = mapping_results['w']\n</code></pre> <p>\u8f93\u5165 :</p> <ul> <li>\\(z\\): \u6f5c\u5728\u5411\u91cf\uff0c\u901a\u5e38\u662f\u4ece\u6807\u51c6\u6b63\u6001\u5206\u5e03\u4e2d\u91c7\u6837\uff0c\u5f62\u72b6\u4e3a \\([B, z\\_dim]\\)</li> <li>\\(\\text{label}\\): \u6761\u4ef6\u751f\u6210\u7684\u6807\u7b7e\uff0c\u53ef\u9009\uff0c\u7528\u4e8e\u63a7\u5236\u751f\u6210\u5185\u5bb9\u3002</li> <li>\u8fc7\u7a0b :</li> <li> <p>\u4f7f\u7528\u4e00\u4e2a\u591a\u5c42\u611f\u77e5\u673a (MLP) \u5c06\u6f5c\u5728\u5411\u91cf \\(z\\) \u6620\u5c04\u5230\u6837\u5f0f\u7a7a\u95f4 \\(w\\)\uff1a</p> \\[w = f(z) \\] <p>\u5176\u4e2d \\(f\\) \u662f\u6620\u5c04\u7f51\u7edc\uff0c\u8f93\u51fa \\(w\\) \u7684\u5f62\u72b6\u4e3a \\([B, w\\_dim]\\)\uff0c  \u901a\u5e38 \\(w\\_dim = 512\\)\u3002 - \u8f93\u51fa :   - \\(w\\): \u6837\u5f0f\u5411\u91cf\uff0c\u4f5c\u4e3a\u540e\u7eed\u751f\u6210\u8fc7\u7a0b\u4e2d\u7684\u7279\u5f81\u63a7\u5236\u53c2\u6570\u3002</p> </li> </ul>"},{"location":"book/chapter5_GAN/3.3stylegan/paper/#312-2-w","title":"3.1.2 2. W \u7a7a\u95f4\u5747\u503c\u7684\u79fb\u52a8\u5e73\u5747\u66f4\u65b0","text":"<pre><code>if self.training and w_moving_decay &lt; 1:\n    batch_w_avg = all_gather(w).mean(dim=0)\n    self.truncation.w_avg.copy_(\n        self.truncation.w_avg * w_moving_decay +\n        batch_w_avg * (1 - w_moving_decay))\n</code></pre> <ul> <li>\u76ee\u7684 :</li> <li> <p>\u5728\u8bad\u7ec3\u9636\u6bb5\uff0c\u8ba1\u7b97 \\(w\\) \u7684\u5747\u503c\u5e76\u8fdb\u884c\u79fb\u52a8\u5e73\u5747\u66f4\u65b0\uff0c\u5f97\u5230\u6837\u5f0f\u7a7a\u95f4\u7684\u4e2d\u5fc3\u70b9 \\(w_{avg}\\)\u3002</p> </li> <li> <p>\\(w_{avg}\\) \u7528\u4e8e\u540e\u7eed\u7684\u622a\u65ad\u64cd\u4f5c\uff08truncation trick\uff09\uff0c\u4ee5\u63a7\u5236\u751f\u6210\u5185\u5bb9\u7684\u591a\u6837\u6027\u548c\u5e73\u8861\u6027\u3002</p> </li> <li> <p>\u8fc7\u7a0b :</p> </li> <li> <p>\u8ba1\u7b97\u5f53\u524d\u6279\u6b21\u7684\u6837\u5f0f\u5411\u91cf\u5e73\u5747\u503c \\(\\text{batch\\_w\\_avg}\\)\u3002</p> </li> <li> <p>\u4f7f\u7528\u6307\u6570\u79fb\u52a8\u5e73\u5747 (EMA) \u66f4\u65b0\u5168\u5c40\u6837\u5f0f\u5747\u503c \\(w\\_avg\\):</p> \\[ w_{avg} \\gets w_{avg} \\cdot \\text{decay} + \\text{batch-w-avg} \\cdot (1 - \\text{decay}) \\] </li> </ul>"},{"location":"book/chapter5_GAN/3.3stylegan/paper/#313-3-style-mixing","title":"3.1.3 3. \u6837\u5f0f\u6df7\u5408 (Style Mixing)","text":"<pre><code>if self.training and style_mixing_prob &gt; 0:\n    new_z = torch.randn_like(z)\n    new_w = self.mapping(new_z, label)['w']\n    lod = self.synthesis.lod.cpu().tolist() if lod is None else lod\n    current_layers = self.num_layers - int(lod) * 2\n    if np.random.uniform() &lt; style_mixing_prob:\n        mixing_cutoff = np.random.randint(1, current_layers)\n        # \u524d\u9762\u7684current_layers \u8868\u793a\u5f53\u524d\u7684\u5206\u8fa8\u7387\u7ea7\u522b\n        # \u540e\u9762\u7684 mixing_cutoff \u8868\u793a\u622a\u65ad\u70b9\n        # \u8fd9\u91cc\u7684 np.random.randint(1, current_layers) \u8868\u793a\u968f\u673a\u9009\u62e9\u4e00\u4e2a\u622a\u65ad\u70b9\n\n        w = self.truncation(w)\n        new_w = self.truncation(new_w)\n        w[:, mixing_cutoff:] = new_w[:, mixing_cutoff:]\n        # \u524d\u534a\u90e8\u5206\u7684 W \u7a7a\u95f4\u4e0d\u53d8\uff0c\u540e\u534a\u90e8\u5206\u7684 W \u7a7a\u95f4\u8fdb\u884c\u4e86\u66ff\u6362\n\n        # \u95ee\u9898\uff1a\u540c\u4e00\u4e2abatch\u91cc\u7684mixing_point\u662f\u4e00\u6837\u7684\u3002\u5982\u679c\u5bf9\u540c\u4e00\u4e2abatch\u91cc\u7684\u4e0d\u540c\u6837\u672c\u505a\u4e0d\u4e00\u6837\u7684\u6837\u5f0f\u6df7\u5408\uff0c\u4f1a\u4e0d\u4f1a\u6709\u95ee\u9898\uff1f\n\n#### 4. \u622a\u65ad\u64cd\u4f5c (Truncation Trick)\n```python\nwp = self.truncation(w, trunc_psi, trunc_layers)\n</code></pre> <p>\u5728self.truncation\u91cc\u9762 \u4f1a\u5148\u5bf9\\(w\\)\u8fdb\u884c\u590d\u5236\uff0c\u590d\u5236\u540e\u7684shape \u4e3a \\([B, \\text{num\\_layers}, w\\_dim]\\)\uff0c \u6bcf\u4e00\u5c42\u7684\u6837\u5f0f\u5411\u91cf\u90fd\u662f\u76f8\u540c\u7684\u3002 \u7136\u540e\u518d\u8fdb\u884c\u622a\u65ad\u64cd\u4f5c.</p> <pre><code>#self traucation\nif w.ndim == 2:\n    if self.repeat_w and w.shape[1] == self.w_space_dim:\n        w = w.view(-1, 1, self.w_space_dim)\n        wp = w.repeat(1, self.num_layers, 1)\n    else:\n        assert w.shape[1] == self.w_space_dim * self.num_layers\n        wp = w.view(-1, self.num_layers, self.w_space_dim)\n</code></pre> <ul> <li>\u76ee\u7684 :</li> <li> <p>\u63a7\u5236\u751f\u6210\u5185\u5bb9\u7684\u591a\u6837\u6027\u4e0e\u7a33\u5b9a\u6027\u3002</p> </li> <li> <p>\u8fc7\u7a0b :</p> </li> <li> <p>\u4f7f\u7528\u6837\u5f0f\u7a7a\u95f4\u7684\u4e2d\u5fc3\u70b9 \\(w\\_avg\\) \u548c\u622a\u65ad\u56e0\u5b50 \\(\\psi\\) \u5bf9\u6837\u5f0f\u5411\u91cf \\(w\\) \u8fdb\u884c\u7f29\u653e\uff1a</p> \\[ w'_i = w_{avg} + \\psi \\cdot (w_i - w_{avg}), \\quad \\text{for layers } i &lt; \\text{trunclayers} \\] </li> <li> <p>\u622a\u65ad\u64cd\u4f5c\u53ef\u4ee5\u51cf\u5c0f\u6837\u5f0f\u7a7a\u95f4\u4e2d\u6837\u5f0f\u5411\u91cf\u7684\u504f\u79bb\u7a0b\u5ea6\uff0c\u4ece\u800c\u751f\u6210\u66f4\u7a33\u5b9a\u7684\u56fe\u50cf\u3002</p> </li> <li>\u8f93\u51fa :</li> <li>\\(wp\\): \u6bcf\u4e00\u5c42\u7684\u6837\u5f0f\u5411\u91cf\uff0c\u5f62\u72b6\u4e3a \\([B, \\text{num\\_layers}, w\\_dim]\\)\u3002</li> <li> <p>\u95ee\u9898 : \u4e25\u683c\u6765\u8bf4\uff0c\u8fd9\u4e2a\u64cd\u4f5c\u786e\u5b9e\u66f4\u63a5\u8fd1\u4e8e \u7f29\u653e (scaling)  \u800c\u4e0d\u662f\u4f20\u7edf\u610f\u4e49\u4e0a\u7684 \u622a\u65ad (truncation) \uff0c\u5c3d\u7ba1\u5728 StyleGAN \u7684\u672f\u8bed\u4e2d\u88ab\u79f0\u4e3a \"truncation trick\"\u3002</p> <p>\u4e3a\u4ec0\u4e48\u662f\u7f29\u653e\uff1f \u622a\u65ad\u64cd\u4f5c\u7684\u516c\u5f0f\u4e3a\uff1a</p> \\[ wp = w_{avg} + (wp - w_{avg}) \\cdot \\text{trunc-psi} \\] <p>\u89c2\u5bdf\u516c\u5f0f\u53ef\u4ee5\u770b\u51fa\uff1a 1. \u6837\u5f0f\u5411\u91cf \\(wp\\) \u88ab\u91cd\u65b0\u8c03\u6574\u5230\u4e00\u4e2a\u4ee5 \\(w_{avg}\\) \u4e3a\u4e2d\u5fc3\u7684\u8303\u56f4\u5185\u3002</p> <ol> <li>\\(\\text{trunc-psi}\\) \u662f\u4e00\u4e2a\u7f29\u653e\u56e0\u5b50\uff0c\u51b3\u5b9a\u4e86 \\(wp\\) \u504f\u79bb \\(w_{avg}\\) \u7684\u7a0b\u5ea6\u3002</li> </ol> <p>\u7269\u7406\u610f\u4e49 \uff1a   - \u5982\u679c \\(\\text{trunc-psi} &lt; 1\\)\uff0c\u6837\u5f0f\u5411\u91cf\u7684\u504f\u79bb\u88ab\u7f29\u5c0f\uff0c\u751f\u6210\u7684\u56fe\u50cf\u66f4\u63a5\u8fd1\u4e8e\u5168\u5c40\u6837\u5f0f\u7684\u201c\u5e73\u5747\u503c\u201d\u3002</p> </li> <li> <p>\u5982\u679c \\(\\text{trunc-psi} &gt; 1\\)\uff0c\u6837\u5f0f\u5411\u91cf\u7684\u504f\u79bb\u88ab\u653e\u5927\uff0c\u751f\u6210\u7684\u56fe\u50cf\u4f1a\u66f4\u6781\u7aef\uff0c\u66f4\u504f\u79bb\u5e73\u5747\u98ce\u683c\u3002</p> <p>\u4f20\u7edf\u622a\u65ad (Clipping) \u5728\u4f20\u7edf\u7684\u201c\u622a\u65ad\u201d\u6982\u5ff5\u4e2d\uff0c\u6211\u4eec\u4f1a\u5c06\u67d0\u4e9b\u8d85\u51fa\u6307\u5b9a\u8303\u56f4\u7684\u503c \u76f4\u63a5\u9650\u5236  \u5728\u8fd9\u4e2a\u8303\u56f4\u5185\uff0c\u4f8b\u5982\uff1a$ x = \\max(\\min(x, \\text{upper_bound}), \\text{lower_bound}) $</p> <p>leGAN \u7684\u8fd9\u4e2a\u5b9e\u73b0\u4e2d\uff1a</p> </li> <li> <p>\u8fc7\u7f29\u653e\u64cd\u4f5c\u8c03\u6574\u6837\u5f0f\u5411\u91cf\u7684\u5e45\u5ea6\u3002</p> </li> <li> <p>\u8fd9\u79cd\u65b9\u5f0f\u4e0d\u4f1a\u5b8c\u5168\u53bb\u9664\u591a\u6837\u6027\uff0c\u800c\u662f\u63a7\u5236\u591a\u6837\u6027\u7684\u5e45\u5ea6\u3002     \u56e0\u6b64\uff0cStyleGAN \u7684\u201c\u622a\u65ad\u6280\u5de7\u201d\u5b9e\u9645\u4e0a\u662f\u4e00\u79cd\u52a8\u6001\u7684 \u6837\u5f0f\u5411\u91cf\u7f29\u653e\u64cd\u4f5c \u3002</p> <p>\u4e3a\u4ec0\u4e48\u79f0\u4e3a\u622a\u65ad\uff1f \u5c3d\u7ba1\u64cd\u4f5c\u672c\u8d28\u662f\u7f29\u653e\uff0c\u4f46\u88ab\u79f0\u4e3a\u622a\u65ad\u53ef\u80fd\u6709\u4ee5\u4e0b\u539f\u56e0\uff1a</p> <ol> <li>\u7ed3\u679c\u4e0a\u7684\u7c7b\u4f3c\u6027 \uff1a</li> <li>\u7f29\u653e\u64cd\u4f5c\u548c\u4f20\u7edf\u622a\u65ad\u5728\u51cf\u5c11\u751f\u6210\u6837\u5f0f\u7684\u591a\u6837\u6027\u4e0a\u6709\u76f8\u4f3c\u6548\u679c\u3002</li> </ol> </li> <li> <p>\u5f53 \\(\\text{trunc\\_psi}\\) \u63a5\u8fd1 0 \u65f6\uff0c\u6837\u5f0f\u5411\u91cf\u8d8b\u8fd1 \\(w\\_avg\\)\uff0c\u6b64\u65f6\u7684\u884c\u4e3a\u7c7b\u4f3c\u4e8e\u5c06\u6240\u6709\u6837\u5f0f\u5411\u91cf\u201c\u622a\u65ad\u201d\u5230\u4e00\u4e2a\u72ed\u7a84\u7684\u8303\u56f4\u3002</p> <ol> <li>\u672f\u8bed\u6cbf\u88ad \uff1a</li> <li>\u5728 GAN \u793e\u533a\uff0c\"truncation trick\" \u662f\u4e00\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684\u672f\u8bed\uff0c\u5c3d\u7ba1\u5177\u4f53\u5b9e\u73b0\u53ef\u80fd\u4f1a\u6709\u6240\u4e0d\u540c\u3002</li> </ol> </li> </ul> <p>\u603b\u7ed3</p> <ol> <li> <p>StyleGAN \u7684\u64cd\u4f5c\u662f\u7f29\u653e \uff1a</p> </li> <li> <p>\u5b83\u6839\u636e \\(w\\_avg\\) \u52a8\u6001\u8c03\u6574\u6837\u5f0f\u5411\u91cf \\(wp\\) \u7684\u5e45\u5ea6\uff0c\u800c\u4e0d\u662f\u7b80\u5355\u5730\u5bf9\u5176\u503c\u8fdb\u884c\u88c1\u526a(\u7f29\u653e)\u3002</p> </li> <li> <p>\u79f0\u4e3a\u622a\u65ad\u7684\u539f\u56e0 \uff1a</p> </li> <li> <p>\u7ed3\u679c\u4e0a\u7c7b\u4f3c\u4f20\u7edf\u622a\u65ad\uff0c\u80fd\u6709\u6548\u51cf\u5c11\u751f\u6210\u6837\u5f0f\u7684\u591a\u6837\u6027\u3002</p> </li> <li> <p>\u672f\u8bed\u5ef6\u7eed\u4e86 GAN \u793e\u533a\u7684\u4e60\u60ef\u7528\u6cd5\u3002</p> </li> <li> <p>\u672c\u8d28 \uff1a</p> </li> <li> <p>\u5b83\u662f \u6837\u5f0f\u5411\u91cf\u7684\u5e45\u5ea6\u7f29\u653e \uff0c\u8c03\u63a7\u751f\u6210\u56fe\u50cf\u7684\u591a\u6837\u6027\u4e0e\u7a33\u5b9a\u6027\u4e4b\u95f4\u7684\u6743\u8861\u3002</p> </li> </ol>"},{"location":"book/chapter5_GAN/3.3stylegan/paper/#5","title":"5. \u56fe\u50cf\u751f\u6210","text":"<pre><code>synthesis_results = self.synthesis(wp, lod, randomize_noise)\n</code></pre> <ul> <li>\u8f93\u5165 :</li> <li>\\(wp\\): \u5206\u5c42\u6837\u5f0f\u5411\u91cf\u3002</li> <li>\\(\\text{lod}\\): \u5206\u8fa8\u7387\u7ea7\u522b\uff08Level of Detail\uff09\uff0c\u7528\u4e8e\u63a7\u5236\u751f\u6210\u56fe\u50cf\u7684\u7ec6\u8282\u5c42\u6b21\u3002</li> <li>\\(\\text{randomize\\_noise}\\): \u662f\u5426\u5728\u751f\u6210\u8fc7\u7a0b\u4e2d\u968f\u673a\u5316\u566a\u58f0\u3002</li> <li>\u8fc7\u7a0b :</li> <li> <p>\u4f7f\u7528\u6837\u5f0f\u5411\u91cf \\(wp\\) \u548c\u566a\u58f0\u63a7\u5236\u56fe\u50cf\u7684\u751f\u6210\u8fc7\u7a0b\u3002</p> </li> <li> <p>\\(\\text{lod}\\) \u53ef\u4ee5\u8c03\u6574\u751f\u6210\u56fe\u50cf\u7684\u5206\u8fa8\u7387\uff0c\u652f\u6301\u9010\u6b65\u589e\u52a0\u7ec6\u8282\uff08\u6e10\u8fdb\u5f0f\u751f\u6210\uff09\u3002</p> </li> <li>\u8f93\u51fa :</li> <li>\u751f\u6210\u7684\u56fe\u50cf\u53ca\u5176\u76f8\u5173\u7279\u5f81\u3002</li> </ul>"},{"location":"book/chapter5_GAN/3.3stylegan/paper/#2-synthesis-network","title":"2. synthesis network","text":"<p>synthesis network \u5b9a\u4e49\u5728class SynthesisModule \u91cc\u9762\uff0c\u662f\u4e00\u4e2a\u751f\u6210\u5668\u7684\u4e3b\u8981\u90e8\u5206\uff0c\u8d1f\u8d23\u751f\u6210\u56fe\u50cf\u7684\u8fc7\u7a0b\u3002 \u5b83\u7684\u53c2\u6570\u610f\u4e49</p> <pre><code>resolution (\u9ed8\u8ba41024): \u751f\u6210\u56fe\u50cf\u7684\u6700\u7ec8\u8f93\u51fa\u5206\u8fa8\u7387\u3002\u4f8b\u5982\u8bbe\u7f6e\u4e3a1024\u65f6\uff0c\u6700\u7ec8\u751f\u62101024x1024\u50cf\u7d20\u7684\u56fe\u50cf\u3002\ninit_resolution (\u9ed8\u8ba44): \u751f\u6210\u5668\u7684\u521d\u59cb\u7279\u5f81\u56fe\u5206\u8fa8\u7387\u3002StyleGAN\u4ece\u8fd9\u4e2a\u4f4e\u5206\u8fa8\u7387(\u901a\u5e38\u662f4\u62168)\u5f00\u59cb\uff0c\u7136\u540e\u901a\u8fc7\u4e00\u7cfb\u5217\u4e0a\u91c7\u6837\u5c42\u9010\u6b65\u589e\u52a0\u5206\u8fa8\u7387\u76f4\u5230\u8fbe\u5230\u76ee\u6807\u5206\u8fa8\u7387\u3002\nw_space_dim (\u9ed8\u8ba4512): W\u6f5c\u5728\u7a7a\u95f4\u7684\u7ef4\u5ea6\u3002\u8fd9\u662fStyleGAN\u7684\u4e00\u4e2a\u5173\u952e\u7279\u5f81\uff0c\u5b83\u662f\u5c06\u8f93\u5165\u7684Z\u7a7a\u95f4\u901a\u8fc7\u6620\u5c04\u7f51\u7edc\u8f6c\u6362\u540e\u7684\u4e2d\u95f4\u6f5c\u5728\u7a7a\u95f4\uff0c\u7528\u4e8e\u66f4\u597d\u5730\u63a7\u5236\u4e0d\u540c\u5c3a\u5ea6\u7684\u56fe\u50cf\u7279\u5f81\u3002\nimage_channels (\u9ed8\u8ba43): \u8f93\u51fa\u56fe\u50cf\u7684\u989c\u8272\u901a\u9053\u6570\uff0c\u5bf9\u4e8eRGB\u5f69\u8272\u56fe\u50cf\u662f3\u3002\nfinal_tanh (\u9ed8\u8ba4False): \u662f\u5426\u5728\u7f51\u7edc\u6700\u540e\u4e00\u5c42\u4f7f\u7528tanh\u6fc0\u6d3b\u51fd\u6570\u3002\u4f7f\u7528tanh\u53ef\u4ee5\u5c06\u8f93\u51fa\u4e25\u683c\u9650\u5236\u5728[-1, 1]\u8303\u56f4\u5185\u3002\nconst_input (\u9ed8\u8ba4True): \u662f\u5426\u4f7f\u7528\u5e38\u91cf\u8f93\u5165\u3002StyleGAN\u7684\u4e00\u4e2a\u521b\u65b0\u662f\u4f7f\u7528\u5b66\u4e60\u7684\u5e38\u91cf\u4f5c\u4e3a\u751f\u6210\u5668\u7684\u8d77\u70b9\uff0c\u800c\u4e0d\u662f\u968f\u673a\u566a\u58f0\u3002\nfused_scale (\u9ed8\u8ba4'auto'): \u63a7\u5236\u662f\u5426\u4f7f\u7528\u878d\u5408\u7684\u4e0a\u91c7\u6837\u5377\u79ef\u64cd\u4f5c\u3002\u878d\u5408\u64cd\u4f5c\u53ef\u4ee5\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\u3002\nuse_wscale (\u9ed8\u8ba4True): \u662f\u5426\u4f7f\u7528\u6743\u91cd\u7f29\u653e\u3002\u8fd9\u662f\u4e00\u79cd\u8bad\u7ec3\u6280\u5de7\uff0c\u901a\u8fc7\u5bf9\u6743\u91cd\u8fdb\u884c\u9002\u5f53\u7684\u7f29\u653e\u6765\u5e2e\u52a9\u8bad\u7ec3\u7a33\u5b9a\u6027\u3002\nnoise_type (\u9ed8\u8ba4'spatial'): \u63a7\u5236\u6dfb\u52a0\u5230\u6bcf\u4e00\u5c42\u7684\u968f\u673a\u566a\u58f0\u7684\u7c7b\u578b\u3002\u7a7a\u95f4\u566a\u58f0\u53ef\u4ee5\u5e2e\u52a9\u751f\u6210\u66f4\u591a\u7684\u7ec6\u8282\u53d8\u5316\u3002\nfmaps_base (\u9ed8\u8ba416&lt;&lt;10): \u57fa\u7840\u7279\u5f81\u56fe\u6570\u91cf\uff0c\u7528\u4e8e\u63a7\u5236\u7f51\u7edc\u5404\u5c42\u7684\u901a\u9053\u6570\u3002\u9ed8\u8ba4\u503c\u662f16384\u3002\nfmaps_max (\u9ed8\u8ba4512): \u9650\u5236\u7f51\u7edc\u4e2d\u4efb\u4f55\u5c42\u7684\u6700\u5927\u7279\u5f81\u56fe\u6570\u91cf\uff0c\u9632\u6b62\u7f51\u7edc\u53d8\u5f97\u8fc7\u5927\u3002\n</code></pre> <p>forward \u6b65\u9aa4</p> <pre><code>    def forward(self, wp, lod=None, randomize_noise=False):\n        # wp \u4ee3\u8868\u7ecf\u8fc7\u6620\u5c04\u7f51\u7edc\u5904\u7406\u540e\u7684\u98ce\u683c\u5411\u91cf\uff08style vector\uff09\u3002\n        # Z \u7a7a\u95f4\uff08\u521d\u59cb\u6f5c\u5728\u7a7a\u95f4\uff09\n        # \u8fd9\u662f\u8f93\u5165\u7684\u968f\u673a\u566a\u58f0\u5411\u91cf\n        # \u901a\u5e38\u662f\u4ece\u6807\u51c6\u6b63\u6001\u5206\u5e03\u91c7\u6837\u5f97\u5230\n        # W \u7a7a\u95f4\uff08\u4e2d\u95f4\u6f5c\u5728\u7a7a\u95f4\uff09\n        # \u901a\u8fc7\u6620\u5c04\u7f51\u7edc(Mapping Network)\u5c06 Z \u7a7a\u95f4\u5411\u91cf\u8f6c\u6362\u5f97\u5230\n        # \u76f8\u6bd4 Z \u7a7a\u95f4\uff0cW \u7a7a\u95f4\u5177\u6709\u66f4\u597d\u7684\u89e3\u8026\u7279\u6027\n        # W+ \u7a7a\u95f4\uff08\u6269\u5c55\u7684 W \u7a7a\u95f4\uff09\n        # \u8fd9\u5c31\u662f\u4ee3\u7801\u4e2d\u7684 wp\uff08w plus\uff09\n        # \u5b83\u662f\u5c06 W \u7a7a\u95f4\u7684\u5411\u91cf\u6269\u5c55\u5230\u6bcf\u4e00\u5c42\u90fd\u6709\u4e00\u4e2a\u72ec\u7acb\u7684\u98ce\u683c\u5411\u91cf\n        # \u5982\u679c\u7f51\u7edc\u6709 n \u5c42\uff0c\u90a3\u4e48 wp \u7684\u5f62\u72b6\u5c31\u662f [batch_size, n, w_dim]\n        lod = self.lod.cpu().tolist() if lod is None else lod\n        # lod \u7684\u8ba1\u7b97\u8fc7\u7a0b\uff1a\n        # \u57fa\u4e8e\u5df2\u8bad\u7ec3\u7684\u56fe\u50cf\u6570\u91cf\uff08total_img\uff09\u8ba1\u7b97\n        # \u6bcf\u4e2a\u5206\u8fa8\u7387\u7ea7\u522b\u7684\u6301\u7eed\u65f6\u95f4 = \u8bad\u7ec3\u56fe\u50cf\u6570 + \u8fc7\u6e21\u56fe\u50cf\u6570\n        # \u5f53\u524d\u7684 lod \u503c\u51b3\u5b9a\u4e86\u751f\u6210\u56fe\u50cf\u7684\u5206\u8fa8\u7387\n        # \u4f8b\u5982\uff0c\u5bf9\u4e8e512x512\u7684\u6700\u7ec8\u5206\u8fa8\u7387\uff1a\n        # \u5206\u8fa8\u7387\u5e8f\u5217\uff1a8 \u2192 16 \u2192 32 \u2192 64 \u2192 128 \u2192 256 \u2192 512\n        # LOD\u5e8f\u5217\uff1a6 \u2192 5 \u2192 4 \u2192 3 \u2192 2 \u2192 1 \u2192 0\n        if lod + self.init_res_log2 &gt; self.final_res_log2: # lod \u5f02\u5e38\n            raise ValueError(f'Maximum level-of-detail (lod) is '\n                             f'{self.final_res_log2 - self.init_res_log2}, '\n                             f'but `{lod}` is received!')\n\n        results = {'wp': wp}\n        for res_log2 in range(self.init_res_log2, self.final_res_log2 + 1):\n            current_lod = self.final_res_log2 - res_log2\n            if lod &lt; current_lod + 1:\n                block_idx = res_log2 - self.init_res_log2\n                if block_idx == 0: # \u6700\u4f4e\u5206\u8fa8\u7387\n                    if self.const_input:\n                        x, style = self.layer0(None, wp[:, 0], randomize_noise)\n                    else:\n                        x = wp[:, 0].view(-1, self.w_space_dim, 1, 1)\n                        x, style = self.layer0(x, wp[:, 0], randomize_noise)\n                else:\n                    x, style = self.__getattr__(f'layer{2 * block_idx}')(\n                        x, wp[:, 2 * block_idx], randomize_noise)\n                    results[f'style{2 * block_idx:02d}'] = style\n                    x, style = self.__getattr__(f'layer{2 * block_idx + 1}')(\n                        x, wp[:, 2 * block_idx + 1], randomize_noise)\n                    results[f'style{2 * block_idx + 1:02d}'] = style\n            if current_lod - 1 &lt; lod &lt;= current_lod:\n                image = self.__getattr__(f'output{block_idx}')(x, None)\n            elif current_lod &lt; lod &lt; current_lod + 1:\n                alpha = np.ceil(lod) - lod\n                image = (self.__getattr__(f'output{block_idx}')(x, None) * alpha\n                         + self.upsample(image) * (1 - alpha))\n            elif lod &gt;= current_lod + 1:\n                image = self.upsample(image)\n        results['image'] = self.final_activate(image)\n        return results\n</code></pre> <p>lod \u8868\u793a level of details.\u8868\u793a\u5206\u8fa8\u7387\u3002</p> <pre><code>        # Compute level-of-details.\n        phase, subphase = divmod(runner.seen_img, self.lod_duration)\n        lod = self.init_lod - phase\n        if self.lod_transition_img:\n            transition_img = max(subphase - self.lod_training_img, 0)\n            lod = lod - transition_img / self.lod_transition_img\n        lod = max(lod, 0.0)\n        resolution = self.init_res * (2 ** int(np.ceil(self.init_lod - lod)))\n        return lod, resolution\n</code></pre> <p>lod \u8be6\u7ec6\u8ba1\u7b97\u8fc7\u7a0b\u3002\u5047\u8bbe \u5176\u4e2d\uff0cinit_res \u662f\u521d\u59cb\u5206\u8fa8\u7387\uff08\u901a\u5e38\u662f4\u62168\uff09\u3002 \u4e3e\u4f8b\u8bf4\u660e\uff1a</p> <pre><code>\u5047\u8bbe init_lod = 8\uff08\u4ece8x8\u52302048x2048\uff09\nlod_duration = 600,000\uff08\u6bcf\u4e2a\u5206\u8fa8\u7387\u7ea7\u522b60\u4e07\u5f20\u56fe\u50cf\uff09,\nlod_training_img = 300,000\uff08\u7a33\u5b9a\u9636\u6bb530\u4e07\u5f20\u56fe\u50cf\uff09\u8fd9\u4e2a\u9636\u6bb5lod\u4e00\u76f4\u4fdd\u6301\u4e3a8,\u5206\u8fa8\u7387\u4e3a8x8,\nlod_transition_img = 300,000\uff08\u8fc7\u6e21\u9636\u6bb530\u4e07\u5f20\u56fe\u50cf\uff09,\n\u5230\u4e86\u8fd9\u4e2a\u9636\u6bb5\u4e4b\u540e, lod \u4ece 8.0 \u9010\u6e10\u964d\u4f4e\u5230 7.0\uff0c\u5206\u8fa8\u7387\u4e00\u76f4\u662f16x16\u3002,\n\u76f4\u89c2\u4e0a\u770b \u6bcf\u4e2a\u5206\u8fa8\u7387\u8bad\u7ec3\u5206\u6210\u4e24\u4e2a\u9636\u6bb5\uff0c\u7b2c\u4e00\u9636\u6bb5\u8bad\u7ec3\u5f53\u524d\u5206\u8fa8\u7387\u7684\u7a33\u5b9a\u9636\u6bb5\uff0c\u7b2c\u4e8c\u9636\u6bb5\u8bad\u7ec3\u4e0b\u4e00\u4e2a\u5206\u8fa8\u7387\u7684\u8fc7\u6e21\u9636\u6bb5\uff0clod\u7ebf\u6027\u9012\u51cf\u5230\u4e0b\u4e00\u4e2a\u5206\u8fa8\u7387\u5bf9\u5e94\u7684lod\u3002\n</code></pre> <p>synthesis \u7f51\u7edc\u7684\u6bcf\u4e00\u4e2a\u5206\u8fa8\u7387\u5c42\u90fd\u6709\u4e24\u4e2a\u5377\u79ef\u5c42\u3002\u521d\u59cb\u5206\u8fa8\u7387\u7684\u7b2c\u4e00\u4e2a\u5377\u79ef\u5c42\u6709\u6240\u533a\u522b\u3002</p>"},{"location":"book/chapter5_GAN/3.3stylegan/paper/#_1","title":"\u7b2c\u4e00\u4e2a\u5206\u8fa8\u7387\u5c42","text":""},{"location":"book/chapter5_GAN/3.3stylegan/paper/#layer0","title":"layer0","text":"<p>layer0 \u7684\u7f51\u7edc\u5b9a\u4e49\u4e3a</p> <pre><code>self.layer0 =ConvBlock(\n    in_channels=self.get_nf(res),\n    out_channels=self.get_nf(res),\n    resolution=self.init_res,\n    w_space_dim=self.w_space_dim,\n    position='const_init', # \u6807\u8bb0\u4e3aconst_init\n    use_wscale=self.use_wscale,\n    noise_type=self.noise_type)\n</code></pre> <p>\u8f93\u5165\u4e3a</p> <pre><code>x, style = self.layer0(None, wp[:, 0], randomize_noise)\n</code></pre> <p>\u7b2c\u4e00\u4e2a\u5206\u8fa8\u7387\u53ea\u6709\u4e00\u4e2aconvblock\uff0c\u5c06\u539f\u59cb\u7684\u8f93\u51654x4x512 \u8f6c\u5316\u4e3a 4x4x512</p>"},{"location":"book/chapter5_GAN/3.3stylegan/paper/#k","title":"\u7b2ck\u4e2a\u5206\u8fa8\u7387\u5c42","text":"<p>\u6b21\u540e\u7684\u6bcf\u4e2a\u5206\u8fa8\u7387\u5c42\u5305\u542b\u4e24\u4e2aconvblock \u7b2c\u4e00\u4e2aconvblock \u589e\u52a0\u4e86\u4e0a\u91c7\u6837\u7684\u64cd\u4f5c\u3002\u5176\u4f59\u7684\u4e00\u6837\u3002 \u6700\u540e\u4e00\u4e2a\u5206\u8fa8\u7387\u53ea\u6709\u4e00\u4e2aconvblock\uff0c\u5c06512x512x32 \u8f6c\u5316\u4e3a 1024x1024x16 \u5206\u8fa8\u7387\u589e\u52a0\u4e00\u500d\uff0coutput channel \u51cf\u534a\uff0c\u4fdd\u6301\u5377\u79ef\u6574\u4f53\u7684\u53c2\u6570\u91cf\u6bcf\u4e00\u5c42\u4e00\u81f4\u3002</p> <pre><code>self.layer{2k-1} =  ConvBlock(\n    in_channels=self.get_nf(res // 2),\n    out_channels=self.get_nf(res),\n    resolution=res,\n    w_space_dim=self.w_space_dim,\n    upsample=True,\n    fused_scale=fused_scale,\n    use_wscale=self.use_wscale,\n    noise_type=self.noise_type\n)\n\nself.layer{2k} =ConvBlock(\n    in_channels=self.w_space_dim,\n    out_channels=self.get_nf(res),\n    resolution=self.init_res,\n    w_space_dim=self.w_space_dim,\n    kernel_size=self.init_res,\n    padding=self.init_res - 1,\n    use_wscale=self.use_wscale,\n    noise_type=self.noise_type\n)\n</code></pre> <p>\u8f93\u5165</p> <pre><code>x, style = f\"self.layer{2k-11}\"(x, wp[:, 2 * block_idx - 1], randomize_noise)\nx, style = f\"self.layer{2k}\"(x, wp[:, 2 * block_idx],randomize_noise)\n</code></pre> <p>\u6bcf\u4e2aconvblock \u7684\u8f93\u5165\u90fd\u5305\u542b\u4e0a\u4e00\u5c42\u7684\u8f93\u5165,\u672c\u5c42\u7684\u98ce\u683c\u5411\u91cf\uff0c\u4ee5\u53ca\u662f\u5426\u9700\u8981\u6dfb\u52a0\u566a\u58f0\u3002</p> <p>\u6bcf\u4e00\u4e2a\u5206\u8fa8\u7387\u7684\u7b2c\u4e00\u4e2a\u5377\u79ef\u5c42\u548c\u7b2c\u4e8c\u4e2a\u5377\u79ef\u5c42\u533a\u522b\u5728\u4e8e\u7b2c\u4e8c\u4e2a\u4f1a\u52a0\u5165\u4e0a\u91c7\u6837\u3002</p>"},{"location":"book/chapter5_GAN/3.3stylegan/paper/#3-convblock","title":"3. ConvBlock","text":"<pre><code>    def forward(self, x, w, randomize_noise=False):\n        if self.position != 'const_init':\n            x = self.upsample(x)\n            weight = self.weight * self.wscale\n            x = F.conv2d(x,\n                             weight=weight,\n                             bias=None,\n                             stride=self.stride,\n                             padding=self.padding)\n            x = self.blur(x)\n        else:\n            x = self.const.repeat(w.shape[0], 1, 1, 1)  # \u521d\u59cb\u8f93\u5165\n\n        bias = self.bias * self.bscale if self.bias is not None else None\n\n        if self.position == 'last':\n            if bias is not None:\n                x = x + bias.view(1, -1, 1, 1)\n            return x\n\n        x = self.apply_noise(x, randomize_noise)\n        if bias is not None:\n            x = x + bias.view(1, -1, 1, 1)\n        x = self.activate(x)\n        x = self.normalize(x)\n        x, style = self.style(x, w)\n        return x, style\n</code></pre> <p>\u5177\u4f53\u6b65\u9aa4</p> <ol> <li> <p>\u4e0a\u91c7\u6837\u548c\u5377\u79ef\u3002\u53ea\u5728\u6bcf\u4e00\u4e2a\u5206\u8fa8\u7387\u7684\u7b2c\u4e00\u5c42\u8fdb\u884c\u4e0a\u91c7\u6837\u3002\u4f7f\u7528\u7684\u4e0a\u91c7\u6837\u662f</p> <pre><code>return F.interpolate(x, scale_factor=self.scale_factor, mode='nearest')\n</code></pre> <p>\u5377\u79ef\u7684\u8fc7\u7a0b\u4e2d\u4f1a\u5229\u7528\u53ef\u5b66\u4e60\u7684\u4e00\u4e2a\\(w_{scale}\\)\u5bf9\u5377\u79ef\u7684\u6743\u91cd\u8fdb\u884c\u7f29\u653e\u3002\u8fd9\u4e2a\u60f3\u6cd5\u6765\u81ea\u4e8e progressive growing of gan\u4e2d\u3002</p> <p>\u5176\u4e2d\uff0c\u5982\u679c\u662finit \u8f93\u5165 \u53ea\u4f1a\u5c06\u53ef\u4ee5\u5b66\u4e60\u7684init\u5728batch \u7ef4\u5ea6\u8fdb\u884c\u590d\u5236 2. \u589e\u52a0bias \u53ef\u5b66\u4e60\u7684\u4e00\u4e2abias\u3002\u8fd9\u4e2a\u5e94\u8be5\u4e0d\u91cd\u8981\u3002 1. \u589e\u52a0\u566a\u58f0</p> </li> </ol> <pre><code>if randomize_noise:\n    if self.noise_type == 'spatial':\n        noise = torch.randn(x.shape[0], 1, self.res, self.res).to(x)\n    elif self.noise_type == 'channel':\n        noise = torch.randn(x.shape[0], self.channels, 1, 1).to(x)\nelse:\n    noise = self.noise\nif self.noise_type == 'spatial':\n    x = x + noise * self.weight.view(1, self.channels, 1, 1)\nelif self.noise_type == 'channel':\n    x = x + noise * self.weight.view(1, 1, self.res, self.res)\n</code></pre> <p>\u566a\u97f3\u7684\u589e\u52a0\u6709\u4e24\u79cd\u6cd5\u6848\u3002\u4e00\u4e2a\u662f\u589e\u52a0\u5728\u7a7a\u95f4\u4e0a\uff0c\u4e00\u4e2a\u662f\u589e\u52a0\u5728channel \u4e0a\u3002</p> <ol> <li>\u975e\u7ebf\u6027\u6fc0\u6d3b\u51fd\u6570</li> </ol> <pre><code>self.activate = nn.LeakyReLU(negative_slope=0.2, inplace=True)\n</code></pre> <p> LeakyReLU \u7684\u597d\u5904\u4e3b\u8981\u4f53\u73b0\u5728\u4ee5\u4e0b\u51e0\u4e2a\u65b9\u9762\uff1a</p> <ul> <li>\u9632\u6b62\u795e\u7ecf\u5143\u6b7b\u4ea1\uff1a\u8d1f\u503c\u533a\u57df\u7684\u659c\u7387\u4f7f\u5f97\u795e\u7ecf\u5143\u4e0d\u4f1a\u5b8c\u5168\u5931\u6d3b\u3002</li> <li>\u6539\u5584\u68af\u5ea6\u6d41\u52a8\uff1a\u51cf\u5c11\u68af\u5ea6\u6d88\u5931\u95ee\u9898\uff0c\u652f\u6301\u66f4\u6df1\u5c42\u7f51\u7edc\u7684\u8bad\u7ec3\u3002</li> <li>\u9002\u5e94\u6570\u636e\u5206\u5e03\uff1a\u6355\u6349\u8d1f\u503c\u533a\u57df\u7684\u4fe1\u606f\uff0c\u66f4\u597d\u5730\u5904\u7406\u5177\u6709\u8d1f\u503c\u7279\u5f81\u7684\u6570\u636e\u3002</li> <li>\u8bad\u7ec3\u7a33\u5b9a\u6027\uff1a\u63d0\u5347\u8bad\u7ec3\u8fc7\u7a0b\u7684\u7a33\u5b9a\u6027\u548c\u6536\u655b\u6027\u3002</li> <li> <p>\u901a\u7528\u6027\uff1a\u5728\u56fe\u50cf\u751f\u6210\u4efb\u52a1\u548c\u6df1\u5ea6\u5b66\u4e60\u7f51\u7edc\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u6210\u4e3a\u8bb8\u591a\u6a21\u578b\u7684\u9ed8\u8ba4\u9009\u62e9\u3002</p> </li> <li> <p>instance normalization  \u6807\u51c6instance normalization\u3002 \u4f7f\u5f97\u6bcf\u4e2a\u6837\u672c\u7684\u6bcf\u4e2a\u901a\u9053\u7684featuremap\u7684\u5747\u503c\u4e3a0\uff0c \u65b9\u5dee\u4e3a1.</p> </li> <li>\u98ce\u683c\u5316</li> </ul> <pre><code>def forward(self, x, w):\n    style = self.forward_style(w)\n    style_split = style.view(-1, 2, self.out_channels, 1, 1)\n    x = x * (style_split[:, 0] + 1) + style_split[:, 1]\n    return x, style\n</code></pre> <p>\u5bf9featuremap\u7684\u6bcf\u4e00\u5c42\u5229\u7528\u5b66\u4e60\u5230\u7684\u98ce\u683c\u5411\u91cf\u8fdb\u884c\u98ce\u683c\u8c03\u5236\u3002\u5177\u4f53\u6765\u8bf4style_split \u6bcf\u4e2achannel \u5305\u542b\u4e00\u4e2a\u5b66\u4e60\u5230\u7684\u6807\u51c6\u5dee\u548c\u5747\u503c</p> <pre><code>x = x * (style_split[:, 0] + 1) + style_split[:, 1]\n</code></pre> <p>\u610f\u5473\u6700\u6bcf\u4e00\u4e2achannel \u7684feature map\u663e\u5f0f\u5f97\u8c03\u8282\u65b9\u5dee\u548c\u6807\u51c6\u5dee\u3002\u4e00\u822c\u5f97\uff0cfeaturemap\u7684\u65b9\u5dee\u548c\u5747\u503c\u8868\u793a\u56fe\u7247\u7684\u98ce\u683c\u3002</p> <p>```</p>"},{"location":"book/chapter5_GAN/3.5stylegan3/paper/","title":"StyleGAN3 Overview","text":""},{"location":"book/chapter5_GAN/3.5stylegan3/paper/#1-terms","title":"1. Terms","text":"<p>Aliasing\uff08\u6df7\u53e0\uff09 \u662f\u4e00\u4e2a\u4fe1\u53f7\u5904\u7406\u9886\u57df\u7684\u57fa\u672c\u95ee\u9898\uff0c\u6307\u7684\u662f\u5f53\u4fe1\u53f7\u5728\u91c7\u6837\u8fc7\u7a0b\u4e2d\u91c7\u6837\u7387\u4e0d\u8db3\u65f6\uff0c\u9ad8\u9891\u4fe1\u53f7\u7684\u7279\u6027\u4f1a\u88ab\u9519\u8bef\u5730\u6620\u5c04\u5230\u4f4e\u9891\u90e8\u5206\uff0c\u4ece\u800c\u5bfc\u81f4\u5931\u771f\u6216\u4e0d\u6b63\u786e\u7684\u7ed3\u679c\u3002\u8fd9\u79cd\u73b0\u8c61\u540c\u6837\u9002\u7528\u4e8e\u56fe\u50cf\u5904\u7406\u548c\u6df1\u5ea6\u5b66\u4e60\u4e2d\u7684\u751f\u6210\u7f51\u7edc\u3002</p> <p>\u5728\u4fe1\u53f7\u5904\u7406\u4e2d\u7684\u89e3\u91ca \u5b9a\u4e49\uff1a</p> <p>\u5728\u79bb\u6563\u5316\u8fde\u7eed\u4fe1\u53f7\u65f6\uff0c\u5982\u679c\u91c7\u6837\u7387\u4f4e\u4e8e\u4fe1\u53f7\u7684\u5948\u594e\u65af\u7279\u9891\u7387\uff08Nyquist frequency\uff0c\u5373\u4fe1\u53f7\u6700\u9ad8\u9891\u7387\u7684\u4e24\u500d\uff09\uff0c\u5c31\u4f1a\u53d1\u751f\u6df7\u53e0\u3002 \u6df7\u53e0\u4f1a\u5bfc\u81f4\u9ad8\u9891\u4fe1\u53f7\u88ab\u201c\u6298\u53e0\u201d\u5230\u4f4e\u9891\u57df\uff0c\u4ea7\u751f\u9519\u8bef\u7684\u9891\u7387\u4fe1\u606f\u3002 \u793a\u4f8b\uff1a</p> <p>\u5728\u97f3\u9891\u4fe1\u53f7\u4e2d\uff0c\u91c7\u6837\u4e0d\u8db3\u4f1a\u5bfc\u81f4\u539f\u672c\u7684\u9ad8\u97f3\u53d8\u6210\u4e0d\u76f8\u5173\u7684\u4f4e\u97f3\u3002 \u5728\u56fe\u50cf\u5904\u7406\u4e2d\uff0c\u7f29\u5c0f\u56fe\u50cf\u800c\u6ca1\u6709\u6b63\u786e\u4f4e\u901a\u6ee4\u6ce2\u65f6\u4f1a\u5bfc\u81f4\u8fb9\u7f18\u6216\u7eb9\u7406\u51fa\u73b0\u6ce2\u7eb9\u6216\u952f\u9f7f\u72b6\u4f2a\u5f71\u3002</p>"},{"location":"book/chapter5_GAN/3.5stylegan3/paper/#2-abstract","title":"2. Abstract","text":"<p>\u95ee\u9898\u63cf\u8ff0\uff1a \u5f53\u524d\u5178\u578b\u7684 GAN \u5c3d\u7ba1\u5177\u6709\u5c42\u6b21\u5316\u7684\u5377\u79ef\u7ed3\u6784\uff0c\u4f46\u751f\u6210\u8fc7\u7a0b\u5374\u4f9d\u8d56\u4e8e\u7edd\u5bf9\u50cf\u7d20\u5750\u6807\uff0c\u5bfc\u81f4\u56fe\u50cf\u7ec6\u8282\u201c\u7c98\u5728\u201d\u50cf\u7d20\u7f51\u683c\u4e0a\uff0c\u800c\u4e0d\u662f\u81ea\u7136\u5730\u9644\u7740\u5728\u7269\u4f53\u8868\u9762\u3002</p> <p>\u95ee\u9898\u6839\u6e90\uff1a \u8fd9\u79cd\u73b0\u8c61\u7684\u6839\u672c\u539f\u56e0\u662f\u751f\u6210\u5668\u7f51\u7edc\u4e2d\u7684\u4e0d\u5f53\u4fe1\u53f7\u5904\u7406\uff0c\u7279\u522b\u662f\u6df7\u53e0\u95ee\u9898\uff08aliasing\uff09\u3002</p> <p>\u89e3\u51b3\u65b9\u6cd5\uff1a \u901a\u8fc7\u5c06\u7f51\u7edc\u4e2d\u7684\u6240\u6709\u4fe1\u53f7\u89c6\u4e3a\u8fde\u7eed\u4fe1\u53f7\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e9b\u666e\u9002\u7684\u3001\u8f83\u5c0f\u7684\u67b6\u6784\u8c03\u6574\uff0c\u4ee5\u786e\u4fdd\u4e0d\u5fc5\u8981\u7684\u4fe1\u606f\u4e0d\u4f1a\u6cc4\u6f0f\u5230\u5c42\u6b21\u5316\u7684\u751f\u6210\u8fc7\u7a0b\u4e2d\u3002</p> <p>\u6539\u8fdb\u6548\u679c\uff1a \u65b0\u67b6\u6784\u5728\u56fe\u50cf\u8d28\u91cf\u6307\u6807\uff08\u5982 FID\uff09\u4e0a\u4e0e StyleGAN2 \u76f8\u5f53\uff0c\u4f46\u5176\u5185\u90e8\u8868\u793a\u53d1\u751f\u4e86\u663e\u8457\u53d8\u5316\u3002 \u65b0\u6a21\u578b\u5728\u4e9a\u50cf\u7d20\u7ea7\u522b\u5b9e\u73b0\u4e86\u5bf9\u5e73\u79fb\u548c\u65cb\u8f6c\u7684\u7b49\u53d8\u6027\u3002</p> <p>\u5e94\u7528\u524d\u666f\uff1a \u8fd9\u4e9b\u6539\u8fdb\u4e3a\u751f\u6210\u6a21\u578b\u5728\u89c6\u9891\u548c\u52a8\u753b\u7b49\u52a8\u6001\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u4f7f\u751f\u6210\u6548\u679c\u66f4\u52a0\u81ea\u7136\u548c\u8fde\u8d2f\u3002</p>"},{"location":"book/chapter5_GAN/3.5stylegan3/paper/#3-introduction","title":"3. Introduction","text":"<p>\u5f15\u8a00\u90e8\u5206\u660e\u786e\u4e86\u73b0\u6709 GAN \u4e2d\u6df7\u53e0\u95ee\u9898\u7684\u5371\u5bb3\uff0c\u5206\u6790\u4e86\u5176\u539f\u56e0\uff0c\u5e76\u63d0\u51fa\u4e86\u901a\u8fc7\u6539\u8fdb\u4fe1\u53f7\u5904\u7406\u548c\u751f\u6210\u5668\u67b6\u6784\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u7684\u7814\u7a76\u76ee\u6807\u548c\u8d21\u732e</p>"},{"location":"book/chapter5_GAN/3.5stylegan3/paper/#31","title":"3.1 \u95ee\u9898\u80cc\u666f","text":"<p>\u8fd1\u5e74\u6765\uff0cGAN \u7684\u56fe\u50cf\u751f\u6210\u8d28\u91cf\u6709\u4e86\u663e\u8457\u63d0\u5347\uff08\u5982 StyleGAN2 \u7b49\uff09\uff0c\u5e7f\u6cdb\u5e94\u7528\u4e8e\u56fe\u50cf\u7f16\u8f91\u3001\u57df\u8fc1\u79fb\u548c\u89c6\u9891\u751f\u6210\u7b49\u9886\u57df\u3002 \u5c3d\u7ba1\u751f\u6210\u5668\u5177\u6709\u5c42\u6b21\u5316\u7684\u5377\u79ef\u7ed3\u6784\uff0c\u4f46\u751f\u6210\u8fc7\u7a0b\u5bf9\u7edd\u5bf9\u50cf\u7d20\u5750\u6807\u7684\u4f9d\u8d56\u4f1a\u5bfc\u81f4 \u201c\u7eb9\u7406\u7c98\u8fde\u201d\uff08texture sticking\uff09 \u95ee\u9898\uff0c\u5373\u7ec6\u8282\u56fa\u5b9a\u5728\u50cf\u7d20\u5750\u6807\u4e0a\u800c\u975e\u81ea\u7136\u9644\u7740\u5728\u7269\u4f53\u8868\u9762\u3002</p>"},{"location":"book/chapter5_GAN/3.5stylegan3/paper/#32","title":"3.2 \u95ee\u9898\u5206\u6790","text":"<p>\u7eb9\u7406\u7c98\u8fde\u73b0\u8c61\uff1a \u751f\u6210\u7ec6\u8282\uff08\u5982\u7eb9\u7406\u3001\u6bdb\u53d1\uff09\u5728\u5bf9\u8c61\u79fb\u52a8\u65f6\u672a\u80fd\u6b63\u786e\u968f\u7269\u4f53\u8868\u9762\u79fb\u52a8\uff0c\u7834\u574f\u4e86\u89c6\u89c9\u4e00\u81f4\u6027\uff0c\u7279\u522b\u662f\u5728\u89c6\u9891\u548c\u52a8\u753b\u751f\u6210\u4e2d\u3002 \u95ee\u9898\u6839\u6e90\uff1a \u6df7\u53e0\u662f\u5bfc\u81f4\u8fd9\u4e00\u73b0\u8c61\u7684\u6838\u5fc3\u539f\u56e0\u3002\u6df7\u53e0\u6e90\u4e8e\u4e0d\u5f53\u7684\u4fe1\u53f7\u5904\u7406\uff0c\u5982\uff1a    - \u4e0d\u7406\u60f3\u7684\u4e0a\u91c7\u6837\u6ee4\u6ce2\u5668\uff08\u5982\u53cc\u7ebf\u6027\u63d2\u503c\uff09\u3002    - \u6fc0\u6d3b\u51fd\u6570\uff08\u5982 ReLU\uff09\u5e26\u6765\u7684\u9ad8\u9891\u5206\u91cf\u3002    - \u7f51\u7edc\u8fb9\u754c\u586b\u5145\uff08padding\uff09\u7b49\u64cd\u4f5c\u5bfc\u81f4\u7edd\u5bf9\u50cf\u7d20\u5750\u6807\u6cc4\u9732\u3002    - \u6df7\u53e0\u7684\u653e\u5927\u673a\u5236\uff1a \u7f51\u7edc\u4f1a\u4e3b\u52a8\u5229\u7528\u8fd9\u4e9b\u6df7\u53e0\u4fe1\u606f\uff0c\u901a\u8fc7\u591a\u4e2a\u5c3a\u5ea6\u7684\u7ed3\u5408\u653e\u5927\u5b83\u4eec\uff0c\u4ece\u800c\u5efa\u7acb\u4f9d\u8d56\u7edd\u5bf9\u5c4f\u5e55\u5750\u6807\u7684\u7eb9\u7406\u6a21\u5f0f\u3002</p>"},{"location":"book/chapter5_GAN/3.5stylegan3/paper/#33","title":"3.3 \u8bba\u6587\u76ee\u6807","text":"<p>\u8bbe\u8ba1\u4e00\u4e2a\u751f\u6210\u5668\u67b6\u6784\uff0c\u80fd\u591f\uff1a \u5b8c\u5168\u6d88\u9664\u6df7\u53e0\u95ee\u9898\uff0c\u786e\u4fdd\u751f\u6210\u8fc7\u7a0b\u4e0d\u4f9d\u8d56\u7edd\u5bf9\u50cf\u7d20\u5750\u6807\u3002 \u5b9e\u73b0 \u5e73\u79fb\u548c\u65cb\u8f6c\u7b49\u53d8\u6027\uff08translation and rotation equivariance\uff09\uff0c\u4f7f\u751f\u6210\u7684\u56fe\u50cf\u7ec6\u8282\u80fd\u591f\u81ea\u7136\u968f\u7269\u4f53\u53d8\u5316\u3002 \u4fdd\u6301\u4e0e\u73b0\u6709 GAN\uff08\u5982 StyleGAN2\uff09\u76f8\u5f53\u7684\u56fe\u50cf\u8d28\u91cf\u3002</p>"},{"location":"book/chapter5_GAN/3.5stylegan3/paper/#34","title":"3.4 \u4e3b\u8981\u8d21\u732e","text":"<p>\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e \u8fde\u7eed\u4fe1\u53f7\u89e3\u91ca\uff08continuous signal interpretation\uff09 \u7684\u65b9\u6cd5\uff0c\u91cd\u65b0\u8bbe\u8ba1 StyleGAN2 \u7684\u751f\u6210\u5668\u67b6\u6784\u3002 \u53d1\u73b0\u5f53\u524d\u4e0a\u91c7\u6837\u6ee4\u6ce2\u5668\u5728\u6291\u5236\u6df7\u53e0\u65b9\u9762\u4e0d\u591f\u6709\u6548\uff0c\u9700\u8981\u66f4\u9ad8\u8d28\u91cf\u7684\u6ee4\u6ce2\u5668\uff08\u5982\u8d85\u8fc7 100dB \u7684\u8870\u51cf\u80fd\u529b\uff09\u3002 \u63d0\u51fa\u4e86\u4e00\u4e9b\u666e\u9002\u7684\u5c0f\u578b\u67b6\u6784\u6539\u52a8\uff0c\u65e2\u80fd\u6709\u6548\u6291\u5236\u6df7\u53e0\uff0c\u53c8\u80fd\u4fdd\u8bc1\u751f\u6210\u5668\u7684\u7b49\u53d8\u6027\u3002 \u65b0\u7684\u751f\u6210\u5668\u5728\u56fe\u50cf\u8d28\u91cf\u6307\u6807\uff08\u5982 FID\uff09\u4e0a\u4e0e StyleGAN2 \u6301\u5e73\uff0c\u4f46\u89e3\u51b3\u4e86\u7eb9\u7406\u7c98\u8fde\u95ee\u9898\uff0c\u66f4\u9002\u5408\u7528\u4e8e\u89c6\u9891\u548c\u52a8\u753b\u751f\u6210\u3002</p> <ul> <li>Texture sticking \u95ee\u9898\u4e3e\u4f8b\u8bf4\u660e \u5de6\u4fa7\uff08Central \u548c Averaged\uff09\uff1a StyleGAN2\uff1a \u73b0\u8c61\uff1a\u5373\u4f7f\u751f\u6210\u4e86\u4e00\u4e2a\u56fe\u50cf\u7684\u591a\u4e2a\u7248\u672c\uff08\u901a\u8fc7\u5bf9\u6f5c\u5728\u7a7a\u95f4\u7684\u7ec6\u5fae\u6270\u52a8\uff09\uff0c\u56fe\u50cf\u7684\u7ec6\u8282\uff08\u5982\u732b\u7684\u6bdb\u53d1\u6216\u7eb9\u7406\uff09\u4f9d\u7136\u56fa\u5b9a\u5728\u7edd\u5bf9\u7684\u50cf\u7d20\u5750\u6807\u4e0a\u3002 \u7ed3\u679c\uff1a\u5f53\u5bf9\u4e0d\u540c\u7248\u672c\u8fdb\u884c\u5e73\u5747\u65f6\uff0c\u7ec6\u8282\u4f1a\u5448\u73b0\u51fa\u975e\u81ea\u7136\u7684\u9510\u5316\uff08sharpness\uff09\uff0c\u56e0\u4e3a\u7eb9\u7406\u6ca1\u6709\u968f\u7269\u4f53\u79fb\u52a8\u3002 Ours\uff08\u6539\u8fdb\u540e\u7684\u6a21\u578b\uff09\uff1a \u73b0\u8c61\uff1a\u56fe\u50cf\u7684\u7ec6\u8282\u4e0d\u518d\u56fa\u5b9a\u4e8e\u50cf\u7d20\u5750\u6807\uff0c\u800c\u662f\u81ea\u7136\u5730\u8ddf\u968f\u7269\u4f53\u8868\u9762\u7684\u53d8\u5316\u3002 \u7ed3\u679c\uff1a\u5e73\u5747\u540e\u7684\u56fe\u50cf\u66f4\u5e73\u6ed1\uff0c\u7b26\u5408\u9884\u671f\u3002 \u53f3\u4fa7\uff08Latent Interpolation\uff09\uff1a StyleGAN2\uff1a \u73b0\u8c61\uff1a\u5728\u6f5c\u5728\u7a7a\u95f4\u4e2d\u8fdb\u884c\u63d2\u503c\u751f\u6210\u65f6\uff0c(\u5f53\u751f\u6210\u5185\u5bb9\u8fdb\u884c\u6c34\u5e73\u7684traslation\u65f6) \u5934\u53d1\u7b49\u7ec6\u8282\u6ca1\u6709\u8ddf\u968f\u4eba\u8138\u7684\u4f4d\u7f6e\u53d8\u5316\uff0c\u800c\u662f\u50cf\u201c\u7c98\u5728\u201d\u56fa\u5b9a\u7684\u50cf\u7d20\u4e0a\uff0c\u5bfc\u81f4\u751f\u6210\u7684\u52a8\u753b\u4e2d\u5934\u53d1\u5448\u73b0\u6c34\u5e73\u6761\u7eb9\uff08streaks\uff09\u3002 Ours\uff08\u6539\u8fdb\u540e\u7684\u6a21\u578b\uff09\uff1a \u73b0\u8c61\uff1a\u5934\u53d1\u7684\u7ec6\u8282\u4f1a\u968f\u4eba\u7269\u7684\u4f4d\u7f6e\u81ea\u7136\u79fb\u52a8\uff0c\u751f\u6210\u66f4\u8fde\u8d2f\u7684\u52a8\u6001\u6548\u679c\u3002 \u7ed3\u679c\uff1a\u89e3\u51b3\u4e86\u7eb9\u7406\u7c98\u8fde\u95ee\u9898\uff0c\u5934\u53d1\u770b\u8d77\u6765\u66f4\u50cf\u771f\u5b9e\u7269\u4f53\u7684\u4e00\u90e8\u5206\u3002 \u89c6\u5c4f\u4e2d\u66f4\u52a0\u660e\u663e\u3002 </li> </ul>"},{"location":"book/chapter5_GAN/3.5stylegan3/paper/#4-continuous-and-discrete-signals","title":"4. Continuous and Discrete Signals","text":"<p>\u5c06\u7f51\u7edc\u4e2d\u7684\u7279\u5f81\u56fe\u89c6\u4e3a\u8fde\u7eed\u4fe1\u53f7\uff0c\u800c\u4e0d\u662f\u79bb\u6563\u50cf\u7d20\uff0c\u4ece\u800c\u4e25\u683c\u9075\u5faa\u4fe1\u53f7\u5904\u7406\u7406\u8bba\uff08\u5982 Nyquist \u5b9a\u7406\uff09</p>"},{"location":"book/chapter5_GAN/3.5stylegan3/paper/#41-relationship-between-continuous-and-discrete-signals","title":"4.1 Relationship Between Continuous and Discrete Signals","text":"<p>\u5047\u8bbe\u8fde\u7eed\u4fe1\u53f7\u4e3a\\(z(x)\\),\u79bb\u6563\u4fe1\u53f7\u4e3a\\(Z(x)\\), \u91c7\u6837\u9891\u7387\u4e3a\\(s\\), \u91c7\u6837\u95f4\u9694\u5219\u4e3a\\(T=\\frac{1}{s}\\).\\(\\cdot\\)\u8868\u793a\u4e58\u79ef, \u5377\u79ef\u8868\u793a\\(\\ast\\). \u4e8c\u7ef4\u72c4\u62c9\u514b\u68b3\u5986\u51fd\u6570\u4e3a\\(III(x,y)=\\sum_{m=-\\infty}^{\\infty}\\sum_{n=-\\infty}^{\\infty}\\delta(x-mT)\\delta(y-nT)\\) \u6839\u636e\u63d2\u503c\u516c\u5f0f</p> \\[ Z(x,y)=z(x,y)\\cdot\\left(\\text{III}(x,y)\\right)\\newline = z(x,y)\\cdot\\left(\\sum_{m=-\\infty}^{\\infty}\\sum_{n=-\\infty}^{\\infty}\\delta(x-mT)\\delta(y-nT)\\right)\\newline = \\sum_{m=-\\infty}^{\\infty}\\sum_{n=-\\infty}^{\\infty}z(mT,nT)\\delta(x-mT)\\delta(y-nT)\\newline \\] <p>\u8bba\u6587\u4e2d\u5bf9\u91c7\u6837\u70b9\u5411\u53f3\u8fdb\u884c\u4e86\\(\\frac{T}{2}\\)\u7684\u504f\u79fb\uff0c\u8fd9\u6837\u7684\u8bdd</p> \\[Z(x,y) = \\left(\\sum_{m=-\\infty}^{\\infty}\\sum_{n=-\\infty}^{\\infty} z\\left((m+\\frac{1}{2})T,(n+\\frac{1}{2})T\\right)\\delta(x-(m+\\frac{1}{2})T)\\delta(y-(n+\\frac{1}{2})T)\\right)\\newline \\] <p>\u4ece\u79bb\u6563\u4fe1\u53f7\u6062\u590d\u4e3a\u8fde\u7eed\u4fe1\u53f7\uff0c \u6839\u636e\u63d2\u503c\u516c\u5f0f</p> \\[ z(x,y) = \\left(\\sum_{m=-\\infty}^{\\infty}\\sum_{n=-\\infty}^{\\infty}Z(mT,nT)\\text{sinc}(\\frac{x - mT}{T})\\text{sinc}(\\frac{y - nT}{T})\\right)\\newline  = \\left(\\sum_{m=-\\infty}^{\\infty}\\sum_{n=-\\infty}^{\\infty}Z(mT,nT)\\alpha(x - mT,y - nT)\\right)\\newline  = (Z\\ast \\alpha)(x,y) \\] <p>suppose\\(\\alpha(x\uff0cy) = \\text{sinc}(\\frac{x}{T})\\text{sinc}(\\frac{y}{T})\\)</p> <p>\u5047\u8bbe\u9650\u5b9a\u7a7a\u95f4\u753b\u5e03\u4e3a[0,1]x[0,1]\uff0c \u4ee5\\(s=\\frac{1}{T}\\)\u9891\u7387\u8fdb\u884c\u91c7\u6837\u65f6\uff0c\u504f\u79fb\\(\\frac{1}{2}T\\)\u91c7\u6837\u4f1a\u751f\u6210\u603b\u5171\\(s^2\\)\u4e2a\u91c7\u6837\u70b9. \u6839\u636e\u63d2\u503c\u516c\u5f0f\uff0c\u5982\u679c\u8981\u5b8c\u5168\u6062\u590d\u539f\u59cb\u4fe1\u53f7\uff0c\u5219\u9700\u8981[0,1]x[0,1] \u4e4b\u5916\u7684\u4fe1\u53f7\u3002 \u4e3a\u4ec0\u4e48\u5462\uff1f  \u4e0a\u9762\u662fsinc \u51fd\u6570\u7684\u56fe\u5f62\u3002\u5bf9\u4e8ex,y \u8fd9\u4e2a\u4f4d\u7f6e, \u6062\u590d\u8fd9\u4e00\u70b9\u7684\u4fe1\u606f\u9700\u8981\u9644\u8fd1\u533a\u57df\u7684\u91c7\u6837\u503c\uff0c\u4e14\u8ddd\u79bbx,y \u8d8a\u8fdc\uff0c\u5bf9\u4e8e\u6062\u590d\u4fe1\u606f\u7684\u8d21\u732e\u8d8a\u5c0f\u3002 \u8fd9\u5c31\u662f\u4e3a\u4ec0\u4e48\u9700\u8981\u6269\u5145\u91c7\u6837\u7a7a\u95f4\u7684\u539f\u56e0\u3002\u5728\u5b9e\u9645\u60c5\u51b5\u4e0b\uff0c\u5bf9\u4e8e\u7ed9\u5b9a\u533a\u57df\u4e0d\u9700\u8981\u6269\u5145\u592a\u5927\uff0c\u56e0\u4e3asinc \u5448\u73b0\u4e86\u4e00\u4e2a\u968f\u8ddd\u79bb\u8870\u51cf\u7684\u8d8b\u52bf\u3002\u8bba\u6587\u5728\u5b9e\u73b0\u7684\u65f6\u5019\u4f1a\u5148\u5bf9\u7279\u5f81\u56fe\u505a\u4e00\u4e2a\u6269\u5145\uff0c\u4e5f\u5c31\u662f\u8fd9\u4e2a\u539f\u7406\u3002</p>"},{"location":"book/chapter5_GAN/3.5stylegan3/paper/#42-equivariant-network-layers","title":"4.2 Equivariant Network Layers","text":"<p>translation equivariance transformation</p> \\[f\\cdot t = t\\cdot f\\] <p>\u5047\u8bbe\u8f93\u51fa\u7684\u91c7\u6837\u9891\u7387\u4e3a\\(s'\\)\uff0c \u90a3\u4e48\u6839\u636e\u91c7\u6837\u5b9a\u7406\uff0c\u9700\u8981\u6ee1\u8db3\\(f\\)\u4f5c\u7528\u4e4b\u540e\u7684\u4fe1\u53f7\u9891\u7387\u4e0d\u64cd\u4f5c\\(s'/2\\)\uff0c\u4e5f\u5c31\\(f\\)\u4e0d\u4ea7\u751f\u8d85\u8fc7\\(s'/2\\)\u7684\u9ad8\u9891\u4fe1\u53f7\u3002</p>"},{"location":"book/chapter5_GAN/3.5stylegan3/paper/#421-convolution-layer","title":"4.2.1 Convolution Layer","text":""},{"location":"book/chapter5_GAN/3.5stylegan3/paper/#422-convolution","title":"4.2.2 Convolution","text":"<p>Consider a standard convolution with a discrete kernel\\(K\\). We can interpret\\(K\\)as living in the same grid as the input feature map, with sampling rate\\(s\\). The discrete-domain operation is simply:</p> \\[ \\text{F}_{\\text{conv}}(Z) = K \\ast Z, \\] <p>and we obtain the corresponding continuous operation:</p> \\[ \\text{f}_{\\text{conv}}(z) = \\varphi_s \\ast \\left( K \\ast \\left( \\Pi_s \\odot z \\right) \\right) = K \\ast \\left( \\varphi_s \\ast \\left( \\Pi_s \\odot z \\right) \\right) = K \\ast z \\] <p>\u8fd9\u4e00\u6b65\u7528\u5230\u4e86\u5377\u79ef\u662f\u53ef\u4ee5\u4ea4\u6362\u7684\u3002</p> <p>\u540c\u65f6 \u6839\u636e\u5377\u79ef\u7684\u9891\u57df\u7b49\u4e8e\u9891\u57df\u7684\u4e58\u79ef</p> \\[ \\text{F}_{\\text{conv}}(K\\ast Z)(e^{jw}) =\\text{F}_{\\text{conv}}(Z)(e^{jw}) \\ast\\text{F}_{\\text{conv}}(K)(e^{jw}) \\] <p>\u4e5f\u5c31\u662f\u5bf9\u5e94\u9891\u7387\u7684\u7cfb\u6570\u7b49\u4e8e\u539f\u59cb\u4fe1\u53f7\u7684\u9891\u7387\u4e58\u4ee5\u5377\u79ef\u7684\u9891\u7387\u7cfb\u6570\u3002 \u56e0\u6b64\u5e26\u5bbd\u53ea\u4f1a\u53d8\u5c0f\uff0c\u4e0d\u4f1a\u53d8\u5927\u3002 \u8fd9\u5c31\u4f7f\u5f97\u5377\u79ef\u64cd\u4f5c\u5929\u7136\u6ee1\u8db3\u91c7\u6837\u5b9a\u7406\u7684\u8981\u6c42\u3002</p> <p>\u5377\u79ef\u5bf9\u5e94\u7684\u9891\u57df\u793a\u610f\u56fe </p>"},{"location":"book/chapter5_GAN/3.5stylegan3/paper/#423-upsample-and-downsample","title":"4.2.3 Upsample and Downsample","text":"<p>\u4e0a\u91c7\u6837 \u4e0a\u91c7\u6837\u589e\u52a0\u4e86\u4fe1\u53f7\u7684\u91c7\u6837\u7387\u3002\u8fd9\u91cc\u5047\u8bbe\u662f\u7406\u60f3\u4e0a\u91c7\u6837\uff0c\u4e5f\u5c31\u662f\u201c\u63d20\u201d + \u7406\u60f3\u4f4e\u901a\u6ee4\u6ce2 \u7406\u60f3\u4e0a\u91c7\u6837\u540e\u7684\u4fe1\u53f7\u9891\u7387\u4f1a\u88ab\u538b\u7f29\\(n\\)\u500d.\\(n\\)\u662f\u4e0a\u91c7\u6837\u7684\u500d\u6570\u3002 \u7ecf\u8fc7\u7406\u60f3\u4e0a\u91c7\u6837\u540e\uff0c\u8f93\u51fa\\(Y(e^{j\\omega})\\)\u5b8c\u5168\u548c\u539f\u6765\u7684 \\(X(e^{j\\omega})\\)\u5728\u9891\u57df\u4e2d\u201c\u7f29\u653e\u201d\u540e\u7684\u4e3b\u74e3\u90e8\u5206\u76f8\u5bf9\u5e94\uff0c\u4e5f\u5c31\u662f\u8bf4\uff0c\u5b83\u5728\u65b0\u7684\u91c7\u6837\u7387\u4e0b\u5904\u4e8e\u5e26\u5bbd\\(\\pi/n\\)\u7684\u8303\u56f4\u4e4b\u5185\uff0c\u4e14\u643a\u5e26\u7740\u539f\u4fe1\u53f7\u4e0d\u5931\u771f\u7684\u9891\u8c31\u4fe1\u606f\u3002\u8fd9\u5c31\u662f\u201c\u7406\u60f3\u5347\u91c7\u6837\u201d\u8981\u8fbe\u5230\u7684\u76ee\u7684\u3002</p> <p>\u4e0b\u91c7\u6837</p> <p>\u4e0b\u91c7\u6837\u9891\u57df\u516c\u5f0f\u79bb\u6563\u5f62\u5f0f</p> \\[y[m] = x[m\\,M], \\quad Y(e^{j\\Omega}) = \\frac{1}{M}\\sum_{k=0}^{M-1} X\\!\\Bigl(e^{\\,j\\,\\tfrac{\\Omega + 2\\pi k}{M}}\\Bigr).\\] <p>\u8fde\u7eed\u5f62\u5f0f</p> \\[ Y_{\\mathrm{sample}}(\\omega) \\;=\\; \\frac{1}{M\\,T} \\sum_{k=-\\infty}^{\\infty} X\\!\\Bigl(\\omega - 2\\pi\\,\\tfrac{k}{M\\,T}\\Bigr). \\] <p>\u4e3a\u4e86\u6d88\u9664\u6df7\u53e0\u73b0\u8c61\uff0c\u9700\u8981\u8fc7\u6ee4\u6389\u9ad8\u9891\u4fe1\u53f7(f/2\u4ee5\u4e0a\u7684, f\u662f\u539f\u59cb\u4fe1\u53f7\u9891\u7387)\u518d\u8fdb\u884c\u4e0b\u91c7\u6837\u3002</p> <p>\u5047\u8bbe\u4e0b\u91c7\u6837\u500d\u6570\u4e3a\\(s' = s/n\\),\\(s\\)\u4e3a\u539f\u59cb\u91c7\u6837\u9891\u7387\uff0c\u90a3\u4e48</p> \\[ \\begin{aligned} F_{down} (Z)&amp; = \\mathrm{III}_{s'} \\odot \\left[  \\psi_{s'} \\ast \\left( \\phi_{s} \\ast Z \\right) \\right]\\\\ &amp; = \\frac{1}{s^2} \\mathrm{III}_{s'} \\odot \\left[  \\psi_{s'} \\ast \\psi_{s} \\ast Z \\right]\\\\ &amp; = \\frac{s'^2}{s^2} \\mathrm{III}_{s'} \\odot \\left[  \\phi_{s'} \\ast Z \\right] \\end{aligned} \\] <p>\u4e24\u4e2a\u4f4e\u901a\u6ee4\u6ce2\u7684\u5377\u79ef\u4efb\u7136\u662f\u4e00\u4e2a\u4f4e\u901a\u6ee4\u6ce2.\u5e26\u5bbd\u4e3a\u6700\u5c0f\u7684\u5e26\u5bbd\u3002 \\(\\left( \\phi_{s} \\ast Z \\right)\\)\u662f\u539f\u59cb\u91c7\u6837\u4fe1\u53f7\u7ecf\u8fc7\u4f4e\u901a\u6ee4\u6ce2\uff0c\u53bb\u9664\u79bb\u6563\u91c7\u7528\u5bfc\u81f4\u7684\u9ad8\u9891\u4fe1\u53f7\u3002 \u56e0\u4e3a\u9700\u8981\u4e0b\u91c7\u6837,\u9700\u8981\u989d\u5916\u79fb\u9664\u9ad8\u9891\u4fe1\u53f7\uff0c\u6240\u4ee5\u4f1a\u4f5c\u7528\u53e6\u5916\u4e00\u4e2a\\(\\psi_{s'}\\)\u4f4e\u901a\u6ee4\u6ce2\u3002\u7406\u60f3\u4f4e\u901a\u6ee4\u6ce2\u5668\u7684\u7cfb\u6570\u53ea\u6539\u53d8\u4fe1\u53f7\u6574\u4f53\u7684\u5f3a\u5ea6\uff0c\u76f8\u5f53\u4e8e\u5f52\u4e00\u4e0b\u3002\u5148\u5ffd\u7565\u6389\u7cfb\u6570\u7684\u5f71\u54cd\u3002 \u56e0\u4e3a\u5377\u79ef\u5177\u6709\u4ea4\u6362\u5f8b\uff0c\u53ef\u4ee5\u5148\u7ed3\u5408\u4e24\u4e2a\u7406\u60f3\u9ad8\u901a\u6ee4\u6ce2\u5668\uff0c\u4ece\u800c\u5f97\u5230\u6700\u7ec8\u7684\u7ed3\u679c\u3002 \u8fd9\u4e2a\u7ed3\u679c\u76f4\u89c2\u8868\u793a\u4e3a \u4e0b\u91c7\u6837\u4e4b\u540e\u7684\u4fe1\u53f7\u548c\u539f\u59cb\u4fe1\u53f7\u6309\u7167\u6700\u65b0\u7684\u4e0b\u91c7\u6837\u9891\u7387\u8fdb\u884c\u91c7\u6837\u65f6\u4e00\u81f4\u7684\uff0c\u90fd\u6ee1\u8db3\u91c7\u6837\u5b9a\u7406\uff0c\u524d\u63d0\u662f\u539f\u59cb\u4fe1\u53f7\u9700\u8981\u6ee1\u8db3\u5e26\u9650\u6027\uff0c\u5e76\u4e14\u5e26\u5bbd\\(f&lt;\\frac{1}{2}s'\\)\u3002</p> <p>\u4e0b\u91c7\u6837\u5177\u6709translation \u4e0d\u53d8\u6027\uff0c\u5373\u5e73\u79fb\u4e4b\u540e\u518d\u4e0b\u91c7\u6837\u548c\u4e0b\u91c7\u6837\u4e4b\u540e\u518d\u5e73\u79fb\u5f97\u5230\u7684\u7ed3\u679c\u662f\u4e00\u6837\u7684\u3002 \u4f46\u662f\u5bf9\u4e8e\u65cb\u8f6c\u5e76\u4e0d\u4fdd\u6301\u4e0d\u53d8\u6027\u3002\u5982\u679c\u8981\u4fdd\u6301\u9009\u62e9\u4e0d\u53d8\u6027\uff0c\u9700\u8981\u5f15\u5165\u7406\u60f3\u5706\u76d8\u4f4e\u7b52\u6ee4\u6ce2\u5668\uff0c i.e., 2D Jinc filter</p>"},{"location":"book/chapter5_GAN/3.5stylegan3/paper/#424-2d-jinc-filter-frequency-spectrum","title":"4.2.4 2D \"Jinc\" Filter Frequency Spectrum","text":""},{"location":"book/chapter5_GAN/3.5stylegan3/paper/#4241-spatial-domain-definition","title":"4.2.4.1 Spatial Domain Definition","text":"<p>In the spatial domain, the 2D \"Jinc\" filter is:</p> \\[ h(x, y) = 2 \\frac{J_1(2\\pi r)}{r}, \\quad r = \\sqrt{x^2 + y^2}. \\] <p>at \\(r = 0\\),\\(h(0, 0) = 1\\).</p>"},{"location":"book/chapter5_GAN/3.5stylegan3/paper/#43-fourier-transform","title":"4.3 Fourier Transform","text":"<p>The frequency response is:</p> \\[ H(\\rho) = 2\\pi \\int_0^\\infty h(r) r J_0(2\\pi \\rho r) \\, dr, \\] <p>where: -\\(\\rho = \\sqrt{u^2 + v^2}\\), -\\(J_0\\)is the zero-order Bessel function. Substitute\\(h(r)\\):</p> \\[ H(\\rho) = 4\\pi \\int_0^\\infty J_1(2\\pi r) J_0(2\\pi \\rho r) \\, dr. \\] <p>Using Bessel orthogonality:</p> \\[ H(\\rho) = \\begin{cases} 1, &amp; \\rho \\leq 1, \\\\ 0, &amp; \\rho &gt; 1. \\end{cases} \\] <p>\u6839\u636e\u5085\u91cc\u53f6\u53d8\u6362\u7406\u8bba\uff0c\u53ef\u77e5\u7a7a\u95f4\u7684\u65cb\u8f6c\u5bf9\u5e94\u7740\u9891\u57df\u7684\u65cb\u8f6c\uff0c\u9891\u57df\u7684\u65cb\u8f6c\u5bf9\u5e94\u7a7a\u95f4\u7684\u65cb\u8f6c\u3002\u5373\u65cb\u8f6c\u7b49\u53d8\u6027\u3002 \u5982\u679c\u4e00\u4e2a\u64cd\u4f5c\u5728\u7a7a\u95f4\u4e0a\u6ee1\u8db3\u65cb\u8f6c\u4e0d\u53d8\u6027\uff0c\u5c31\u9700\u8981\u5728\u9891\u57df\u4e0a\u6ee1\u8db3\u65cb\u8f6c\u4e0d\u53d8\u6027\u3002\u9891\u57df\u4e0a\u66f4\u5bb9\u6613\u7406\u89e3\u3002\u56e0\u6b64\u6211\u4eec\u53ea\u8981\u8003\u8651\u9891\u57df\u5c31\u884c\u3002\u9891\u57df\u6ee1\u8db3\u65cb\u8f6c\u4e0d\u53d8\u6027\u9996\u5148\u5c31\u9700\u8981\u9891\u57df\u662f\u5f84\u5411\u5bf9\u79f0\u7684\uff0c\u8fd9\u4e5f\u662f\u4e3a\u4ec0\u4e48\u9700\u8981\u4e00\u4e2a\u5f84\u5411\u5bf9\u79f0\u7406\u60f3\u6ee4\u6ce2\u5668(2D Jinc filter)\u7684\u539f\u56e0\u3002\u5f53\u7136\u8fdb\u4e00\u6b65\u4e25\u683c\u5b9e\u73b0\u9009\u62e9\u4e0d\u53d8\u6027\u9700\u8981\u4e0b\u91c7\u6837\u662f\u4f5c\u7528\u5728\u6781\u5750\u6807\u7a7a\u95f4\u4e0b\u3002</p> <p>\u975e\u7ebf\u6027\u6fc0\u6d3b\u51fd\u6570 pointwise\u64cd\u4f5c\u5929\u7136\u6ee1\u8db3 \u51e0\u4f55\u7b49\u53d8\u6027\u3002\u4e0b\u9762\u8003\u8651\u5e26\u5bbd\u7684\u6761\u4ef6\u3002 </p> <p>\u4e3e\u4e00\u4e2a\u5177\u4f53\u7684\u4f8b\u5b50\uff0c\u4f8b\u5982\\(x^2\\), - \u539f\u59cb\u4fe1\u53f7     \u8bbe\u4e00\u4e2a\u4fe1\u53f7\u7684\u5085\u91cc\u53f6\u5c55\u5f00\u4e3a\uff1a</p> <p>$$     x(t) = \\sum_{k} a_k e^{j 2\\pi f_k t},    $$</p> <pre><code>\u5176\u4e2d\uff1a\n-$a_k$\uff1a\u4fe1\u53f7\u7684\u5085\u91cc\u53f6\u7cfb\u6570\u3002\n-$f_k$\uff1a\u4fe1\u53f7\u7684\u9891\u7387\u5206\u91cf\u3002\n</code></pre> <ul> <li>\u975e\u7ebf\u6027\u64cd\u4f5c\u540e\u7684\u9891\u8c31**     \u5047\u8bbe\u5bf9\u4fe1\u53f7\u8fdb\u884c\u975e\u7ebf\u6027\u64cd\u4f5c\\(f(x(t))\\)\uff0c\u5982\u5e73\u65b9\u64cd\u4f5c\\(x^2(t)\\)\uff0c\u5219\u7ed3\u679c\u4e3a\uff1a</li> </ul> <p>$$     f(x(t)) \\sim \\sum_{k,l} g(a_k, a_l) e^{j 2\\pi (f_k + f_l)t},    $$</p> <pre><code>\u5176\u4e2d\uff1a\n-$g(a_k, a_l)$\uff1a\u975e\u7ebf\u6027\u64cd\u4f5c\u4ea7\u751f\u7684\u7cfb\u6570\u3002\n-$f_k + f_l$\uff1a\u65b0\u4ea7\u751f\u7684\u9891\u7387\u5206\u91cf\u3002\n</code></pre> <p>\u90a3\u8981\u600e\u4e48\u5b9e\u73b0\u975e\u7ebf\u6027\u64cd\u4f5c\u7684\u5e26\u5bbd\u9650\u5236</p> <p>\u975e\u7ebf\u6027\u64cd\u4f5c\u540e\uff0c\u7ed3\u5408\u7406\u60f3\u4f4e\u901a\u6ee4\u6ce2\u5668\\(\\psi_s\\)\uff0c\u8fde\u7eed\u8868\u793a\u4e3a\uff1a</p> \\[ f_\\sigma(z) = \\psi_s * \\sigma(z), \\] <p>\u5176\u4e2d\uff1a -\\(\\psi_s\\)\u662f\u7406\u60f3\u4f4e\u901a\u6ee4\u6ce2\u5668\u3002 -\\(\\sigma(z)\\)\u662f\u975e\u7ebf\u6027\u64cd\u4f5c\u540e\u7684\u4fe1\u53f7\u3002 -\\(*\\)\u8868\u793a\u5377\u79ef\u3002</p>"},{"location":"book/chapter5_GAN/3.5stylegan3/paper/#431","title":"4.3.1 \u79bb\u6563\u5f62\u5f0f","text":"<p>\u5bf9\u5e94\u7684\u79bb\u6563\u7248\u672c\u8868\u793a\u4e3a\uff1a</p> \\[ F_\\sigma(Z) = s^2 \\cdot \\Pi_s \\odot (\\phi_s _\\sigma(\\phi_s_ Z)), \\] <p>\u5176\u4e2d\uff1a -\\(s^2\\)\u662f\u6bd4\u4f8b\u56e0\u5b50\u3002 -\\(\\Pi_s\\)\u8868\u793a\u964d\u91c7\u6837\u64cd\u4f5c\u3002 -\\(\\odot\\)\u8868\u793a\u9010\u70b9\u4e58\u79ef\uff08Hadamard\u4e58\u79ef\uff09\u3002 -\\(\\phi_s\\)\u662f\u63d2\u503c\u6ee4\u6ce2\u5668\u3002 -\\(\\sigma(\\phi_s * Z)\\)\u8868\u793a\u5728\u4e0a\u91c7\u6837\u540e\u5e94\u7528\u975e\u7ebf\u6027\u64cd\u4f5c\u3002</p> <p>\u5176\u4e2d\\(\\sigma(\\phi_s * Z)\\)\u9700\u8981\u5728\u8fde\u7eed\u7a7a\u95f4\u4e2d\u8fdb\u884c\u64cd\u4f5c\u3002\u4e3a\u4ec0\u4e48\u4e0d\u80fd\u5728\u79bb\u6563\u7a7a\u95f4\u4e2d\u5b9e\u73b0\uff1f</p> <p>\u7406\u60f3\u4f4e\u901a\u6ee4\u6ce2\u5668\u7684\u65e0\u9650\u652f\u6301\uff1a\u7406\u60f3\u4f4e\u901a\u6ee4\u6ce2\u5668\u7684\u9891\u57df\u662f\u4e00\u4e2a\u77e9\u5f62\u51fd\u6570\uff0c\u5176\u65f6\u57df\u54cd\u5e94\u662f\u4e00\u4e2a\u65e0\u9650\u957f\u7684 sinc \u51fd\u6570\u3002\u5728\u79bb\u6563\u57df\u4e2d\uff0c\u8fd9\u79cd\u65e0\u9650\u652f\u6301\u65e0\u6cd5\u76f4\u63a5\u5b9e\u73b0\uff0c\u53ea\u80fd\u901a\u8fc7\u622a\u65ad\u8fd1\u4f3c\uff0c\u4f46\u8fd9\u4f1a\u5f15\u5165\u5176\u4ed6\u8bef\u5dee\uff08\u5982\u632f\u94c3\u6548\u5e94\uff09\u3002 \u975e\u7ebf\u6027\u64cd\u4f5c\u4f1a\u5f15\u5165\u9ad8\u9891\u5206\u91cf\uff0c\u79bb\u6563\u57df\u4e2d\u5bb9\u6613\u4ea7\u751f\u9891\u8c31\u6df7\u53e0\u3002</p> <p>\u56e0\u6b64\u4f5c\u8005\u7684\u60f3\u6cd5\u662f\u7528\u4e0a\u91c7\u6837\u6a21\u62df\u8fde\u7eed\u7a7a\u95f4\uff0c\u5148\u4e0a\u91c7\u6837\uff0c\u518d\u505a\u975e\u7ebf\u6027\u64cd\u4f5c\uff0c\u518d\u4e0b\u91c7\u6837\u3002\u5f53\u7136\uff0c\u8981\u6ee1\u8db3\u65cb\u8f6c\u4e0d\u53d8\u6027\uff0c\u5219\u9700\u8981\u4e0b\u91c7\u6837\u5e94\u7528 2D Jinc filter\u3002</p> <p>\u800c\u4e14\u975e\u7ebf\u6027\u64cd\u4f5c\u4e5f\u662f\u7f51\u7edc\u4e2d\u552f\u4e00\u751f\u6210\u989d\u5916\u9ad8\u9891\u4fe1\u606f\u7684\u64cd\u4f5c\u3002\u53ef\u4ee5\u63a7\u5236\u5979\u4ece\u800c\u63a7\u5236\u6bcf\u4e00\u5c42\u9700\u8981\u7684\u989d\u5916\u9ad8\u9891\u4fe1\u606f\u3002\u9ad8\u9891\u4fe1\u606f\u5373\u7eb9\u7406\u4fe1\u606f\u3002</p>"},{"location":"book/chapter5_GAN/3.5stylegan3/paper/#5-practical-application","title":"5. Practical Application","text":"<p>descriminator \u4e0d\u53d1\u751f\u53d8\u5316</p> <p>generator \u76ee\u6807\uff1a \u8bbe\u8ba1\u7b49\u53d8\u6027\u795e\u7ecf\u7f51\u7edc \u7528PSNR\u503c\u8861\u91cf\u3002\u503c\u8d8a\u9ad8\u8868\u793a\u7b49\u53d8\u5f62\u8d8a\u5f3a\u3002</p>"},{"location":"book/chapter5_GAN/3.5stylegan3/paper/#51-eq-t","title":"5.1 EQ-T \u516c\u5f0f","text":"\\[ \\text{EQ-T} = 10 \\cdot \\log_{10} \\left( \\frac{I_{\\text{max}}^2}{\\mathbb{E}_{\\text{w} \\sim \\mathcal{W}, x \\sim \\mathcal{X}^2, p \\sim \\mathcal{V}, c \\sim \\mathcal{C}} \\left[ \\left( g(t_x[z_0]; \\text{w})_c(p) - t_x[g(z_0; \\text{w})]_c(p) \\right)^2 \\right]} \\right) \\]"},{"location":"book/chapter5_GAN/3.5stylegan3/paper/#511","title":"5.1.1 \u8bf4\u660e","text":"<p>-\\(I_{\\text{max}}\\): \u56fe\u50cf\u50cf\u7d20\u7684\u6700\u5927\u53ef\u80fd\u503c\uff08\u5982 255\uff09\u3002 -\\(\\mathbb{E}\\): \u8868\u793a\u671f\u671b\u503c\u3002 -\\(\\text{w} \\sim \\mathcal{W}\\): \u6743\u91cd\u4ece\u5206\u5e03\\(\\mathcal{W}\\)\u4e2d\u91c7\u6837\u3002 -\\(x \\sim \\mathcal{X}^2\\): \u8f93\u5165\u4ece\u5206\u5e03\\(\\mathcal{X}^2\\)\u4e2d\u91c7\u6837\u3002 -\\(p \\sim \\mathcal{V}\\): \u50cf\u7d20\u5750\u6807\u4ece\u7a7a\u95f4\u5206\u5e03\\(\\mathcal{V}\\)\u4e2d\u91c7\u6837\u3002 -\\(c \\sim \\mathcal{C}\\): \u901a\u9053\\(c\\)\u4ece\u901a\u9053\u5206\u5e03\\(\\mathcal{C}\\)\u4e2d\u91c7\u6837\u3002 -\\(g(\\cdot; \\text{w})\\): \u8868\u793a\u56fe\u50cf\u64cd\u4f5c\u6216\u6a21\u578b\u751f\u6210\u51fd\u6570\u3002 -\\(t_x\\): \u51e0\u4f55\u53d8\u6362\uff08\u5982\u5e73\u79fb\u3001\u65cb\u8f6c\u3001\u7f29\u653e\u7b49\uff09\u3002 -\\(z_0\\): \u8f93\u5165\u566a\u58f0\u6216\u6f5c\u5728\u53d8\u91cf\u3002 \u4ece\u8fd9\u4e2a\u516c\u5f0f\u53ef\u4ee5\u770b\u5230, \u5728\u65cb\u8f6c\u548c\u5e73\u79fb\u662f\u4f5c\u7528\u5728 \u521d\u59cb\u8f93\u5165\\(z_0\\)\u4e0a\u7684\uff0c\u800c\u4e0d\u662flatent code\\(w\\).</p>"},{"location":"book/chapter5_GAN/3.5stylegan3/paper/#52-fourier","title":"5.2 Fourier \u7279\u5f81","text":"<p>\u7528 Fourier \u7279\u5f81\u66ff\u6362 StyleGAN2 \u4e2d\u7684\u5b66\u4e60\u8f93\u5165\u5e38\u6570\uff0c\u4fbf\u4e8e\u7cbe\u786e\u8fde\u7eed\u53d8\u6362\u8f93\u5165\uff0c\u6539\u5584\u4e86 FID \u5e76\u80fd\u8ba1\u7b97\u7b49\u53d8\u6027\u6307\u6807\uff0c\u4f46\u521d\u59cb\u67b6\u6784\u79bb\u7b49\u53d8\u6027\u4ecd\u8fdc\u3002 SynthesisInput Forward \u8ba1\u7b97\u6d41\u7a0b\u6570\u5b66\u516c\u5f0f \u8f93\u5165\u5b9a\u4e49\u548c\u7b26\u53f7\u8bf4\u660e \u5047\u8bbe\uff1a -\\(\\text{w} \\in \\mathbb{R}^{B \\times d}\\)\uff1a\u8f93\u5165\u6837\u5f0f\u5411\u91cf\uff0c\u6765\u81ea\u6f5c\u5728\u7a7a\u95f4\u7684\u6620\u5c04\u7f51\u7edc\u3002 -\\(\\text{f} \\in \\mathbb{R}^{C \\times 2}\\)\uff1a\u53ef\u8bad\u7ec3\u7684\u9891\u7387\u5411\u91cf\u3002 -\\(\\text{p} \\in \\mathbb{R}^C\\)\uff1a\u53ef\u8bad\u7ec3\u7684\u76f8\u4f4d\u5411\u91cf\u3002 -\\(\\text{A} \\in \\mathbb{R}^{C \\times C}\\)\uff1a\u53ef\u8bad\u7ec3\u7684\u7ebf\u6027\u6620\u5c04\u6743\u91cd\u3002 -\\(\\text{T} \\in \\mathbb{R}^{3 \\times 3}\\)\uff1a\u7528\u6237\u5b9a\u4e49\u7684\u53d8\u6362\u77e9\u9635\u3002 -\\(H, W\\)\uff1a\u8f93\u51fa\u7279\u5f81\u56fe\u7684\u7a7a\u95f4\u5c3a\u5bf8\u3002 -\\(\\text{bandwidth}\\)\u548c\\(\\text{sampling\\_rate}\\)\uff1a\u9891\u7387\u8303\u56f4\u548c\u91c7\u6837\u7387\u3002 \u521d\u59cb\u5316\u9891\u7387\u548c\u76f8\u4f4d \u9891\u7387\u5f52\u4e00\u5316 \u5bf9\u4e8e\u6bcf\u4e2a\u901a\u9053\u7684\u9891\u7387\u5411\u91cf\\(\\text{f}_i \\in \\mathbb{R}^2\\)\uff0c\u8fdb\u884c\u5f52\u4e00\u5316\uff1a</p> \\[ \\text{f}_i' = \\frac{\\text{f}_i}{\\|\\text{f}_i\\|^2} \\cdot \\|\\text{f}_i\\|^{0.25} \\cdot \\text{bandwidth}, \\quad \\forall i \\in [1, C] \\] <p>\u5176\u4e2d\uff1a -\\(\\|\\text{f}_i\\|^2 = \\text{f}_i \\cdot \\text{f}_i\\)\u662f\u9891\u7387\u5411\u91cf\u7684\u5e73\u65b9\u8303\u6570\u3002 \u968f\u673a\u521d\u59cb\u5316\u76f8\u4f4d \u76f8\u4f4d\\(\\text{p}_i\\)\u521d\u59cb\u5316\u4e3a\u5747\u5300\u5206\u5e03\uff1a</p> \\[ \\text{p}_i \\sim \\text{Uniform}(-0.5, 0.5), \\quad \\forall i \\in [1, C] \\] <p>\u6837\u5f0f\u5411\u91cf\u5230\u53d8\u6362\u53c2\u6570 \u4ece\u6837\u5f0f\u5411\u91cf\\(\\text{w}\\)\u6620\u5c04\u5230\u53d8\u6362\u53c2\u6570\\(\\text{t}\\)\uff1a</p> \\[ \\text{t} = \\text{Affine}(\\text{w}), \\quad \\text{t} = [r_c, r_s, t_x, t_y] \\in \\mathbb{R}^{B \\times 4} \\] <p>\u5f52\u4e00\u5316\u65cb\u8f6c\u53c2\u6570 \u5bf9\u65cb\u8f6c\u53c2\u6570\u8fdb\u884c\u5f52\u4e00\u5316\uff1a</p> \\[ r_c' = \\frac{r_c}{\\sqrt{r_c^2 + r_s^2}}, \\quad r_s' = \\frac{r_s}{\\sqrt{r_c^2 + r_s^2}} \\] <p>\u6784\u9020\u53d8\u6362\u77e9\u9635 \u6784\u9020\u65cb\u8f6c\u77e9\u9635\u548c\u5e73\u79fb\u77e9\u9635\uff1a</p> \\[ \\text{M}_r=\\begin{bmatrix} r_c'&amp;-r_s'&amp;0;\\\\ r_s'&amp;r_c'&amp;0;\\\\ 0&amp;0&amp;1; \\end{bmatrix}, \\text{M}_t=\\begin{bmatrix} 1&amp;0&amp;-t_x;\\\\ 0&amp;1&amp;-t_y;\\\\ 0&amp;0&amp;1;\\end{bmatrix}\\] <p>\u7528\u6237\u5b9a\u4e49\u7684\u53d8\u6362\u77e9\u9635\\(T_\\text{user}\\)\u548c\u4e0a\u8ff0\u77e9\u9635\u7ec4\u5408\u5f97\u5230\u6700\u7ec8\u7684\u53d8\u6362\u77e9\u9635\uff1a</p> \\[ T = M_r M_t T_\\text{user} \\] <p>\u9891\u7387\u548c\u76f8\u4f4d\u7684\u53d8\u6362 \u5c06\u53d8\u6362\u77e9\u9635\u5e94\u7528\u4e8e\u9891\u7387\u548c\u76f8\u4f4d\uff1a</p>"},{"location":"book/chapter5_GAN/3.5stylegan3/paper/#53-31","title":"5.3 3.1 \u9891\u7387\u53d8\u6362","text":"\\[ \\text{f}_i'' = \\text{f}_i' \\cdot \\text{T}_{1:2, 1:2}, \\quad \\forall i \\in [1, C] \\] <p>\u76f8\u4f4d\u53d8\u6362</p> \\[ \\text{p}_i'' = \\text{p}_i + \\text{f}_i' \\cdot \\text{T}_{1:2, 2:3}, \\quad \\forall i \\in [1, C] \\] <p>\u9891\u7387\u5e45\u503c\u8c03\u6574 \u4e3a\u4e86\u6291\u5236\u8d85\u51fa\u9891\u7387\u8303\u56f4\u7684\u5206\u91cf\uff0c\u8c03\u6574\u5e45\u503c\uff1a</p> \\[ \\text{a}_i = \\max\\left(0, 1 - \\frac{\\|\\text{f}_i''\\| - \\text{bandwidth}}{\\frac{\\text{sampling\\_rate}}{2} - \\text{bandwidth}}\\right), \\quad \\forall i \\in [1, C] \\] <p>\u6784\u9020\u5085\u91cc\u53f6\u7279\u5f81 \u91c7\u6837\u7f51\u683c \u5b9a\u4e49\u91c7\u6837\u7f51\u683c\\(\\text{G} \\in \\mathbb{R}^{H \\times W \\times 2}\\)\uff1a</p> \\[ \\text{G}[h, w] = \\left(\\frac{w}{W} - 0.5, \\frac{h}{H} - 0.5\\right), \\quad \\forall h \\in [0, H], w \\in [0, W] \\] <p>\u5085\u91cc\u53f6\u7279\u5f81\u8ba1\u7b97 \u901a\u8fc7\u9891\u7387\u548c\u76f8\u4f4d\u751f\u6210\u5085\u91cc\u53f6\u7279\u5f81\uff1a</p> \\[ \\text{x}_\\text{fourier}[b, h, w, c] = \\sin\\left(2 \\pi (\\text{G}[h, w] \\cdot \\text{f}_c'' + \\text{p}_c'')\\right) \\cdot \\text{a}_c \\] <p>\u5e94\u7528\u7ebf\u6027\u6620\u5c04 \u4f7f\u7528\u53ef\u8bad\u7ec3\u7684\u7ebf\u6027\u6743\u91cd\\(\\text{A}\\)\u5bf9\u5085\u91cc\u53f6\u7279\u5f81\u8fdb\u884c\u901a\u9053\u6620\u5c04\uff1a</p> \\[ \\text{x}_\\text{out}[b, c, h, w] = \\sum_{c'=1}^C \\text{x}_\\text{fourier}[b, h, w, c'] \\cdot \\frac{\\text{A}_{c, c'}}{\\sqrt{C}} \\] <p>\u6700\u7ec8\u516c\u5f0f\u603b\u7ed3 \u5b8c\u6574\u7684 <code>SynthesisInput</code> forward \u8ba1\u7b97\u6d41\u7a0b\uff1a</p> \\[ \\text{x}_\\text{out}[b, c, h, w] = \\sum_{c'=1}^C \\left[ \\sin\\left(2 \\pi (\\text{G}[h, w] \\cdot \\text{f}_{c'}'' + \\text{p}_{c'}'')\\right) \\cdot \\text{a}_{c'} \\right] \\cdot \\frac{\\text{A}_{c, c'}}{\\sqrt{C}} \\] <p>\u5176\u4e2d\uff1a -\\(\\text{f}_c''\\)\u548c\\(\\text{p}_c''\\)\u662f\u7ecf\u8fc7\u6837\u5f0f\u53d8\u6362\u540e\u7684\u9891\u7387\u548c\u76f8\u4f4d\u3002 -\\(\\text{a}_c\\)\u662f\u5e45\u503c\u8c03\u6574\u56e0\u5b50\u3002 -\\(\\text{A}\\)\u662f\u901a\u9053\u6620\u5c04\u7684\u6743\u91cd\u3002 \u7269\u7406\u610f\u4e49</p> <ol> <li>\u901a\u8fc7\u9891\u7387\\(\\text{f}\\)\u548c\u76f8\u4f4d\\(\\text{p}\\)\u751f\u6210\u5085\u91cc\u53f6\u7279\u5f81\uff0c\u6784\u5efa\u7a7a\u95f4\u4f4d\u7f6e\u548c\u6837\u5f0f\u76f8\u5173\u7684\u521d\u59cb\u7279\u5f81\u3002</li> <li>\u7ebf\u6027\u6620\u5c04\\(\\text{A}\\)\u5b66\u4e60\u4e0d\u540c\u9891\u7387\u548c\u76f8\u4f4d\u7684\u7ec4\u5408\u5173\u7cfb\uff0c\u4e3a\u751f\u6210\u5668\u63d0\u4f9b\u4efb\u52a1\u76f8\u5173\u7684\u7279\u5f81\u3002 \u5e73\u79fb\u4e0d\u4f1a\u6539\u53d8\u4fe1\u53f7\u7684\u9891\u7387\u5206\u91cf\uff08\u632f\u5e45\u4e0d\u53d8\uff09\uff0c\u4f46\u4f1a\u5f15\u5165\u4e0e\u5e73\u79fb\u91cf\u6210\u6bd4\u4f8b\u7684\u76f8\u4f4d\u504f\u79fb\u3002 \u65cb\u8f6c\u4f1a\u540c\u65f6\u6539\u53d8\u7a7a\u95f4\u57df\u548c\u9891\u57df\u4fe1\u53f7\u7684\u65b9\u5411\uff0c\u4f46\u9891\u7387\u7684\u5e45\u5ea6\u4e0d\u53d8</li> </ol>"},{"location":"book/chapter5_GAN/3.5stylegan3/paper/#6","title":"6. \u4ee3\u7801\u89e3\u8bfb","text":""},{"location":"book/chapter5_GAN/3.5stylegan3/paper/#61-modulated_conv2d","title":"6.1 modulated_conv2d","text":"<pre><code>def modulated_conv2d(\n    x,                  # Input tensor: [batch_size, in_channels, in_height, in_width]\n    w,                  # Weight tensor: [out_channels, in_channels, kernel_height, kernel_width]\n    s,                  # Style tensor: [batch_size, in_channels]\n    demodulate  = True, # Apply weight demodulation?\n    padding     = 0,    # Padding: int or [padH, padW]\n    input_gain  = None, # Optional scale factors for the input channels: [], [in_channels], or [batch_size, in_channels]\n):\n    with misc.suppress_tracer_warnings(): # this value will be treated as a constant\n        batch_size = int(x.shape[0])\n    out_channels, in_channels, kh, kw = w.shape\n    misc.assert_shape(w, [out_channels, in_channels, kh, kw]) # [OIkk]\n    misc.assert_shape(x, [batch_size, in_channels, None, None]) # [NIHW]\n    misc.assert_shape(s, [batch_size, in_channels]) # [NI]\n\n    # Pre-normalize inputs.\n    if demodulate:\n        w = w * w.square().mean([1,2,3], keepdim=True).rsqrt()\n        s = s * s.square().mean().rsqrt()\n\n    # Modulate weights.\n    w = w.unsqueeze(0) # [NOIkk] # \u589e\u52a0batch\u7ef4\u5ea6\n    w = w * s.unsqueeze(1).unsqueeze(3).unsqueeze(4) # [NOIkk]\n\n    # Demodulate weights.\n    if demodulate:\n        dcoefs = (w.square().sum(dim=[2,3,4]) + 1e-8).rsqrt() # [NO]\n        w = w * dcoefs.unsqueeze(2).unsqueeze(3).unsqueeze(4) # [NOIkk]\n\n    # Apply input scaling.\n    if input_gain is not None:\n        input_gain = input_gain.expand(batch_size, in_channels) # [NI]\n        w = w * input_gain.unsqueeze(1).unsqueeze(3).unsqueeze(4) # [NOIkk]\n\n    # Execute as one fused op using grouped convolution.\n    x = x.reshape(1, -1, *x.shape[2:])\n    w = w.reshape(-1, in_channels, kh, kw)\n    x = conv2d_gradfix.conv2d(input=x, weight=w.to(x.dtype), padding=padding, groups=batch_size)\n    x = x.reshape(batch_size, -1, *x.shape[2:])\n    return x\n</code></pre>"},{"location":"book/chapter5_GAN/3.5stylegan3/paper/#62","title":"6.2 \u6700\u7ec8\u6570\u5b66\u8868\u8fbe\u5f0f","text":"<p>\u7ecf\u8fc7\u4ee5\u4e0a\u6b65\u9aa4\uff0c\u6700\u7ec8\u8f93\u51fa \\( y \\) \u7684\u6570\u5b66\u8868\u8fbe\u4e3a\uff1a</p> \\[ y_{b,o,h',w'} = \\sum_{i,k_h,k_w} \\left[ x_{b,i,h+k_h,w+k_w} \\cdot \\left( w_{o,i,k_h,k_w} \\cdot s_{b,i} \\cdot d_{\\text{coef},o} \\cdot \\text{input\\_gain}_{b,i} \\right) \\right] \\] <p>\u5176\u4e2d\uff1a</p> <ul> <li>$ b $: \u6279\u91cf\u7d22\u5f15\u3002</li> <li>$ o, i $: \u8f93\u51fa\u901a\u9053\u548c\u8f93\u5165\u901a\u9053\u7d22\u5f15\u3002</li> <li>$ h', w'$: \u8f93\u51fa\u7279\u5f81\u56fe\u7684\u4f4d\u7f6e\u3002</li> <li>$ k_h, k_w $: \u5377\u79ef\u6838\u7684\u7a7a\u95f4\u7ef4\u5ea6\u7d22\u5f15\u3002</li> </ul>"},{"location":"book/chapter5_GAN/3.5stylegan3/paper/#63","title":"6.3 \u76f4\u89c2\u610f\u4e49","text":"<ol> <li>\u6837\u5f0f $ s $ \u52a8\u6001\u5730\u8c03\u8282\u6743\u91cd\uff0c\u8c03\u6574\u6bcf\u4e2a\u5377\u79ef\u6838\u7684\u6743\u91cd\u3002\u540c\u4e00\u4e2abatch\u91cc\u4e0d\u540c\u7684\u4e0d\u540c\u7684\u6837\u672cstyle\u662f\u72ec\u7acb\u7684\u3002\u4f53\u73b0\u4e86\u751f\u6210\u5f0f\u6a21\u578b\u4e2d\u7279\u5f81\u7684\u4e2a\u6027\u5316\u8c03\u6574\u3002</li> <li>\u5f52\u4e00\u5316\u548c\u53bb\u5f52\u4e00\u5316\u8fc7\u7a0b\u907f\u514d\u4e86\u6570\u503c\u4e0d\u7a33\u5b9a\u6027\u3002\u6743\u91cd\u5f52\u4e00\u5316\u4f5c\u7528\u5728i,k,h \u7ef4\u5ea6\u4e0a\uff0c\u4e5f\u5c31\u662f\u4e0d\u540c\u7684\u5377\u79ef\u6838\u4e0a\u505anormalize\uff0c\u5177\u6709\u76f8\u540c\u7684\u8303\u6570\u3002\u5bf9style \u7684\u5f52\u4e00\u5316\u4f5c\u7528\u5728\u6240\u6709\u7684\u7ef4\u5ea6\u4e0a\u3002\u4e5f\u5c31\u662f\u6574\u4e2as \u5f52\u4e00\u5316\u4e4b\u540e\u7684\u8303\u6570\u4e3a1.</li> <li>\u5206\u7ec4\u5377\u79ef\u9ad8\u6548\u5730\u5b9e\u73b0\u4e86\u6bcf\u4e2a\u6837\u672c\u72ec\u7acb\u7684\u6743\u91cd\u8c03\u5236\u8ba1\u7b97\u3002</li> </ol>"},{"location":"book/chapter5_GAN/3.5stylegan3/paper/#64-synthesislayer","title":"6.4 SynthesisLayer","text":"<pre><code># Track input magnitude.\nif update_emas:\n    with torch.autograd.profiler.record_function('update_magnitude_ema'):\n        magnitude_cur = x.detach().to(torch.float32).square().mean()\n        self.magnitude_ema.copy_(magnitude_cur.lerp(self.magnitude_ema, self.magnitude_ema_beta))\ninput_gain = self.magnitude_ema.rsqrt()\n\n# Execute affine layer.\nstyles = self.affine(w)\nif self.is_torgb:\n    weight_gain = 1 / np.sqrt(self.in_channels * (self.conv_kernel ** 2))\n    styles = styles * weight_gain\n\n# Execute modulated conv2d.\ndtype = torch.float16 if (self.use_fp16 and not force_fp32 and x.device.type == 'cuda') else torch.float32\nx = modulated_conv2d(x=x.to(dtype), w=self.weight, s=styles,\n    padding=self.conv_kernel-1, demodulate=(not self.is_torgb), input_gain=input_gain)\n</code></pre>"},{"location":"book/chapter5_GAN/3.5stylegan3/paper/#65","title":"6.5 \u6570\u5b66\u516c\u5f0f","text":"<ol> <li>\u5f53\u524d\u8f93\u5165\u5e45\u503c\u7684\u5e73\u65b9\u5747\u503c\uff1a</li> </ol> <p>$$    \\text{magnitude_cur} = \\frac{1}{N} \\sum_i x_i^2    $$</p> <p>\u5176\u4e2d\uff1a    - \\( x \\): \u8f93\u5165\u7279\u5f81\u3002    - \\( N \\): \u8f93\u5165\u7279\u5f81\u4e2d\u5143\u7d20\u7684\u603b\u6570\u3002</p> <ol> <li>EMA \u66f4\u65b0\uff1a</li> </ol> <p>$$    \\text{magnitude_ema} = \\beta \\cdot \\text{magnitude_ema} + (1 - \\beta) \\cdot \\text{magnitude_cur}    $$</p> <p>\u5176\u4e2d\uff1a    - $ \\beta\\(: EMA \u7684\u5e73\u6ed1\u7cfb\u6570 (\\) 0 &lt; \\beta &lt; 1 $)\u3002    - $ \\text{magnitude_cur} $: \u5f53\u524d\u8f93\u5165\u5e45\u503c\u7684\u5e73\u65b9\u5747\u503c\u3002    - $ \\text{magnitude_ema} $: \u5386\u53f2\u5e73\u6ed1\u7684\u8f93\u5165\u5e45\u503c\u3002</p> <ol> <li>\u8f93\u5165\u589e\u76ca\uff1a</li> </ol> <p>$$    \\text{input_gain} = \\frac{1}{\\sqrt{\\text{magnitude_ema}}}    $$</p>"},{"location":"book/chapter5_GAN/3.5stylegan3/paper/#66","title":"6.6 \u516c\u5f0f\u7684\u76f4\u89c2\u610f\u4e49","text":"<ul> <li>\u52a8\u6001\u5f52\u4e00\u5316\uff1a\u901a\u8fc7 \\(\\text{input\\_gain}\\) \u8c03\u6574\u8f93\u5165\u7279\u5f81\u7684\u5e45\u503c\uff0c\u786e\u4fdd\u5176\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u4fdd\u6301\u9002\u5f53\u8303\u56f4\u3002</li> <li>\u5e73\u6ed1\u66f4\u65b0\uff1aEMA \u63d0\u4f9b\u4e86\u4e00\u79cd\u5e73\u6ed1\u7684\u5386\u53f2\u5e45\u503c\u4f30\u8ba1\uff0c\u907f\u514d\u8bad\u7ec3\u4e2d\u7684\u5267\u70c8\u6ce2\u52a8\u3002</li> <li>\u6570\u503c\u7a33\u5b9a\u6027\uff1a\u9650\u5236\u8f93\u5165\u7279\u5f81\u5e45\u503c\u7684\u8fc7\u5927\u6216\u8fc7\u5c0f\uff0c\u786e\u4fdd\u8bad\u7ec3\u4e2d\u7684\u68af\u5ea6\u7a33\u5b9a\u3002     input_gain \u4f1a\u4f5c\u7528\u5728\u4e4b\u540e\u7684\u5377\u79ef\u4e0a\uff0c\u4f5c\u7528\u76f8\u5f53\u4e8e\u5bf9X\u505a\u4e86\u4e00\u4e2a\u5f52\u4e00\u5316\u3002\u53ef\u4ee5\u79f0\u4e4b\u4e3a\u6ed1\u52a8\u5e73\u5747\u5f52\u4e00\u5316\u3002\u76ee\u524d\u6240\u6709\u7684\u5f52\u4e00\u5316\u90fd\u4e0d\u6539\u53d8mean\u3002</li> </ul>"},{"location":"book/chapter5_GAN/3.5stylegan3/paper/#67-filtered_lrelu","title":"6.7 filtered_lrelu","text":"<pre><code>x = filtered_lrelu.filtered_lrelu(x=x, fu=self.up_filter, fd=self.down_filter, b=self.bias.to(x.dtype),\n            up=self.up_factor, down=self.down_factor, padding=self.padding, gain=gain, slope=slope, clamp=self.conv_clamp)\n</code></pre> <p>https://github.com/NVlabs/stylegan3/blob/main/torch_utils/ops/filtered_lrelu.py \u4f5c\u8005\u628a\u4e0a\u91c7\u6837\u4e0b\u91c7\u6837\u548c\u6fc0\u6d3b\u51fd\u6570\u91cd\u65b0\u5199\u4e86\u4e00\u4e2acuda kernel\u3002\u592a\u8fc7\u4e8e\u5de5\u7a0b\u5316\uff0c\u5148\u8df3\u8fc7\u8fd9\u90e8\u5206\u3002</p>"},{"location":"book/chapter5_GAN/3.5stylegan3/paper/#68-synthesislayerdesign_lowpass_filter","title":"6.8 SynthesisLayer.design_lowpass_filter","text":"<pre><code>    @staticmethod\n    def design_lowpass_filter(numtaps, cutoff, width, fs, radial=False):\n        assert numtaps &gt;= 1\n\n        # Identity filter.\n        if numtaps == 1:\n            return None\n\n        # Separable Kaiser low-pass filter.\n        if not radial:\n            f = scipy.signal.firwin(numtaps=numtaps, cutoff=cutoff, width=width, fs=fs)\n            return torch.as_tensor(f, dtype=torch.float32)\n\n        # Radially symmetric jinc-based filter.\n        x = (np.arange(numtaps) - (numtaps - 1) / 2) / fs\n        r = np.hypot(*np.meshgrid(x, x))\n        f = scipy.special.j1(2 * cutoff * (np.pi * r)) / (np.pi * r)\n        beta = scipy.signal.kaiser_beta(scipy.signal.kaiser_atten(numtaps, width / (fs / 2)))\n        w = np.kaiser(numtaps, beta)\n        f *= np.outer(w, w)\n        f /= np.sum(f)\n        return torch.as_tensor(f, dtype=torch.float32)\n</code></pre>"},{"location":"book/chapter5_GAN/3.5stylegan3/paper/#69","title":"6.9 \u6ee4\u6ce2\u5668\u7684\u4f5c\u7528\u57df\u4e0e\u8bbe\u8ba1\u8fc7\u7a0b","text":""},{"location":"book/chapter5_GAN/3.5stylegan3/paper/#691","title":"6.9.1 \u4f5c\u7528\u57df","text":"<p>\u8fd9\u4e9b\u6ee4\u6ce2\u5668 \u4f5c\u7528\u5728\u65f6\u95f4\u57df\uff0c\u5b83\u4eec\u901a\u8fc7\u65f6\u95f4\u57df\u5377\u79ef\u64cd\u4f5c\u5904\u7406\u8f93\u5165\u4fe1\u53f7\u6216\u56fe\u50cf\u3002\u5377\u79ef\u516c\u5f0f\u4e3a\uff1a</p> \\[ y[n] = \\sum_{k} x[k] \\cdot h[n-k] \\] <p>\u5176\u4e2d\uff1a</p> <ul> <li>\\(x[k]\\): \u8f93\u5165\u4fe1\u53f7\u3002</li> <li>\\(h[k]\\): \u6ee4\u6ce2\u5668\u7684\u65f6\u95f4\u57df\u6743\u91cd\uff08\u8109\u51b2\u54cd\u5e94\uff09\u3002</li> <li>\\(y[n]\\): \u6ee4\u6ce2\u540e\u7684\u8f93\u51fa\u4fe1\u53f7\u3002</li> </ul>"},{"location":"book/chapter5_GAN/3.5stylegan3/paper/#692","title":"6.9.2 \u8bbe\u8ba1\u8fc7\u7a0b","text":"<p>\u5c3d\u7ba1\u6ee4\u6ce2\u5668\u4f5c\u7528\u5728\u65f6\u95f4\u57df\uff0c\u5176\u8bbe\u8ba1\u8fc7\u7a0b\u901a\u5e38\u57fa\u4e8e\u9891\u57df\u7684\u8981\u6c42\uff0c\u6bd4\u5982\uff1a</p> <ul> <li>\u622a\u6b62\u9891\u7387 (\\(\\text{cutoff}\\))\uff1a\u6307\u5b9a\u6ee4\u6ce2\u5668\u5141\u8bb8\u901a\u8fc7\u7684\u9891\u7387\u8303\u56f4\u3002</li> <li>\u8fc7\u6e21\u5e26\u5bbd (\\(\\text{width}\\))\uff1a\u63a7\u5236\u6ee4\u6ce2\u5668\u4ece\u901a\u5e26\u5230\u963b\u5e26\u7684\u8fc7\u6e21\u533a\u57df\u7684\u5bbd\u5ea6\u3002</li> <li>\u9891\u57df\u5f62\u72b6\uff1a\u6ee4\u6ce2\u5668\u7684\u8bbe\u8ba1\u76ee\u6807\u662f\u5b9e\u73b0\u67d0\u79cd\u7406\u60f3\u9891\u7387\u54cd\u5e94\uff08\u5982\u4f4e\u901a\u3001\u9ad8\u901a\u6216\u5e26\u901a\uff09\u3002</li> </ul>"},{"location":"book/chapter5_GAN/3.5stylegan3/paper/#693","title":"6.9.3 \u9891\u57df\u4e0e\u65f6\u95f4\u57df\u7684\u5173\u7cfb","text":"<p>\u6839\u636e\u5085\u91cc\u53f6\u53d8\u6362\u7406\u8bba\uff0c\u65f6\u95f4\u57df\u4e0e\u9891\u57df\u662f\u4e00\u5bf9\u4e92\u8865\u7684\u8868\u793a\uff1a</p> <ul> <li>\u6ee4\u6ce2\u5668\u7684 \u65f6\u95f4\u57df\u6743\u91cd\uff08\u8109\u51b2\u54cd\u5e94\uff09 \u51b3\u5b9a\u5176\u9891\u57df\u54cd\u5e94\u3002</li> <li>\u6ee4\u6ce2\u5668\u7684 \u9891\u57df\u8bbe\u8ba1\u76ee\u6807\uff08\u5982\u622a\u6b62\u9891\u7387\u3001\u8fc7\u6e21\u5e26\u5bbd\uff09\u901a\u8fc7\u8bbe\u8ba1\u8fc7\u7a0b\u6620\u5c04\u4e3a\u65f6\u95f4\u57df\u6743\u91cd\u3002</li> </ul>"},{"location":"book/chapter5_GAN/3.5stylegan3/paper/#610","title":"6.10 \u4ee3\u7801\u4e2d\u7684\u6ee4\u6ce2\u5668\u8bbe\u8ba1","text":"<ol> <li>Kaiser \u6ee4\u6ce2\u5668\uff1a</li> <li>\u4f7f\u7528 <code>scipy.signal.firwin</code> \u57fa\u4e8e\u9891\u57df\u8981\u6c42\u751f\u6210\u65f6\u95f4\u57df\u6ee4\u6ce2\u5668\u6743\u91cd\u3002</li> <li>\u7a97\u51fd\u6570\u6cd5\u901a\u8fc7\u8c03\u6574 Kaiser \u7a97\u53e3\u7684\u5f62\u72b6\u5b9e\u73b0\u9891\u7387\u54cd\u5e94\u7684\u4f18\u5316\u3002</li> <li>Jinc \u6ee4\u6ce2\u5668\uff1a</li> <li>\u57fa\u4e8e\u5f84\u5411\u5bf9\u79f0\u7684 Jinc \u51fd\u6570\u8bbe\u8ba1\uff0c\u5176\u6838\u5fc3\u601d\u60f3\u6e90\u81ea\u9891\u57df\u7279\u6027\u3002</li> <li>\u901a\u8fc7\u53e0\u52a0 Kaiser \u7a97\u53e3\u8fdb\u4e00\u6b65\u8c03\u6574\u9891\u57df\u7279\u6027\u5e76\u751f\u6210\u65f6\u95f4\u57df\u6ee4\u6ce2\u5668\u6743\u91cd\u3002</li> </ol>"},{"location":"book/chapter5_GAN/3.5stylegan3/paper/#611","title":"6.11 \u603b\u7ed3","text":"<ul> <li>\u4f5c\u7528\u57df\uff1a\u6ee4\u6ce2\u5668\u4f5c\u7528\u5728\u65f6\u95f4\u57df\uff0c\u4f7f\u7528\u5377\u79ef\u64cd\u4f5c\u5904\u7406\u8f93\u5165\u4fe1\u53f7\u6216\u56fe\u50cf\u3002</li> <li>\u8bbe\u8ba1\u8fc7\u7a0b\uff1a\u57fa\u4e8e\u9891\u57df\u8981\u6c42\uff08\u5982\u622a\u6b62\u9891\u7387\u3001\u5e26\u5bbd\uff09\u8bbe\u8ba1\u65f6\u95f4\u57df\u6ee4\u6ce2\u5668\u6743\u91cd\u3002</li> <li>\u5b9e\u9645\u5e94\u7528\uff1a\u5728\u65f6\u95f4\u57df\u4e2d\u901a\u8fc7\u5377\u79ef\u5b9e\u73b0\u5bf9\u4fe1\u53f7\u6216\u56fe\u50cf\u9891\u7387\u6210\u5206\u7684\u63a7\u5236\u3002</li> </ul>"},{"location":"book/chapter5_GAN/3.6styleganT/paper/","title":"StyleGAN-T","text":"<p>paper year: 2023</p>"},{"location":"book/chapter5_GAN/3.7R3Gan/paper/","title":"R3GAN","text":"<p>R3gan year: 20025</p>"},{"location":"book/chapter6_VAE/vae_introduction/","title":"VAE \u7406\u8bba","text":""},{"location":"book/chapter6_VAE/vae_introduction/#1-1-p_theta","title":"1. 1. \\(p_\\theta\\) \u4e3a\u9ad8\u65af\u5206\u5e03","text":""},{"location":"book/chapter6_VAE/vae_introduction/#11-11-variational-autoencoder-vae-p_thetaxz","title":"1.1 1.1 Variational Autoencoder (VAE) \u4e2d\u5173\u4e8e \\(P_\\theta(x|z)\\) \u662f\u9ad8\u65af\u5206\u5e03\u7684\u5047\u8bbe","text":"<p>\u5728 VAE \u7684\u6846\u67b6\u4e2d\uff0c\u89e3\u7801\u5668 \\( P_\\theta(x|z) \\) \u901a\u5e38\u88ab\u5047\u8bbe\u4e3a \u9ad8\u65af\u5206\u5e03\u3002\u8fd9\u79cd\u5047\u8bbe\u662f VAE \u7684\u57fa\u7840\u4e4b\u4e00\uff0c\u5bf9\u6a21\u578b\u7684\u91cd\u5efa\u8bef\u5dee\u5b9a\u4e49\u548c\u4f18\u5316\u76ee\u6807\u81f3\u5173\u91cd\u8981\u3002\u4ee5\u4e0b\u662f\u5173\u4e8e\u8fd9\u4e2a\u5047\u8bbe\u7684\u76f8\u5173\u77e5\u8bc6\u3002</p>"},{"location":"book/chapter6_VAE/vae_introduction/#12-12-p_thetaxz","title":"1.2 1.2 \u4e3a\u4ec0\u4e48\u5047\u8bbe \\(P_\\theta(x|z)\\) \u4e3a\u9ad8\u65af\u5206\u5e03\uff1f","text":""},{"location":"book/chapter6_VAE/vae_introduction/#121-121","title":"1.2.1 1.2.1 \u7b80\u5316\u95ee\u9898","text":"<ul> <li>\u9ad8\u65af\u5206\u5e03\u662f\u4e00\u79cd\u8fde\u7eed\u578b\u6982\u7387\u5206\u5e03\uff0c\u6570\u5b66\u6027\u8d28\u826f\u597d\uff0c\u6613\u4e8e\u8ba1\u7b97\u3002</li> <li>\u5bf9\u4e8e\u8fde\u7eed\u578b\u6570\u636e\uff08\u5982\u56fe\u50cf\u50cf\u7d20\u503c\u3001\u97f3\u9891\u4fe1\u53f7\u7b49\uff09\uff0c\u9ad8\u65af\u5206\u5e03\u80fd\u5f88\u597d\u5730\u62df\u5408\u5927\u591a\u6570\u6570\u636e\u70b9\u7684\u6ce2\u52a8\u7279\u6027\u3002</li> </ul>"},{"location":"book/chapter6_VAE/vae_introduction/#122-122","title":"1.2.2 1.2.2 \u7b26\u5408\u91cd\u5efa\u8bef\u5dee\u7684\u5b9a\u4e49","text":"<ul> <li>\u9ad8\u65af\u5206\u5e03\u7684\u5bf9\u6570\u4f3c\u7136\u5177\u6709\u4ee5\u4e0b\u5f62\u5f0f\uff1a</li> </ul> <p>$$   \\log P_\\theta(x|z) = -\\frac{|x - \\mu_\\theta(z)|<sup>2}{2\\sigma</sup>2} - \\frac{1}{2}\\log(2\\pi\\sigma^2)   $$</p> <ul> <li>\u8fd9\u91cc\uff0c\\(\\mu_\\theta(z)\\) \u662f\u89e3\u7801\u5668\u9884\u6d4b\u7684\u9ad8\u65af\u5206\u5e03\u5747\u503c\uff0c\\(\\sigma^2\\) \u662f\u65b9\u5dee\uff08\u901a\u5e38\u53ef\u4ee5\u5047\u8bbe\u4e3a\u5e38\u91cf\u6216\u7531\u89e3\u7801\u5668\u9884\u6d4b\uff09\u3002</li> <li> <p>\u6700\u5927\u5316 \\(\\log P_\\theta(x|z)\\) \u7b49\u4ef7\u4e8e\u6700\u5c0f\u5316\u5747\u65b9\u8bef\u5dee\uff08MSE\uff09\uff1a</p> \\[ \\|x - \\mu_\\theta(z)\\|^2 \\] </li> </ul>"},{"location":"book/chapter6_VAE/vae_introduction/#123-123","title":"1.2.3 1.2.3 \u5141\u8bb8\u5efa\u6a21\u6570\u636e\u7684\u4e0d\u786e\u5b9a\u6027","text":"<ul> <li>\u5047\u8bbe \\(P_\\theta(x|z)\\) \u4e3a\u9ad8\u65af\u5206\u5e03\uff0c\u89e3\u7801\u5668\u4e0d\u4ec5\u9884\u6d4b\u91cd\u6784\u7684\u5747\u503c \\(\\mu_\\theta(z)\\)\uff0c\u8fd8\u53ef\u4ee5\u901a\u8fc7\u65b9\u5dee \\(\\sigma^2_\\theta(z)\\) \u6355\u6349\u6570\u636e\u7684\u4e0d\u786e\u5b9a\u6027\u3002</li> <li>\u65b9\u5dee\u7684\u5f15\u5165\u6709\u52a9\u4e8e\u907f\u514d\u8fc7\u5ea6\u62df\u5408\uff0c\u5c24\u5176\u662f\u5728\u8bad\u7ec3\u6570\u636e\u5b58\u5728\u566a\u58f0\u7684\u60c5\u51b5\u4e0b\u3002</li> </ul>"},{"location":"book/chapter6_VAE/vae_introduction/#13-13","title":"1.3 1.3 \u6570\u5b66\u5f62\u5f0f","text":""},{"location":"book/chapter6_VAE/vae_introduction/#131-131","title":"1.3.1 1.3.1 \u89e3\u7801\u5668\u5206\u5e03","text":"<p>\u5728 VAE \u4e2d\uff0c\u89e3\u7801\u5668\u5b9a\u4e49\u4e3a\u6761\u4ef6\u6982\u7387\u5206\u5e03 \\(P_\\theta(x|z)\\)\uff0c\u5047\u8bbe\u4e3a\u9ad8\u65af\u5206\u5e03\uff1a</p> \\[ P_\\theta(x|z) = \\mathcal{N}(x; \\mu_\\theta(z), \\sigma_\\theta^2(z)) \\] <ul> <li>\\(\\mu_\\theta(z)\\)\uff1a\u89e3\u7801\u5668\u9884\u6d4b\u7684\u91cd\u6784\u5747\u503c\uff0c\u901a\u5e38\u7531\u795e\u7ecf\u7f51\u7edc\u5efa\u6a21\u3002</li> <li>\\(\\sigma_\\theta^2(z)\\)\uff1a\u89e3\u7801\u5668\u9884\u6d4b\u7684\u91cd\u6784\u65b9\u5dee\uff0c\u53ef\u4ee5\u662f\u56fa\u5b9a\u5e38\u91cf\uff0c\u4e5f\u53ef\u4ee5\u7531\u7f51\u7edc\u5efa\u6a21\u3002</li> </ul>"},{"location":"book/chapter6_VAE/vae_introduction/#2-2","title":"2. 2. \u5176\u4ed6\u5206\u5e03","text":""},{"location":"book/chapter6_VAE/vae_introduction/#21-21-l_1","title":"2.1 2.1 \u62c9\u666e\u62c9\u65af\u5206\u5e03\u4e0e \\(L_1\\) \u8303\u6570","text":"<ul> <li>\u5047\u8bbe\u5206\u5e03:   \\(P_\\theta(x|z) = \\text{Laplace}(x; \\mu_\\theta(z), b)\\)</li> <li>\u5bf9\u6570\u4f3c\u7136:</li> </ul> <p>$$   \\log P_\\theta(x|z) = -\\frac{|x - \\mu_\\theta(z)|_1}{b} - \\log(2b)   $$</p> <ul> <li>\u635f\u5931\u51fd\u6570:</li> </ul> <p>$$   L = \\frac{1}{b}|x - \\mu_\\theta(z)|_1   $$</p> <ul> <li>\u5bf9\u5e94\u5f62\u5f0f: \u7edd\u5bf9\u8bef\u5dee\uff08MAE\uff09\u3002</li> </ul>"},{"location":"book/chapter6_VAE/vae_introduction/#22-22","title":"2.2 2.2 \u4f2f\u52aa\u5229\u5206\u5e03\u4e0e\u4ea4\u53c9\u71b5","text":"<ul> <li>\u5047\u8bbe\u5206\u5e03:   \\(P_\\theta(x|z) = \\text{Bernoulli}(x; p_\\theta(z))\\)</li> <li>\u5bf9\u6570\u4f3c\u7136:</li> </ul> <p>$$   \\log P_\\theta(x|z) = x \\log p_\\theta(z) + (1-x) \\log (1-p_\\theta(z))   $$</p> <ul> <li>\u635f\u5931\u51fd\u6570:</li> </ul> <p>$$   L = -[x \\log p_\\theta(z) + (1-x) \\log (1-p_\\theta(z))]   $$</p> <ul> <li>\u5bf9\u5e94\u5f62\u5f0f: \u4e8c\u5143\u4ea4\u53c9\u71b5\u635f\u5931\u3002</li> </ul>"},{"location":"book/chapter6_VAE/vae_introduction/#23-23","title":"2.3 2.3 \u591a\u9879\u5206\u5e03\u4e0e\u591a\u5206\u7c7b\u4ea4\u53c9\u71b5","text":"<ul> <li>\u5047\u8bbe\u5206\u5e03:   \\(P_\\theta(x|z) = \\text{Categorical}(x; \\mathbf{p}_\\theta(z))\\)</li> <li>\u5bf9\u6570\u4f3c\u7136:</li> </ul> <p>$$   \\log P_\\theta(x|z) = \\sum_i x_i \\log p_{\\theta,i}(z)   $$</p> <ul> <li>\u635f\u5931\u51fd\u6570:</li> </ul> <p>$$   L = -\\sum_i x_i \\log p_{\\theta,i}(z)   $$</p> <ul> <li>\u5bf9\u5e94\u5f62\u5f0f: \u591a\u5206\u7c7b\u4ea4\u53c9\u71b5\u3002</li> </ul>"},{"location":"book/chapter6_VAE/vae_introduction/#24-24","title":"2.4 2.4 \u6df7\u5408\u9ad8\u65af\u5206\u5e03","text":"<ul> <li>\u5047\u8bbe\u5206\u5e03:   \\(P_\\theta(x|z) = \\sum_k \\pi_k \\mathcal{N}(x; \\mu_k(z), \\sigma_k^2(z))\\)</li> <li>\u5bf9\u6570\u4f3c\u7136:</li> </ul> <p>$$   \\log P_\\theta(x|z) = \\log \\sum_k \\pi_k \\mathcal{N}(x; \\mu_k(z), \\sigma_k^2(z))   $$</p> <ul> <li>\u7279\u70b9: \u7528\u4e8e\u591a\u6a21\u6001\u6570\u636e\u5efa\u6a21\uff0c\u8ba1\u7b97\u635f\u5931\u9700\u8981\u6570\u503c\u8fd1\u4f3c\u3002</li> </ul>"},{"location":"book/chapter6_VAE/vae_introduction/#25-25","title":"2.5 2.5 \u603b\u7ed3","text":"<ul> <li> <p>\u6838\u5fc3\u601d\u60f3:   \u635f\u5931\u51fd\u6570\u4e0e\u6982\u7387\u5206\u5e03\u7684\u5173\u7cfb\u4e3a\u6211\u4eec\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u89c6\u89d2\uff0c\u7528\u4e8e\u8bbe\u8ba1\u548c\u4f18\u5316\u673a\u5668\u5b66\u4e60\u6a21\u578b\u3002\u5e38\u89c1\u635f\u5931\u51fd\u6570\uff08\u5982 MSE\u3001MAE\u3001\u4ea4\u53c9\u71b5\uff09\u5747\u53ef\u4ee5\u4ece\u5bf9\u5e94\u7684\u5206\u5e03\u5047\u8bbe\u4e2d\u63a8\u5bfc\u800c\u6765\u3002</p> </li> <li> <p>\u5b9e\u9645\u5e94\u7528:   \u6839\u636e\u6570\u636e\u7279\u6027\u9009\u62e9\u5408\u9002\u7684\u5206\u5e03\u5047\u8bbe\u548c\u635f\u5931\u51fd\u6570\u53ef\u4ee5\u63d0\u9ad8\u6a21\u578b\u7684\u6027\u80fd\u3002\u4f8b\u5982\uff1a</p> </li> <li>\u8fde\u7eed\u503c\u6570\u636e\u9002\u7528\u9ad8\u65af\u5206\u5e03\uff08MSE\uff09\u3002</li> <li>\u4e8c\u503c\u6570\u636e\u9002\u7528\u4f2f\u52aa\u5229\u5206\u5e03\uff08\u4ea4\u53c9\u71b5\uff09\u3002</li> <li>\u7a00\u758f\u6570\u636e\u9002\u7528\u62c9\u666e\u62c9\u65af\u5206\u5e03\uff08MAE\uff09\u3002</li> </ul>"},{"location":"book/chapter6_VAE/vae_introduction/#26-26","title":"2.6 2.6 \u76f8\u5173\u8bba\u6587","text":"<ol> <li>\u300aAuto-Encoding Variational Bayes\u300b</li> <li>\u4f5c\u8005: Kingma, D.P., Welling, M.</li> <li>\u94fe\u63a5: https://arxiv.org/abs/1312.6114</li> <li> <p>\u5185\u5bb9: \u63d0\u51fa\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08VAE\uff09\uff0c\u63a8\u5bfc\u51fa\u91cd\u5efa\u8bef\u5dee\u9879\u4e0e\u5206\u5e03\u5047\u8bbe\u7684\u5173\u7cfb\u3002</p> </li> <li> <p>\u300aHybridised Loss Functions for Improved Neural Network Generalisation\u300b</p> </li> <li>\u4f5c\u8005: Matthew C. Malan \u7b49</li> <li>\u94fe\u63a5: https://arxiv.org/abs/2204.12241</li> <li> <p>\u5185\u5bb9: \u63a2\u8ba8\u4ea4\u53c9\u71b5\u548c\u5747\u65b9\u8bef\u5dee\u7684\u6df7\u5408\u635f\u5931\u53ca\u5176\u5f71\u54cd\u3002</p> </li> <li> <p>\u300ap-Huber\u635f\u5931\u51fd\u6570\u53ca\u5176\u9c81\u68d2\u6027\u7814\u7a76\u300b</p> </li> <li>\u4f5c\u8005: \u4f59\u535a\u5929</li> <li>\u94fe\u63a5: https://pdf.hanspub.org/AAM20201200000_75579140.pdf</li> <li>\u5185\u5bb9: \u7814\u7a76 p-Huber \u635f\u5931\u5728\u6709\u566a\u58f0\u6570\u636e\u4e2d\u7684\u8868\u73b0\u3002</li> </ol>"},{"location":"book/chapter6_VAE/vq_vae/","title":"VQ-VAE","text":"<ul> <li>paper: VA-VAE:arxiv</li> <li>year: 2018</li> <li>Author Deepmind</li> </ul> <p>Note</p> <p>Please refer basic VAE theorem for better understanding</p>"},{"location":"book/chapter6_VAE/vq_vae/#1-vae-intrduction","title":"1. VAE Intrduction","text":"<p>In recent years, Variational Autoencoders (VAEs) and their discrete counterparts, Vector Quantized Variational Autoencoders (VQ-VAEs), have gained significant attention in the deep learning community. While both models share a common goal of learning efficient latent representations, their underlying loss functions and theoretical derivations differ notably. In this post, we summarize the key points discussed regarding these loss functions and explore the theoretical motivations behind VQ-VAE\u2019s design.</p> <p>The VAE Loss Function</p> <p>The standard VAE is built upon a probabilistic framework. Its loss function consists of two main terms:</p> \\[ \\mathcal{L}_{\\text{VAE}} = -\\mathbb{E}_{q_\\phi(z|x)}\\big[\\log p_\\theta(x|z)\\big] + D_{\\text{KL}}\\big(q_\\phi(z|x) \\,\\|\\, p(z)\\big) \\] <ul> <li> <p>Reconstruction Loss:   \\(-\\mathbb{E}_{q_\\phi(z|x)}[\\log p_\\theta(x|z)]\\) ensures that the decoder can accurately reconstruct the input \\(x\\) from the latent variable \\(z\\). Depending on the nature of the data (continuous or discrete), this term is instantiated as a mean squared error (MSE) or a cross-entropy loss.</p> </li> <li> <p>KL Divergence Regularization:   \\(D_{\\text{KL}}(q_\\phi(z|x) \\| p(z))\\) acts as a regularizer, forcing the approximate posterior \\(q_\\phi(z|x)\\) (often modeled as a Gaussian with parameters \\(\\mu(x)\\) and \\(\\sigma(x)\\)) to be close to the prior \\(p(z)\\) (usually chosen as a standard normal distribution).</p> </li> </ul> <p>This formulation is derived from maximizing the Evidence Lower Bound (ELBO) on the data likelihood, providing a rigorous probabilistic foundation for learning continuous latent representations.</p> <p>VQ-VAE: Architecture and Loss Function</p>"},{"location":"book/chapter6_VAE/vq_vae/#2-architecture","title":"2. Architecture","text":"<p>Unlike the continuous latent spaces of VAEs, VQ-VAE employs discrete latent representations using vector quantization. The key difference lies in how the encoder\u2019s output is mapped to a latent code:</p> <ul> <li> <p>Vector Quantization:   The encoder produces a continuous representation \\(z_e(x)\\), which is then quantized by mapping it to the closest vector \\(e\\) in a finite codebook.</p> </li> <li> <p>The Codebook is a \\(K\\times D\\) table, corresponds to the purple \\(e_1,e_2,\\ldots, e_K\\), each is a \\(D\\) dimension vector.</p> </li> <li>The encoder compresses the input image \\(H\\times W\\times 3\\) to \\(h\\times w \\times D\\) dimension feature map (or considered as compressed information).</li> <li> <p>Use the feature map to find the index of the closest feature among \\(e_1, ...e_K\\) in the codebook for each location, which is \\(q(z|x)\\). Here we need to consider the prior distribution \\(p(z)\\) as the discrete distribution. \\(z\\) can be considered as the random variable of the \\(e_i\\) or the index of the codebook \\(i\\). In the following section, we consider it as the index.</p> </li> <li> <p>After we have the index for each location, we can replace it with the corresponding vector in the codebook which will be fed into the decoder to recover the original image.</p> </li> </ul> <p>Let \\(E\\) and \\(G\\) be the encoder and decoder, respectively, we have</p> \\[z_e(x) = E(x), \\hat{x} = G(z_q(x))\\] <p>In fact, \\(z\\) should have the same shape as \\(z_e(x)\\) which is \\(h\\times w\\), in other words, \\(z\\) should be a feature map of indexes. Then the probability \\(p(z)\\) and \\(q(z|x)\\) will be the discrete probability distribution.</p> <p>Analytically, \\(z=(z_{ij})\\) and \\(q(z|x) = q(z_{1,1}, z_{1,2},\\ldots, z_{h,w}|x)\\).</p> <p>Revision of one-hot posterior distribution</p> <p>In the paper, it is assumed that \\(p(z|x)\\) is the one-hot</p> \\[ q(z=k|x) = \\begin{cases} 1 &amp;\\forall k = \\argmin_j ||z_e(x) - e_j||,\\\\ 0 &amp; otherwise \\end{cases} \\] <p>This is not analytically correct since \\(z_e(x)\\) is not one vector. More accurately, we have</p> \\[ q(z_{ij}=k;i\\in[1,2,...,h],j\\in[1,2,...,w]|x) = \\begin{cases} 1 &amp;\\forall k = \\argmin_j ||z_e[x]_{i,j} - e_j||,\\\\ 0 &amp; otherwise \\end{cases} \\] <p>And thus we have</p> \\[ z_q(x)_{ij} = e_k, where \\; k  = \\argmin_j ||z_e(x)_{i,j} - e_j||\\; \\forall i\\in[1,2,...,h],j\\in[1,2,...,w] \\]"},{"location":"book/chapter6_VAE/vq_vae/#3-loss","title":"3. Loss","text":"<p>The loss function in VQ-VAE is composed of three terms:</p> \\[ \\mathcal{L}_{\\text{VQ-VAE}} = \\underbrace{\\| x - \\hat{x} \\|^2}_{\\text{Reconstruction Loss}} + \\underbrace{\\| \\operatorname{sg}[z_e(x)] - e \\|^2}_{\\text{Codebook Loss}} + \\beta\\, \\underbrace{\\| z_e(x) - \\operatorname{sg}[e] \\|^2}_{\\text{Commitment Loss}} \\] <ul> <li> <p>Reconstruction Loss (\\(\\| x - \\hat{x} \\|^2\\)):   Similar to VAE, this term ensures that the decoder can reconstruct the input \\(x\\) from the quantized latent representation.</p> </li> <li> <p>Codebook Loss (\\(\\| \\operatorname{sg}[z_e(x)] - e \\|^2\\)):   Here, the stop-gradient operator (\\(\\operatorname{sg}[\\cdot]\\)) prevents gradients from flowing into the encoder. This term updates the codebook vectors so that they move closer to the encoder outputs, akin to updating cluster centers in k-means clustering.</p> </li> <li> <p>Commitment Loss (\\(\\beta\\, \\| z_e(x) - \\operatorname{sg}[e] \\|^2\\)):   This term ensures that the encoder commits to the discrete codebook representations by penalizing large deviations between its continuous outputs and the corresponding codebook vectors. The hyperparameter \\(\\beta\\) balances its contribution relative to the other loss components.</p> </li> </ul> <p>Unlike the VAE, the VQ-VAE loss function is not derived from a strict probabilistic model but is rather engineered based on heuristic motivations and practical considerations for training models with discrete latent variables.</p>"},{"location":"book/chapter6_VAE/vq_vae/#4-tricks-on-reconstruction-loss","title":"4. Tricks on Reconstruction Loss","text":"<p>The problem in the reconstruction loss is that \\(z_e(x)\\) to \\(z_q(x)\\) is not differentiable thus the gradient cannot be passed successfully.</p> <p>To solve this, let</p> \\[L_{reconstruct} = ||x - D(z_e(x) + sg[z_q(x) - z_e(x)])||\\] reconstruction loss<pre><code>L = x - decoder(z_e + (z_q - z_e).detach())\n</code></pre> <p>Theoretical Justification: Commitment Loss as a KL Divergence</p> <p>A recurring question is whether the commitment loss in VQ-VAE can be theoretically derived or understood as an equivalent to the KL divergence in the VAE loss. Although VQ-VAE\u2019s loss is largely heuristic, several insightful approximations help bridge the conceptual gap:</p>"},{"location":"book/chapter6_VAE/vq_vae/#5-gaussian-approximation","title":"5. Gaussian Approximation","text":"<p>One can imagine \u201csoftening\u201d the hard quantization by approximating the encoder output with a Gaussian distribution:</p> <ul> <li> <p>Approximate Posterior:   $$   q(z|x) = \\mathcal{N}(z_e(x), \\sigma^2 I)   $$</p> </li> <li> <p>Local Prior Centered at the Codebook Vector:   $$   p(z) = \\mathcal{N}(e, \\sigma^2 I)   $$</p> </li> </ul> <p>Under these assumptions, the KL divergence between \\(q(z|x)\\) and \\(p(z)\\) becomes</p> \\[ D_{\\mathrm{KL}}\\Big(q(z|x) \\,\\|\\, p(z)\\Big) = \\frac{1}{2\\sigma^2}\\|z_e(x)-e\\|^2, \\] <p>which is proportional to the squared Euclidean distance between \\(z_e(x)\\) and \\(e\\). With proper scaling (multiplying by \\(2\\sigma^2\\)), this shows that minimizing the commitment loss is analogous to minimizing a KL divergence term.</p>"},{"location":"book/chapter6_VAE/vq_vae/#6-limit-arguments","title":"6. Limit Arguments","text":"<p>Another perspective involves considering extreme limits:</p> <ul> <li> <p>Encoder Output as a Dirac Delta:   Let the posterior \\(q(z|x)\\) tend to a delta function \\(\\delta(z-z_e(x))\\), reflecting the hard quantization.</p> </li> <li> <p>Flat Prior Approximation:   Although a truly flat prior can be seen as a Gaussian with variance tending to infinity, in practice, one assumes both the posterior and prior share the same finite variance \\(\\sigma^2\\). This shared scale ensures that the derived KL divergence maintains sensitivity to differences in the means.</p> </li> </ul> <p>In this limit, after appropriate re-scaling, the commitment loss</p> \\[ \\|z_e(x)-e\\|^2 \\] <p>effectively serves the same purpose as the KL divergence term in a VAE, enforcing that the encoder output remains close to the codebook vector.</p> <p>Is the VQ-VAE Loss Theoretically Derived?</p> <p>In contrast to the VAE\u2019s loss function, which is rigorously derived from maximizing the ELBO, the VQ-VAE loss is primarily an engineered objective. Its components are motivated by:</p> <ul> <li>Reconstruction Fidelity: Ensuring that the autoencoder captures the key information of the input.</li> <li>Discrete Representation Learning: Employing vector quantization to yield interpretable, discrete latent codes.</li> <li>Stabilizing Training: Using the codebook and commitment losses to regulate the encoder\u2019s outputs and update the codebook effectively.</li> </ul> <p>While heuristic derivations using approximations and limit arguments (as described above) provide useful insights\u2014particularly regarding the similarity between commitment loss and a properly scaled KL divergence\u2014the overall loss function of VQ-VAE is not strictly deduced from a complete probabilistic model.</p>"},{"location":"book/chapter6_VAE/vq_vae/#7-sampling-with-vq-vae","title":"7. Sampling with VQ-VAE","text":"<p>In VQ\u2011VAE, the sampling (or generation) process is typically handled by two main components:</p> <ol> <li>A discrete prior (e.g., an autoregressive model) over the latent codes.</li> <li>The decoder, which maps the sampled discrete codes back to the data space.</li> </ol> <p>Below is an outline of how it usually works:</p>"},{"location":"book/chapter6_VAE/vq_vae/#71-training-a-discrete-prior","title":"7.1 Training a Discrete Prior","text":"<ul> <li> <p>Why we need a prior:   In a standard VAE, the prior \\( p(z) \\) is often a continuous Gaussian, and we can easily sample \\( z \\) from it. However, in VQ\u2011VAE, the latent representation is discrete (a grid of codebook indices). We therefore need a model that can learn a distribution over these discrete indices.</p> </li> <li> <p>How it\u2019s done:   After training the VQ\u2011VAE (encoder, decoder, and codebook), we collect the discrete codes (the nearest codebook index at each spatial location) for all training samples. These codes can be viewed as sequences (or 2D arrays) of discrete tokens.   We then train a prior model on these discrete sequences. Common choices include:</p> </li> <li>Autoregressive models like PixelCNN, PixelSNAIL, or Transformers (GPT-like).</li> <li>Masked language modeling style approaches.</li> </ul> <p>The prior model learns \\( p(\\text{codes}) \\), effectively capturing how different code indices co-occur in space.</p>"},{"location":"book/chapter6_VAE/vq_vae/#72-sampling-from-the-discrete-prior","title":"7.2 Sampling from the Discrete Prior","text":"<ul> <li> <p>Sampling the latent codes:   Once the prior is trained, we can generate new sequences of code indices by sampling from it. For an autoregressive model, for example, we sample each code index one step at a time, conditioning on previously sampled indices.</p> </li> <li> <p>Spatial layout:   Often, the latent representation in VQ\u2011VAE is a 2D grid (e.g., \\(h \\times w\\) codes). If we use a PixelCNN-style prior, we sample code indices in raster-scan order (row by row, column by column). If we use a Transformer, we might flatten the 2D grid into a 1D sequence and sample tokens left to right.</p> </li> </ul>"},{"location":"book/chapter6_VAE/vq_vae/#73-decoding-the-sampled-codes","title":"7.3 Decoding the Sampled Codes","text":"<ul> <li> <p>Feed the discrete codes into the decoder:   After sampling a full grid of code indices (e.g., \\(\\{c_{ij}\\}\\) for \\(i=1,\\dots,h\\) and \\(j=1,\\dots,w\\)), we look up the codebook embeddings for each index and form a 2D grid of embedded vectors. This is the quantized latent representation.</p> </li> <li> <p>Generate data:   We pass this grid of embedded vectors into the VQ\u2011VAE\u2019s decoder. The decoder is a CNN (or other architecture) that upsamples (or transforms) the latent grid back to the original data space. The result is a synthetic sample in the style of the training data.</p> </li> </ul>"},{"location":"book/chapter6_VAE/vq_vae/#8-code-example","title":"8. code example","text":"<pre><code>import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport pytorch_lightning as pl\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom datasets import load_dataset\nfrom PIL import Image\n\n\nclass AnimeFacesDataset(Dataset):\n    \"\"\"\n    A simple dataset wrapper for the 'jlbaker361/anime_faces_dim_128_40k' dataset.\n    Adjust if the dataset structure differs from these assumptions.\n    \"\"\"\n    def __init__(self, split=\"train\"):\n        super().__init__()\n        # Load the dataset split\n        self.data = load_dataset(\"jlbaker361/anime_faces_dim_128_40k\", split=split)\n        # Basic transform: convert PIL image to tensor. Add other transforms as needed.\n        self.transform = transforms.Compose([\n            transforms.ToTensor(),\n        ])\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        item = self.data[idx]\n        # The dataset typically returns a PIL image in item[\"image\"].\n        # If it\u2019s already a PIL Image, we can directly apply self.transform.\n        image = item[\"image\"]\n        image = self.transform(image)\n        return image\n\n\nclass AnimeFacesDataModule(pl.LightningDataModule):\n    \"\"\"\n    PyTorch Lightning DataModule for the AnimeFacesDataset.\n    \"\"\"\n    def __init__(self, batch_size=32):\n        super().__init__()\n        self.batch_size = batch_size\n\n    def setup(self, stage=None):\n        # We only define a train dataset here, but you can also split off validation/test sets if needed.\n        self.train_dataset = AnimeFacesDataset(split=\"train\")\n\n    def train_dataloader(self):\n        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=2)\n\n\nclass VQVAE(pl.LightningModule):\n    \"\"\"\n    A simple VQ-VAE implementation with:\n      - A small encoder/decoder\n      - A codebook (nn.Embedding)\n      - Basic VQ losses: reconstruction, codebook, and commitment\n    \"\"\"\n    def __init__(\n        self,\n        in_channels=3,\n        hidden_channels=64,\n        embedding_dim=32,\n        n_embeddings=128,\n        commitment_cost=0.25,\n        lr=1e-3\n    ):\n        super().__init__()\n        self.save_hyperparameters()\n\n        # Encoder: downsamples the image and outputs embedding_dim channels\n        self.encoder = nn.Sequential(\n            nn.Conv2d(in_channels, hidden_channels, 4, 2, 1),  # 128 -&gt; 64\n            nn.ReLU(),\n            nn.Conv2d(hidden_channels, hidden_channels, 4, 2, 1),  # 64 -&gt; 32\n            nn.ReLU(),\n            nn.Conv2d(hidden_channels, self.hparams.embedding_dim, 1)\n        )\n\n        # Decoder: upsamples back to the original image size\n        self.decoder = nn.Sequential(\n            nn.ConvTranspose2d(self.hparams.embedding_dim, hidden_channels, 4, 2, 1),  # 32 -&gt; 64\n            nn.ReLU(),\n            nn.ConvTranspose2d(hidden_channels, hidden_channels, 4, 2, 1),  # 64 -&gt; 128\n            nn.ReLU(),\n            nn.ConvTranspose2d(hidden_channels, in_channels, 1)\n        )\n\n        # Codebook: nn.Embedding for vector quantization\n        self.codebook = nn.Embedding(self.hparams.n_embeddings, self.hparams.embedding_dim)\n        nn.init.uniform_(self.codebook.weight, -1, 1)  # Initialize codebook\n\n    def forward(self, x):\n        \"\"\"\n        Forward pass returns:\n          z_e: The continuous encoder output.\n          z_q: The quantized output (nearest codebook embeddings).\n          indices: The codebook indices selected for each latent position.\n        \"\"\"\n        # Encode\n        z_e = self.encoder(x)  # (B, embedding_dim, H, W)\n\n        # Reshape/flatten for nearest-neighbor search in codebook\n        B, C, H, W = z_e.shape\n        z_e_flat = z_e.permute(0, 2, 3, 1).reshape(-1, C)  # (B*H*W, embedding_dim)\n\n        # Compute distances to each embedding in the codebook\n        codebook_weight = self.codebook.weight  # (n_embeddings, embedding_dim)\n        z_e_sq = (z_e_flat ** 2).sum(dim=1, keepdim=True)  # (B*H*W, 1)\n        e_sq = (codebook_weight ** 2).sum(dim=1)           # (n_embeddings)\n        # distances: (B*H*W, n_embeddings)\n        distances = z_e_sq + e_sq.unsqueeze(0) - 2 * z_e_flat @ codebook_weight.T\n\n        # Nearest embedding index for each latent vector\n        indices = distances.argmin(dim=1)  # (B*H*W)\n\n        # Quantize: get codebook vectors and reshape back\n        z_q = self.codebook(indices).view(B, H, W, C).permute(0, 3, 1, 2)\n\n        return z_e, z_q, indices\n\n    def training_step(self, batch, batch_idx):\n        \"\"\"\n        Computes the VQ-VAE loss, which includes:\n          1) Reconstruction loss\n          2) Codebook loss (MSE between z_q and stop_grad(z_e))\n          3) Commitment loss (MSE between stop_grad(z_q) and z_e)\n        \"\"\"\n        x = batch\n        z_e, z_q, _ = self(x)\n\n        # Reconstruct\n        x_recon = self.decoder(z_q)\n        recon_loss = F.mse_loss(x_recon, x)\n\n        # Codebook loss: codebook vectors should match encoder output (stop-grad on encoder)\n        codebook_loss = F.mse_loss(z_q.detach(), z_e)\n\n        # Commitment loss: encoder output should commit to codebook vector (stop-grad on codebook)\n        commitment_loss = F.mse_loss(z_q, z_e.detach())\n\n        # Weighted sum of losses\n        loss = recon_loss + codebook_loss + self.hparams.commitment_cost * commitment_loss\n\n        # Logging\n        self.log(\"train_recon_loss\", recon_loss)\n        self.log(\"train_codebook_loss\", codebook_loss)\n        self.log(\"train_commitment_loss\", commitment_loss)\n        self.log(\"train_loss\", loss)\n\n        return loss\n\n    def configure_optimizers(self):\n        return torch.optim.Adam(self.parameters(), lr=self.hparams.lr)\n\n\nif __name__ == \"__main__\":\n    # Instantiate the DataModule\n    dm = AnimeFacesDataModule(batch_size=32)\n\n    # Create the VQ-VAE model\n    model = VQVAE(\n        in_channels=3,\n        hidden_channels=64,\n        embedding_dim=32,\n        n_embeddings=128,\n        commitment_cost=0.25,\n        lr=1e-3\n    )\n\n    # Trainer\n    trainer = pl.Trainer(\n        max_epochs=10,\n        accelerator=\"auto\",  # auto-detect GPU if available\n        devices=\"auto\"       # use all available GPUs if accelerator=\"gpu\"\n    )\n\n    # Train\n    trainer.fit(model, dm)\n</code></pre>"},{"location":"book/chapter6_VAE/vq_vae/#9-references","title":"9. References","text":"<ol> <li>\u8f7b\u677e\u7406\u89e3 VQ-VAE\uff1a\u9996\u4e2a\u63d0\u51fa codebook \u673a\u5236\u7684\u751f\u6210\u6a21\u578b</li> </ol>"},{"location":"book/chapter7_diffusion/DiT/","title":"Scalable Diffusion Models with Transformers (DiT)","text":"<ul> <li>Year: March 2023</li> <li>Authors:</li> <li>William Peebles<ul> <li>DiT model (UC Berkeley)</li> <li>SORA project (OpenAI)</li> </ul> </li> <li>Saining Xie<ul> <li>DiT model (New York University)</li> <li>ResNeXt</li> <li>Cambrian-1 with Yann LeCun</li> </ul> </li> <li>Main Contributions:</li> <li>Replaced the U-Net backbone with transformers</li> <li>Analyzed scalability properties</li> <li>Repository: https://github.com/facebookresearch/DiT/tree/main</li> </ul>"},{"location":"book/chapter7_diffusion/DiT/#1-diffusion-transformer-design","title":"1. Diffusion Transformer Design","text":"<p>The transformer diffusion is also trained with the latent diffusion model. Thus, the transformer diffusion is designed on the latent space.</p>"},{"location":"book/chapter7_diffusion/DiT/#11-patchify","title":"1.1 Patchify","text":"<ul> <li>Converts spatial input into a sequence of \\(T\\) tokens.</li> <li>Suppose the input size is [64, 64, 4], \\(p=16\\). For each \\(16\\times16\\) square, we flatten it into a single token with a linear embedding layer. In total, we obtain \\(64\\times 64 / (p^2) = 16\\) tokens. The output shape should be [16, d].</li> <li>In the design, the patch size \\(p\\) is regarded as a parameter.</li> </ul> <p>We can use <code>conv2d</code> to perform patchification, followed by flattening and transposing to reshape the output.</p> <pre><code>import torch\nimport torch.nn as nn\n# Define the patch size\npatch_size = 16\n# Create a convolutional layer to extract patches\n# The number of output channels (embedding_dim) is a hyperparameter\nembedding_dim = 768  # Example embedding dimension\npatchify = nn.Conv2d(\n    in_channels=4,       # Number of input channels\n    out_channels=embedding_dim,  # Embedding dimension\n    kernel_size=patch_size,      # Size of each patch\n    stride=patch_size            # Stride to ensure non-overlapping patches\n)\n# Example input tensor with shape (batch_size, channels, height, width)\nbatch_size = 8  # Example batch size\ninput_tensor = torch.randn(batch_size, 4, 64, 64)  # Random input tensor\n# Apply the patchify operation\npatches = patchify(input_tensor)  # Shape: (batch_size, embedding_dim, 4, 4)\n# Reshape patches to (batch_size, num_patches, embedding_dim)\n# Here, num_patches = (64 / 16) * (64 / 16) = 4 * 4 = 16\npatches = patches.flatten(2)  # Shape: (batch_size, embedding_dim, num_patches)\npatches = patches.transpose(1, 2)  # Shape: (batch_size, num_patches, embedding_dim)\nprint(patches.shape)  # Output: torch.Size([batch_size, 16, 768])\n</code></pre>"},{"location":"book/chapter7_diffusion/DiT/#12-positional-encoding","title":"1.2 Positional Encoding","text":"<p>Similar to the standard sine-cosine positional encoding, we can also use <code>conv2d</code> for positional encoding.</p> <pre><code>import torch\nimport torch.nn as nn\nimport math\n\nclass PositionalEncoding(nn.Module):\n    def __init__(self, d_model, max_len=5000):\n        super(PositionalEncoding, self).__init__()\n        # Create a matrix of shape (max_len, d_model) to hold the positional encodings\n        pe = torch.zeros(max_len, d_model)\n        # Position indices (0, 1, 2, ..., max_len-1)\n        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n        # Compute the div_term for the exponential function\n        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n        # Apply sine to even indices in the array; 2i\n        pe[:, 0::2] = torch.sin(position * div_term)\n        # Apply cosine to odd indices in the array; 2i+1\n        pe[:, 1::2] = torch.cos(position * div_term)\n        # Add a batch dimension\n        pe = pe.unsqueeze(0)\n        # Register pe as a buffer to prevent it from being considered a model parameter\n        self.register_buffer('pe', pe)\n\n    def forward(self, x):\n        # Add positional encoding to the input tensor\n        x = x + self.pe[:, :x.size(1), :]\n        return x\n</code></pre> <p>In transformer models, positional encoding is used to inject information about the position of tokens in a sequence, as the model itself doesn't inherently capture positional information. A common method is to use sinusoidal functions to generate these encodings. The formulas for sine and cosine positional encodings are as follows:</p> <p>For a given position \\( \\text{pos} \\) and embedding dimension \\( i \\):</p> <ul> <li>When \\( i \\) is even:</li> </ul> \\[ \\text{PE}(\\text{pos}, i) = \\sin\\left(\\frac{\\text{pos}}{10000^{\\frac{i}{d_{\\text{model}}}}}\\right) \\] <ul> <li>When \\( i \\) is odd:</li> </ul> \\[ \\text{PE}(\\text{pos}, i) = \\cos\\left(\\frac{\\text{pos}}{10000^{\\frac{i}{d_{\\text{model}}}}}\\right) \\] <p>Here, \\( d_{\\text{model}} \\) represents the dimensionality of the model's embeddings. These functions use different frequencies to encode each dimension, allowing the model to distinguish between different positions in the sequence. This approach was introduced in the \"Attention Is All You Need\" paper.</p>"},{"location":"book/chapter7_diffusion/DiT/#2-dit-block-design","title":"2. DiT Block Design","text":"<p>The core challenge is to design how to incorporate conditional information such as:</p> <ul> <li>Timestep \\(t\\)</li> <li>Class label \\(c\\)</li> <li>Guided text</li> <li>Guided spatial information such as depth, etc.</li> </ul> <p>To implement this, the paper designs four different blocks to accept the conditions.</p>"},{"location":"book/chapter7_diffusion/DiT/#21-in-context-conditioning","title":"2.1 In-context Conditioning","text":"<p>Similar to the <code>cls</code> token in ViT, treat the embeddings of \\(t\\) and \\(c\\) as two additional tokens in the input sequence:</p> \\[ [e_t, e_c, \\text{patch}_1, \\text{patch}_2, ..., \\text{patch}_N] \\] <p>Then the input sequence is passed through a transformer encoder to extract context information.</p>"},{"location":"book/chapter7_diffusion/DiT/#22-cross-attention-block","title":"2.2 Cross Attention Block","text":"<p>Similar to the Latent Diffusion latent diffusion hands-on</p> <p></p> <p></p> <p>The \\(t\\) and \\(c\\) are concatenated as a length-two sequence and act as \\(K\\) and \\(V\\) in the cross-attention block, as shown in the above picture.</p>"},{"location":"book/chapter7_diffusion/DiT/#23-adaptive-layer-norm-adaln","title":"2.3 Adaptive Layer Norm (adaLN)","text":"<p>Borrowing ideas from StyleGAN's AdaIN, here is a comparison of Adaptive Layer Normalization (adaLN) in DiT and Adaptive Instance Normalization (AdaIN) in StyleGAN in tabular format:</p> Feature adaLN (DiT) AdaIN (StyleGAN) Purpose Modulates transformer layers based on conditioning input (e.g., class labels, text embeddings). Transfers style by aligning content feature statistics to match style feature statistics. Normalization Scope Normalizes across the entire layer (layer normalization). Normalizes each feature channel independently per instance. (instance normalization) Mathematical Formula \\( o_i = \\gamma(y) \\cdot \\frac{x_i - \\mu}{\\sigma + \\epsilon} + \\beta(y) \\) \\( o_i = \\sigma(y) \\cdot \\frac{x_i - \\mu(x)}{\\sigma(x) + \\epsilon} + \\mu(y) \\) Parameter Modulation \\( \\gamma \\) and \\( \\beta \\) are dynamically generated from a conditioning input \\( y \\). \\( \\mu(y) \\) and \\( \\sigma(y) \\) are extracted from the style input \\( y \\). Dependency Learns conditioning through a neural network (e.g., MLP). Uses statistics (mean &amp; variance) directly from the style input. Application Used in transformer-based models like DiT to condition the model on auxiliary data (e.g., text, class labels). Used in StyleGAN for style transfer and control of image synthesis. <p>Here <code>adaLN_modulation</code> predicts the parameters \\(\\alpha_1\\), \\(\\alpha_2\\), \\(\\beta_1\\), \\(\\beta_2\\), \\(\\gamma_1\\), \\(\\gamma_2\\).</p> <p>The DiTBlock with Adaptive Layer Norm Zero (adaLN-Zero) can be mathematically represented by the following function:</p> \\[ (S_{\\text{MSA}}, \\alpha_{\\text{MSA}}, G_{\\text{MSA}}, S_{\\text{MLP}}, \\alpha_{\\text{MLP}}, G_{\\text{MLP}}) = f_{\\text{adaLN}}(C) \\] <ul> <li>Self attention</li> </ul> \\[  X' = X + G_{\\text{MSA}} \\cdot \\text{MSA} \\left( \\alpha_{\\text{MSA}} \\cdot \\frac{X - \\mu_X}{\\sigma_X + \\epsilon} + S_{\\text{MSA}} \\right) \\] <ul> <li>Feedforward (MLP) Update</li> </ul> \\[  X'' = X' + G_{\\text{MLP}} \\cdot \\text{MLP} \\left( \\alpha_{\\text{MLP}} \\cdot \\frac{X' - \\mu_{X'}}{\\sigma_{X'} + \\epsilon} + S_{\\text{MLP}} \\right) \\]"},{"location":"book/chapter7_diffusion/DiT/#24-adaln-zero-initialization","title":"2.4 adaLN Zero Initialization","text":"<p>Assuming that zero initialization for residual networks is beneficial, we add the parameter \\(scale\\) to control the effects of adaLN. Initially, we set all the parameters of linear layers to 0.</p>"},{"location":"book/chapter7_diffusion/DiT/#25-overall-structure-of-dit","title":"2.5 Overall Structure of DiT","text":"<pre><code>  def forward(self, x, t, y):\n        \"\"\"\n        Forward pass of DiT.\n        x: (N, C, H, W) tensor of spatial inputs (images or latent representations of images)\n        t: (N,) tensor of diffusion timesteps\n        y: (N,) tensor of class labels\n        \"\"\"\n        x = self.x_embedder(x) + self.pos_embed  # (N, T, D), where T = H * W / patch_size ** 2\n        t = self.t_embedder(t)                   # (N, D)\n        y = self.y_embedder(y, self.training)    # (N, D)\n        c = t + y                                # (N, D)\n        for block in self.blocks:\n            x = block(x, c)                      # (N, T, D)\n        x = self.final_layer(x, c)                # (N, T, patch_size ** 2 * out_channels)\n        x = self.unpatchify(x)                   # (N, out_channels, H, W)\n        return x\n</code></pre> <p>The structure of DiT is quite simple:</p> <ol> <li>Patchify the input \\(x\\), which has the shape [B, C, H, W].</li> <li>Apply position embedding of shape [B, T, D] on the patched tokens.</li> <li>Apply class/label embedding of shape [B, D] on the patched tokens.</li> <li>Combine time and class embedding \\(c = t + y\\).</li> <li>Process through the attention blocks.</li> <li>Apply the final layer to re-patchify.</li> <li>Convert to the original shape [B, C', H, W].</li> </ol>"},{"location":"book/chapter7_diffusion/DiT/#3-results","title":"3. Results","text":"<ol> <li>Larger size improves FID.     </li> <li>With the same computational cost, larger models perform better.    </li> <li>State-of-the-art results</li> </ol>"},{"location":"book/chapter7_diffusion/ddpm/","title":"Diffusion Models","text":"<p>preliminary</p> <p>In order to have a fully understand of the diffusion model, it is recommend to have the knowledges of the following - Math   - derivatives   - partial derivatives   - chain rule   - multi variable function optimization -  Diffential Equation    -  Ordinary Differential Equation    -  SDE    -  It\u00f4 Integra and It\u00f4 Lemma</p>"},{"location":"book/chapter7_diffusion/ddpm/#1-understanding-denoising-diffusion-probabilistic-models-ddpm","title":"1. Understanding Denoising Diffusion Probabilistic Models (DDPM)","text":"<p>Generative models have revolutionized machine learning by enabling the creation of realistic data, from images to audio. Among these, Denoising Diffusion Probabilistic Models (DDPM) stand out for their simplicity, stability, and high-quality outputs. In this blog, we\u2019ll break down the theory behind DDPMs, their training process, and the intuition that makes them work.</p>"},{"location":"book/chapter7_diffusion/ddpm/#11-what-is-a-diffusion-model","title":"1.1 What is a Diffusion Model?","text":"<p>Diffusion models are inspired by non-equilibrium thermodynamics. The core idea is simple: gradually destroy data by adding noise (forward process), then learn to reverse this process to generate new data (reverse process). DDPMs formalize this intuition into a probabilistic framework.</p>"},{"location":"book/chapter7_diffusion/ddpm/#12-the-forward-process-gradually-adding-noise","title":"1.2 The Forward Process: Gradually Adding Noise","text":"<p>The forward process is a fixed Markov chain that slowly corrupts data over \\( T \\) timesteps. Given an input \\( x_0 \\) (e.g., an image), we define a sequence \\( x_1, x_2, \\dots, x_T \\), where each step adds Gaussian noise according to a schedule \\( \\beta_1, \\beta_2, \\dots, \\beta_T \\).</p>"},{"location":"book/chapter7_diffusion/ddpm/#121-mathematically","title":"1.2.1 Mathematically","text":"<p>At each timestep \\( t \\), $$ q(x_t | x_{t-1}) = \\mathcal{N}(x_t; \\sqrt{1-\\beta_t} x_{t-1}, \\beta_t \\mathbf{I}) $$ This means \\( x_t \\) is a noisy version of \\( x_{t-1} \\), with variance \\( \\beta_t \\).</p>"},{"location":"book/chapter7_diffusion/ddpm/#122-reparameterization-trick","title":"1.2.2 Reparameterization Trick","text":"<p>We can directly compute \\( x_t \\) from \\( x_0 \\) in closed form: $$ x_t = \\sqrt{\\alpha_t} x_0 + \\sqrt{1 - \\alpha_t} \\epsilon, \\quad \\epsilon \\sim \\mathcal{N}(0, \\mathbf{I}) $$ where \\( \\alpha_t = \\prod_{i=1}^t (1 - \\beta_i) \\). This accelerates training by avoiding iterative sampling.</p>"},{"location":"book/chapter7_diffusion/ddpm/#13-the-reverse-process-learning-to-denoise","title":"1.3 The Reverse Process: Learning to Denoise","text":"<p>The goal is to learn a neural network \\( \\theta \\) that reverses the forward process. Starting from noise \\( x_T \\sim \\mathcal{N}(0, \\mathbf{I}) \\), the model iteratively denoises \\( x_t \\) to \\( x_{t-1} \\).</p>"},{"location":"book/chapter7_diffusion/ddpm/#131-reverse-distribution","title":"1.3.1 Reverse Distribution","text":"<p>$$ p_\\theta(x_{t-1} | x_t) = \\mathcal{N}(x_{t-1}; \\mu_\\theta(x_t, t), \\Sigma_\\theta(x_t, t)) $$ In practice, \\( \\Sigma_\\theta \\) is often fixed to \\( \\sigma_t^2 \\mathbf{I} \\), and the network predicts the mean \\( \\mu_\\theta \\).</p>"},{"location":"book/chapter7_diffusion/ddpm/#132-key-insight","title":"1.3.2 Key Insight","text":"<p>Instead of directly predicting \\( x_{t-1} \\), the network predicts the noise \\( \\epsilon \\) added at each step. This simplifies training and improves stability.</p>"},{"location":"book/chapter7_diffusion/ddpm/#14-training-objective-variational-bound","title":"1.4 Training Objective: Variational Bound","text":"<p>The loss function is derived from the variational lower bound (ELBO) of the log-likelihood: $$ \\mathbb{E}{q(x \\right] $$ After simplification, the objective reduces to: $$ \\mathcal{L} = \\mathbb{E}}|x_0)} \\left[ \\log \\frac{q(x_{1:T}|x_0)}{p_\\theta(x_{0:T}){t, x_0, \\epsilon} \\left[ | \\epsilon - \\epsilon\\theta(x_t, t) |^2 \\right] $$ where \\( \\epsilon_\\theta \\) is the network predicting noise. Minimizing this loss trains the model to reverse the diffusion process.</p>"},{"location":"book/chapter7_diffusion/ddpm/#15-intuition-behind-ddpm","title":"1.5 Intuition Behind DDPM","text":""},{"location":"book/chapter7_diffusion/ddpm/#151-noise-as-a-scaffold","title":"1.5.1 Noise as a Scaffold","text":"<p>By iteratively removing noise, the model refines its output from coarse to fine details, akin to an artist sketching and refining a painting.</p>"},{"location":"book/chapter7_diffusion/ddpm/#152-stability-via-small-steps","title":"1.5.2 Stability via Small Steps","text":"<p>Unlike GANs, which can suffer from mode collapse, DDPMs break generation into many small, stable denoising steps.</p>"},{"location":"book/chapter7_diffusion/ddpm/#153-connection-to-score-matching","title":"1.5.3 Connection to Score Matching","text":"<p>DDPMs implicitly learn the gradient of the data distribution (score function), guiding the denoising process toward high-probability regions.</p>"},{"location":"book/chapter7_diffusion/ddpm/#16-sampling-generation","title":"1.6 Sampling (Generation)","text":"<p>To generate data:</p> <ol> <li>Sample \\( x_T \\sim \\mathcal{N}(0, \\mathbf{I}) \\).</li> <li>For \\( t = T, \\dots, 1 \\):</li> <li>Predict \\( \\epsilon_\\theta(x_t, t) \\).</li> <li>Compute \\( x_{t-1} = \\frac{1}{\\sqrt{\\alpha_t}} \\left( x_t - \\frac{\\beta_t}{\\sqrt{1 - \\alpha_t}} \\epsilon_\\theta \\right) + \\sigma_t z \\), where \\( z \\sim \\mathcal{N}(0, \\mathbf{I}) \\).</li> </ol>"},{"location":"book/chapter7_diffusion/ddpm/#17-why-ddpms-work","title":"1.7 Why DDPMs Work","text":"<ul> <li>Robust Training: The per-timestep noise prediction task is easier to learn than modeling the full data distribution at once.</li> <li>High Flexibility: The iterative process allows capturing complex dependencies in data.</li> <li>No Adversarial Training: Unlike GANs, DDPMs avoid unstable min-max optimization.</li> </ul>"},{"location":"book/chapter7_diffusion/ddpm/#18-limitations","title":"1.8 Limitations","text":"<ul> <li>Slow Sampling: Generating samples requires \\( T \\) steps (often \\( T \\sim 1000 \\)).</li> <li>Fixed Noise Schedule: Poorly chosen \\( \\beta_t \\) can harm performance.</li> </ul>"},{"location":"book/chapter7_diffusion/ddpm/#19-summarization","title":"1.9 Summarization","text":"<p>Here\u2019s a concise summary of the key formulas in Denoising Diffusion Probabilistic Models (DDPM), focusing on the forward/reverse processes, noise schedules, and critical relationships:</p>"},{"location":"book/chapter7_diffusion/ddpm/#191-1-forward-process-noise-addition","title":"1.9.1 1. Forward Process (Noise Addition)","text":"<p>Gradually corrupts data \\( x_0 \\) over \\( T \\) steps via a fixed Markov chain.</p> <ul> <li>Conditional distribution:</li> </ul> <p>$$   q(x_t | x_{t-1}) = \\mathcal{N}\\left(x_t; \\sqrt{1-\\beta_t} x_{t-1}, \\beta_t \\mathbf{I}\\right)   $$</p> <ul> <li> <p>\\( \\beta_t \\): Predefined noise schedule (small values increasing with \\( t \\)).</p> </li> <li> <p>Reparameterization (direct sampling from \\( x_0 \\)):   $$   x_t = \\sqrt{\\alpha_t} x_0 + \\sqrt{1 - \\alpha_t} \\epsilon, \\quad \\epsilon \\sim \\mathcal{N}(0, \\mathbf{I})   $$</p> </li> <li>\\( \\alpha_t = \\prod_{i=1}^t (1-\\beta_i) \\): Cumulative product of \\( 1-\\beta_i \\).</li> <li>\\( \\sqrt{\\alpha_t} \\): Signal retention coefficient.</li> <li>\\( \\sqrt{1-\\alpha_t} \\): Noise scaling coefficient.</li> </ul>"},{"location":"book/chapter7_diffusion/ddpm/#192-2-reverse-process-denoising","title":"1.9.2 2. Reverse Process (Denoising)","text":"<p>Learns to invert the forward process using a neural network \\( \\epsilon_\\theta \\).</p> <ul> <li>Reverse distribution:</li> </ul> <p>$$   p_\\theta(x_{t-1} | x_t) = \\mathcal{N}\\left(x_{t-1}; \\mu_\\theta(x_t, t), \\sigma_t^2 \\mathbf{I}\\right)   $$</p> <ul> <li>\\( \\mu_\\theta \\): Predicted mean, derived from noise estimate \\( \\epsilon_\\theta \\).</li> <li> <p>\\( \\sigma_t^2 \\): Fixed to \\( \\beta_t \\) (original DDPM) or \\( \\frac{1-\\alpha_{t-1}}{1-\\alpha_t}\\beta_t \\).</p> </li> <li> <p>Mean prediction:</p> </li> </ul> <p>$$   \\mu_\\theta(x_t, t) = \\frac{1}{\\sqrt{\\alpha_t}} \\left( x_t - \\frac{\\beta_t}{\\sqrt{1-\\alpha_t}} \\epsilon_\\theta(x_t, t) \\right)   $$</p>"},{"location":"book/chapter7_diffusion/ddpm/#193-3-training-objective","title":"1.9.3 3. Training Objective","text":"<p>Simplified loss derived from variational bound (ELBO):</p> \\[ \\mathcal{L} = \\mathbb{E}_{t, x_0, \\epsilon} \\left[ \\| \\epsilon - \\epsilon_\\theta(x_t, t) \\|^2 \\right] \\] <ul> <li>\\( \\epsilon \\sim \\mathcal{N}(0, \\mathbf{I}) \\): Ground-truth noise added at step \\( t \\).</li> <li>\\( \\epsilon_\\theta \\): Neural network predicting noise in \\( x_t \\).</li> </ul>"},{"location":"book/chapter7_diffusion/ddpm/#194-4-sampling-generation","title":"1.9.4 4. Sampling (Generation)","text":"<p>Starts from \\( x_T \\sim \\mathcal{N}(0, \\mathbf{I}) \\) and iteratively denoises: $$ x_{t-1} = \\frac{1}{\\sqrt{\\alpha_t}} \\left( x_t - \\frac{\\beta_t}{\\sqrt{1-\\alpha_t}} \\epsilon_\\theta(x_t, t) \\right) + \\sigma_t z, \\quad z \\sim \\mathcal{N}(0, \\mathbf{I}) $$</p> <ul> <li>\\( \\sigma_t = \\sqrt{\\beta_t} \\): Controls stochasticity (set to 0 for deterministic sampling in DDIM).</li> <li>At \\( t=1 \\), the \\( \\sigma_t z \\) term is omitted.</li> </ul>"},{"location":"book/chapter7_diffusion/ddpm/#195-5-key-relationships","title":"1.9.5 5. Key Relationships","text":"<ul> <li>Cumulative noise: \\( \\alpha_t = \\prod_{i=1}^t (1-\\beta_i) \\).</li> <li>Signal-to-noise ratio (SNR): \\( \\text{SNR}_t = \\frac{\\alpha_t}{1-\\alpha_t} \\).</li> <li>Noise schedule: \\( \\beta_t \\) is often linear or cosine-based (e.g., \\( \\beta_t \\in [10^{-4}, 0.02] \\)).</li> </ul>"},{"location":"book/chapter7_diffusion/ddpm/#196-6-intuition","title":"1.9.6 6. Intuition","text":"<ul> <li>\\( \\alpha_t \\): Decays monotonically, controlling how much signal remains at step \\( t \\).</li> <li>\\( \\beta_t \\): Balances noise addition speed (small \\( \\beta_t \\) = slow corruption).</li> <li>\\( \\epsilon_\\theta \\): Predicts the noise to subtract, steering \\( x_t \\) toward high-probability regions.</li> </ul> <p>DDPMs hinge on:</p> <ol> <li>Forward process equations for efficient training.</li> <li>Noise prediction (\\( \\epsilon_\\theta \\)) and simplified loss.</li> <li>Sampling via iterative denoising with \\( \\alpha_t, \\beta_t, \\sigma_t \\).</li> </ol> <p>DDPMs offer a elegant framework for generation by iteratively denoising data. Their simplicity, stability, and quality have made them a cornerstone of modern generative AI. In future posts, we\u2019ll explore accelerated variants like DDIM and extensions like Latent Diffusion Models (LDM). Stay tuned!</p>"},{"location":"book/chapter7_diffusion/ddpm/#2-references","title":"2. References","text":"<ol> <li>Ho et al., Denoising Diffusion Probabilistic Models (2020).</li> <li> <p>Sohl-Dickstein et al., Deep Unsupervised Learning Using Nonequilibrium Thermodynamics (2015).</p> </li> <li> <p>Denoising Diffusion Probabilistic Models (DDPM)</p> </li> <li> <p>Improved Denoising Diffusion Probabilistic Models</p> </li> <li> <p>Diffusion Models Beat GANs on Image Synthesis</p> </li> <li> <p>Score-Based Generative Modeling through Stochastic Differential Equations</p> </li> <li> <p>Latent Diffusion Models  -</p> </li> <li> <p>Understanding Diffusion Models: A Unified Perspective</p> </li> </ol>"},{"location":"book/chapter7_diffusion/diffusion_model_varients/","title":"Diffusion Model Variants","text":""},{"location":"book/chapter7_diffusion/diffusion_model_varients/#1-speed-up-sampling","title":"1. SPeed up Sampling","text":""},{"location":"book/chapter7_diffusion/diffusion_model_varients/#11-progressive-distillation-for-fast-sampling-of-diffusion-models","title":"1.1 PROGRESSIVE DISTILLATION FOR FAST SAMPLING OF DIFFUSION MODELS","text":"<ul> <li> <p>paper: https://arxiv.org/pdf/2202.00512</p> </li> <li> <p>Author:</p> <p>Tim Salimans</p> <ul> <li> <p>\u804c\u4e1a\u80cc\u666f\uff1a       Tim Salimans \u662f\u77e5\u540d\u7684\u751f\u6210\u6a21\u578b\u7814\u7a76\u8005\uff0c\u66fe\u5728 OpenAI \u5de5\u4f5c\uff0c\u5bf9\u6df1\u5ea6\u751f\u6210\u6a21\u578b\uff08\u5982 GANs \u548c\u6269\u6563\u6a21\u578b\uff09\u7684\u8bad\u7ec3\u548c\u7a33\u5b9a\u6027\u6539\u8fdb\u6709\u91cd\u8981\u8d21\u732e\u3002\u4ed6\u5728\u591a\u4e2a\u5f71\u54cd\u6df1\u8fdc\u7684\u5de5\u4f5c\u4e2d\u62c5\u4efb\u6838\u5fc3\u89d2\u8272\uff0c\u4f8b\u5982\u5728\u6539\u8fdb GAN \u8bad\u7ec3\u6280\u672f\u65b9\u9762\u7684\u5de5\u4f5c\uff08\u4f8b\u5982 \u201cImproved Techniques for Training GANs\u201d\uff09\u4e2d\u5747\u6709\u8d21\u732e\u3002</p> </li> <li> <p>\u7814\u7a76\u65b9\u5411\uff1a     \u4e3b\u8981\u805a\u7126\u4e8e\u6df1\u5ea6\u751f\u6210\u6a21\u578b\u3001\u6982\u7387\u5efa\u6a21\u4ee5\u53ca\u9ad8\u6548\u7684\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u65b9\u6cd5\u3002\u4ed6\u7684\u5de5\u4f5c\u7ecf\u5e38\u63a2\u7d22\u5982\u4f55\u5229\u7528\u566a\u58f0\u3001\u6b63\u5219\u5316\u4ee5\u53ca\u5148\u8fdb\u7684\u4f18\u5316\u6280\u5de7\u6765\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002</p> </li> <li> <p>\u5b66\u672f\u4e0e\u5de5\u4e1a\u7ecf\u5386\uff1a     \u5728\u52a0\u5165 OpenAI \u524d\uff0cTim Salimans \u4e5f\u66fe\u5728\u5b66\u672f\u754c\u6216\u5176\u4ed6\u7814\u7a76\u673a\u6784\u79ef\u7d2f\u7ecf\u9a8c\uff0c\u5176\u7814\u7a76\u6210\u679c\u53d1\u8868\u5728\u673a\u5668\u5b66\u4e60\u548c\u4eba\u5de5\u667a\u80fd\u9886\u57df\u7684\u91cd\u8981\u4f1a\u8bae\u548c\u671f\u520a\u4e0a\u3002\u5173\u4e8e\u4ed6\u7684\u8be6\u7ec6\u6559\u80b2\u80cc\u666f\u548c\u5de5\u4f5c\u5c65\u5386\uff0c\u53ef\u53c2\u8003\u5176\u516c\u5f00\u7684\u7b80\u5386\u6216\u4e2a\u4eba\u4e3b\u9875\uff08\u5982\u6709\u516c\u5f00\uff09\u3002</p> </li> </ul> <p>Jonathan Ho</p> <ul> <li> <p>\u804c\u4e1a\u80cc\u666f\uff1a     Jonathan Ho \u662f\u6269\u6563\u6a21\u578b\u9886\u57df\u7684\u91cd\u8981\u4eba\u7269\uff0c\u4ee5\u5176\u5728\u751f\u6210\u6a21\u578b\u4e2d\u7684\u6269\u6563\u8fc7\u7a0b\u7814\u7a76\u800c\u5e7f\u4e3a\u4eba\u77e5\u3002\u4ed6\u662f\u300aDenoising Diffusion Probabilistic Models\u300b\u8fd9\u7bc7\u5f00\u521b\u6027\u8bba\u6587\u7684\u7b2c\u4e00\u4f5c\u8005\uff0c\u8be5\u8bba\u6587\u5960\u5b9a\u4e86\u57fa\u4e8e\u6269\u6563\u8fc7\u7a0b\u7684\u751f\u6210\u6a21\u578b\u65b9\u6cd5\u7684\u7406\u8bba\u57fa\u7840\uff0c\u5e76\u5bf9\u540e\u7eed\u5de5\u4f5c\u4ea7\u751f\u4e86\u6df1\u8fdc\u5f71\u54cd\u3002</p> </li> <li> <p>\u7814\u7a76\u65b9\u5411\uff1a     \u4e3b\u8981\u4e13\u6ce8\u4e8e\u6982\u7387\u751f\u6210\u6a21\u578b\u548c\u6269\u6563\u6a21\u578b\u7684\u7406\u8bba\u4e0e\u5e94\u7528\uff0c\u63a2\u7d22\u5982\u4f55\u901a\u8fc7\u9010\u6b65\u201c\u53bb\u566a\u201d\u7684\u65b9\u5f0f\u5c06\u7b80\u5355\u7684\u566a\u58f0\u5206\u5e03\u8f6c\u6362\u4e3a\u590d\u6742\u7684\u6570\u636e\u5206\u5e03\u3002\u4ed6\u7684\u5de5\u4f5c\u5e2e\u52a9\u63a8\u52a8\u4e86\u6269\u6563\u6a21\u578b\u5728\u56fe\u50cf\u751f\u6210\u7b49\u4efb\u52a1\u4e0a\u7684\u5e7f\u6cdb\u5e94\u7528\u3002</p> </li> <li> <p>\u5b66\u672f\u4e0e\u673a\u6784\u80cc\u666f\uff1a     \u6839\u636e\u8bba\u6587\u7f72\u540d\u548c\u516c\u5f00\u4fe1\u606f\uff0cJonathan Ho \u66fe\u4e0e\u5305\u62ec Pieter Abbeel \u7b49\u77e5\u540d\u5b66\u8005\u5408\u4f5c\uff0c\u5176\u8bba\u6587\u53d1\u5e03\u65f6\u7684\u673a\u6784\u80cc\u666f\uff08\u5982\u52a0\u5dde\u5927\u5b66\u4f2f\u514b\u5229\u5206\u6821\u7684BAIR\u5b9e\u9a8c\u5ba4\u6216\u5176\u4ed6\u673a\u6784\uff09\u4e3a\u4ed6\u5728\u751f\u6210\u6a21\u578b\u9886\u57df\u5960\u5b9a\u4e86\u575a\u5b9e\u7684\u57fa\u7840\u3002\u66f4\u591a\u8be6\u7ec6\u7684\u5c65\u5386\u4fe1\u606f\u53ef\u53c2\u8003\u5176\u5728\u8bba\u6587\u4e2d\u7684\u4f5c\u8005\u4fe1\u606f\u6216\u5176\u516c\u5f00\u7684\u4e2a\u4eba\u7b80\u4ecb\u3002</p> </li> </ul> </li> </ul> <p>The main idea of this paper is two use teacher model to distill student model with fewer sampling steps.</p> <p>Which is similar to the DDIM idea to device the total steps \\(N\\) by half iteratively as illusrated as the following figure</p> <p></p> <p>The Algorithm states </p> <p>\u4ee3\u7801\u4e2d\u7684\u5173\u952e\u70b9\uff1a</p> <ol> <li> <p>\u6559\u5e08-\u5b66\u751f\u6846\u67b6\uff1a</p> </li> <li> <p>\u521d\u59cb\u6559\u5e08\u6a21\u578b\u7ecf\u8fc7\u591a\u4e2a\u91c7\u6837\u6b65\u9aa4\uff08\u4f8b\u5982 \\(T\\) \u6b65\uff09\u751f\u6210\u6570\u636e\u3002</p> </li> <li> <p>\u5b66\u751f\u6a21\u578b\u88ab\u8bad\u7ec3\u5728\u66f4\u5c11\u7684\u6b65\u6570\uff08\u4f8b\u5982 \\(T/2\\) \u6b65\uff09\u5185\u590d\u73b0\u6559\u5e08\u6a21\u578b\u7684\u91c7\u6837\u884c\u4e3a\u3002</p> </li> <li> <p>\u4f2a\u6807\u7b7e\u751f\u6210\uff1a</p> </li> <li> <p>\u5bf9\u4e8e\u6bcf\u4e2a\u8bad\u7ec3\u6837\u672c\uff0c\u901a\u8fc7\u6559\u5e08\u6a21\u578b\u8fdb\u884c\u591a\u6b65\u91c7\u6837\uff08\u8fd9\u91cc\u4e00\u822c\u6a21\u62df 2 \u6b65\u8fc7\u7a0b\uff09\u83b7\u5f97\u4f2a\u76ee\u6807\uff08\\(x_{\\text{teacher}}\\)\uff09\u3002</p> </li> <li> <p>\u5b66\u751f\u6a21\u578b\u4ee5\u66f4\u5c11\u7684\u6b65\u6570\u751f\u6210\u9884\u6d4b\uff08\\(x_{\\text{student}}\\)\uff09\uff0c\u7136\u540e\u901a\u8fc7\u635f\u5931\u51fd\u6570\u903c\u8fd1\u4f2a\u76ee\u6807\u3002</p> </li> <li> <p>\u9010\u6b65\u9012\u51cf\u6b65\u6570\uff1a</p> </li> <li> <p>\u6bcf\u6b21\u5b8c\u6210\u84b8\u998f\u540e\uff0c\u66f4\u65b0\u6559\u5e08\u6a21\u578b\u4e3a\u5f53\u524d\u5b66\u751f\u6a21\u578b\uff0c\u5e76\u5c06\u91c7\u6837\u6b65\u6570\u51cf\u534a\u3002</p> </li> <li> <p>\u53cd\u590d\u8fed\u4ee3\uff0c\u76f4\u5230\u8fbe\u5230\u9884\u8bbe\u7684\u5c11\u6b65\u91c7\u6837\u76ee\u6807\uff0c\u4ece\u800c\u6781\u5927\u52a0\u5feb\u91c7\u6837\u901f\u5ea6\u3002</p> </li> </ol>"},{"location":"book/chapter7_diffusion/diffusion_model_varients/#2-references-ddpm-speed-up-methods","title":"2. References: DDPM speed up methods","text":""},{"location":"book/chapter7_diffusion/from_ddpm_2_sde/","title":"Stochastic Differential Equation for DDPM","text":"<p>In this section, we will explore how Stochastic Differential Equations (SDEs) are connected to the denoising diffusion probabilistic model and the denoising score matching.</p>"},{"location":"book/chapter7_diffusion/from_ddpm_2_sde/#1-forward-diffusion-process","title":"1. Forward Diffusion Process","text":"<p>The forward diffusion process is described by a stochastic differential equation (SDE) that gradually adds noise to the data. The general form of this forward SDE is:</p> \\[  \\tag{1} dx \\;=\\; f(x,t)\\,dt \\;+\\; g(t)\\,dW_t \\] <p>where:</p> <ul> <li>\\(f(x,t)\\) is the drift term that controls the deterministic evolution</li> <li>\\(g(t)\\) is the diffusion coefficient that modulates the noise intensity</li> <li>\\(W_t\\) represents a standard Wiener process (Brownian motion)</li> <li>\\(p_t(x)\\) denotes the probability density of the state \\(x\\) at time \\(t\\)</li> </ul> <p>For simplicity, we assume \\(g(t)\\) depends only on time, not space, though it may vary throughout the diffusion process.</p>"},{"location":"book/chapter7_diffusion/from_ddpm_2_sde/#2-reverse-diffusion-process","title":"2. Reverse Diffusion Process","text":"<p>The reverse diffusion process describes how we can recover the original data distribution by reversing the noise addition process. For a system with probability density \\(p_t(x)\\) at time \\(t\\), the Fokker-Planck equation yields the following reverse SDE:</p> \\[ \\tag{2}  dx \\;=\\; \\bigl[f(x,t)\\;-\\;g(t)^2\\,\\nabla_x \\log p_{t}(x)\\bigr]\\;dt \\;+\\; g(t)\\,d\\overline{W}_t \\] <p>This equation has two key components:</p> <ol> <li>A drift term \\(f(x,t)\\) from the forward process</li> <li>A score-based correction term \\(-g(t)^2\\,\\nabla_x \\log p_{t}(x)\\) that guides the system toward higher probability regions</li> </ol> <p>In the following sections, we'll derive this backward diffusion equation and explain why it correctly describes the time-reversal of our forward process.</p>"},{"location":"book/chapter7_diffusion/from_ddpm_2_sde/#21-fokkerplanck-forward-kolmogorov-equation","title":"2.1 Fokker\u2013Planck (Forward Kolmogorov) Equation","text":"<p>The density \\(p_t(x)\\) satisfies the Fokker\u2013Planck (or forward\u2010Kolmogorov) PDE</p> \\[\\tag{3}  \\frac{\\partial p_t(x)}{\\partial t} \\;=\\; -\\nabla\\!\\cdot\\!\\bigl[f(x,t)\\,p_t(x)\\bigr] \\;+\\; \\frac{1}{2}\\,g(t)^2\\,\\Delta p_t(x), \\] <p>where \\(\\Delta\\) is the Laplacian in \\(x\\).</p> <p>note</p> <p>In one dimension , the Laplacian simplifies to:</p> \\[ \\Delta p_t(x) = \\frac{\\partial^2 p_t(x)}{\\partial x^2} \\] <p>In higher dimensions , the Laplacian is given by:</p> \\[ \\Delta p_t(x) = \\sum_{i=1}^{d} \\frac{\\partial^2 p_t(x)}{\\partial x_i^2} \\] <p>where \\(d\\) is the dimension of the space. Thus, in the context of the Fokker-Planck equation, the Laplacian term governs the diffusive spreading  of the probability density due to the noise term \\(g(t) dW_t\\) in the associated SDE.</p> <p>Importance of the Fokker-Planck Equation</p> <p>The Fokker-Planck equation (also known as the forward Kolmogorov equation) is a fundamental equation that describes the temporal evolution of probability distributions in stochastic processes. Its significance spans multiple fields including physics, finance, biology, and chemistry. Here's why it's crucial:</p> <p>1. Evolution of Probability Distributions The Fokker-Planck equation computes the probability distribution of a system described by Stochastic Differential Equations (SDEs) at different time points, rather than tracking individual sample paths. This provides a complete statistical description of the system's behavior. This represents a fundamental shift in how we model system evolution: - In deterministic systems, we use Ordinary Differential Equations (ODEs) to describe the evolution of states directly - In stochastic systems, we use the Fokker-Planck equation to describe how the Probability Density Function (PDF) of states evolves over time</p> <p>2. Bridging SDEs and Probability Distributions While Stochastic Differential Equations (SDEs) typically simulate individual sample paths, the Fokker-Planck equation provides a more comprehensive view of the probability distribution evolution: - SDE \u7ed9\u51fa\u7684\u662f\u968f\u673a\u8f68\u8ff9\uff0c\u800c Fokker-Planck \u65b9\u7a0b\u63d0\u4f9b\u4e86\u6574\u4f53\u7edf\u8ba1\u7279\u6027\u3002 - \u901a\u8fc7\u6c42\u89e3 Fokker-Planck \u65b9\u7a0b\uff0c\u53ef\u4ee5\u83b7\u5f97\u7cfb\u7edf\u7684\u7a33\u6001\u5206\u5e03\uff0c\u751a\u81f3\u9884\u6d4b\u5176\u957f\u671f\u884c\u4e3a\u3002</p> <p>3. \u9002\u7528\u4e8e\u591a\u4e2a\u79d1\u5b66\u9886\u57df Fokker-Planck \u65b9\u7a0b\u5728\u591a\u4e2a\u5b66\u79d1\u9886\u57df\u90fd\u5177\u6709\u5e7f\u6cdb\u5e94\u7528</p> <ul> <li>\u7edf\u8ba1\u7269\u7406\u4e0e\u70ed\u529b\u5b66<ul> <li>\u63cf\u8ff0\u5e03\u6717\u8fd0\u52a8\uff08\u7c92\u5b50\u5728\u6d41\u4f53\u4e2d\u7684\u6269\u6563\uff09\u3002</li> <li>\u7528\u4e8e\u6717\u4e4b\u4e07\u65b9\u7a0b\uff08Langevin equation\uff09\u7684\u6982\u7387\u63cf\u8ff0\uff0c\u7814\u7a76\u566a\u58f0\u5bf9\u7269\u7406\u7cfb\u7edf\u7684\u5f71\u54cd\u3002</li> <li>\u8ba1\u7b97\u975e\u5e73\u8861\u7cfb\u7edf\u7684\u7a33\u6001\u5206\u5e03\uff0c\u4f8b\u5982\u7535\u573a\u4e2d\u7684\u5e26\u7535\u7c92\u5b50\u8fd0\u52a8\u3002</li> </ul> </li> <li>\u751f\u7269\u5b66\u4e0e\u751f\u6001\u7cfb\u7edf<ul> <li>\u5728\u79cd\u7fa4\u52a8\u529b\u5b66\u4e2d\uff0c\u63cf\u8ff0\u968f\u673a\u73af\u5883\u4e0b\u7684\u79cd\u7fa4\u6f14\u5316\uff08\u5982\u968f\u673a Logistic \u6a21\u578b\uff09\u3002</li> <li>\u7814\u7a76\u795e\u7ecf\u5143\u653e\u7535\u4e2d\u7684\u968f\u673a\u6548\u5e94\uff08Fokker-Planck \u5f62\u5f0f\u7684\u795e\u7ecf\u52a8\u529b\u5b66\u6a21\u578b\uff09\u3002</li> <li>\u7814\u7a76\u86cb\u767d\u8d28\u6298\u53e0\u548c\u7ec6\u80de\u4fe1\u53f7\u4f20\u5bfc\u4e2d\u7684\u5206\u5b50\u566a\u58f0\u5f71\u54cd\u3002</li> </ul> </li> <li>\u91d1\u878d\u4e0e\u7ecf\u6d4e\u5b66<ul> <li>\u5728\u91d1\u878d\u6570\u5b66\u4e2d\uff0cFokker-Planck \u65b9\u7a0b\u4e0eBlack-Scholes \u65b9\u7a0b\uff08\u7528\u4e8e\u671f\u6743\u5b9a\u4ef7\uff09\u5bc6\u5207\u76f8\u5173\u3002</li> <li>\u63cf\u8ff0\u80a1\u7968\u4ef7\u683c\u5206\u5e03\uff0c\u5efa\u6a21\u5e02\u573a\u4e2d\u8d44\u4ea7\u4ef7\u683c\u7684\u6f14\u5316\u3002</li> <li>\u7528\u4e8e\u8ba1\u7b97\u98ce\u9669\u5206\u5e03\uff0c\u5206\u6790\u6295\u8d44\u7ec4\u5408\u7684\u957f\u671f\u6536\u76ca\u5206\u5e03\u3002</li> </ul> </li> <li>\u5316\u5b66\u4e0e\u5206\u5b50\u52a8\u529b\u5b66<ul> <li>\u7814\u7a76\u5316\u5b66\u53cd\u5e94\u4e2d\u7684\u968f\u673a\u8fc7\u7a0b\uff0c\u5982\u53cd\u5e94\u6269\u6563\u7cfb\u7edf\u3002</li> <li>\u5728\u5206\u5b50\u52a8\u529b\u5b66\u4e2d\uff0c\u63cf\u8ff0\u5e26\u566a\u58f0\u7684\u7c92\u5b50\u8fd0\u52a8\uff0c\u5982\u9ad8\u5206\u5b50\u6269\u6563\u3002</li> </ul> </li> </ul> <p>4. \u8ba1\u7b97\u7a33\u6001\u89e3\u4e0e\u52a8\u6001\u5206\u5e03 - \u5728\u957f\u65f6\u95f4\u6781\u9650\u4e0b\uff0cFokker-Planck \u65b9\u7a0b\u7684\u89e3\u53ef\u80fd\u8d8b\u4e8e\u7a33\u6001\u5206\u5e03\uff08\u5e73\u8861\u89e3\uff09\uff0c\u7528\u4e8e\u5206\u6790\u957f\u671f\u7a33\u5b9a\u6027\u3002 - \u5728\u77ed\u65f6\u95f4\u8303\u56f4\u5185\uff0c\u65b9\u7a0b\u63d0\u4f9b\u4e86\u65f6\u95f4\u6f14\u5316\u4fe1\u606f\uff0c\u5e2e\u52a9\u7814\u7a76\u7cfb\u7edf\u7684\u77ed\u671f\u884c\u4e3a\u3002</p> <p>\u603b\u7ed3 Fokker-Planck \u65b9\u7a0b\u662f\u968f\u673a\u52a8\u529b\u7cfb\u7edf\u7684\u6838\u5fc3\u5de5\u5177\uff0c\u80fd\u591f\u5728\u591a\u79cd\u79d1\u5b66\u548c\u5de5\u7a0b\u9886\u57df\u4e2d\u63d0\u4f9b\u6982\u7387\u5206\u5e03\u7684\u8be6\u7ec6\u63cf\u8ff0\u3002\u76f8\u6bd4\u5355\u7eaf\u4f7f\u7528 SDE \u8fdb\u884c\u6a21\u62df\uff0cFokker-Planck \u65b9\u7a0b\u63d0\u4f9b\u4e86\u66f4\u6df1\u5165\u7684\u6570\u5b66\u7406\u89e3\uff0c\u7279\u522b\u662f\u5728\u7a33\u6001\u5206\u6790\u3001\u5206\u5e03\u6f14\u5316\u4ee5\u53ca\u968f\u673a\u7cfb\u7edf\u957f\u671f\u884c\u4e3a\u9884\u6d4b\u65b9\u9762\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002</p> <p>\u2705 SDE \u63cf\u8ff0\u4e2a\u4f53\u884c\u4e3a\uff0c\u662f\u968f\u673a\u7684\u3002 \u2705 FPE \u63cf\u8ff0\u603b\u4f53\u6982\u7387\u5206\u5e03\uff0c\u662f\u786e\u5b9a\u7684\u3002 \u2705 FPE \u63d0\u4f9b\u4e86\u66f4\u7a33\u5b9a\u7684\u7cfb\u7edf\u63cf\u8ff0\uff0c\u53ef\u7528\u4e8e\u957f\u671f\u5206\u6790\u548c\u7a33\u6001\u8ba1\u7b97\u3002</p> <p>Now we prove that the reverse diffusion formula</p>"},{"location":"book/chapter7_diffusion/from_ddpm_2_sde/#22-strategy-diffusion-derivation","title":"2.2 Strategy Diffusion Derivation","text":"<p>We want an SDE whose sample paths \u201crun backward\u201d in time with the same distributions as \\((x_t)\\)  running forward. Concretely, define</p> \\[  \\hat{X}_s \\;=\\; x_{T - s} \\quad \\text{for } 0 \\le s \\le T. \\] <p>That is, \\(\\hat{X}_0 = x_{T}\\), \\(\\hat{X}_T = x_0\\). Our goal is to find a stochastic differential equation of the form</p> \\[  \\tag{4} d\\hat{X}_s \\;=\\; \\hat{f}\\bigl(\\hat{X}_s, s\\bigr)\\,ds \\;+\\; g(T-s)\\,d\\overline{W}_s \\] <p>(where \\(\\overline{W}_s\\) is another Wiener process) such that \\(\\hat{X}_s\\) has the same distribution as \\(x_{T-s}\\).In other words, if \\(q_s(x)\\) denotes the density of \\(\\hat{X}_s\\), we want \\(q_s(x) = p_{T-s}(x)\\). We must determine the drift \\(\\hat{f}(x,s)\\).</p>"},{"location":"book/chapter7_diffusion/from_ddpm_2_sde/#221-matching-probability-densities-via-fokkerplanck","title":"2.2.1 Matching Probability Densities via Fokker\u2013Planck","text":"<p>If \\(\\hat{X}_s\\) satisfies</p> \\[  d\\hat{X}_s = \\hat{f}(\\hat{X}_s, s)\\,ds \\;+\\; g(T-s)\\,d\\overline{W}_s, \\] <p>then its density \\(q_s(x)\\) obeys</p> \\[  \\frac{\\partial q_s(x)}{\\partial s} \\;=\\; -\\nabla \\cdot \\bigl[\\hat{f}(x, s)\\;q_s(x)\\bigr] \\;+\\; \\frac{1}{2}\\,g(T-s)^2\\;\\Delta\\,q_s(x). \\] <p>We require \\(q_s(x) = p_{T-s}(x)\\). Substitute \\(q_s(x) = p_{T-s}(x)\\) into the PDE. Note that</p> \\[  \\frac{\\partial}{\\partial s}\\,p_{T-s}(x) \\;=\\; -\\,\\frac{\\partial}{\\partial t}\\,p_{t}(x)\\Bigr|_{\\,t=T-s}. \\] <p>Hence</p> \\[  \\frac{\\partial q_s}{\\partial s}(x) \\;=\\; -\\,\\frac{\\partial}{\\partial t}\\,p_{t}(x)\\Bigr|_{t=T-s}. \\] <p>But from the forward Fokker\u2013Planck equation, we know</p> \\[  \\frac{\\partial}{\\partial t}\\,p_{t}(x) \\;=\\; -\\nabla\\!\\cdot\\!\\bigl[f(x,t)\\,p_t(x)\\bigr] +\\tfrac{1}{2}\\,g(t)^2\\,\\Delta\\,p_t(x). \\] <p>Putting \\(t = T-s\\) and changing the sign, we get</p> \\[  \\frac{\\partial q_s}{\\partial s}(x) \\;=\\; +\\nabla\\!\\cdot\\!\\bigl[f(x,T-s)\\,p_{T-s}(x)\\bigr] \\;-\\; \\tfrac{1}{2}\\,g(T-s)^2\\,\\Delta\\,p_{T-s}(x). \\] <p>Identifying the reversed drift \\(\\hat{f}\\) Meanwhile, from the PDE for \\(q_s\\) we also have</p> \\[ \\frac{\\partial q_s}{\\partial s}(x) \\;=\\; -\\,\\nabla\\!\\cdot\\!\\bigl[\\hat{f}(x,s)\\,q_s(x)\\bigr] \\;+\\; \\tfrac12\\,g(T-s)^2\\,\\Delta\\,q_s(x). \\] <p>Because \\(q_s(x) = p_{T-s}(x)\\), we can equate the two expressions. Matching terms gives</p> \\[ \\nabla\\!\\cdot\\!\\bigl[\\hat{f}(x,s)\\,p_{T-s}(x)\\bigr] \\;=\\; -\\,\\nabla\\!\\cdot\\!\\bigl[f(x,T-s)\\,p_{T-s}(x)\\bigr] \\;+\\; g(T-s)^2 \\,\\nabla \\!\\cdot\\!\\bigl[\\tfrac12\\,p_{T-s}(x)\\bigr], \\] <p>where we used that</p> \\[ \\Delta\\,p_{T-s}(x) = \\nabla \\cdot (\\nabla\\,p_{T-s}(x)) \\] <p>Rearrange:</p> \\[  \\nabla\\!\\cdot\\!\\Bigl[\\hat{f}(x,s)\\,p_{T-s}(x)\\Bigr] \\;=\\; -\\nabla\\!\\cdot\\!\\Bigl[f(x,T-s)\\,p_{T-s}(x)\\Bigr] \\;+\\; \\tfrac12\\,g(T-s)^2\\,\\nabla \\cdot\\!\\Bigl[\\nabla\\,p_{T-s}(x)\\Bigr]. \\] <p>We can factor out \\(p_{T-s}(x)\\) to write</p> \\[ \\hat{f}(x,s)\\,p_{T-s}(x) \\;=\\; f(x,T-s)\\,p_{T-s}(x) \\;-\\; \\tfrac12\\,g(T-s)^2\\,\\nabla\\,p_{T-s}(x) \\;+\\; \\text{(gradient\u2010free constant in } x\\text{)}, \\] <p>but the divergence\u2010free \u201cconstant\u201d in \\(x\\) must be zero if we want the correct boundary conditions at infinity and a well\u2010defined velocity field. Dividing both sides by \\(p_{T-s}(x)\\) then yields</p> \\[ \\hat{f}(x,s) \\;=\\; f(x,T-s) \\;-\\; \\tfrac12\\,g(T-s)^2\\,\\nabla \\log p_{T-s}(x). \\] <p>This is precisely the extra \u201cscore\u2010function\u201d correction term discovered by Nelson and Anderson.</p>"},{"location":"book/chapter7_diffusion/from_ddpm_2_sde/#222-final-reverse-sde","title":"2.2.2 Final Reverse SDE","text":"<p>Hence the reversed SDE can be written as</p> \\[ \\boxed{ d\\hat{X}_s \\;=\\; \\Bigl[ f(\\hat{X}_s,\\,T-s) \\;-\\; \\tfrac12\\,g(T-s)^2\\,\\nabla \\log p_{T-s}(\\hat{X}_s) \\Bigr]\\;ds \\;+\\; g(T-s)\\,d\\overline{W}_s. } \\] <p>Often one writes the time variable in the same forward direction and just says \u201cthe reverse\u2010time SDE from \\(t\\) down to 0 is</p> \\[ dx \\;=\\; \\bigl[f(x,t)\\;-\\;g(t)^2\\,\\nabla_x \\log p_{t}(x)\\bigr]\\;dt \\;+\\; g(t)\\,d\\overline{W}_t, \\] <p>where \\(\\overline{W}_t\\) is a standard Wiener process when viewed backward in the original clock. In either notation, the key extra piece is \\(\\,-\\,g^{2}\\nabla\\log p_{t}(\\cdot)\\), which ensures the distributions truly run in reverse.</p> <ul> <li> <p>The drift in the reverse process must \u201ccompensate\u201d for how diffusion was spreading mass forward in time.</p> </li> <li> <p>This compensation appears as \\(\\,-\\,\\tfrac12\\,g^2 \\nabla \\log p_t(x)\\).</p> </li> <li> <p>Equivalently, one can say that in the backward direction, the random walk \u201cknows\u201d how to concentrate probability back into regions from which it had been dispersing forward.</p> </li> </ul> <p>This completes the derivation (sometimes known as Anderson\u2019s theorem).</p> <p>Understanding the Fokker\u2013Planck Equation: A Gentle Introduction In many physical, biological, and financial systems, we are often interested not only in the behavior of individual particles or agents but also in how probability distributions evolve over time. If you have ever encountered a situation where randomness (noise) and drift (directed motion) both play roles in the dynamics, you have likely brushed up against the Fokker\u2013Planck equation (FP equation). In this blog, we will explore:</p> <ol> <li> <p>What the Fokker\u2013Planck equation is.</p> </li> <li> <p>When and why the probability density follows it.</p> </li> <li> <p>An intuitive explanation to help you understand it deeply.</p> </li> </ol>"},{"location":"book/chapter7_diffusion/from_ddpm_2_sde/#3-stochastic-differential-equation-sde-for-ddpm","title":"3. Stochastic Differential Equation (SDE) for DDPM","text":"<p> Denoising Diffusion Probabilistic Models (DDPMs) are generative models that progressively add noise to data in a forward process, and then learn to invert this process to generate new data samples from noise. In the original DDPM (Ho et al., 2020), the forward diffusion is discrete, applying noise in \\(N\\) steps until data become (approximately) Gaussian. The reverse process is also defined discretely, denoising step by step. Recent perspectives (Song et al., 2021) have shown that we can view diffusion models in continuous time, describing them via SDEs. This text shows how the discrete forward process in DDPM converges to a continuous SDE when we let the number of steps \\(N \\to \\infty\\), and how the corresponding reverse SDE aligns with the DDPM reverse noising formula.</p> <p></p> <p>In the following sections, let's derivate the continous format of diffusion process by taking the timestep to limit 0.</p>"},{"location":"book/chapter7_diffusion/from_ddpm_2_sde/#31-discrete-forward-process-in-ddpm","title":"3.1 Discrete Forward Process in DDPM","text":"<p>In the standard (discrete) DDPM, each forward step is:</p> \\[  x_i \\;=\\; \\sqrt{1 - \\beta_i}\\, x_{i-1} \\;+\\; \\sqrt{\\beta_i}\\,\\epsilon_i, \\quad \\epsilon_i \\sim \\mathcal{N}(0, I), \\quad i=1,\\dots,N. \\] <ul> <li> <p>\\(\\beta_i \\in [0,1]\\) is the noise intensity at step \\(i\\).</p> </li> <li> <p>\\(x_0\\) is sampled from the real data distribution \\(p_{\\mathrm{data}}\\).</p> </li> <li> <p>After \\(N\\) steps, \\(x_N\\) is (approximately) Gaussian. Often, \\(\\beta_i\\) is chosen according to a schedule (e.g. linear, cosine) from a small value to a moderately larger one. Even if some \\(\\beta_i\\) are not very small, we can view each step as adding Gaussian noise to the current sample.</p> </li> </ul>"},{"location":"book/chapter7_diffusion/from_ddpm_2_sde/#32-splitting-large-steps-via-gaussian-additivity","title":"3.2 Splitting Large Steps via Gaussian Additivity","text":"<p>A key observation is that a single \u201clarge step\u201d of Gaussian noise can be split into many smaller Gaussian increments without changing the final distribution . Formally, if</p> <p>$$  x_{i} \\;=\\; \\sqrt{1-\\beta_i}\\,x_{i-1} \\;+\\; \\sqrt{\\beta_i}\\,\\epsilon_i, $$ we can represent \\(\\epsilon_i\\) as the sum of \\(M\\) smaller Gaussians of variance \\(\\beta_i/M\\). In other words, we can rewrite that same update with \\(M\\) micro-steps, each of which has variance \\(\\beta_i/M\\). Because Gaussians are closed under convolution, \\(M\\) small steps or \\(1\\) big step produce the same marginal distribution for \\(x_i\\). When \\(M \\to \\infty\\), each micro-step becomes infinitesimally small. Hence, we can imagine the entire forward diffusion as a limit of infinitely many tiny Gaussian increments. This viewpoint paves the way to interpret the forward process as a stochastic differential equation.</p> <p>In other point of view, since we want to get the continuous format by taking the \\(N\\) tends to infinity, corresponds the increment of \\(x_t\\) be infenitesimal, which also requires that \\(\\beta_i \\to 0\\). In this sense, we have enough confidence to assume that</p> \\[\\tag{1}\\boxed{\\beta_i = \\beta(t_i)\\Delta t},\\quad \\beta(x): X \\to \\mathbb{R^+}\\]"},{"location":"book/chapter7_diffusion/from_ddpm_2_sde/#33-from-discrete-updates-to-a-continuous-sde","title":"3.3 From Discrete Updates to a Continuous SDE","text":""},{"location":"book/chapter7_diffusion/from_ddpm_2_sde/#331-mapping-steps-to-time","title":"3.3.1 Mapping Steps to Time","text":"<p>Let the total diffusion run over time \\(t \\in [0,1]\\), with discrete steps \\(t_i = i/N\\). Denote \\(\\Delta t = 1/N\\)</p>"},{"location":"book/chapter7_diffusion/from_ddpm_2_sde/#332-taylor-expansion-argument","title":"3.3.2 Taylor Expansion Argument","text":"<p>Consider one discrete step:</p> \\[ x_{i}=\\sqrt{1-\\beta_i}\\,x_{i-1} \\;+\\; \\sqrt{\\beta_i}\\,\\epsilon_i. \\] <p>If \\(\\beta_i\\) is small, we use a first-order expansion:</p> \\[  \\sqrt{1-\\beta_i} \\;\\approx\\; 1 \\;-\\; \\tfrac12\\,\\beta_i. \\] <p>Then</p> \\[ x_i - x_{i-1}\\;\\approx\\;-\\tfrac12\\,\\beta_i\\,x_{i-1}\\;+\\; \\sqrt{\\beta_i}\\,\\epsilon_i. \\] <p>Suppose \\(x_i = x_{t+\\Delta t}\\) and \\(x_{i-1}= x_{t}\\), Hence</p> \\[ \\begin{aligned} x_{t + \\Delta t}  - x_{t} &amp;= -\\frac{1}{2} \\beta (t + \\Delta t) \\Delta t x_{t} + \\sqrt{\\beta(t+\\Delta t)\\Delta t}\\epsilon_t\\\\ &amp;\\approx  -\\frac{1}{2} \\beta (t ) \\Delta t x_{t} + \\sqrt{\\beta(t)\\Delta t}\\epsilon_t \\\\ &amp; = -\\frac{1}{2} \\beta (t ) x_{t} \\Delta t + \\sqrt{\\beta(t)} \\Delta t \\epsilon_t \\\\ &amp; = -\\frac{1}{2} \\beta (t ) x_{t} \\Delta t + \\sqrt{\\beta(t)} \\big(W(t+\\Delta t)- W(t) \\big)\\\\ &amp; = -\\frac{1}{2} \\beta (t ) x_{t} \\Delta t + \\sqrt{\\beta(t)} dW \\end{aligned} \\] <p>Note that</p> \\[ W(t + \\Delta t) - W(t) \\sim \\mathcal{N}(0, \\Delta t). \\] <p>Thus in the limit we get the SDE:</p> \\[ d x = -\\tfrac12\\,\\beta(t)\\,x\\,dt \\;+\\; \\sqrt{\\beta(t)}\\,dw \\] <p>This is often referred to as the Variance Preserving SDE (VP-SDE)  in the score-based literature.</p>"},{"location":"book/chapter7_diffusion/from_ddpm_2_sde/#333-splitting-steps-argument","title":"3.3.3 Splitting Steps Argument","text":"<p>Alternatively, if \\(\\beta_i\\) is not initially small, we can split each \u201cbig step\u201d into \\(M\\) micro-steps of size \\(\\beta_i/M\\). If we then let \\(N \\to \\infty\\) and \\(M \\to \\infty\\), so that \\(\\beta_i/M \\to 0\\), the entire chain of \\(N\\times M\\) micro-steps again converges to the same SDE. Both methods lead to the conclusion:</p> \\[  \\boxed{ \\text{Forward SDE: } dx = -\\tfrac12\\,\\beta(t)\\,x\\,dt \\;+\\; \\sqrt{\\beta(t)}\\,dw. } \\]"},{"location":"book/chapter7_diffusion/from_ddpm_2_sde/#334-the-reverse-sde","title":"3.3.4 The Reverse SDE","text":"<p>Given a forward SDE of the form:</p> \\[  dx = f(x,t)\\,dt \\;+\\; g(t)\\,dw, \\] <p>the corresponding reverse-time SDE is derived by Anderson (1982) and extended by Song et al. (2021):</p> \\[ d\\tilde{x}=\\bigl[f(\\tilde{x}, t) \\;-\\; g(t)^2\\,\\nabla_{\\tilde{x}}\\log p_t(\\tilde{x})\\bigr]\\;dt \\;+\\; g(t)\\,d\\tilde{w}, \\] <p>where:</p> <ul> <li>\\(\\tilde{w}\\) represents a Brownian motion in reverse time</li> <li>\\(\\nabla_{\\tilde{x}}\\log p_t(\\tilde{x})\\) is the score function (gradient of the log density) at time \\(t\\)</li> </ul> <p>For our specific case where \\(f(x,t) = -\\frac{1}{2}\\beta(t)x\\) and \\(g(t)=\\sqrt{\\beta(t)}\\), the reverse SDE takes the form:</p> \\[ d\\tilde{x}(t)= - \\bigl[\\tfrac12\\,\\beta(t)\\,\\tilde{x}+\\beta(t)\\,\\nabla_{\\tilde{x}}\\log p_t(\\tilde{x})\\bigr]\\;dt \\;+\\;\\sqrt{\\beta(t)}\\,d\\tilde{w}. \\]"},{"location":"book/chapter7_diffusion/from_ddpm_2_sde/#335-consistency-with-ddpms-reverse","title":"3.3.5 Consistency with DDPM\u2019s Reverse","text":"<p>Here we can derivate the reserve formula from the DDPM reverse discrete steps by taking into infinitesimal  timestep, which should be matched with the above formula which derivated from FPE.</p> <p>Review the reserve step in DDPM</p> \\[\\tag{5}\\boxed{ x_{t-1} = \\frac{1}{\\sqrt{1-\\beta_t}}\\left(x_t - \\frac{\\beta_t}{\\sqrt{1-\\bar{\\alpha}_t}}\\,\\epsilon_\\theta(x_t,t)\\right) + \\sqrt{\\tilde{\\beta}_t}\\,z,\\quad z\\sim\\mathcal{N}(0,I)} \\] <p>Recall that in the DDPM reverse process the update (when the network predicts the noise \\(\\epsilon_\\theta\\)) is given by</p> \\[  x_{t-1} = \\frac{1}{\\sqrt{1-\\beta_t}}\\left(x_t - \\frac{\\beta_t}{\\sqrt{1-\\bar{\\alpha}_t}}\\,\\epsilon_\\theta(x_t,t)\\right) + \\sqrt{\\tilde{\\beta}_t}\\,z,\\quad z\\sim \\mathcal{N}(0,I), \\] <p>with $$  \\bar{\\alpha}t = \\prod}^t (1-\\beta_s),\\qquad \\tilde{\\betat = \\frac{1-\\bar{\\alpha}\\,\\beta_t. $$}}{1-\\bar{\\alpha}_t</p> <p>When the number of steps is large, one may view each update as occurring over a small time interval. In what follows we will reparameterize the discrete index in terms of a small time increment.</p> <p>Suppose that in the original (forward) time variable \\(t\\) we write the update from \\(t\\) to \\(t-\\Delta t\\) as</p> \\[  x(t-\\Delta t) = \\frac{1}{\\sqrt{1-\\beta(t)\\,\\Delta t}}\\left(x(t) - \\frac{\\beta(t)\\,\\Delta t}{\\sqrt{1-\\bar{\\alpha}(t)}}\\,\\epsilon_\\theta(x(t),t)\\right) + \\sqrt{\\tilde{\\beta}(t)\\,\\Delta t}\\,z. \\] <p>For a small time interval, we assume the noise variance scales as \\(\\beta(t)\\,\\Delta t\\). Similarly, \\(\\tilde{\\beta}(t)\\,\\Delta t\\) represents the variance used in the reverse update. Note that in the continuous limit, we typically find that \\(\\tilde{\\beta}(t)\\) converges to \\(\\beta(t)\\).</p> <p>Expanding to first order in \\(\\Delta t\\) gives</p> \\[ \\begin{aligned} x(t-\\Delta t) &amp;\\approx \\Bigl(1+\\tfrac{1}{2}\\beta(t)\\Delta t\\Bigr)\\left(x(t) - \\frac{\\beta(t)\\Delta t}{\\sqrt{1-\\bar{\\alpha}(t)}}\\,\\epsilon_\\theta(x(t),t)\\right) + \\sqrt{\\tilde{\\beta}(t)\\Delta t}\\,z\\\\ &amp;\\approx x(t) - \\frac{\\beta(t)\\,\\Delta t}{\\sqrt{1-\\bar{\\alpha}(t)}}\\,\\epsilon_\\theta(x(t),t)+ \\frac{1}{2}\\beta(t)x(t)\\,\\Delta t+ \\sqrt{\\tilde{\\beta}(t)\\Delta t}\\,z. \\end{aligned} \\] <p>That is, the increment in the original (forward) time is</p> \\[-\\Delta x = x(t-\\Delta t)-x(t) = \\left[\\frac{1}{2}\\beta(t)x(t)-\\frac{\\beta(t)}{\\sqrt{1-\\bar{\\alpha}(t)}}\\,\\epsilon_\\theta(x(t),t)\\right]\\Delta t + \\sqrt{\\tilde{\\beta}(t)\\,\\Delta t}\\,z. \\] <p>In the continuous limit, \\(\\sqrt{\\Delta t}\\,z\\) becomes the differential \\(dW\\) of a standard Wiener process.</p> \\[  \\text{d} x =- \\left[\\frac{1}{2}\\beta(t)\\,x(t) -\\frac{\\beta(t)}{\\sqrt{1-\\bar{\\alpha}(t)}}\\,\\epsilon_\\theta\\Bigl(x(t),\\,t)\\Bigr) \\right]dt - \\sqrt{\\beta(t))}\\,dW. \\] <p>To complete our analysis of the reverse process, let's introduce a time change:</p> <p>Let \\(\\tau = T - t\\) and \\(\\tilde{x}(\\tau) = x(T-\\tau)\\)</p> <p>Under this transformation:</p> <ul> <li>\\(d\\tau = -dt\\) (time reversal)</li> <li>\\(d\\tilde{x} = -dx\\) (process reversal)</li> </ul> <p>This leads to:</p> \\[  \\text{d} \\tilde{x} =- \\left[\\frac{1}{2}\\beta(T-\\tau)\\,\\tilde{x}(\\tau) -\\frac{\\beta(T-\\tau)}{\\sqrt{1-\\bar{\\alpha}(T-\\tau)}}\\,\\epsilon_\\theta\\Bigl(\\tilde{x}(\\tau),\\,T-\\tau\\Bigr) \\right]\\tau + \\sqrt{\\beta(T-\\tau)}\\,dW. \\] <p>This derivation shows how one may obtain a continuous-time (SDE) formulation of the DDPM reverse process with an explicit reversed time mapping.</p> <p>Recall the formula from the reverse\u2010time dynamics,</p> \\[  dx = \\Bigl[-\\frac{1}{2}\\beta(t)x - \\beta(t)\\,\\nabla_x\\log p_t(x)\\Bigr]dt + \\sqrt{\\beta(t)}\\,d\\bar{w}. \\] <p>Use the estimator of the gradient from learning</p> \\[  \\nabla_x\\log p_t(x) \\approx -\\frac{1}{\\sqrt{1-\\bar{\\alpha}(t)}}\\,\\epsilon_\\theta(x,t), \\] <p>We got</p> \\[ dx = \\left[-\\frac{1}{2}\\beta(t)x + \\frac{\\beta(t)}{\\sqrt{1-\\bar{\\alpha}(t)}}\\,\\epsilon_\\theta(x,t)\\right]dt + \\sqrt{\\beta(t)}\\,d\\bar{w}. \\]"},{"location":"book/chapter7_diffusion/from_ddpm_2_sde/#4-summary-of-correspondence","title":"4. Summary of Correspondence","text":"<p>In the continuous format, we name it as VP-SDE, refer score based SDE for more details.</p> VP-SDE (Continuous) DDPM (Discrete) \\(x_t\\) \\(x_t = \\sqrt{\\alpha_t} x_0 + \\sqrt{1 - \\alpha_t} \\epsilon\\) \\(x_t = \\sqrt{\\bar{\\alpha}_t} x_0 + \\sqrt{1 - \\bar{\\alpha}_t} \\epsilon\\) \\(\\alpha_t\\) \\(\\alpha_t = e^{-\\int_0^t \\beta(s) ds}\\) \\(\\bar{\\alpha}_t = \\prod_{s=1}^{t} (1 - \\beta_s)\\) \\(\\beta_t\\) \\(\\beta_t^{\\text{VP-SDE}} = d(-\\log \\alpha_t) / dt\\) \\(\\beta_t^{\\text{DDPM}} \\approx \\beta_t^{\\text{VP-SDE}} \\Delta t\\) \\(\\sigma_t\\) \\(\\sigma_t =\\sqrt{ 1 - \\alpha_t}\\) \\(\\sigma_t =\\sqrt{1 - \\bar{\\alpha}_t}\\) forward \\(dx = -\\frac{1}{2} \\beta(t) x dt + \\sqrt{\\beta(t)} dw\\) \\(x_t = \\sqrt{1 - \\beta_t} x_{t-1} + \\sqrt{\\beta_t} \\epsilon\\) backward \\(dx = -\\frac{1}{2} \\beta(t) \\left(  x + 2 s_\\theta(x, t) \\right) dt + \\sqrt{\\beta(t)} dw\\) \\(x_{t-1} = \\frac{1}{\\sqrt{\\alpha_t}} \\left( x_t - \\frac{1 - \\alpha_t}{\\sqrt{1 - \\bar{\\alpha}_t}} \\epsilon_\\theta(x_t, t) \\right) + \\sigma_t z\\) Flow ODE \\(dx = - \\frac{1}{2} \\beta(t)\\left( x + s_\\theta(x, t) \\right) dt\\) Na loss \\(\\mathbb{E}_{t, x_0, \\epsilon} \\left[ \\lambda_t \\|s_\\theta(x_t, t) + \\frac{\\epsilon_\\theta(x,t)}{\\sqrt{1-\\alpha_t}} \\|^2 \\right] \\) \\(\\mathbb{E}_{t,x_0,\\epsilon} \\left[\\| \\epsilon_\\theta(x,t) - \\epsilon\\|^2\\right] \\) score function \\(-\\frac{\\epsilon}{\\sqrt{1-\\alpha_t}}\\) Reverse Sampling \\(x_{t-1} =x_{t} +\\frac{1}{2} \\beta(t) \\left(  x + 2 s_\\theta(x, t) \\right) dt - \\sqrt{\\beta(t)} dw\\) or \\(x_{t-1} =x_{t} +\\frac{1}{2} \\beta(t) \\left(  x +  s_\\theta(x, t) \\right) dt\\) \\(x_{t-1} = \\frac{1}{\\sqrt{\\alpha_t}} \\left( x_t - \\frac{1 - \\alpha_t}{\\sqrt{1 - \\bar{\\alpha}_t}} \\epsilon_\\theta(x_t, t) \\right) + \\sigma_t z\\)"},{"location":"book/chapter7_diffusion/from_ddpm_2_sde/#5-network-output-noise-prediction-vs-score","title":"5. Network Output: Noise Prediction vs. Score","text":"<p>In practice, DDPM commonly trains a network to predict the added noise \\(\\epsilon\\) rather than directly predicting \\(\\nabla_x \\log p(x_t)\\) for better stability or convergence rage. However, there is a simple linear relation  between \\(\\epsilon\\) and the score. Therefore:</p> <ol> <li> <p>Predicting noise  and predicting the score  are equivalent in mathematical terms.</p> </li> <li> <p>Score-based SDE models often produce \\(\\mathbf{s}_\\theta(x,t) \\approx \\nabla_x \\log p_t(x)\\).</p> </li> <li> <p>DDPM-like models produce \\(\\epsilon_\\theta(x_t,t)\\), from which the score can be derived.</p> </li> </ol> <p>Either way, we get a functional approximation to the same \u201cdenoising direction\u201d that enables the reverse-time generative process.</p> <p>Extenstion of the prediction types of diffusion model</p> Diffusion Target Definition Formula Loss Function Pros Common Use Cases \\( \\epsilon \\)-Prediction (Noise Prediction) Predicts the added noise. \\( \\epsilon_\\theta(x_t, t) \\approx \\epsilon \\) \\( \\mathbb{E} [ \\| \\epsilon - \\epsilon_\\theta(x_t, t) \\|^2 ] \\) Standard DDPM target, works well in pixel space. Classical DDPMs (e.g., OpenAI DDPM, ADM) \\( x_0 \\)-Prediction (Data Prediction) Predicts the clean image directly. \\( x_{0_\\theta}(x_t, t) \\approx x_0 \\) \\( \\mathbb{E} [ \\| x_0 - x_{0_\\theta}(x_t, t) \\|^2 ] \\) Directly generates the final image. Consistency Models, improved diffusion models \\( v \\)-Prediction (Velocity Prediction) Predicts a combination of noise and clean data. \\( v_\\theta(x_t, t) = \\alpha_t \\epsilon - \\sigma_t x_0 \\) \\( \\mathbb{E} [ \\| v - v_\\theta(x_t, t) \\|^2 ] \\) More stable training, better for latent diffusion. Stable Diffusion, Latent Diffusion Models \\( \\Sigma \\)-Prediction (Variance Prediction) Predicts the variance of the noise. \\(p_\\theta(x_{t-1} \\| x_t) = \\mathcal{N}(\\mu_\\theta, \\Sigma_\\theta)\\) \\( \\mathbb{E} [ \\| \\epsilon - \\epsilon_\\theta \\|^2 + w(t) \\cdot \\text{KL}(\\Sigma_\\theta) ] \\) Better uncertainty estimation, prevents variance explosion. Class-conditional DDPMs (ADM), Stable Diffusion \\( s \\)-Prediction (Score Function Prediction) Predicts the score function instead of noise. \\( s_\\theta(x_t, t) = -\\nabla_{x_t} \\log p_t(x_t) \\) \\( \\mathbb{E} [ \\| s_\\theta - \\nabla_{x_t} \\log p_t(x_t) \\|^2 ] \\) Works well in continuous-time diffusion models. Score-Based Models (SGM), Continuous-Time Diffusion Models EBM-Prediction (Energy-Based Model) Learns an energy function. \\( \\frac{\\partial x}{\\partial t} = -\\nabla_x E_\\theta(x, t) + \\sigma \\xi_t \\) N/A (Energy-Based Loss) Unifies score-based and energy-based models. Diffusion-EBMs <p>Key Takeaways</p> <ul> <li>Most standard diffusion models use \\( \\epsilon \\)-prediction.</li> <li>\\( v \\)-prediction improves stability and is common in latent diffusion.</li> <li>\\( \\Sigma \\)-prediction adds variance modeling for better flexibility.</li> <li>Score-based prediction is used in continuous-time models.</li> <li>EBMs provide an alternative energy-based formulation.</li> </ul>"},{"location":"book/chapter7_diffusion/from_ddpm_2_sde/#6-appendix","title":"6. Appendix","text":""},{"location":"book/chapter7_diffusion/from_ddpm_2_sde/#61-what-is-the-fokkerplanck-equation","title":"6.1 What is the Fokker\u2013Planck Equation?","text":"<p>Put simply, the Fokker\u2013Planck equation describes how the probability density function (PDF) of a stochastic (random) process evolves over time. More formally, if we let \\(p(x,t)\\) be the probability density of finding the system in state \\(x\\) at time \\(t\\), the Fokker\u2013Planck equation reads:</p> \\[ \\frac{\\partial p(x,t)}{\\partial t} =  \\left\\lbrace -\\frac{\\partial}{\\partial x} \\left[ \\mu(x)p(x,t)\\right] + \\frac{1}{2}\\,\\frac{\\partial^2}{\\partial x^2}(\\,D(x)\\,p(x,t))\\right\\rbrace \\] <p>where</p> <ul> <li> <p>\\(\\mu(x)\\)  represents the deterministic drift or \u201cdrift velocity\u201d. It reflects the average effect of an external force acting on the system.</p> </li> <li> <p>\\(D(x)\\)  represents the diffusion (random fluctuations) at state \\(x\\).</p> </li> </ul> <p>For simplicity, we often see the equation in the case of constant diffusion \\(D\\) and constant drift \\(v\\): $$  \\frac{\\partial p(x,t)}{\\partial t} = -v\\,\\frac{\\partial p(x,t)}{\\partial x} + \\frac{D}{2}\\,\\frac{\\partial^2 p(x,t)}{\\partial x^2}. $$</p> <p>This partial differential equation tells us how the probability density changes because of both deterministic drift (\\(v\\)) and random diffusion (\\(D\\)).</p>"},{"location":"book/chapter7_diffusion/from_ddpm_2_sde/#62-when-does-the-probability-follow-the-fokkerplanck-equation","title":"6.2 When Does the Probability Follow the Fokker\u2013Planck Equation?","text":"<p>The Fokker\u2013Planck equation is typically valid under these conditions:</p> <ol> <li> <p>Continuous Markov processes in one dimension (or higher).</p> </li> <li> <p>The process must be Markovian: the future depends only on the present state, not on the history.</p> </li> <li> <p>Stochastic differential equations (SDEs) of the form</p> \\[ dX_t = \\mu(X_t)\\,dt + \\sqrt{D(X_t)}\\,dW_t, \\] <ul> <li>where \\(W_t\\) is a standard Brownian motion (Wiener process).</li> </ul> </li> <li> <p>Small, Gaussian-like noise.</p> </li> <li> <p>The derivation of the Fokker\u2013Planck relies on the assumption that increments of noise are small over short intervals (leading to the second-order derivative term in the FP equation).</p> </li> <li> <p>No long-range jumps (no L\u00e9vy flights).</p> </li> <li> <p>If jumps or large discontinuous moves exist, then we would use generalized kinetic equations (like fractional Fokker\u2013Planck or Master equations) rather than the classical FP equation.    In essence, if your system follows an It\u00f4-type (or Stratonovich-type) SDE with drift \\(\\mu\\) and diffusion coefficient \\(D\\), then the probability density of where that system might be at time \\(t\\) will satisfy the Fokker\u2013Planck equation.</p> </li> </ol>"},{"location":"book/chapter7_diffusion/from_ddpm_2_sde/#63-intuitive-interpretation-of-drift-and-diffusion-in-the-fokkerplanck-equation","title":"6.3 Intuitive Interpretation of Drift and Diffusion in the Fokker\u2013Planck Equation","text":"<p>The Fokker\u2013Planck equation is a powerful tool for describing how probability densities evolve over time. In many fields\u2014such as physics, biology, and finance\u2014it is used to capture the interplay between deterministic forces and random fluctuations. This blog post provides an intuitive explanation of the two key components: drift  and diffusion .</p>"},{"location":"book/chapter7_diffusion/from_ddpm_2_sde/#631-drift-the-deterministic-push","title":"6.3.1 Drift: The Deterministic Push","text":"<p>In the one-dimensional Fokker\u2013Planck equation, the drift term is commonly written as:</p> \\[  -\\frac{\\partial}{\\partial x}\\Big[A(x)P(x,t)\\Big] \\] <p>Here,</p> <ul> <li> <p>\\(A(x)\\)  represents the deterministic drift or \u201cdrift velocity\u201d. It reflects the average effect of an external force acting on the system.</p> </li> <li> <p>\\(P(x,t)\\)  is the probability density at position \\(x\\) and time \\(t\\).</p> </li> <li> <p>The product The product \\(A(x)P(x,t)\\)  represents the probability flux resulting from the deterministic motion.</p> </li> </ul> <p>Imagine particles moving under the influence of an external force:</p> <ul> <li> <p>Probability Flow: The term \\(A(x)P(x,t)\\) can be thought of as the flow of particles moving with velocity \\(A(x)\\). This is similar to how a group of people might move along a corridor when prompted by a guiding signal.</p> </li> <li> <p>Divergence and Local Density Change: The spatial derivative \\(\\frac{\\partial}{\\partial x}[A(x)P(x,t)]\\) measures how the flow changes along the \\(x\\)-direction (its divergence).</p> </li> <li> <p>If the divergence is positive  at a point, more particles are leaving that region than entering it. Because of the negative sign in the equation, this results in a decrease in the probability density (\\(\\frac{\\partial P}{\\partial t} &lt; 0\\)).</p> </li> <li> <p>Conversely, if the divergence is negative , particles are converging at that point, leading to an increase in the local density (\\(\\frac{\\partial P}{\\partial t} &gt; 0\\)).</p> </li> </ul> <p>This formulation captures how deterministic forces cause a net flow of probability, thereby modifying the local density.</p>"},{"location":"book/chapter7_diffusion/from_ddpm_2_sde/#632-diffusion-the-smoothing-effect-of-random-perturbations","title":"6.3.2 Diffusion: The Smoothing Effect of Random Perturbations","text":"<p>The diffusion term in the Fokker\u2013Planck equation is typically expressed as: $$  \\frac{1}{2}\\frac{\\partial^2}{\\partial x^2}\\Big[B(x)P(x,t)\\Big] $$</p> <p>Here,</p> <ul> <li> <p>\\(B(x)\\)  is the diffusion coefficient, indicating the strength of random fluctuations.</p> </li> <li> <p>The second derivative \\(\\frac{\\partial^2}{\\partial x^2}\\) reflects the curvature of the probability density, indicating how \"peaked\" or \"spread out\" the distribution is locally.</p> </li> </ul> <p>Diffusion describes how random perturbations work to smooth out irregularities in the probability distribution:</p> <ul> <li> <p>High-Density Regions (Peaks): At locations where \\(P(x,t)\\) forms a peak, the distribution is concave down (negative curvature). The diffusion term acts to reduce the density at these peaks, causing the probability to spread out.</p> </li> <li> <p>Low-Density Regions (Valleys): In contrast, in regions where the density is low and the distribution is convex (positive curvature), diffusion causes the density to increase by \u201cfilling in\u201d these valleys with probability from neighboring regions.</p> </li> </ul> <p>This effect is analogous to a drop of ink spreading on paper: the concentrated ink in the center disperses outward, leading to a more uniform concentration over time. Diffusion thus does not simply lower the density everywhere; rather, it redistributes it, diminishing local extremes to create a smoother overall profile.</p>"},{"location":"book/chapter7_diffusion/from_ddpm_2_sde/#6321-drift-and-diffusion-combined-evolution-of-the-probability-density","title":"6.3.2.1 Drift and Diffusion: Combined Evolution of the Probability Density","text":"<p>In the Fokker\u2013Planck equation, drift and diffusion work together to dictate how the probability density evolves:</p> <ul> <li> <p>Drift  accounts for the systematic, directional movement driven by deterministic forces. It creates flows that can either concentrate or deplete the density depending on the spatial gradient (divergence) of the flux.</p> </li> <li> <p>Diffusion  represents the effect of random fluctuations, working to smooth out the probability distribution. It reduces sharp peaks and fills in dips, leading to a more even spread of the density.</p> </li> </ul> <p>Together, these processes explain how the overall distribution changes over time, even if the motion of individual particles is unpredictable. By considering both the directional push of drift and the smoothing influence of diffusion, the Fokker\u2013Planck equation provides a comprehensive framework for understanding the evolution of complex systems under uncertainty.</p> <p>In the Fokker\u2013Planck equation, drift and diffusion work together to dictate how the probability density evolves:</p> <ul> <li> <p>Drift  accounts for the systematic, directional movement driven by deterministic forces. It creates flows that can either concentrate or deplete the density depending on the spatial gradient (divergence) of the flux.</p> </li> <li> <p>Diffusion  represents the effect of random fluctuations, working to smooth out the probability distribution. It reduces sharp peaks and fills in dips, leading to a more even spread of the density.</p> </li> </ul> <p>Together, these processes explain how the overall distribution changes over time, even if the motion of individual particles is unpredictable. By considering both the directional push of drift and the smoothing influence of diffusion, the Fokker\u2013Planck equation provides a comprehensive framework for understanding the evolution of complex systems under uncertainty.</p>"},{"location":"book/chapter7_diffusion/general_diffusion_model/","title":"General Diffusion Theory","text":""},{"location":"book/chapter7_diffusion/general_diffusion_model/#1-1-general-diffusion-theory","title":"1. 1. General Diffusion Theory","text":"<p>Diffusion models, such as DDPM (Denoising Diffusion Probabilistic Models), reformulate complex data generation as a gradual denoising process. The core idea is to define two processes:</p>"},{"location":"book/chapter7_diffusion/general_diffusion_model/#11-11-the-forward-diffusion-process","title":"1.1 1.1 The Forward (Diffusion) Process","text":"<ul> <li> <p>Process Description   The forward process is a fixed Markov chain that gradually adds noise to the original data \\( x_0 \\) until it eventually resembles pure noise. At each time step \\( t \\), the sample \\( x_t \\) is obtained by:   $$   q(x_t \\mid x_{t-1}) = \\mathcal{N}\\Big(x_t; \\sqrt{1-\\beta_t}\\, x_{t-1},\\, \\beta_t \\mathbf{I}\\Big)   $$   where \\(\\beta_t\\) is a pre-defined noise schedule.</p> </li> <li> <p>Overall Process   After \\( T \\) steps, one can show that:   $$   q(x_T \\mid x_0) = \\mathcal{N}\\Big(x_T; \\mu_T(x_0),\\, \\sigma_T^2 \\mathbf{I}\\Big)   $$   When \\( T \\) is sufficiently large, \\( x_T \\) approximates a standard normal distribution, effectively losing most information about the original data.</p> </li> </ul>"},{"location":"book/chapter7_diffusion/general_diffusion_model/#12-12-the-reverse-generative-process","title":"1.2 1.2 The Reverse (Generative) Process","text":"<ul> <li> <p>Process Description   The reverse process is parameterized by a model \\( p_\\theta(x_{t-1} \\mid x_t) \\) that aims to reverse the forward diffusion. Starting from a noise sample \\( x_T \\sim \\mathcal{N}(0, \\mathbf{I}) \\), the model gradually denoises the data to recover \\( x_0 \\):   $$   p_\\theta(x_{0:T}) = p(x_T) \\prod_{t=1}^{T} p_\\theta(x_{t-1} \\mid x_t)   $$   Each reverse transition is typically modeled as a Gaussian:   $$   p_\\theta(x_{t-1} \\mid x_t) = \\mathcal{N}\\Big(x_{t-1};\\, \\mu_\\theta(x_t, t),\\, \\Sigma_\\theta(x_t, t)\\Big)   $$</p> </li> <li> <p>Training Objective   The model is trained by maximizing the log-likelihood of the data or, more commonly, by minimizing a variational lower bound (ELBO). In practice, a simplified loss is often used where the model directly predicts the noise added to the data.</p> </li> </ul>"},{"location":"book/chapter7_diffusion/general_diffusion_model/#13-13-theoretical-insights","title":"1.3 1.3 Theoretical Insights","text":"<ul> <li> <p>Stability in Generation:   The gradual denoising in the reverse process simplifies the learning task to removing noise incrementally, which contributes to stable training and generation.</p> </li> <li> <p>Inverse Problem Framing:   The diffusion process transforms data generation into solving an inverse problem, where the goal is to reconstruct the original data from noisy observations.</p> </li> </ul>"},{"location":"book/chapter7_diffusion/general_diffusion_model/#2-2-conditional-diffusion-models","title":"2. 2. Conditional Diffusion Models","text":"<p>In many applications (e.g., image generation, text-to-image synthesis), it is desirable for the generated samples to adhere to certain conditions \\( y \\) (such as class labels, textual descriptions, or structural information). In the diffusion framework, conditional generation is typically incorporated into the reverse process:</p> <ul> <li> <p>Conditional Reverse Process   The model is modified to condition on \\( y \\):   $$   p_\\theta(x_{t-1} \\mid x_t, y)   $$   This means that at each denoising step, the model not only uses the noisy input \\( x_t \\) but also leverages the condition \\( y \\) to guide the restoration process.</p> </li> <li> <p>Implementation Strategies   In practice, the condition \\( y \\) is often embedded into the network (e.g., through feature concatenation, cross-attention, or other conditioning mechanisms) so that the network learns to generate data that meets the desired criteria.</p> </li> </ul>"},{"location":"book/chapter7_diffusion/general_diffusion_model/#3-3-classifier-guided-diffusion","title":"3. 3. Classifier-Guided Diffusion","text":""},{"location":"book/chapter7_diffusion/general_diffusion_model/#31-31-basic-idea","title":"3.1 3.1 Basic Idea","text":"<ul> <li> <p>Separate Classifier Training   In this approach, an auxiliary classifier \\( p(y \\mid x_t) \\) is trained to predict the condition \\( y \\) from the noisy sample \\( x_t \\). Note that the classifier must be robust to varying noise levels since \\( x_t \\) is noisy.</p> </li> <li> <p>Guiding the Generation Process   During sampling, the gradient of the classifier\u2019s log-probability with respect to \\( x_t \\) is used to adjust the denoising direction. By applying the chain rule, one obtains:   $$   \\nabla_{x_t} \\log p(x_t \\mid y) = \\nabla_{x_t} \\log p(x_t) + \\nabla_{x_t} \\log p(y \\mid x_t)   $$   Thus, in the reverse step, an extra gradient term is incorporated:   $$   \\tilde{\\mu}\\theta(x_t, t, y) = \\mu\\theta(x_t, t) + s\\, \\Sigma_\\theta(x_t, t) \\nabla_{x_t} \\log p(y \\mid x_t)   $$   Here, \\( s \\) is a guidance scale that balances sample diversity and conditional fidelity.</p> </li> </ul>"},{"location":"book/chapter7_diffusion/general_diffusion_model/#32-32-advantages-and-challenges","title":"3.2 3.2 Advantages and Challenges","text":"<ul> <li>Advantages:</li> <li>Significantly improves the alignment of the generated sample with the condition \\( y \\).</li> <li> <p>Can yield high-quality, condition-consistent results in certain tasks.</p> </li> <li> <p>Challenges:</p> </li> <li>Requires an additional, robust classifier that can handle noisy inputs across different diffusion time steps.</li> <li>Excessive guidance strength (i.e., a large \\( s \\)) may lead to instability or a reduction in sample diversity.</li> </ul>"},{"location":"book/chapter7_diffusion/general_diffusion_model/#4-4-classifier-free-diffusion","title":"4. 4. Classifier-Free Diffusion","text":""},{"location":"book/chapter7_diffusion/general_diffusion_model/#41-41-core-idea","title":"4.1 4.1 Core Idea","text":"<ul> <li>Joint Training Strategy   Instead of relying on an external classifier, the model is trained to perform both conditional and unconditional denoising. During training, the condition \\( y \\) is randomly dropped (or masked) with a certain probability. This forces the network to learn two mappings:</li> <li>The conditional noise prediction: \\( \\epsilon_\\theta(x_t, y) \\)</li> <li>The unconditional noise prediction: \\( \\epsilon_\\theta(x_t) \\)</li> </ul>"},{"location":"book/chapter7_diffusion/general_diffusion_model/#42-42-conditional-guidance-during-sampling","title":"4.2 4.2 Conditional Guidance During Sampling","text":"<ul> <li>Sampling Strategy   At generation time, the two predictions are combined to guide the sampling:   $$   \\hat{\\epsilon}\\theta(x_t, y) = \\epsilon\\theta(x_t) + s\\, \\bigl( \\epsilon_\\theta(x_t, y) - \\epsilon_\\theta(x_t) \\bigr)   $$   Here, \\( s \\) again controls the influence of the condition. When \\( s &gt; 1 \\), the effect of the condition is amplified, encouraging the generation of samples that more strongly adhere to \\( y \\).</li> </ul>"},{"location":"book/chapter7_diffusion/general_diffusion_model/#43-43-advantages","title":"4.3 4.3 Advantages","text":"<ul> <li> <p>Simplified Architecture:   No need to train or maintain an extra classifier, resulting in a cleaner overall model design.</p> </li> <li> <p>Stability:   Since the guidance is integrated into the same network, the generated gradients tend to be more stable, often leading to a balanced quality in the generated samples.</p> </li> </ul>"},{"location":"book/chapter7_diffusion/general_diffusion_model/#5-5-summary","title":"5. 5. Summary","text":"<ol> <li>General Diffusion Framework (DDPM):</li> <li>Forward Process: Incrementally adds noise to data, eventually producing a sample from a simple distribution (e.g., standard normal).</li> <li> <p>Reverse Process: Uses a neural network to gradually remove noise, reconstructing the original data from the noisy input.</p> </li> <li> <p>Conditional Diffusion Models:</p> </li> <li> <p>Conditions \\( y \\) are incorporated into the reverse process so that the generated samples meet specific criteria.</p> </li> <li> <p>Two Main Conditional Guidance Methods:</p> </li> <li>Classifier-Guided Diffusion:<ul> <li>Uses a separately trained classifier to compute \\( \\nabla_{x_t} \\log p(y \\mid x_t) \\) and guides the reverse process with this gradient.</li> </ul> </li> <li>Classifier-Free Diffusion:<ul> <li>Relies on a training strategy that randomly drops the condition during training, allowing the model to learn both conditional and unconditional noise predictions.</li> <li>At sampling time, these predictions are combined to steer the generation toward the condition \\( y \\).</li> </ul> </li> </ol> <p>Each method has its trade-offs: classifier-guided approaches can more precisely leverage condition information but require an extra robust classifier, while classifier-free methods offer a simpler, more stable alternative that is widely used in practice.</p> <p>This overview abstracts the diffusion model theory from DDPM and explains how to incorporate conditions using both classifier-guided and classifier-free strategies.</p>"},{"location":"book/chapter7_diffusion/introduction_sde/","title":"SDE","text":"<p>Welcome to the world of Stochastic Differential Equations (SDEs)! SDEs are a powerful tool for modeling systems that involve randomness, such as stock prices, particle motion, or population growth with unpredictable fluctuations. This article will break down the basics of SDEs in an intuitive and easy-to-understand way. Let's dive in!</p>"},{"location":"book/chapter7_diffusion/introduction_sde/#1-prerequisites","title":"1. Prerequisites","text":"<p>To follow along, you'll need a basic understanding of:</p> <ul> <li>Calculus (derivatives and integrals).</li> <li>Ordinary differential equations (ODEs).</li> <li>Probability (random variables, mean, variance).</li> </ul> <p>Don't worry if you're not an expert in these areas\u2014we'll keep things simple and intuitive!</p>"},{"location":"book/chapter7_diffusion/introduction_sde/#2-what-makes-sdes-different","title":"2. What Makes SDEs Different?","text":"<p>Ordinary Differential Equations (ODEs) model deterministic systems, where the future is entirely predictable based on the present. In contrast, SDEs (\u968f\u673a\u5fae\u5206\u65b9\u7a0b) model systems with randomness. Think of SDEs as ODEs with an added 'noise' term to account for uncertainty.</p>"},{"location":"book/chapter7_diffusion/introduction_sde/#3-the-building-blocks-of-sdes","title":"3. The Building Blocks of SDEs","text":""},{"location":"book/chapter7_diffusion/introduction_sde/#31-stochastic-processes","title":"3.1 Stochastic Processes","text":"<p>A stochastic process is a collection of random variables that evolve over time. The most well-known example is Brownian motion \u5e03\u6717\u8fd0\u52a8 (or Wiener process\u7ef4\u7eb3\u8fc7\u7a0b), which describes random movement, such as pollen particles moving in water.</p> <p>Random Process</p> <p>Let - \\((\\Omega, \\mathcal{F}, P)\\) be a probability space, where: - \\(\\Omega\\) is the sample space, - \\(\\mathcal{F}\\) is a \\(\\sigma\\)-algebra on \\(\\Omega\\), - \\(P\\) is a probability measure on \\(\\mathcal{F}\\).</p> <ul> <li> <p>\\(T\\) be an index set (often representing time, e.g., \\(T = [0,\\infty)\\)).</p> </li> <li> <p>\\((S, \\mathcal{S})\\) be a measurable space (typically, \\(S = \\mathbb{R}\\) or \\(\\mathbb{R}^d\\) with its Borel \\(\\sigma\\)-algebra).</p> </li> </ul> <p>A stochastic process is a collection (or family) of random variables</p> \\[ \\{X_t : t \\in T\\}, \\] <p>where for each \\(t \\in T\\), the mapping</p> \\[ X_t : \\Omega \\to S \\] <p>is a random variable; that is, for every \\(B \\in \\mathcal{S}\\),</p> \\[ X_t^{-1}(B) = \\{\\omega \\in \\Omega : X_t(\\omega) \\in B\\} \\in \\mathcal{F}. \\] <p>Alternatively, one may define a stochastic process as a function</p> \\[ X: T \\times \\Omega \\to S, \\] <p>which is jointly measurable with respect to the product \\(\\sigma\\)-algebra \\(\\mathcal{B}(T) \\otimes \\mathcal{F}\\) and \\(\\mathcal{S}\\). In this formulation, for each fixed \\(t \\in T\\), the mapping</p> \\[ X(t, \\cdot): \\Omega \\to S \\] <p>is a random variable.</p> <p>Intuitive Explanation</p> <ul> <li> <p>Mapping Outcomes to Trajectories: Each element \\(\\omega \\in \\Omega\\) (a specific outcome) produces a function \\(t \\mapsto X(t,\\omega)\\). This function is called a sample path and represents how the state of the system evolves over time (or over the index set).</p> </li> <li> <p>Family of Random Variables: At every fixed time \\(t\\), \\(X_t\\) is a random variable that describes the state of the system at that moment. The collection \\(\\{X_t: t \\in T\\}\\) shows the system\u2019s evolution through time, capturing the inherent randomness at each point.</p> </li> <li> <p>Describing Random Evolution: The stochastic process encapsulates the idea that the system's behavior is random, and its state changes in a way that can be described by probability. The joint distribution of all the random variables \\(\\{X_t\\}\\) characterizes the overall behavior of the process.</p> </li> </ul> <p>Wiener Process</p> <p>A Wiener process (also known as Brownian motion) is a continuous-time stochastic process \\(\\{W_t\\}_{t \\geq 0}\\) that is defined by the following properties:</p> <ol> <li> <p>Initial Condition: \\(W_0 = 0\\).</p> </li> <li> <p>Independent Increments:     For any sequence of times \\(0 \\leq t_0 &lt; t_1 &lt; \\dots &lt; t_n\\), the increments</p> \\[ W_{t_1} - W_{t_0},\\ W_{t_2} - W_{t_1},\\ \\dots,\\ W_{t_n} - W_{t_{n-1}} \\] <p>are independent random variables.</p> </li> <li> <p>Stationary Increments:    For any \\(s, t \\geq 0\\), the distribution of the increment \\(W_{t+s} - W_t\\) depends only on \\(s\\) (the length of the time interval), not on \\(t\\).</p> </li> <li> <p>Gaussian Increments:    For any \\(s, t \\geq 0\\) with \\(s &gt; 0\\), the increment \\(W_{t+s} - W_t\\) is normally distributed with mean 0 and variance \\(s\\):</p> </li> </ol> <p>$$    W_{t+s} - W_t \\sim N(0, s).    $$</p> <ol> <li>Continuous Paths:   With probability 1, the function \\(t \\mapsto W_t\\) is continuous.</li> </ol> <p>In summary, a Wiener process is a model for random continuous motion, encapsulating the idea of both randomness (through independent, normally distributed increments) and continuity in time.</p> <p></p> <p>Examples of Wiener Process:</p> <p></p>"},{"location":"book/chapter7_diffusion/introduction_sde/#32-intuitive-explanation","title":"3.2 Intuitive Explanation","text":"<p>From Discrete Markov Chains to Brownian Motion: A Walking Analogy</p> <ul> <li> <p>Discrete Markov Chain: Walking in Four Directions     Imagine you are standing on a grid in a large square. Each step, you can only move up, down, left, or right\u2014no diagonals, no curves, just one step in one of these four directions.</p> <p>This is a discrete Markov chain, because:   - Your next step depends only on your current position (memoryless property).   - You have a fixed set of choices (four directions), and each step has the same size.   - Time is also discrete\u2014you take one step at a time in fixed intervals.   - That is given \\(x_t\\), \\(x_{t+1}\\) has two possibles</p> \\[\\Delta x = x_{t+1}-x_{t}, p(\\Delta x = \\Delta t \\cdot d_i) = \\frac{1}{4}, i\\in \\{\u4e0a,\u4e0b,\u5de6,\u53f3\\} \\] <p>where \\(d_i\\) is the direction, \\(\\Delta t\\) is the time step.</p> </li> <li> <p>Brownian Motion: Walking in Infinite Directions     Now, imagine the grid disappears, and you are standing on a smooth, open floor. Instead of being restricted to just four directions, you can walk in any direction\u2014360 degrees around you.     Your step is infinitesimally small and follows a distribution, that is, random chosed.</p> <p>This describes Brownian motion:   - Your next move is still random (preserving the Markov property).   - But now, you can move in any possible direction, not just four fixed ones.   - Your steps become smaller and more frequent, eventually forming a continuous, smooth path instead of discrete jumps.   - that is then \\(\\Delta t \\rightarrow 0\\)  and \\(d_i\\) is the whole Euclidean  space. But for Wiener process, usually we assume \\(d_i\\) is follow a Standard Gaussian Distribution. Formally, we denote</p> \\[ \\tag{1} X_{t+1}-X_{t}= \\Delta x = \\mathcal{N}(0,\\Delta t) = \\sqrt{\\Delta t} \\mathcal{N}(0,1) = \\Delta W\\] </li> </ul> <p>Summary: Brownian Motion as the Limit of a Discrete Markov Chain</p> <ul> <li>Discrete Markov Chain \u2192 You walk on a grid, choosing between four directions in fixed steps at fixed time intervals.</li> <li>Brownian Motion \u2192 You walk on a continuous surface, able to move in infinite directions, with smaller, more frequent steps, forming a smooth trajectory.</li> </ul> <p>In other words, Brownian motion is the limiting case of a discrete Markov chain, when both step size and time interval shrink to zero. This transition mirrors the shift from grid-based walking (discrete) to free, smooth movement (continuous), just like how dust particles in air move randomly due to molecular collisions.</p> <p>Why Gaussian Distribution</p> <ul> <li>Caused by the Central Limit Theorem, which states that the sum of many small independent random variables tends toa Gaussian distribution regardless of their original distribution. For example, we have small air molecules bumping into a pollen grain lead to Brownian motion\u2014each bump is random, but their collective effect is Gaussian-distributed.</li> </ul>"},{"location":"book/chapter7_diffusion/introduction_sde/#4-structure-of-an-sde","title":"4. Structure of an SDE","text":""},{"location":"book/chapter7_diffusion/introduction_sde/#41-from-ode-to-sde","title":"4.1 From ODE to  SDE","text":""},{"location":"book/chapter7_diffusion/introduction_sde/#411-ordinary-differential-equations-odes","title":"4.1.1 Ordinary Differential Equations (ODEs)","text":"<p>An ODE is an equation involving a function and its derivatives \\(\\frac{dx}{dt} = f(x,t)\\) where \\(x(t)\\) is the unknown function, and \\(f(x,t)\\) is a known deterministic function.</p> <p>Example</p> <p>Exponential Growth</p> \\[ \\frac{dx}{dt} = \\lambda x \\] <p>Solution:</p> \\[x(t) = x_0 e^{\\lambda t}\\] <p>where \\(x_0\\) is the initial condition.</p>"},{"location":"book/chapter7_diffusion/introduction_sde/#412-stochastic-differential-equations-sdes","title":"4.1.2 Stochastic Differential Equations (SDEs)","text":"<p>If we define the SDE similar like the ODE, we can extend ODE to SDE adding a stochastic (random) component :</p> \\[ \\frac{d x}{dt} = f(x,t) + g(x, t)\\xi(t) \\] <p>where \\(\\xi(t)\\) provides the randomness.</p> <p>However, this definition is illegal, since no mather what function here \\(xi(t)\\) defines here it leads to \\(x(t)\\) be a differentiable function, contradict with the fact that Brownian motion is nowhere differentiable.</p>"},{"location":"book/chapter7_diffusion/introduction_sde/#42-standard-formulation-of-sde","title":"4.2 Standard formulation of SDE","text":"<p>choice of random process</p> <p>In most of the SDE contents, we are talking about the Wiener Process which has good properties like independent and continuity. But there actually has different kinds of SDE. We will introduce this at the end of this article. From now, just consider the random process as the Wiener Process</p> <p>SDE Definition</p> \\[ dX_t = f(X_t, t) dt + g(X_t, t) dW_t \\] <p>where:</p> <ul> <li> <p>\\(dX_t\\) represents the infinitesimal change in \\(X_t\\).</p> </li> <li> <p>\\(f(X_t, t)dt\\) is the drift term , describing deterministic motion.</p> </li> <li> <p>\\(g(X_t, t)dW_t\\) is the diffusion term , incorporating randomness via a Wiener process \\(W_t\\) (also called Brownian  motion).</p> </li> </ul> <p>By the random term, we know that the randomniness is independent of the \\(x\\).</p> <p>Example: Geometric Brownian Motion (GBM)</p> \\[ dX_t = \\mu X_t dt + \\sigma X_t dW_t \\] <p>used to model stock prices in the Black-Scholes model .</p> <p>Why the Derivative Formulation of SDEs is Invalid</p> <p>The equation</p> \\[\\frac{dx(t)}{dt} = f(t, \\mathbf{x}) + g(t, \\mathbf{x})\\xi(t), \\quad \\text{where} \\quad \\xi(t) \\sim \\mathcal{N}(0, \\mathbf{I}) \\] <p>is mathematically problematic for defining a stochastic differential equation (SDE). Below are the key reasons:</p> <ol> <li> <p>White Noise as a Generalized Function</p> <ul> <li>\\(\\xi(t)\\) represents \"white noise,\" which is not a classical function but a generalized stochastic process.</li> <li>Rigorously, \\(\\xi(t)\\) is interpreted as the formal derivative of a Wiener process \\(W(t)\\) (Brownian motion).</li> <li>However, \\(W(t)\\) is nowhere differentiable with probability 1, so \\(\\xi(t) = \\frac{dW}{dt}\\) does not exist in the classical sense.</li> </ul> </li> <li> <p>Stochastic Integrals vs. Derivatives</p> <ul> <li>SDEs are properly defined using stochastic integrals (It\u00f4 or Stratonovich), not derivatives.</li> <li> <p>The standard SDE formulation is:</p> \\[dx(t) = f(t, \\mathbf{x})dt + g(t, \\mathbf{x})dW(t),\\] <p>where \\(dW(t)\\) is the increment of a Wiener process.</p> </li> <li> <p>This avoids differentiating \\(W(t)\\) and instead uses integration to handle its irregular paths.</p> </li> </ul> </li> <li> <p>Path Regularity</p> <ul> <li>Solutions to SDEs are typically nowhere differentiable due to the roughness of \\(W(t)\\).</li> <li>Writing \\(\\frac{dx(t)}{dt}\\) implicitly assumes \\(x(t)\\) is differentiable, which contradicts the nature of stochastic processes driven by white noise.</li> </ul> </li> <li> <p>Conclusion     The derivative form \\(\\frac{dx(t)}{dt}\\) is invalid for SDEs because:</p> <ol> <li>White noise (\\(\\xi(t)\\)) is not a classical function.</li> <li>The rigorous framework requires stochastic integrals with \\(dW(t)\\), not \\(\\xi(t)dt\\).</li> <li>Solutions to SDEs lack the regularity needed for classical derivatives.</li> </ol> <p>The standard SDE formulation resolves these issues by using differentials (\\(dx(t)\\), \\(dW(t)\\)) instead of derivatives.</p> </li> </ol> <p>A very important property we need to care is that \\(dW(t)\\sim \\sqrt{dt}\\) (asymptotically equivalent infinitesimals,\u7b49\u4ef7\u65e0\u7a77\u5c0f ) in practice either in theorem deduction or algorithm implementation.</p> <p>why \\(dW(t)\\sim\\sqrt{dt}\\)</p> <p>The fact that</p> \\[ \\begin{equation} W(t+\\delta) - W(t) \\sim N(0, \\delta) \\end{equation} \\] <p>and not</p> \\[ W(t+\\delta) - W(t) \\sim N(0, \\delta^2) \\] <p>stems from the definition and fundamental properties of Brownian motion (or the Wiener process), which also reflect physical realities. Here are the key points:</p> <ol> <li>Linear Variance Growth:   A fundamental property of Brownian motion is that the variance of its increments grows linearly with the time interval. Specifically,</li> </ol> <p>$$   \\operatorname{Var}[W(t+\\delta) - W(t)] = \\delta.   $$</p> <p>This relationship reflects the diffusion phenomenon observed in nature\u2014for instance, in molecular diffusion, the mean squared displacement is proportional to time.</p> <ol> <li> <p>Scale Invariance (Self-Similarity):   Brownian motion is self-similar. For any positive constant \\( c \\), the process satisfies</p> \\[ \\begin{equation} \\{W(ct)\\}_{t \\ge 0} \\stackrel{d}{=} \\{\\sqrt{c}\\,W(t)\\}_{t \\ge 0}. \\end{equation} \\] </li> </ol> <p>This scaling property implies that when time is dilated by a factor of \\( c \\), the magnitude of the process scales by \\(\\sqrt{c}\\), so the variance scales by \\( c \\). If we were to use \\( N(0, \\delta^2) \\) for the increments, the variance would scale with the square of the time interval, which would contradict this self-similarity property.</p> <ol> <li> <p>Limit Process and the Central Limit Theorem:   Brownian motion can be derived as the limit of a random walk with many small steps. In a simple random walk, the variance of each small step is proportional to the time step. By the central limit theorem and an appropriate scaling, the limiting process (i.e., Brownian motion) has increments with variance proportional to \\(\\delta\\), not \\(\\delta^2\\).</p> </li> <li> <p>Physical Significance:    Empirical observations of phenomena such as the erratic motion of particles in a fluid (Brownian motion) show that the mean squared displacement is proportional to time. This experimental fact underpins the theoretical model of Brownian motion with increments distributed as \\( N(0, \\delta) \\) rather than \\( N(0, \\delta^2) \\).</p> <p>In summary, defining</p> \\[ W(t+\\delta) - W(t) \\sim N(0, \\delta) \\] <p>is not an arbitrary choice; it is dictated by the mathematical properties of Brownian motion and the physical behavior of diffusive systems. Choosing \\( N(0, \\delta^2) \\) would lead to a model where the variance grows with the square of the time interval, which does not match the observed and theoretical properties of diffusion.</p> </li> </ol>"},{"location":"book/chapter7_diffusion/introduction_sde/#5-solving-sde","title":"5. Solving SDE","text":""},{"location":"book/chapter7_diffusion/introduction_sde/#51-ode-solution","title":"5.1 ODE solution","text":"<p>Let's consider how to solve ODE first</p> <p>Analytical Solution of ODE</p> <p>Solving ODE Analytically: A Quick Example Given the first-order ODE:</p> \\[ \\frac{dy}{dx} = -2y \\] <p>Solution Steps: 1. Separate variables:</p> \\[ \\frac{dy}{y} = -2 dx \\] <ol> <li>Integrate:</li> </ol> \\[ \\ln |y| = -2x + C \\] <ol> <li>Solve for \\( y \\):</li> </ol> \\[ y = C e^{-2x} \\] <p>With Initial Condition \\( y(0) = 5 \\):</p> \\[ 5 = C e^0 \\Rightarrow C = 5 \\] \\[ y = 5 e^{-2x} \\] <p>\u2714 Final Answer:</p> \\[ y = C e^{-2x} \\quad \\text{(or \\( y = 5 e^{-2x} \\) if \\( y(0) = 5 \\))} \\] <p>From the examle, we know, it the initial condition is not given, there could be infinite solutions of the ODE since the derivative of constant is always zero. Hence in the following, we are always assume the initial condition is given.</p> <p>General method for ODE solution analytically</p> ODE Type Method \\(\\frac{dy}{dx} = f(x) g(y)\\) Separation of Variables \\(\\frac{dy}{dx} + P(x)y = Q(x)\\) Integrating Factor \\(M(x,y)dx + N(x,y)dy = 0\\) Exact Equation Special forms (Bernoulli, Riccati, etc.) Substitutions \\(a_n y^{(n)} + \\dots + a_0 y = 0\\) Characteristic Equation With Initial Conditions Laplace Transform Cannot solve with elementary functions Power Series <p>Genrally, suppose</p> \\[\\frac{d f(t)}{d t} = f'(t) = g(t)\\] <p>in ODEs, you integrate to find solutions</p> \\[ f(t) = \\int_{0}^z f'(z) d z + f(0) =  \\int_{0}^z g(z) d z + f(0)\\] <p>But in SDEs, the noise term \\(dW_t\\) isn\u2019t smooth\u2014it\u2019s wildly erratic! Traditional calculus fails. To make the integra be sensible, we need to introduce the tow toolss:</p> <ol> <li>It\u00f4\u2019s Lemma (\u4f0a\u85e4\u5f15\u7406): A \u201cchain rule\u201d for stochastic processes.</li> <li>It\u00f4 Integral (\u4f0a\u85e4\u5f15\u7406\u79ef\u5206): A way to integrate with respect to Brownian motion.</li> </ol> \\[ \\mathbf{x}(t, \\omega) = \\mathbf{x}_0 + \\int_0^t f(s, \\mathbf{x}(s, \\omega)) ds + \\int_0^t g(s, \\mathbf{x}(s, \\omega)) d\\mathbf{w}(s, \\omega) \\]"},{"location":"book/chapter7_diffusion/introduction_sde/#52-what-is-the-ito-integral","title":"5.2 What is the It\u00f4 Integral?","text":"<p>Consider the normal integral (Riemann integral,\u9ece\u66fc\u79ef\u5206), it can be represented as the area below the function, as shown in the image. It is also a limit of the discrete sum by griding the area into smaller cubes.</p> \\[\\int_{0}^t f(t) dt = \\lim_{\\Delta x \\rightarrow 0} \\sum_{i=0}^{n-1} f(t_i) t_{i+1}-t_{i} \\] <p>The It\u00f4 Integral is a way to integrate stochastic processes with respect to Brownian motion (a Wiener process, denoted \\(W_t\\)). Formally, for a stochastic process $ H_t $ adapted to the filtration of \\(W_t\\), the It\u00f4 Integral is defined as:</p> \\[ \\int_{0}^{T} H_t \\, dW_t = \\lim_{\\Delta t \\to 0} \\sum_{i=0}^{n-1} H_{t_i} (W_{t_{i+1}} - W_{t_i}), \\] <p>where the integrand \\(H_t\\) is evaluated at the left endpoint of each subinterval \\([t_i, t_{i+1}]\\). This \"non-anticipating\" property ensures the integral is a martingale. The formula is quite similar to the Riemann integral but the difference is the increment term \\(W_{t_{i+1}} - W_{t_i}\\) is a Gaussian distribution .</p>"},{"location":"book/chapter7_diffusion/introduction_sde/#53-key-properties","title":"5.3 Key Properties","text":"<ol> <li>Adaptedness: \\(H_t\\) must depend only on information up to time \\(t\\).</li> <li> <p>It\u00f4 Isometry:</p> \\[ \\mathbb{E}\\left[ \\left( \\int_{0}^{T} H_t \\, dW_t \\right)^2 \\right] = \\mathbb{E}\\left[ \\int_{0}^{T} H_t^2 \\, dt \\right]. \\] </li> <li> <p>Zero Mean:</p> \\[ \\mathbb{E}\\left[ \\int_{0}^{T} H_t \\, dW_t \\right] = 0 \\] <p>By the first part, we can solve it according to the method used in ODE, but the last term is tricky.</p> <p>Classical integration fails because Brownian motion has infinite total variation but finite quadratic variation:</p> \\[ \\lim_{\\Delta t \\to 0} \\sum_{i=0}^{n-1} |W_{t_{i+1}} - W_{t_i}|^2 = T. \\] <p>This irregularity forces a new calculus. 4. integra</p> </li> </ol> <p>\\(\\(\\int_{s}^{s+\\sigma} dW_t = W_{s+\\sigma} - W_{s} \\sim \\mathcal{N}(0,\\sigma)=\\sqrt{\\sigma}Z, Z\\sim\\mathcal{N}(0,1)\\)\\)</p>"},{"location":"book/chapter7_diffusion/introduction_sde/#54-itos-lemma","title":"5.4 It\u00f4\u2019s Lemma","text":"<p>It\u00f4\u2019s Lemma is a fundamental result in stochastic calculus, often described as the stochastic analog of the chain rule from classical calculus. It provides a way to compute the differential of a function of a stochastic process that evolves according to an It\u00f4 process.</p> <p>It\u00f4\u2019s Lemma</p> <p>Suppose you have an It\u00f4 process \\( X_t \\) defined by the stochastic differential equation (SDE)</p> \\[ dX_t = a(t, X_t)\\,dt + b(t, X_t)\\,dW_t, \\] <p>where: - \\( a(t, X_t) \\) is the drift coefficient, - \\( b(t, X_t) \\) is the diffusion coefficient, and - \\( W_t \\) is a standard Brownian motion.</p> <p>Now, consider a function \\( f(t, x) \\) that is once continuously differentiable in \\( t \\) and twice continuously differentiable in \\( x \\).</p> <p>It\u00f4\u2019s Lemma states that the process \\( Y_t = f(t, X_t) \\) evolves according to:</p> \\[ df(t, X_t) = \\frac{\\partial f}{\\partial t}(t, X_t)\\,dt + \\frac{\\partial f}{\\partial x}(t, X_t)\\,dX_t + \\frac{1}{2}\\frac{\\partial^2 f}{\\partial x^2}(t, X_t) \\,(dX_t)^2. \\] <p>Since \\( dX_t = a(t, X_t)\\,dt + b(t, X_t)\\,dW_t \\), and using the properties of It\u00f4 calculus (in particular, \\((dW_t)^2 = dt\\) and cross-terms like \\(dt\\,dW_t = 0\\)), the formula becomes:</p> \\[ df(t, X_t) = \\left[\\frac{\\partial f}{\\partial t}(t, X_t) + \\frac{\\partial f}{\\partial x}(t, X_t)a(t, X_t) + \\frac{1}{2}\\frac{\\partial^2 f}{\\partial x^2}(t, X_t)b^2(t, X_t)\\right]dt + \\frac{\\partial f}{\\partial x}(t, X_t)b(t, X_t)\\,dW_t. \\]"},{"location":"book/chapter7_diffusion/introduction_sde/#55-intuitive-explanation","title":"5.5 Intuitive Explanation","text":"<ul> <li> <p>Chain Rule Analogy:   In classical calculus, the chain rule tells you how to differentiate a composite function. It\u00f4\u2019s Lemma plays a similar role, but it also accounts for the randomness and the \u201cextra\u201d quadratic variation that comes from the Brownian motion term \\(dW_t\\).</p> </li> <li> <p>Extra Term:   The term \\(\\frac{1}{2}\\frac{\\partial^2 f}{\\partial x^2}(t, X_t)b^2(t, X_t)dt\\) appears because of the non-zero quadratic variation of \\(W_t\\) (i.e., \\((dW_t)^2 = dt\\)). This term has no counterpart in the classical chain rule,  which introduces a \"correction\" absent in classical calculus.</p> </li> <li> <p>Practical Use:   It\u00f4\u2019s Lemma is essential in many areas of applied mathematics and finance (such as in the derivation of the Black-Scholes equation) because it allows one to derive the dynamics of a function of a stochastic process.</p> </li> </ul> <p>In summary, It\u00f4\u2019s Lemma provides the differential of a function \\( f(t, X_t) \\) when \\( X_t \\) follows an SDE. It incorporates both the usual chain rule components and an additional term to account for the stochastic nature (specifically, the quadratic variation) of the process. This lemma is a cornerstone of stochastic calculus and is widely used in modeling and solving SDEs.</p>"},{"location":"book/chapter7_diffusion/introduction_sde/#56-analytical-solution-to-sde","title":"5.6 Analytical Solution to SDE","text":"<p>Are There Analytic Solutions for SDEs?</p> <p>Yes, some stochastic differential equations (SDEs) have closed-form analytical solutions, but many require numerical methods. Below, we explore cases where analytical solutions exist and common techniques used.</p> <p>Example: A Simple Linear SDE with Analytic Solution</p> <p>Consider the Ornstein-Uhlenbeck process, a common SDE:</p> \\[ dX_t = -\\lambda X_t dt + \\sigma dW_t \\] <p>where:</p> <ul> <li>\\( \\lambda &gt; 0 \\) is a drift coefficient (controls mean reversion),</li> <li>\\( \\sigma \\) is the noise strength,</li> <li>\\( W_t \\) is a standard Wiener process (Brownian motion).</li> </ul> <p>Solution using the Integrating Factor Method:</p> <ol> <li>Define an integrating factor \\( I_t = e^{\\lambda t} \\).</li> <li>Multiply both sides by \\( I_t \\):</li> </ol> \\[ e^{\\lambda t} dX_t + \\lambda e^{\\lambda t} X_t dt = \\sigma e^{\\lambda t} dW_t \\] <ol> <li>Recognizing the left-hand side as an exact differential:</li> </ol> \\[ d(e^{\\lambda t} X_t) = \\sigma e^{\\lambda t} dW_t \\] <ol> <li>Integrating both sides from \\( 0 \\) to \\( t \\):</li> </ol> \\[ X_t = X_0 e^{-\\lambda t} + \\sigma \\int_0^t e^{-\\lambda (t-s)} dW_s \\] <p>This is the closed-form solution for the Ornstein-Uhlenbeck process.</p>"},{"location":"book/chapter7_diffusion/introduction_sde/#561-solutions-of-sde","title":"5.6.1 Solutions of SDE","text":"<p>Some SDEs admit exact solutions formula, often when they fall into these categories:</p> <ol> <li> <p>Linear SDEs: \\( dX_t = a(t) X_t dt + b(t) dW_t \\)     Using an Integrating Factor \\( I_t = e^{-\\int_0^t a(s) ds} \\):</p> \\[ X_t = X_0 e^{\\int_0^t a(s) ds} + e^{\\int_0^t a(s) ds} \\int_0^t e^{-\\int_0^s a(r) dr} b(s) dW_s \\] </li> <li> <p>Example: Geometric Brownian Motion (GBM)</p> <p>$$  dX_t = \\mu X_t dt + \\sigma X_t dW_t  $$</p> <p>Solution:</p> <p>$$  X_t = X_0 \\exp \\left( (\\mu - \\frac{1}{2} \\sigma^2)t + \\sigma W_t \\right)  $$</p> </li> <li> <p>Separable SDEs: If it can be rewritten as:</p> </li> </ol> <p>$$    f(X_t) dX_t = g(t) dt + h(t) dW_t    $$</p> <p>then explicit integration is possible.</p> <pre><code>**Solution** (Using direct integration when separable):\n\n$$\n\\int \\frac{1}{f(X_t)} dX_t = \\int g(t) dt + \\int h(t) dW_t\n$$\n\n\nFor example, if the equation is:\n\n$$\ndX_t = (\\alpha X_t + \\beta) dt + \\sigma dW_t\n$$\n\n- The **solution** can be derived as:\n\n$$\nX_t = e^{\\alpha t} \\left( X_0 + \\int_0^t e^{-\\alpha s} (\\beta ds + \\sigma dW_s) \\right)\n$$\n</code></pre> <ol> <li> <p>Exact Differential Form: When an integrating factor transforms the SDE into an explicit integral.</p> \\[ dX_t + P(t) X_t dt = Q(t) dW_t \\] <ul> <li>Multiply by the integrating factor \\( I_t = e^{\\int P(t) dt} \\), then integrate:</li> </ul> </li> </ol> \\[ X_t = e^{-\\int_0^t P(s) ds} \\left( X_0 + \\int_0^t e^{\\int_0^s P(r) dr} Q(s) dW_s \\right) \\]"},{"location":"book/chapter7_diffusion/introduction_sde/#57-famus-sdes","title":"5.7 Famus SDEs","text":"SDE Name Equation Application Analytic Solution Brownian Motion \\( dX_t = dW_t \\) Random walk, physics \\( X_t = X_0 + W_t \\) Ornstein-Uhlenbeck \\( dX_t = -\\lambda X_t dt + \\sigma dW_t \\) Mean-reverting, finance \\( X_t = X_0 e^{-\\lambda t} + \\sigma \\int_0^t e^{-\\lambda (t-s)} dW_s \\) Geometric Brownian Motion \\( dX_t = \\mu X_t dt + \\sigma X_t dW_t \\) Stock prices \\( X_t = X_0 \\exp \\left( (\\mu - \\frac{1}{2} \\sigma^2) t + \\sigma W_t \\right) \\) Black-Scholes \\( dS_t = \\mu S_t dt + \\sigma S_t dW_t \\) Option pricing \\( S_t = S_0 e^{(\\mu - \\frac{1}{2} \\sigma^2) t + \\sigma W_t} \\) Cox-Ingersoll-Ross \\( dX_t = \\theta (\\mu - X_t) dt + \\sigma \\sqrt{X_t} dW_t \\) Interest rates \\( X_t = \\) No closed form Heston Model \\( dV_t = \\kappa (\\theta - V_t) dt + \\sigma \\sqrt{V_t} dW_t \\) Stochastic volatility \\( V_t = \\) No closed form Langevin Equation \\( m dV_t = -\\gamma V_t dt + \\sqrt{2D} dW_t \\) Brownian motion with damping \\( V_t = V_0 e^{-\\gamma t} + \\sqrt{2D} \\int_0^t e^{-\\gamma (t-s)} dW_s \\) Wright-Fisher \\( dX_t = \\theta X_t (1 - X_t) dt + \\sigma \\sqrt{X_t (1 - X_t)} dW_t \\) Population genetics No closed form DDPM SDE \\( dX_t = -\\frac{1}{2} \\beta(t) X_t dt + \\sqrt{\\beta(t)} dW_t \\) Deep learning (image generation) No closed form Reverse (Denoising) SDE \\( dX_t = \\left[-\\frac{1}{2} \\beta(t) X_t - \\beta(t) \\nabla_{X_t} \\log p_t(X_t) \\right] dt + \\sqrt{\\beta(t)} d\\bar{W}_t \\) Denoising No closed form"},{"location":"book/chapter7_diffusion/introduction_sde/#6-properties-of-the-wiener-process-w_t-in-the-ito-integral","title":"6. Properties of the Wiener Process \\(W_t\\) in the It\u00f4 Integral","text":"<p>The It\u00f4 integral is defined with respect to the Wiener process (or Brownian motion), denoted as \\(W_t\\). This process is central to stochastic calculus due to its unique properties, which enable rigorous integration in noisy systems. Below are key properties of \\(W_t\\) that underpin the It\u00f4 integral:</p>"},{"location":"book/chapter7_diffusion/introduction_sde/#61-1-continuity-of-paths","title":"6.1 1. Continuity of Paths","text":"<ul> <li>Property: \\(W_t\\) is almost surely (a.s.) continuous.</li> <li>Implication: While \\(W_t\\) has no jumps, its paths are nowhere differentiable, necessitating integral-based formulations (e.g., \\(\\int H_t \\, dW_t\\)) instead of derivatives.</li> </ul>"},{"location":"book/chapter7_diffusion/introduction_sde/#62-2-independent-increments","title":"6.2 2. Independent Increments","text":"<ul> <li>Property: For \\(s &lt; t\\), the increment \\(W_t - W_s\\) is independent of the history \\(\\mathcal{F}_s\\) (the filtration up to time \\(s\\)).</li> <li> <p>Mathematically:</p> <p>$$  W_t - W_s \\perp !!! \\perp \\mathcal{F}_s.  $$</p> </li> <li> <p>Implication: Integrands in the It\u00f4 integral must be adapted (i.e., \\(H_t\\) depends only on information up to \\(t\\)). This ensures no \"peeking into the future.\"</p> </li> </ul>"},{"location":"book/chapter7_diffusion/introduction_sde/#63-3-gaussian-increments","title":"6.3 3. Gaussian Increments","text":"<ul> <li> <p>Property: Increments \\(W_t - W_s\\) follow a normal distribution:</p> <p>$$  W_t - W_s \\sim \\mathcal{N}(0, t-s).  $$</p> </li> <li> <p>Implication: The It\u00f4 integral inherits Gaussian structure, making it analytically tractable.</p> </li> </ul>"},{"location":"book/chapter7_diffusion/introduction_sde/#64-4-quadratic-variation","title":"6.4 4. Quadratic Variation","text":"<ul> <li> <p>Property: The quadratic variation of \\(W_t\\) over \\([0, T]\\) is \\(T\\):</p> <p>$$  \\langle W \\rangle_T = \\lim_{\\Delta t \\to 0} \\sum_{i=0}^{n-1} |W_{t_{i+1}} - W_{t_i}|^2 = T.  $$</p> </li> <li> <p>Heuristic Rule: \\((dW_t)^2 = dt\\) in stochastic calculus.</p> </li> <li>Implication: This drives the \"extra term\" in It\u00f4\u2019s Lemma (e.g., \\(\\frac{1}{2} \\sigma^2 \\frac{\\partial^2 f}{\\partial x^2} dt\\)).</li> </ul>"},{"location":"book/chapter7_diffusion/introduction_sde/#65-5-martingale-property","title":"6.5 5. Martingale Property (\u9785\u6027\u8d28)","text":"<p>\u9785\u662f\u968f\u673a\u8fc7\u7a0b\u7684\u4e00\u79cd\u7279\u6b8a\u7c7b\u578b\uff0c\u6ee1\u8db3 \u672a\u6765\u7684\u671f\u671b\u503c\u7b49\u4e8e\u5f53\u524d\u503c. \u9785\u662f\u65e0\u5957\u5229\u5b9a\u4ef7\u7406\u8bba\u7684\u57fa\u7840\uff0c\u56e0\u4e3a\u5b83\u610f\u5473\u7740\u8d44\u4ea7\u4ef7\u683c\u7684\u672a\u6765\u671f\u671b\u503c\u4e0d\u4f1a\u504f\u79bb\u5f53\u524d\u503c\u3002 \u5728\u98ce\u9669\u4e2d\u6027\u6d4b\u5ea6\u4e0b\uff0c\u80a1\u7968\u4ef7\u683c\u7684\u6298\u73b0\u503c\u662f\u4e00\u4e2a\u9785\uff08\u5982 Black-Scholes \u6a21\u578b\uff09\u3002</p> <ul> <li>Property: \\(W_t\\) is a martingale: \\(\\mathbb{E}[W_t | \\mathcal{F}_s] = W_s\\) for \\(s &lt; t\\).</li> <li>Extension: The It\u00f4 integral \\(\\int_0^t H_s \\, dW_s\\) is also a martingale if \\(H_t\\) is adapted and square-integrable.</li> <li>Implication: No arbitrage in financial models, as future expectations are unbiased.</li> </ul>"},{"location":"book/chapter7_diffusion/introduction_sde/#66-6-ito-isometry","title":"6.6 6. It\u00f4 Isometry","text":"<ul> <li>Property: For adapted \\(H_t\\),</li> </ul> <p>\u4e00\u4e2a\u968f\u673a\u8fc7\u7a0b\u88ab\u79f0\u4e3a \u9002\u5e94\u8fc7\u7a0b\uff08Adapted Process\uff09\uff0c\u5982\u679c\u5b83\u7684\u503c\u4ec5\u4f9d\u8d56\u4e8e\u5f53\u524d\u53ca\u8fc7\u53bb\u7684\u4fe1\u606f\uff0c\u800c\u4e0d\u4f9d\u8d56\u672a\u6765\u7684\u4fe1\u606f\u3002 \u5982\u679cH_t \u6ee1\u8db3\u4e00\u4e2aSDE\uff0c\u90a3\u4e00\u5b9a\u662f\u9002\u5e94\u6027\u7684\u3002</p> \\[ \\mathbb{E}\\left[ \\left( \\int_0^T H_t \\, dW_t \\right)^2 \\right] = \\mathbb{E}\\left[ \\int_0^T H_t^2 \\, dt \\right]. \\] <ul> <li>Implication: Provides a link between the \\(L^2\\)-norms of the integral and the integrand, critical for proving convergence.</li> </ul>"},{"location":"book/chapter7_diffusion/introduction_sde/#67-7-zero-expectation","title":"6.7 7. Zero Expectation","text":"<ul> <li>Property: The It\u00f4 integral has zero mean:</li> </ul> \\[ \\mathbb{E}\\left[ \\int_0^T H_t \\, dW_t \\right] = 0. \\] <ul> <li>Reason: Martingale increments have zero expected value.</li> </ul>"},{"location":"book/chapter7_diffusion/introduction_sde/#7-numerical-solutions-of-sde","title":"7. Numerical Solutions of SDE","text":"<p>Let recall the numerical methods for ODE</p> Method Order Implicit/Explicit Best for Iteration Formula Euler \\( O(h) \\) Explicit Simple problems \\( y_{n+1} = y_n + h f(y_n, t_n) \\) Improved Euler (Heun) \\( O(h^2) \\) Explicit More accurate than Euler \\( y_{n+1} = y_n + \\frac{h}{2} ( f(y_n, t_n) + f(y^*, t_{n+1}) ) \\), where \\( y^* = y_n + h f(y_n, t_n) \\) RK4 (Classical Runge-Kutta) \\( O(h^4) \\) Explicit General-purpose \\( y_{n+1} = y_n + \\frac{h}{6} (k_1 + 2k_2 + 2k_3 + k_4) \\), where \\( k_1, k_2, k_3, k_4 \\) are intermediate evaluations Adams-Bashforth \\( O(h^3) \\) Explicit Multi-step, non-stiff problems \\( y_{n+1} = y_n + \\frac{h}{2} \\left( 3 f(y_n, t_n) - f(y_{n-1}, t_{n-1}) \\right) \\) Adams-Moulton \\( O(h^3) \\) Implicit More stable than Adams-Bashforth \\( y_{n+1} = y_n + \\frac{h}{2} \\left( f(y_{n+1}, t_{n+1}) + f(y_n, t_n) \\right) \\) Backward Euler \\( O(h) \\) Implicit Stiff equations \\( y_{n+1} = y_n + h f(y_{n+1}, t_{n+1}) \\) BDF (Backward Differentiation Formula) \\( O(h^2) \\) or higher Implicit Stiff problems \\( \\frac{3}{2} y_{n+1} - 2 y_n + \\frac{1}{2} y_{n-1} = h f(y_{n+1}, t_{n+1}) \\) Symplectic (Verlet, Leapfrog) \\( O(h^2) \\) Explicit Physics, Hamiltonian systems \\( y_{n+1} = 2y_n - y_{n-1} + h^2 f(y_n, t_n) \\) Adaptive RK45 (Dormand-Prince) \\( O(h^4) \\) or \\( O(h^5) \\) Explicit Automatic step size Uses adaptive step control with embedded RK4 and RK5 methods <p>KR4 formula</p> \\[ k_1 = f(y_n, t_n) \\] \\[ k_2 = f(y_n + \\frac{h}{2} k_1, t_n + \\frac{h}{2}) \\] \\[ k_3 = f(y_n + \\frac{h}{2} k_2, t_n + \\frac{h}{2}) \\] \\[ k_4 = f(y_n + h k_3, t_n + h) \\] \\[ y_{n+1} = y_n + \\frac{h}{6} (k_1 + 2k_2 + 2k_3 + k_4). \\] <p>Good accuracy \\(O(h^4)\\).</p> <p>Similar to the ODE solver, we can solve th SDE by the similar numerical methods</p> <p>One thing need to note is that</p> \\[dW_t \\sim \\sqrt{dt}\\] <p>when using Talay expansion</p>"},{"location":"book/chapter7_diffusion/introduction_sde/#71-euler-maruyama-discretization","title":"7.1 Euler-Maruyama Discretization","text":"<p>For a time step \\(\\Delta t\\), the numerical approximation is:</p> \\[  X_{t+\\Delta t} = X_t + f(X_t, t) \\Delta t + g(X_t, t) \\Delta W_t \\] <p>where</p> <p>\\(\\Delta W_t \\sim \\mathcal{N}(0, \\Delta t)\\) is a normally distributed random variable.</p> <pre><code>def euler_maruyama(f, g, X0, T, dt):\n    N = int(T / dt)\n    X = np.zeros(N + 1)\n    t = np.linspace(0, T, N + 1)\n    X[0] = X0\n\n    for i in range(N):\n        dW = np.sqrt(dt) * np.random.randn()\n        X[i+1] = X[i] + f(X[i], t[i]) * dt + g(X[i], t[i]) * dW\n\n    return t, X\n</code></pre> <p>Pros &amp; Cons</p> <p>\u2705 Simple and easy to implement</p> <p>\u2705 Works well for small time steps</p> <p>\u274c Low accuracy (converges at order \\(O(\\sqrt{\\Delta t})\\))</p> <p>\u274c Poor stability for stiff problems</p>"},{"location":"book/chapter7_diffusion/introduction_sde/#72-milstein-method","title":"7.2 Milstein Method","text":"<p>The Milstein method  improves upon Euler-Maruyama by adding a higher-order correction term from It\u00f4 calculus.Milstein Discretization</p> \\[  X_{t+\\Delta t} = X_t + f(X_t, t) \\Delta t + g(X_t, t) \\Delta W_t + \\frac{1}{2} g(X_t, t) g'(X_t, t) \\left((\\Delta W_t)^2 - \\Delta t \\right) \\] <p>where \\(g'(X_t, t)\\) is the derivative of \\(g(X_t, t)\\).</p> <pre><code>def milstein(f, g, X0, T, dt):\n    N = int(T / dt)\n    X = np.zeros(N + 1)\n    t = np.linspace(0, T, N + 1)\n    X[0] = X0\n\n    for i in range(N):\n        dW = np.sqrt(dt) * np.random.randn()\n        g_prime = (g(X[i] + 1e-5, t[i]) - g(X[i], t[i])) / 1e-5  # Numerical derivative\n        X[i+1] = X[i] + f(X[i], t[i]) * dt + g(X[i], t[i]) * dW + 0.5 * g(X[i], t[i]) * g_prime * (dW**2 - dt)\n\n    return t, X\n</code></pre> <p>Pros &amp; Cons</p> <p>\u2705 Higher accuracy than Euler-Maruyama (\\(O(\\Delta t)\\))</p> <p>\u2705 Useful when the diffusion term \\(g(X_t, t)\\) is non-constant</p> <p>\u274c More complex to implement than Euler-Maruyama</p> <p>Theoretically derivation</p>"},{"location":"book/chapter7_diffusion/introduction_sde/#the-goal","title":"The Goal","text":"<p>We want to approximate \\(X_{t_{n+1}}\\) given \\(X_{t_n} = X_n\\) for a small step \\(\\Delta t = t_{n+1} - t_n\\). We write</p> \\[ X_{t_{n+1}} \\;=\\; X_{t_n} \\;+\\;\\int_{t_n}^{t_{n+1}} f\\bigl(X_{s},s\\bigr)\\,ds \\;+\\;\\int_{t_n}^{t_{n+1}} g\\bigl(X_{s},s\\bigr)\\,dW_{s}. \\] <p>The Milstein scheme refines the simpler Euler\u2013Maruyama  scheme by adding a correction term that captures more information about how \\(g(x)\\) varies with \\(x\\). This provides higher-order accuracy in a single Brownian dimension.</p>"},{"location":"book/chapter7_diffusion/introduction_sde/#intuition-via-local-expansion","title":"Intuition via Local Expansion","text":""},{"location":"book/chapter7_diffusion/introduction_sde/#breaking-down-the-integrals","title":"Breaking down the integrals","text":"<p>We have:</p> <ol> <li>Drift integral :</li> </ol> \\[ \\int_{t_n}^{t_{n+1}} f\\bigl(X_{s},s\\bigr)\\,ds\\] <ol> <li>Diffusion integral :</li> </ol> \\[\\int_{t_n}^{t_{n+1}} g\\bigl(X_{s},s\\bigr)\\,dW_{s}\\] <p>Over a small step \\(\\Delta t\\), a first approximation uses \\(f(X_{s}, s) \\approx f(X_n, t_n)\\) and \\(g(X_{s}, s) \\approx g(X_n, t_n)\\).</p> <p>This yields:</p> \\[ \\int_{t_n}^{t_{n+1}} f\\bigl(X_{n}, t_n\\bigr)\\,ds \\;\\approx\\; f(X_{n}, t_n)\\,\\Delta t, \\] \\[ \\int_{t_n}^{t_{n+1}} g\\bigl(X_{n}, t_n\\bigr)\\,dW_{s} \\;\\approx\\; g(X_{n}, t_n)\\,\\bigl(W_{t_{n+1}} - W_{t_n}\\bigr) \\;=\\; g(X_{n}, t_n)\\,\\Delta W_{n}. \\] <p>This is precisely the Euler\u2013Maruyama  step. However, Euler\u2013Maruyama does not  capture the effect of how \\(g\\) changes when \\(X_s\\) itself changes over the interval. Milstein\u2019s idea is to expand \\(g(X_{s}, s)\\) around \\(X_{n}\\) and keep enough terms in the expansion so that the variance structure (It\u00f4\u2019s isometry) is better approximated.</p>"},{"location":"book/chapter7_diffusion/introduction_sde/#local-linearization-of-gx","title":"Local linearization of \\(g(x)\\)","text":"<p>Consider the diffusion function \\(g(x)\\) at times \\(s \\in [t_n, t_{n+1}]\\). Over that short time, \\(X_s\\) changes from \\(X_n\\). We can do a Taylor expansion:</p> \\[ g\\bigl(X_{s}\\bigr) \\;\\approx\\; g\\bigl(X_{n}\\bigr) \\;+\\; \\frac{\\partial g}{\\partial x}\\bigl(X_{n}\\bigr)\\,\\bigl(X_{s} - X_{n}\\bigr), \\] <p>suppressing explicit time arguments for brevity and focusing on the dependence on \\(x\\). Then:</p> \\[ \\int_{t_n}^{t_{n+1}} g\\bigl(X_{s}\\bigr)\\,dW_{s} \\;\\approx\\; \\int_{t_n}^{t_{n+1}} \\Bigl[g(X_n) \\;+\\; g'(X_n)\\,\\bigl(X_{s} - X_{n}\\bigr)\\Bigr]\\,dW_{s}. \\] <p>The term \\(X_{s} - X_{n}\\) can be approximated by the leading-order  contributions from the SDE:</p> \\[ X_{s} - X_{n} \\;\\approx\\; \\int_{t_n}^{s} f(X_{n}) \\,du \\;+\\; \\int_{t_n}^{s} g(X_{n}) \\,dW_{u} \\;\\approx\\; f(X_{n})\\,(s - t_{n}) \\;+\\; g(X_{n})\\,(W_{s} - W_{t_n}). \\] <p>Hence,</p> \\[ g'(X_n)\\,\\bigl(X_{s} - X_{n}\\bigr) \\;\\approx\\; g'(X_n) \\,\\Bigl[ f(X_{n})\\,(s - t_{n}) \\;+\\; g(X_{n})\\,\\bigl(W_{s} - W_{t_n}\\bigr) \\Bigr]. \\] <p>Substitute back inside the stochastic integral:</p> \\[ \\int_{t_n}^{t_{n+1}} g\\bigl(X_{s}\\bigr)\\,dW_{s} \\;\\approx\\; \\int_{t_n}^{t_{n+1}} g(X_n)\\,dW_{s} \\;+\\; \\int_{t_n}^{t_{n+1}} g'(X_n)\\,g(X_{n})\\,\\bigl(W_{s} - W_{t_n}\\bigr)\\,dW_{s} \\;+\\; \\text{(terms involving \\(\\,f\\))}. \\] <p>However, for the one-dimensional Milstein method in the It\u00f4 sense , the primary correction stems from</p> \\[ \\int_{t_n}^{t_{n+1}} g'(X_n)\\,g(X_{n})\\,\\bigl(W_{s} - W_{t_n}\\bigr)\\,dW_{s}, \\] <p>because the \\(\\,f\\)-related terms contribute at a higher order in \\(\\Delta t\\).</p>"},{"location":"book/chapter7_diffusion/introduction_sde/#evaluating-the-second-stochastic-integral","title":"Evaluating the second stochastic integral","text":"<p>The integral</p> \\[ \\int_{t_n}^{t_{n+1}} (W_{s} - W_{t_n})\\,dW_{s} \\] <p>in the It\u00f4 sense is well-known to satisfy:</p> \\[ \\int_{t_n}^{t_{n+1}} (W_{s} - W_{t_n})\\,dW_{s} \\;=\\; \\tfrac12 \\Bigl[(W_{t_{n+1}} - W_{t_n})^2 - (t_{n+1} - t_n)\\Bigr]. \\] <p>This identity follows from an It\u00f4 integration by parts or can be seen from It\u00f4\u2019s formula applied to \\(\\frac12 (W_s - W_{t_n})^2\\). Hence,</p> \\[ \\int_{t_n}^{t_{n+1}} g'(X_n)\\,g(X_{n})\\,\\bigl(W_{s} - W_{t_n}\\bigr)\\,dW_{s} \\;=\\; g'(X_n)\\,g(X_{n}) \\;\\times\\; \\tfrac12 \\Bigl[(\\Delta W_{n})^2 - \\Delta t\\Bigr]. \\] <p>Thus the additional correction  to the usual Euler\u2013Maruyama term is:</p> \\[ \\tfrac12\\,g\\bigl(X_{n}\\bigr)\\,\\frac{\\partial\\,g\\bigl(X_{n}\\bigr)}{\\partial x} \\bigl((\\Delta W_{n})^2 - \\Delta t \\bigr). \\]"},{"location":"book/chapter7_diffusion/introduction_sde/#collecting-all-terms","title":"Collecting All Terms","text":"<p>Putting everything together for a single step from \\((t_n, X_n)\\) to \\((t_{n+1}, X_{n+1})\\):</p> <ol> <li>Euler\u2013Maruyama \u201cdrift\u201d :</li> </ol> \\[ f\\bigl(X_{n}, t_n\\bigr)\\,\\Delta t, \\] <ol> <li>Euler\u2013Maruyama \u201cdiffusion\u201d :</li> </ol> \\[ g\\bigl(X_{n}, t_n\\bigr)\\,\\Delta W_{n}, \\] <ol> <li>Milstein correction :</li> </ol> \\[ \\tfrac{1}{2}\\,g\\bigl(X_{n}, t_n\\bigr)\\,\\frac{\\partial\\,g\\bigl(X_{n}, t_n\\bigr)}{\\partial x} \\Bigl((\\Delta W_{n})^2 - \\Delta t\\Bigr). \\] <p>Hence, the Milstein update is</p> \\[ \\boxed{ X_{n+1} = X_{n} \\;+\\; f\\bigl(X_{n}, t_n\\bigr)\\,\\Delta t \\;+\\; g\\bigl(X_{n}, t_n\\bigr)\\,\\Delta W_{n} \\;+\\; \\tfrac{1}{2}\\,g\\bigl(X_{n}, t_n\\bigr)\\,\\frac{\\partial\\,g\\bigl(X_{n}, t_n\\bigr)}{\\partial x} \\Bigl((\\Delta W_{n})^2 - \\Delta t\\Bigr). } \\]"},{"location":"book/chapter7_diffusion/introduction_sde/#key-points-in-the-derivation","title":"Key Points in the Derivation","text":"<ul> <li> <p>It\u00f4\u2013Taylor expansion : You can view Milstein\u2019s method as keeping all terms up to order \\(\\Delta t\\) in an It\u00f4\u2013Taylor series expansion of the solution \\(X_{t+\\Delta t}\\) around \\(t\\).</p> </li> <li> <p>Quadratic variation : In It\u00f4 calculus, \\((\\Delta W_n)^2 \\approx \\Delta t\\). This leads to the specific form of the correction \\(\\bigl((\\Delta W_n)^2 - \\Delta t\\bigr)\\).</p> </li> <li> <p>One Brownian dimension : In higher dimensions or with multiple Brownian motions, additional cross-terms appear, and the method\u2019s generalization involves partial derivatives and a (possibly) more complex correction term.</p> </li> </ul>"},{"location":"book/chapter7_diffusion/introduction_sde/#73-runge-kutta-methods-for-sdes","title":"7.3 Runge-Kutta Methods for SDEs","text":"<p>Just like in ODEs, Runge-Kutta methods can be adapted for SDEs. However, their stochastic versions require modifications.</p> <ul> <li> <p>Stochastic Runge-Kutta (SRK) Methods:  These include additional terms to handle randomness effectively.</p> </li> <li> <p>Order-1.5 SRK Schemes:  Higher-order convergence but computationally expensive.</p> </li> </ul> <pre><code>def runge_kutta_sde(f, g, X0, T, dt):\n    N = int(T / dt)\n    X = np.zeros(N + 1)\n    t = np.linspace(0, T, N + 1)\n    X[0] = X0\n\n    for i in range(N):\n        dW = np.sqrt(dt) * np.random.randn()\n        K1 = f(X[i], t[i]) * dt + g(X[i], t[i]) * dW\n        K2 = f(X[i] + K1, t[i] + dt) * dt + g(X[i] + K1, t[i] + dt) * dW\n        X[i+1] = X[i] + 0.5 * (K1 + K2)\n\n    return t, X\n</code></pre> <p>\u2705 More accurate than Milstein \u274c Complex derivation and implementation</p> <p>4. Implicit Methods for Stiff SDEs When dealing with stiff SDEs (e.g., financial models with mean-reverting processes), explicit methods may require very small time steps. Implicit methods improve stability.</p> <ul> <li>Implicit Euler Method:</li> </ul> \\[  X_{t+\\Delta t} = X_t + f(X_{t+\\Delta t}, t+\\Delta t) \\Delta t + g(X_t, t) \\Delta W_t \\] <pre><code>def implicit_euler(f, g, X0, T, dt):\n    N = int(T / dt)\n    X = np.zeros(N + 1)\n    t = np.linspace(0, T, N + 1)\n    X[0] = X0\n\n    for i in range(N):\n        dW = np.sqrt(dt) * np.random.randn()\n        def F(X_next):  # Implicit equation\n            return X_next - X[i] - f(X_next, t[i] + dt) * dt - g(X[i], t[i]) * dW\n        X[i+1] = fsolve(F, X[i])  # Solve for X_next\n\n    return t, X\n</code></pre> <p>This requires solving an implicit equation at each step. \u2705 Stable for stiff equations \u274c Requires solving nonlinear equations at each step</p> <p>Conclusion</p> <ul> <li> <p>Euler-Maruyama : Simple but low accuracy</p> </li> <li> <p>Milstein : Higher accuracy, useful when \\(\\(g(X_t, t)\\)\\) is non-constant</p> </li> <li> <p>Runge-Kutta for SDEs : More accurate but complex</p> </li> <li> <p>Implicit Methods : Needed for stiff SDEs</p> </li> </ul> <p>Summary</p> Method Order of Convergence Pros Cons Euler-Maruyama \\(O(\\sqrt{\\Delta t})\\) Simple, easy to implement Low accuracy Milstein \\(O(\\Delta t)\\) More accurate than Euler-Maruyama Requires derivative of g(x,t)g(x,t)g(x,t) Runge-Kutta (SDE) \\(O(\\Delta t^{1.5})\\) High accuracy Computationally expensive Implicit Euler \\(O(\\Delta t)\\) Good for stiff problems Needs a nonlinear solver"},{"location":"book/chapter7_diffusion/introduction_sde/#74-applications-of-sdes","title":"7.4 Applications of SDEs","text":"<p>SDEs are everywhere:</p> <ul> <li>Finance: Modeling stock prices (Black-Scholes equation).</li> <li>Physics: Describing thermal fluctuations.</li> <li>Biology: Population dynamics in random environments.</li> <li>Engineering: Signal processing with noise.</li> </ul>"},{"location":"book/chapter7_diffusion/introduction_sde/#75-simulating-an-sde-a-hands-on-example","title":"7.5 Simulating an SDE: A Hands-On Example","text":"<p>Assume we have the SDE The stochastic logistic model is governed by the following stochastic differential equation (SDE):</p> \\[ dx = r x \\left(1 - \\frac{x}{K} \\right) dt + \\sqrt{2D} dW_t \\] <p>where:</p> <ul> <li>\\( x \\) is the population size,</li> <li>\\( r \\) is the intrinsic growth rate,</li> <li>\\( K \\) is the carrying capacity,</li> <li>\\( D \\) is the diffusion coefficient (determining the noise intensity),</li> <li>\\( dt \\) is the time step,</li> </ul> <p>which is wsed to model population growth of species in an environment with a carrying capacity and random environmental variations (e.g., climate changes, food availability). Example: Studying fluctuations in animal populations, bacterial growth under limited resources, and human population modeling with stochastic factors.</p> <p>The discrete-time approximation (Euler-Maruyama scheme) used in the Python implementation follows:</p> \\[ x_n = x_{n-1} + r x_{n-1} \\left(1 - \\frac{x_{n-1}}{K} \\right) \\Delta t + \\sqrt{2D \\Delta t} \\mathcal{N}(0,1) \\] numerical SDE<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\ndef stochastic_logistic_SDE(X0, r, K, D, T, dt, N_paths):\n    \"\"\"\n    Simulates the stochastic logistic model using the given SDE formulation.\n    Parameters:\n        X0 (float): Initial population size\n        r (float): Growth rate\n        K (float): Carrying capacity\n        D (float): Diffusion coefficient (noise intensity)\n        T (float): Total time\n        dt (float): Time step size\n        N_paths (int): Number of simulation paths\n    \"\"\"\n    N_steps = int(T / dt)\n    t = np.linspace(0, T, N_steps + 1)\n    X = np.zeros((N_paths, N_steps + 1))\n    X[:, 0] = X0\n    for i in range(N_steps):\n        dW = np.sqrt(2 * D * dt) * np.random.randn(N_paths)  # Brownian motion increment\n        X_t = X[:, i]\n        dX = r * X_t * (1 - X_t / K) * dt + dW * np.random.randn(N_paths)\n        X[:, i + 1] = np.maximum(X_t + dX, 0)  # Ensure non-negativity\n\n    return t, X\n# Parameters\nX0 = 3   # Initial population size\nr = 0.8   # Growth rate\nK = 100   # Carrying capacity\nD = 0.1   # Diffusion coefficient\nT = 10    # Total time\ndt = 0.01 # Time step size\nN_paths = 20  # Number of simulation paths\n\n# Run simulation\nt, X = stochastic_logistic_SDE(X0, r, K, D, T, dt, N_paths)\n\n# Plot results\nplt.figure(figsize=(10, 6))\nfor i in range(N_paths):\n    plt.plot(t, X[i, :], label=f'Path {i+1}')\nplt.xlabel('Time')\nplt.ylabel('Population Size')\nplt.title('Stochastic Logistic Model Simulation')\nplt.legend()\nplt.show()\n</code></pre> <p>With different diffusion coefficient, we have the plot of the population size over time.</p> D = 0.1D = 1D=5D=10 <p></p> <p></p> <p></p> <p></p> <p>The simulation shows population growth under logistic constraints with stochastic fluctuations. Initially, the population grows exponentially but slows as it nears the carrying capacity \\( K \\). Random noise causes deviations from the deterministic trend, leading to varied trajectories. Higher noise intensity \\( D \\) increases fluctuations, sometimes pushing populations below or above expected levels. Despite randomness, most paths stabilize around \\( K \\) over time.</p> <p>We can also consider this in the expectation point of view. Given a fixed starting point, let's see what is the distribution at given time \\(t\\) for the pupolation size.</p> D=0.001D=0.1D=0.5D=1D=5D=10D=50Code <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> simulation Code<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom scipy.stats import gaussian_kde\n\ndef stochastic_logistic_SDE(X0, r, K, D, T, dt, N_paths):\n    \"\"\"\n    Simulates the stochastic logistic model using the given SDE formulation.\n\n    Parameters:\n        X0 (float): Initial population size\n        r (float): Growth rate\n        K (float): Carrying capacity\n        D (float): Diffusion coefficient (noise intensity)\n        T (float): Total time\n        dt (float): Time step size\n        N_paths (int): Number of simulation paths\n    \"\"\"\n    N_steps = int(T / dt)\n    t = np.linspace(0, T, N_steps + 1)\n    X = np.zeros((N_paths, N_steps + 1))\n    X[:, 0] = X0\n\n    for i in range(N_steps):\n        dW = np.sqrt(2 * D * dt) * np.random.randn(N_paths)  # Brownian motion increment\n        X_t = X[:, i]\n        dX = r * X_t * (1 - X_t / K) * dt + dW * np.random.randn(N_paths)\n        X[:, i + 1] = np.maximum(X_t + dX, 0)  # Ensure non-negativity\n\n    return t, X\n\n# Parameters\nX0 = 3   # Initial population size\nr = 0.5   # Growth rate\nK = 100   # Carrying capacity\nD = 50   # Diffusion coefficient\nT = 30    # Total time\ndt = 0.01 # Time step size\nN_paths = 1000  # Number of simulation paths\n\n# Run simulation\nt, X = stochastic_logistic_SDE(X0, r, K, D, T, dt, N_paths)\n\n# Select multiple time points for distribution analysis\ntime_points = np.linspace(0, T, num=20)  # Sample 10 time points\ntime_points = time_points[2:]\ntime_indices = [int(tp / dt) for tp in time_points]\n\n# Create 3D figure\nfig = plt.figure(figsize=(10, 7))\nax = fig.add_subplot(111, projection='3d')\n\n# Plot smooth KDE-based distributions over time\nfor i, index in enumerate(time_indices):\n    kde = gaussian_kde(X[:, index])\n    x_range = np.linspace(np.min(X[:, index]), np.max(X[:, index]), 100)\n    density = kde(x_range)\n    ax.plot(x_range, [time_points[i]] * len(x_range), density, lw=2)\n\nax.set_xlabel('Population Size')\nax.set_ylabel('Time')\nax.set_zlabel('Density')\nax.set_title('Evolution of Population Distribution Over Time')\nplt.show()\n</code></pre>"},{"location":"book/chapter7_diffusion/introduction_sde/#8-extension-other-sde-type","title":"8. Extension: Other SDE type","text":"<p>Below are several common forms of stochastic differential equations (SDEs) when different types of noise are used as the driving term, along with their corresponding integral forms:</p>"},{"location":"book/chapter7_diffusion/introduction_sde/#81-1-sde-driven-by-brownian-motion","title":"8.1 1. SDE Driven by Brownian Motion","text":"<p>Differential Form:</p> \\[ dX_t = b(X_t, t)\\,dt + \\sigma(X_t, t)\\,dW_t, \\] <p>where:</p> <ul> <li>\\(b(X_t, t)\\) is the drift coefficient,</li> <li>\\(\\sigma(X_t, t)\\) is the diffusion coefficient, and</li> <li>\\(W_t\\) is a standard Brownian motion.</li> </ul> <p>Integral Form:</p> \\[ X_t = X_0 + \\int_0^t b(X_s, s)\\,ds + \\int_0^t \\sigma(X_s, s)\\,dW_s. \\] <p>Here, the stochastic integral \\(\\int_0^t \\sigma(X_s, s)\\,dW_s\\) is interpreted in the It\u00f4 sense.</p>"},{"location":"book/chapter7_diffusion/introduction_sde/#82-2-sde-driven-by-a-levy-process-including-jumps","title":"8.2 2. SDE Driven by a L\u00e9vy Process (Including Jumps)","text":"<p>L\u00e9vy processes generalize Brownian motion by allowing jumps. In many models, a L\u00e9vy process is represented as a combination of a continuous part (often still a Brownian motion) and a jump part, typically modeled using a compensated Poisson random measure.</p> <p>Differential Form:</p> \\[ dX_t = b(X_{t-}, t)\\,dt + \\sigma(X_{t-}, t)\\,dW_t + \\int_{\\mathbb{R}} \\gamma(X_{t-}, t, z)\\,\\tilde{N}(dt,dz), \\] <p>where:</p> <ul> <li>\\(X_{t-}\\) denotes the left-limit of \\(X\\) at time \\(t\\) (to handle jump discontinuities),</li> <li>\\(\\tilde{N}(dt,dz)\\) is the compensated Poisson random measure, and</li> <li>\\(\\gamma(X_{t-}, t, z)\\) describes the impact on \\(X_t\\) when a jump of size \\(z\\) occurs.</li> </ul> <p>Integral Form:</p> \\[ X_t = X_0 + \\int_0^t b(X_{s-}, s)\\,ds + \\int_0^t \\sigma(X_{s-}, s)\\,dW_s + \\int_0^t\\int_{\\mathbb{R}} \\gamma(X_{s-}, s, z)\\,\\tilde{N}(ds,dz). \\]"},{"location":"book/chapter7_diffusion/introduction_sde/#83-3-sde-driven-by-a-pure-jump-process-jump-diffusion-model","title":"8.3 3. SDE Driven by a Pure Jump Process (Jump-Diffusion Model)","text":"<p>In some models, the jump component is emphasized. Here, the SDE might include both a continuous part (from Brownian motion) and a pure jump part, often represented by a Poisson random measure.</p> <p>Differential Form:</p> \\[ dX_t = b(X_{t-}, t)\\,dt + \\sigma(X_{t-}, t)\\,dW_t + dJ_t, \\] <p>where the jump process \\(J_t\\) is given by</p> \\[ J_t = \\int_0^t\\int_{\\mathbb{R}} z\\,N(ds,dz), \\] <p>with \\(N(ds,dz)\\) being the (non-compensated) Poisson random measure.</p> <p>Integral Form:</p> \\[ X_t = X_0 + \\int_0^t b(X_{s-}, s)\\,ds + \\int_0^t \\sigma(X_{s-}, s)\\,dW_s + \\int_0^t\\int_{\\mathbb{R}} z\\,N(ds,dz). \\]"},{"location":"book/chapter7_diffusion/introduction_sde/#84-4-sde-driven-by-fractional-brownian-motion-fbm","title":"8.4 4. SDE Driven by Fractional Brownian Motion (fBm)","text":"<p>Fractional Brownian motion \\(B^H_t\\) is a generalization of standard Brownian motion that exhibits self-similarity and long-range dependence. Its increments are not independent, which means that the standard It\u00f4 calculus does not apply; one must use other definitions of stochastic integration (e.g., Young integration or the rough paths approach).</p> <p>Differential Form:</p> \\[ dX_t = b(X_t, t)\\,dt + \\sigma(X_t, t)\\,dB^H_t, \\] <p>where \\(B^H_t\\) is a fractional Brownian motion with Hurst parameter \\(H \\in (0,1)\\).</p> <p>Integral Form:</p> \\[ X_t = X_0 + \\int_0^t b(X_s, s)\\,ds + \\int_0^t \\sigma(X_s, s)\\,dB^H_s. \\] <p>The integral \\(\\int_0^t \\sigma(X_s, s)\\,dB^H_s\\) is defined according to a theory appropriate for fractional Brownian motion, such as Young integration or the rough paths framework.</p>"},{"location":"book/chapter7_diffusion/introduction_sde/#85-summary","title":"8.5 Summary","text":"<ul> <li> <p>Standard Brownian Motion:   Uses It\u00f4 integration; the noise is continuous and has independent, normally distributed increments.</p> </li> <li> <p>L\u00e9vy Process:   Combines a Brownian motion component with a jump component modeled by a compensated Poisson random measure.</p> </li> <li> <p>Pure Jump Process:   Focuses on the jump component, often represented by a Poisson random measure, sometimes combined with a Brownian motion.</p> </li> <li> <p>Fractional Brownian Motion:   Incorporates memory effects and long-range dependence; requires alternative integration methods due to the non-independent increments.</p> </li> </ul> <p>Each of these forms is chosen based on the characteristics of the system being modeled and the specific features (such as jumps or long-range dependence) that need to be captured.</p>"},{"location":"book/chapter7_diffusion/introduction_sde/#9-refered-book","title":"9. refered book","text":"<ul> <li>AN INTRODUCTION TO STOCHASTIC DIFFERENTIAL EQUATIONS</li> </ul> <p>\u4e0b\u56fe\u6a21\u62df\u4e86\u82b1\u7c89(\u9ec4\u8272)\u6536\u5230\u5927\u91cf\u6c34\u5206\u5b50\u7684\u649e\u51fb\u8fdb\u884c\u968f\u673a\u7684\u5e03\u6717\u8fd0\u52a8\u7684\u60c5\u5f62\u3002</p>"},{"location":"book/chapter7_diffusion/introduction_sde/#10-reference","title":"10. reference","text":"<ol> <li>AN INTRODUCTION TO STOCHASTIC DIFFERENTIAL EQUATIONS</li> <li>\u6269\u6563\u6a21\u578b\u4e2d\u5e03\u6717\u8fd0\u52a8</li> </ol>"},{"location":"book/chapter7_diffusion/ldm/","title":"Understanding Latent Diffusion Models (LDMs): A Comprehensive Guide","text":""},{"location":"book/chapter7_diffusion/ldm/#1-introduction","title":"1. Introduction","text":"<p>Latent Diffusion Models (LDMs) have revolutionized the field of generative AI by significantly improving efficiency and control in image generation tasks. Unlike traditional diffusion models that operate in pixel space, LDMs perform the diffusion process in a compressed latent space, reducing computational overhead while maintaining high-quality results. This blog explores the fundamental concepts of LDMs, their architecture, training process, and practical applications in image editing and style transfer.</p>"},{"location":"book/chapter7_diffusion/ldm/#2-1-what-are-latent-diffusion-models-ldms","title":"2. 1. What Are Latent Diffusion Models (LDMs)?","text":"<p>LDMs are a class of diffusion models designed to operate in a lower-dimensional latent space rather than directly on high-dimensional pixel data. This key innovation allows them to be computationally efficient while retaining the expressive power of traditional diffusion models.</p>"},{"location":"book/chapter7_diffusion/ldm/#21-key-concepts-of-ldms","title":"2.1 Key Concepts of LDMs","text":"<ol> <li>Latent Space Diffusion: Instead of applying noise and denoising directly on images, LDMs first compress the image into a latent space using a pre-trained Variational Autoencoder (VAE). The diffusion process then occurs in this latent space.</li> <li>U-Net for Denoising: LDMs utilize a U-Net-based architecture to learn the denoising process and reconstruct the original latent representation.</li> <li>Cross-Attention for Conditional Control: By incorporating a cross-attention mechanism, LDMs can accept various forms of input conditions, such as text prompts, image guides, or segmentation masks.</li> <li>Efficient Computation: By reducing the dimensionality of the data before diffusion, LDMs significantly lower computational requirements compared to full-resolution diffusion models.</li> </ol>"},{"location":"book/chapter7_diffusion/ldm/#3-conditional-generating","title":"3. Conditional Generating","text":"<p>Beyond the capabilities of latent diffusion, another significant contribution is the implementation of conditional generation.</p> <p>Let's take text-to-image generation as an example:</p> <p>Let \\(\\tau_\\theta(y)\\) be a encoder (like the clip or orther pretrained models), \\(\\tau_\\theta\\) maps the condition \\(y\\) into the space \\(R^{M\\times d}\\), and then use cross attention in the UNet to combine the condition in the model, which looks like </p> <p>The overall framework consists of two phases:</p> <ul> <li>Training </li> <li>Inference </li> </ul> <p>The training process must be jointly performed with the condition encoding network. When using a pretrained network for condition encoding, it can remain fixed while the training focuses on aligning the latent space with that of the pretrained conditioning model.</p>"},{"location":"book/chapter7_diffusion/ldm/#4-2-training-and-inference-in-ldms","title":"4. 2. Training and Inference in LDMs","text":"<p>The training and inference processes of LDMs involve multiple stages, primarily leveraging a VAE for encoding-decoding and a diffusion model for denoising.</p>"},{"location":"book/chapter7_diffusion/ldm/#41-1-training-process","title":"4.1 (1) Training Process","text":""},{"location":"book/chapter7_diffusion/ldm/#411-train-the-vae","title":"4.1.1 Train the VAE","text":"<ul> <li>The VAE consists of an encoder that compresses an input image into a latent representation \\( z \\).</li> <li>A decoder reconstructs the image from \\( z \\), ensuring the latent space preserves meaningful image information.</li> </ul> <p>It has two types of VAEs</p>"},{"location":"book/chapter7_diffusion/ldm/#4111-vq-vae","title":"4.1.1.1 VQ-VAE","text":"<p>It is identical to the <code>VQ-GAN</code> architecture. For more details, please refer to the VQ-GAN article.</p>"},{"location":"book/chapter7_diffusion/ldm/#4112-kl-vae","title":"4.1.1.2 KL-VAE","text":"<p>This variant is a modification of VQ-GAN, where the quantizer module is replaced with a standard <code>KL</code> divergence loss. This simplifies the overall framework to a combination of <code>VAE</code> + <code>GAN</code>.</p> <p>The loss can be represented as:</p> <p>$$  \\mathcal{L} = \\frac{1}{N} \\sum_{i=1}^{N} | x_i - \\hat{x}i |^2+ \\sum \\lambda_l | \\phi_l(x) - \\phi_l(G(z)) |2^2  + \\frac{1}{2} \\sum $$ Refer }^{d} (1 + \\log \\sigma_{i,j}^2 - \\mu_{i,j}^2 - \\sigma_{i,j}^2)+ L_{advLatent Diffusion for more details about the coding. Here is the overall structure of the KL-VAE</p> <p></p>"},{"location":"book/chapter7_diffusion/ldm/#412-train-the-latent-diffusion-model","title":"4.1.2 Train the Latent Diffusion Model","text":"<ul> <li>Noise is gradually added to the latent representation \\( z \\), following a Gaussian noise schedule.</li> <li> <p>The U-Net model learns to denoise and recover the original latent representation. Most steps are similar to those in DDPM. However, in this case, different types of conditions are processed and fed into the model. Here's a concise summary of the model's key components:</p> </li> <li> <p>Input Definitions:</p> </li> <li>Latent and Spatial Condition:      $$      h_0 = \\operatorname{concat}(z,\\, c_{\\text{concat}})      $$</li> <li>Time and Class Embedding:      $$      \\text{emb} = \\phi(t) + \\phi(y)      $$</li> <li> <p>Context for Cross-Attention:      $$      \\text{context} = c_{\\text{crossattn}}      $$</p> </li> <li> <p>Model Operation:</p> </li> <li>The module that processes these inputs is defined as:      $$      h = \\operatorname{module}(h_0,\\, \\text{emb},\\, \\text{context})      $$</li> <li>Within the module:<ul> <li>The embedding \\( \\text{emb} \\) is added to the concatenated input \\( h_0 \\).</li> <li>Cross-attention is applied using the context \\( c_{\\text{crossattn}} \\) (with \\( c_{\\text{crossattn}} \\) serving as both keys and values) to fuse the sequential information with the spatial representation.</li> </ul> </li> </ul> <p>This sophisticated framework enables seamless integration of latent features, spatial conditioning, sequential context, and temporal and class information.</p> <p>Below are visualizations of the Diffusion model framework:</p> <p></p> <pre><code>graph LR\n  subgraph Image Processing\n    direction LR\n    A[down sample layer 1] --&gt; B[SpatialTransformer] --&gt; C[down sample layer 2]\n  end\n\n  subgraph Text Conditioning\n    direction BT\n    F[\"A white cat sitting on a chair\"] --&gt; E[FrozenCLIPEmbedder] --&gt; D[content]\n  end\n\n  D --&gt;|Conditioning| B\n</code></pre> <p> </p>"},{"location":"book/chapter7_diffusion/ldm/#42-2-inference-process","title":"4.2 (2) Inference Process","text":"<ol> <li>Start with Random Noise: Generate a noisy latent variable \\( z_T \\).</li> <li>Denoising Through U-Net: The trained U-Net progressively removes noise, reconstructing a meaningful latent representation \\( z_0 \\).</li> <li>Decode Back to Image: The VAE decoder converts the denoised latent representation into a final high-resolution image.</li> </ol> <p>This workflow enables fast and high-quality image synthesis, forming the backbone of models like Stable Diffusion.</p>"},{"location":"book/chapter7_diffusion/ldm/#5-3-applications-of-ldms","title":"5. 3. Applications of LDMs","text":"<p>LDMs enable a range of advanced applications in image generation and editing. Below, we explore two key applications: image editing and style transfer.</p>"},{"location":"book/chapter7_diffusion/ldm/#51-1-image-editing-with-ldms","title":"5.1 (1) Image Editing with LDMs","text":"<p>LDMs provide powerful image editing capabilities, including Inpainting and Outpainting, by leveraging latent space manipulations.</p>"},{"location":"book/chapter7_diffusion/ldm/#511-a-inpainting-filling-missing-regions","title":"5.1.1 A. Inpainting (Filling Missing Regions)","text":"<ul> <li>Goal: Fill missing parts of an image naturally while keeping the existing content unchanged.</li> <li>Process:</li> <li>Encode the image into latent space.</li> <li>Apply noise selectively to the missing region.</li> <li>Use the U-Net denoising model to reconstruct plausible content.</li> <li>Decode the latent representation back into an image.</li> </ul> <p>\ud83d\udccc Real-world example: Adobe Photoshop\u2019s \"Generative Fill\" uses similar techniques for intelligent image restoration.</p>"},{"location":"book/chapter7_diffusion/ldm/#512-b-outpainting-expanding-image-boundaries","title":"5.1.2 B. Outpainting (Expanding Image Boundaries)","text":"<ul> <li>Goal: Extend an image beyond its original borders while preserving its consistency.</li> <li>Process:</li> <li>Encode the original image.</li> <li>Initialize the extended region with random noise.</li> <li>Perform controlled denoising while maintaining visual coherence.</li> <li>Decode the expanded latent space back into a complete image.</li> </ul> <p>\ud83d\udccc Real-world example: OpenAI\u2019s DALL\u00b7E 2 uses outpainting for creative image expansion.</p>"},{"location":"book/chapter7_diffusion/ldm/#52-2-style-transfer-with-ldms","title":"5.2 (2) Style Transfer with LDMs","text":"<p>Style transfer refers to transforming an image into a new artistic style while maintaining its structural content. LDMs achieve this through two main approaches:</p>"},{"location":"book/chapter7_diffusion/ldm/#521-a-direct-latent-space-manipulation","title":"5.2.1 A. Direct Latent Space Manipulation","text":"<ul> <li>Process:</li> <li>Encode the image into latent space.</li> <li>Introduce a style prompt (e.g., \"Van Gogh style\").</li> <li>Modify the denoising process with a cross-attention mechanism to enforce the style.</li> <li>Decode the final image.</li> </ul> <p>\ud83d\udccc Application: Stable Diffusion enables users to generate images in diverse artistic styles through text prompts.</p>"},{"location":"book/chapter7_diffusion/ldm/#522-b-fine-tuning-with-dreambooth-or-controlnet","title":"5.2.2 B. Fine-tuning with DreamBooth or ControlNet","text":"<ol> <li>DreamBooth:</li> <li>Fine-tunes an LDM with a few style-specific images to learn and replicate custom styles.</li> <li> <p>Useful for custom artistic portrait generation.</p> </li> <li> <p>ControlNet:</p> </li> <li>Guides the diffusion process using structural constraints like depth maps, edge detection, or pose estimation.</li> <li>Enables precise style transfer with structural preservation.</li> </ol> <p>\ud83d\udccc Application: ControlNet is extensively used for anime-style conversions and photo-to-painting transformations.</p> <p>Refer latent diffusion model hands on for deep understanding of the codes.</p>"},{"location":"book/chapter7_diffusion/ldm/#6-4-key-advantages-of-ldms","title":"6. 4. Key Advantages of LDMs","text":"Feature Description Computational Efficiency LDMs perform diffusion in a compressed latent space, reducing the cost significantly. High-Quality Image Generation Produces highly detailed and realistic images. Flexible Conditioning Allows fine-grained control through text prompts, sketches, depth maps, etc. Versatile Applications Used in text-to-image generation, inpainting, style transfer, and more."},{"location":"book/chapter7_diffusion/ldm/#7-conclusion","title":"7. Conclusion","text":"<p>Latent Diffusion Models (LDMs) have emerged as a groundbreaking approach in AI-generated content. By performing diffusion in latent space, they enhance efficiency, improve image quality, and enable advanced conditional control mechanisms. Their applications range from text-to-image generation to professional-grade image editing and style transfer.</p> <p>With continuous advancements, LDM-based models like Stable Diffusion are shaping the future of generative AI, making high-quality image synthesis accessible to a broad audience.</p>"},{"location":"book/chapter7_diffusion/ldm/#8-further-reading","title":"8. Further Reading","text":"<ul> <li>\ud83d\udcc4 High-Resolution Image Synthesis with Latent Diffusion Models - The original LDM paper by Rombach et al.</li> <li>\ud83d\udee0\ufe0f Stable Diffusion GitHub - Open-source implementation of LDMs.</li> <li>\ud83c\udfa8 ControlNet for Stable Diffusion - Advanced conditioning techniques for precise control.</li> </ul>"},{"location":"book/chapter7_diffusion/ldm_handson/","title":"Latent Diffusion Handson","text":""},{"location":"book/chapter7_diffusion/ldm_handson/#1-build-a-web-demo","title":"1. Build A Web Demo","text":"<p>Web Demo</p> <p> Refer the demo in <code>demo/sd_demo/app.py</code> in the repo.</p>"},{"location":"book/chapter7_diffusion/ldm_handson/#2-generating-results","title":"2. Generating Results","text":""},{"location":"book/chapter7_diffusion/ldm_handson/#3-code","title":"3. Code","text":"<p>The overall framework concists of two main blocks, <code>ddpm</code> and <code>vae</code></p> <p>The <code>vae</code> devides intro two types, either the <code>VQ-GAN</code> or <code>KL-VAE</code>. Refer VQ-GAN for more details. Here we only look as the structure details about the <code>KL-VAE</code>. And in the future version, stable diffusion only used the <code>KL-VAE</code>.</p>"},{"location":"book/chapter7_diffusion/ldm_handson/#31-autoencoder","title":"3.1 Autoencoder","text":""},{"location":"book/chapter7_diffusion/ldm_handson/#311-autoencoderkl","title":"3.1.1 AutoencoderKL","text":"AutoEncoderKL<pre><code>class AutoencoderKL(pl.LightningModule):\n    \"\"\"\n    \u8be5\u7c7b\u5b9e\u73b0\u4e86\u4e00\u4e2a\u57fa\u4e8e KL \u6563\u5ea6\u7ea6\u675f\u7684\u81ea\u7f16\u7801\u5668\uff0c\u5176\u7f16\u7801\u5668\u751f\u6210\u6f5c\u53d8\u91cf\u5206\u5e03\uff08\u9ad8\u65af\u5206\u5e03\uff09\uff0c\u89e3\u7801\u5668\u91cd\u6784\u8f93\u5165\u56fe\u50cf\u3002\n    \u901a\u8fc7\u4e24\u4e2a\u5377\u79ef\u5c42\u5b9e\u73b0\u4e86\u4ece\u7f16\u7801\u5668\u7279\u5f81\u5230\u6f5c\u53d8\u91cf\u5206\u5e03\u53c2\u6570\u7684\u8f6c\u6362\u4ee5\u53ca\u4ece\u6f5c\u53d8\u91cf\u5230\u89e3\u7801\u5668\u8f93\u5165\u7684\u8f6c\u6362\u3002\n    \u652f\u6301\u5bf9\u6297\u6027\u8bad\u7ec3\uff1a\u901a\u8fc7\u4e24\u4e2a\u72ec\u7acb\u7684\u4f18\u5316\u5668\u5206\u522b\u8bad\u7ec3\u81ea\u52a8\u7f16\u7801\u5668\u548c\u5224\u522b\u5668\u3002\n    \u540c\u65f6\u8fd8\u5185\u7f6e\u4e86\u6570\u636e\u9884\u5904\u7406\u3001\u56fe\u50cf\u8bb0\u5f55\u548c\u989c\u8272\u6620\u5c04\u7b49\u8f85\u52a9\u529f\u80fd\uff0c\u65b9\u4fbf\u540e\u7eed\u8bad\u7ec3\u548c\u53ef\u89c6\u5316\u3002\n    \"\"\"\n    def __init__(self,\n                 ddconfig, # \u4f20\u9012\u7ed9\u7f16\u7801\u5668\u548c\u89e3\u7801\u5668\u7684\u914d\u7f6e\u5b57\u5178\uff0c\u5305\u542b\u7f51\u7edc\u7ed3\u6784\u53c2\u6570\u3002\n                 lossconfig, # \u635f\u5931\u51fd\u6570\u7684\u914d\u7f6e\uff0c\u901a\u8fc7 instantiate_from_config \u5b9e\u4f8b\u5316\u5177\u4f53\u7684\u635f\u5931\u51fd\u6570\u3002\n                 embed_dim, # \u6f5c\u53d8\u91cf\u7a7a\u95f4\u7684\u7ef4\u5ea6\u3002\n                 ckpt_path=None, # \u82e5\u4e0d\u4e3a\u7a7a\uff0c\u5219\u4ece\u6307\u5b9a\u7684\u68c0\u67e5\u70b9\u52a0\u8f7d\u9884\u8bad\u7ec3\u6a21\u578b\u53c2\u6570\n                 ignore_keys=[], # \u52a0\u8f7d\u9884\u8bad\u7ec3\u53c2\u6570\u65f6\u9700\u8981\u5ffd\u7565\u7684\u952e\u5217\u8868\u3002\n                 image_key=\"image\", # \u4ece\u8f93\u5165 batch \u4e2d\u63d0\u53d6\u56fe\u50cf\u6570\u636e\u65f6\u6240\u4f7f\u7528\u7684\u952e\uff0c\u9ed8\u8ba4\u662f \"image\"\u3002\n                 colorize_nlabels=None, # \u5982\u679c\u63d0\u4f9b\uff0c\u5219\u8bf4\u660e\u6a21\u578b\u652f\u6301\u5c06\u591a\u901a\u9053\uff08\u4f8b\u5982\u5206\u5272\u56fe\uff09\u6620\u5c04\u5230 RGB\uff0c\u6570\u503c\u8868\u793a\u6807\u7b7e\u6570\u91cf\u3002\n                 monitor=None, # \u7528\u4e8e\u76d1\u63a7\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u6307\u6807\uff08\u4f8b\u5982\u7528\u4e8e\u65e9\u505c\u7b49\uff09\u3002\n                 ):\n        ```\n        \u6839\u636e ddconfig \u5b9e\u4f8b\u5316\u7f16\u7801\u5668\u548c\u89e3\u7801\u5668\u3002\n        \u6839\u636e lossconfig \u5b9e\u4f8b\u5316\u635f\u5931\u51fd\u6570\u3002\n        \u65ad\u8a00 ddconfig[\"double_z\"] \u4e3a True\uff0c\u786e\u4fdd\u6f5c\u53d8\u91cf\u7684\u901a\u9053\u6570\u662f\u6210\u5bf9\u7684\uff08\u5e38\u89c1\u4e8e\u5747\u503c\u548c\u5bf9\u6570\u65b9\u5dee\u7684\u7ec4\u5408\uff09\u3002\n        \u5b9a\u4e49\u4e86\u4e24\u4e2a\u5377\u79ef\u5c42\uff1a\n        quant_conv\uff1a\u5c06\u7f16\u7801\u5668\u8f93\u51fa\u7684\u7279\u5f81\uff08\u901a\u9053\u6570\u4e3a 2*z_channels\uff09\u6620\u5c04\u5230 2*embed_dim\uff0c\u7528\u4e8e\u751f\u6210\u9ad8\u65af\u5206\u5e03\u7684\u53c2\u6570\uff08\u5747\u503c\u548c\u5bf9\u6570\u65b9\u5dee\uff09\u3002\n        post_quant_conv\uff1a\u5728\u89e3\u7801\u4e4b\u524d\uff0c\u5c06\u6f5c\u53d8\u91cf\u4ece embed_dim \u6620\u5c04\u56de\u5230\u89e3\u7801\u5668\u6240\u9700\u7684 z_channels\u3002\n        \u5982\u679c colorize_nlabels \u4e0d\u4e3a\u7a7a\uff0c\u5219\u6ce8\u518c\u4e00\u4e2a\u540d\u4e3a colorize \u7684 buffer\uff0c\u7528\u4e8e\u4e4b\u540e\u5c06\u591a\u901a\u9053\u7684\u5206\u5272\u56fe\u8f6c\u6362\u4e3a RGB \u56fe\u50cf\u3002\n        \u5982\u679c\u63d0\u4f9b\u4e86\u68c0\u67e5\u70b9\u8def\u5f84\uff0c\u5219\u8c03\u7528 init_from_ckpt \u65b9\u6cd5\u52a0\u8f7d\u9884\u8bad\u7ec3\u6a21\u578b\u53c2\u6570\u3002\n        ```\n        super().__init__()\n        self.image_key = image_key\n        self.encoder = Encoder(**ddconfig)\n        self.decoder = Decoder(**ddconfig)\n        self.loss = instantiate_from_config(lossconfig)\n        assert ddconfig[\"double_z\"]\n        self.quant_conv = torch.nn.Conv2d(2*ddconfig[\"z_channels\"], 2*embed_dim, 1)\n        self.post_quant_conv = torch.nn.Conv2d(embed_dim, ddconfig[\"z_channels\"], 1)\n        self.embed_dim = embed_dim\n        if colorize_nlabels is not None:\n            assert type(colorize_nlabels)==int\n            self.register_buffer(\"colorize\", torch.randn(3, colorize_nlabels, 1, 1))\n        if monitor is not None:\n            self.monitor = monitor\n        if ckpt_path is not None:\n            self.init_from_ckpt(ckpt_path, ignore_keys=ignore_keys)\n\n    def init_from_ckpt(self, path, ignore_keys=list()):\n        \"\"\" \u53c2\u6570\u52a0\u8f7d\u65b9\u6cd5 init_from_ckpt\n        \u529f\u80fd\uff1a\u4ece\u6307\u5b9a\u8def\u5f84\u52a0\u8f7d\u9884\u8bad\u7ec3\u7684\u6a21\u578b\u72b6\u6001\u5b57\u5178\uff08state_dict\uff09\u3002\n        \u7ec6\u8282\uff1a\n        \u52a0\u8f7d\u540e\u4f1a\u904d\u5386\u6240\u6709\u952e\uff0c\u5982\u679c\u952e\u540d\u4ee5 ignore_keys \u4e2d\u7684\u67d0\u4e2a\u524d\u7f00\u5f00\u5934\uff0c\u5219\u4f1a\u5c06\u8be5\u952e\u4ece\u72b6\u6001\u5b57\u5178\u4e2d\u5220\u9664\uff08\u9002\u7528\u4e8e\u5ffd\u7565\u90e8\u5206\u9884\u8bad\u7ec3\u53c2\u6570\uff09\u3002\n        \u6700\u540e\u4f7f\u7528 load_state_dict \u52a0\u8f7d\u53c2\u6570\uff0cstrict=False \u610f\u5473\u7740\u53ef\u4ee5\u5141\u8bb8\u90e8\u5206\u53c2\u6570\u7f3a\u5931\u6216\u591a\u4f59\u3002\n        \"\"\"\n        sd = torch.load(path, map_location=\"cpu\")[\"state_dict\"]\n        keys = list(sd.keys())\n        for k in keys:\n            for ik in ignore_keys:\n                if k.startswith(ik):\n                    print(\"Deleting key {} from state_dict.\".format(k))\n                    del sd[k]\n        self.load_state_dict(sd, strict=False)\n        print(f\"Restored from {path}\")\n\n    def encode(self, x):\n        \"\"\"\n        encode \u65b9\u6cd5\uff1a\n        \u8f93\u5165\u56fe\u50cf x \u7ecf\u8fc7\u7f16\u7801\u5668\u5f97\u5230\u4e2d\u95f4\u7279\u5f81 h\u3002\n        \u4f7f\u7528 quant_conv \u5c06\u7279\u5f81\u6620\u5c04\u4e3a\u201c\u65f6\u523b\u201d\uff08moments\uff09\uff0c\u901a\u5e38\u5305\u62ec\u5747\u503c\u548c\u5bf9\u6570\u65b9\u5dee\u3002\n        \u5229\u7528\u8fd9\u4e9b\u53c2\u6570\u6784\u9020\u4e00\u4e2a DiagonalGaussianDistribution\uff08\u5bf9\u89d2\u9ad8\u65af\u5206\u5e03\uff09\uff0c\u4f5c\u4e3a\u540e\u9a8c\u5206\u5e03\u8fd4\u56de\u3002\n        \"\"\"\n        h = self.encoder(x)\n        moments = self.quant_conv(h)\n        posterior = DiagonalGaussianDistribution(moments)\n        return posterior\n\n    def decode(self, z):\n        \"\"\"\n        \u5c06\u6f5c\u53d8\u91cf z \u901a\u8fc7 post_quant_conv \u8f6c\u6362\u5230\u9002\u5408\u89e3\u7801\u5668\u7684\u7ef4\u5ea6\uff0c\u7136\u540e\u7ecf\u8fc7\u89e3\u7801\u5668\u751f\u6210\u91cd\u6784\u56fe\u50cf\u3002\n        \"\"\"\n        z = self.post_quant_conv(z)\n        dec = self.decoder(z)\n        return dec\n\n    def forward(self, input, sample_posterior=True):\n        \"\"\"\n        \u8c03\u7528 encode \u5f97\u5230\u540e\u9a8c\u5206\u5e03 posterior\u3002\n        \u6839\u636e sample_posterior \u51b3\u5b9a\u662f\u91c7\u6837\uff08\u968f\u673a\u91c7\u6837\uff09\u8fd8\u662f\u53d6\u6a21\u5f0f\uff08\u5747\u503c\uff09\u4f5c\u4e3a\u6f5c\u53d8\u91cf z\u3002\n        \u5c06 z \u8f93\u5165\u5230 decode \u5f97\u5230\u6700\u7ec8\u8f93\u51fa\u3002\n        \u8fd4\u56de\u89e3\u7801\u540e\u7684\u56fe\u50cf\u548c\u540e\u9a8c\u5206\u5e03\u3002\n        \"\"\"\n        posterior = self.encode(input)\n        if sample_posterior:\n            z = posterior.sample()\n        else:\n            z = posterior.mode()\n        dec = self.decode(z)\n        return dec, posterior\n\n    def get_input(self, batch, k):\n        ```\n        \u529f\u80fd\uff1a\u4ece batch \u4e2d\u63d0\u53d6\u56fe\u50cf\u6570\u636e\u3002\n        \u7ec6\u8282\uff1a\n        \u6839\u636e image_key \u53d6\u51fa\u5bf9\u5e94\u7684\u6570\u636e\u3002\n        \u5982\u679c\u8f93\u5165\u6570\u636e\u7684\u7ef4\u5ea6\u4e3a 3\uff08\u4f8b\u5982\u6ca1\u6709\u660e\u786e\u901a\u9053\u7ef4\u5ea6\uff09\uff0c\u5219\u5728\u6700\u540e\u52a0\u4e00\u4e2a\u7ef4\u5ea6\u3002\n        \u5c06\u6570\u636e\u4ece (batch, height, width, channels) \u8f6c\u6362\u4e3a (batch, channels, height, width)\uff08\u7b26\u5408 PyTorch \u7684\u6807\u51c6\u683c\u5f0f\uff09\u3002\n        \u8f6c\u6362\u4e3a\u6d6e\u70b9\u578b\uff0c\u5e76\u786e\u4fdd\u5185\u5b58\u683c\u5f0f\u8fde\u7eed\u3002\n        ```\n        x = batch[k]\n        if len(x.shape) == 3:\n            x = x[..., None]\n        x = x.permute(0, 3, 1, 2).to(memory_format=torch.contiguous_format).float()\n        return x\n\n    def training_step(self, batch, batch_idx, optimizer_idx):\n        \"\"\"\n        training_step \u65b9\u6cd5\uff1a\n        \u6839\u636e optimizer_idx \u7684\u503c\uff0c\u5206\u522b\u8ba1\u7b97\u81ea\u52a8\u7f16\u7801\u5668\uff08encoder+decoder\uff09\u548c\u5224\u522b\u5668\u7684\u635f\u5931\uff1a\n        \u5f53 optimizer_idx == 0\uff1a\u8ba1\u7b97\u81ea\u52a8\u7f16\u7801\u5668\u7684\u635f\u5931\uff08\u91cd\u6784\u635f\u5931\u3001KL \u6563\u5ea6\u7b49\uff09\uff0c\u5e76\u8bb0\u5f55\u76f8\u5e94\u7684\u65e5\u5fd7\u3002\n        \u5f53 optimizer_idx == 1\uff1a\u8ba1\u7b97\u5224\u522b\u5668\u7684\u635f\u5931\uff08\u901a\u5e38\u7528\u4e8e\u5bf9\u6297\u8bad\u7ec3\uff09\uff0c\u5e76\u8bb0\u5f55\u65e5\u5fd7\u3002\n        \u4f7f\u7528 self.loss \u5bf9\u8c61\u6765\u8ba1\u7b97\u4e0d\u540c\u90e8\u5206\u7684\u635f\u5931\uff0c\u4f20\u5165\u5f53\u524d\u7684\u5168\u5c40\u6b65\u6570\u548c\u6700\u540e\u4e00\u5c42\u53c2\u6570\uff08\u7528\u4e8e\u4f8b\u5982\u68af\u5ea6\u60e9\u7f5a\u6216\u6743\u91cd\u8c03\u6574\uff09\u3002\n        validation_step \u65b9\u6cd5\uff1a\n\n        \u4e0e\u8bad\u7ec3\u6b65\u9aa4\u7c7b\u4f3c\uff0c\u4f46\u8ba1\u7b97\u7684\u662f\u9a8c\u8bc1\u96c6\u4e0a\u7684\u635f\u5931\uff0c\u5e76\u8bb0\u5f55\u9a8c\u8bc1\u65e5\u5fd7\uff08\u4f8b\u5982 \"val/rec_loss\"\uff09\n        \"\"\"\n        inputs = self.get_input(batch, self.image_key)\n        reconstructions, posterior = self(inputs)\n\n        if optimizer_idx == 0:\n            # train encoder+decoder+logvar\n            aeloss, log_dict_ae = self.loss(inputs, reconstructions, posterior, optimizer_idx, self.global_step,\n                                            last_layer=self.get_last_layer(), split=\"train\")\n            self.log(\"aeloss\", aeloss, prog_bar=True, logger=True, on_step=True, on_epoch=True)\n            self.log_dict(log_dict_ae, prog_bar=False, logger=True, on_step=True, on_epoch=False)\n            return aeloss\n\n        if optimizer_idx == 1:\n            # train the discriminator\n            discloss, log_dict_disc = self.loss(inputs, reconstructions, posterior, optimizer_idx, self.global_step,\n                                                last_layer=self.get_last_layer(), split=\"train\")\n\n            self.log(\"discloss\", discloss, prog_bar=True, logger=True, on_step=True, on_epoch=True)\n            self.log_dict(log_dict_disc, prog_bar=False, logger=True, on_step=True, on_epoch=False)\n            return discloss\n\n    def validation_step(self, batch, batch_idx):\n        inputs = self.get_input(batch, self.image_key)\n        reconstructions, posterior = self(inputs)\n        aeloss, log_dict_ae = self.loss(inputs, reconstructions, posterior, 0, self.global_step,\n                                        last_layer=self.get_last_layer(), split=\"val\")\n\n        discloss, log_dict_disc = self.loss(inputs, reconstructions, posterior, 1, self.global_step,\n                                            last_layer=self.get_last_layer(), split=\"val\")\n\n        self.log(\"val/rec_loss\", log_dict_ae[\"val/rec_loss\"])\n        self.log_dict(log_dict_ae)\n        self.log_dict(log_dict_disc)\n        return self.log_dict\n\n    def configure_optimizers(self):\n        \"\"\"\n        \u529f\u80fd\uff1a\n            \u5b9a\u4e49\u4e86\u4e24\u4e2a\u72ec\u7acb\u7684\u4f18\u5316\u5668\uff1a\n            \u4e00\u4e2a\u7528\u4e8e\u8bad\u7ec3\u81ea\u52a8\u7f16\u7801\u5668\uff08\u5305\u542b\u7f16\u7801\u5668\u3001\u89e3\u7801\u5668\u4ee5\u53ca\u4e24\u4e2a\u5377\u79ef\u5c42\uff09\u7684 Adam \u4f18\u5316\u5668\u3002\n            \u4e00\u4e2a\u7528\u4e8e\u8bad\u7ec3\u5224\u522b\u5668\uff08\u901a\u8fc7 self.loss.discriminator \u8bbf\u95ee\uff09\u7684 Adam \u4f18\u5316\u5668\u3002\n            \u4e24\u4e2a\u4f18\u5316\u5668\u90fd\u4f7f\u7528\u76f8\u540c\u7684\u5b66\u4e60\u7387\uff08self.learning_rate\uff09\u4ee5\u53ca\u76f8\u540c\u7684 Adam \u53c2\u6570\uff08betas=(0.5, 0.9)\uff09\u3002\n        \"\"\"\n        lr = self.learning_rate\n        opt_ae = torch.optim.Adam(list(self.encoder.parameters())+\n                                  list(self.decoder.parameters())+\n                                  list(self.quant_conv.parameters())+\n                                  list(self.post_quant_conv.parameters()),\n                                  lr=lr, betas=(0.5, 0.9))\n        opt_disc = torch.optim.Adam(self.loss.discriminator.parameters(),\n                                    lr=lr, betas=(0.5, 0.9))\n        return [opt_ae, opt_disc], []\n\n    def get_last_layer(self):\n        \"\"\"\u8fd4\u56de\u89e3\u7801\u5668\u4e2d\u6700\u540e\u4e00\u5c42\u5377\u79ef\u7684\u6743\u91cd\u3002\u8fd9\u4e2a\u6743\u91cd\u6709\u65f6\u7528\u4e8e\u8f85\u52a9\u635f\u5931\u8ba1\u7b97\u6216\u8005\u68af\u5ea6\u5206\u6790\u3002\"\"\"\n        return self.decoder.conv_out.weight\n\n    @torch.no_grad()\n    def log_images(self, batch, only_inputs=False, **kwargs):\n        \"\"\"\n        \u7528\u4e8e\u5728\u8bad\u7ec3\u6216\u9a8c\u8bc1\u8fc7\u7a0b\u4e2d\u8bb0\u5f55\u8f93\u5165\u56fe\u50cf\u3001\u91cd\u6784\u56fe\u50cf\u4ee5\u53ca\u968f\u673a\u751f\u6210\u7684\u6837\u672c\u56fe\u50cf\u3002\n        \u901a\u9053\u6570\u5927\u4e8e 3\uff08\u4f8b\u5982\u5206\u5272\u56fe\uff09\uff0c\u5219\u8c03\u7528 to_rgb \u65b9\u6cd5\u5c06\u5176\u8f6c\u6362\u4e3a RGB \u56fe\u50cf\u3002\n        \u8fd4\u56de\u4e00\u4e2a\u5305\u542b \"inputs\"\u3001\"reconstructions\"\u3001\"samples\" \u7b49\u952e\u7684\u5b57\u5178\uff0c\u4fbf\u4e8e\u65e5\u5fd7\u8bb0\u5f55\u548c\u53ef\u89c6\u5316\u3002\n        \"\"\"\n        log = dict()\n        x = self.get_input(batch, self.image_key)\n        x = x.to(self.device)\n        if not only_inputs:\n            xrec, posterior = self(x)\n            if x.shape[1] &gt; 3:\n                # colorize with random projection\n                assert xrec.shape[1] &gt; 3\n                x = self.to_rgb(x)\n                xrec = self.to_rgb(xrec)\n            log[\"samples\"] = self.decode(torch.randn_like(posterior.sample()))\n            log[\"reconstructions\"] = xrec\n        log[\"inputs\"] = x\n        return log\n\n    def to_rgb(self, x):\n        \"\"\"\n        \u4e13\u95e8\u7528\u4e8e\u5c06\u5206\u5272\u56fe\uff08\u6216\u901a\u9053\u6570\u5927\u4e8e3\u7684\u56fe\u50cf\uff09\u901a\u8fc7\u4e00\u4e2a\u5377\u79ef\u64cd\u4f5c\u6620\u5c04\u5230 RGB \u56fe\u50cf\u3002\n        \u4f7f\u7528\u9884\u5148\u6ce8\u518c\u7684 colorize buffer\uff08\u82e5\u4e0d\u5b58\u5728\u5219\u65b0\u6ce8\u518c\uff09\u4f5c\u4e3a\u5377\u79ef\u6838\uff0c\u5b8c\u6210\u901a\u9053\u6620\u5c04\u540e\uff0c\u5bf9\u7ed3\u679c\u8fdb\u884c\u5f52\u4e00\u5316\uff0c\u786e\u4fdd\u50cf\u7d20\u503c\u5728 [-1, 1] \u8303\u56f4\u5185\u3002\n        \"\"\"\n        assert self.image_key == \"segmentation\"\n        if not hasattr(self, \"colorize\"):\n            self.register_buffer(\"colorize\", torch.randn(3, x.shape[1], 1, 1).to(x))\n        x = F.conv2d(x, weight=self.colorize)\n        x = 2.*(x-x.min())/(x.max()-x.min()) - 1.\n        return x\n</code></pre> <p>Compared with a \"normal\" VAE, we need to check if the loss and encoding and decoding process is same to the normal VAE.</p> <p>At first look, the loss combines two parts</p> <ol> <li>Standard VAE Loss, that is, the reconstruction loss + KL divergence (regularization) loss</li> <li>GAN loss</li> </ol> <p>Theoretical, the loss should be</p> \\[\\tag{1}  \\mathcal{L} = \\frac{1}{N} \\sum_{i=1}^{N} \\| x_i - \\hat{x}_i \\|^2+ \\sum_{l} \\lambda_l \\| \\phi_l(x) - \\phi_l(G(z)) \\|_2^2  + \\frac{1}{2} \\sum_{j=1}^{d} (1 + \\log \\sigma_{i,j}^2 - \\mu_{i,j}^2 - \\sigma_{i,j}^2)+ L_{adv} \\] <p>where</p> \\[ L_{adv} = -\\mathbb{E}_{z \\sim p(z)}\\left[ D\\bigl(G(z)\\bigr) \\right] \\] <p>and \\(\\phi_l(x)\\) is the feature map from the pretrained CNN.</p> <p>In equation (1), the first two can be considered as the perceptual reconstruction loss which is used in <code>VQ-GAN</code> to train the encoder and decoder.</p> <p>Let's check if it is same with the above assumption.</p>"},{"location":"book/chapter7_diffusion/ldm_handson/#312-gaussian-sampling","title":"3.1.2 Gaussian Sampling","text":"Gaussian Sampling<pre><code>class DiagonalGaussianDistribution(object):\n    def __init__(self, parameters, deterministic=False):\n        self.parameters = parameters\n        self.mean, self.logvar = torch.chunk(parameters, 2, dim=1)\n        self.logvar = torch.clamp(self.logvar, -30.0, 20.0)\n        self.deterministic = deterministic\n        self.std = torch.exp(0.5 * self.logvar)\n        self.var = torch.exp(self.logvar)\n        if self.deterministic:\n            self.var = self.std = torch.zeros_like(self.mean).to(device=self.parameters.device)\n    def sample(self):\n        x = self.mean + self.std * torch.randn(self.mean.shape).to(device=self.parameters.device)\n        return x\n\n    def kl(self, other=None):\n        if self.deterministic:\n            return torch.Tensor([0.])\n        else:\n            if other is None:\n                return 0.5 * torch.sum(torch.pow(self.mean, 2)\n                                       + self.var - 1.0 - self.logvar,\n                                       dim=[1, 2, 3])\n            else:\n                return 0.5 * torch.sum(\n                    torch.pow(self.mean - other.mean, 2) / other.var\n                    + self.var / other.var - 1.0 - self.logvar + other.logvar,\n                    dim=[1, 2, 3])\n    def nll(self, sample, dims=[1,2,3]):\n        if self.deterministic:\n            return torch.Tensor([0.])\n        logtwopi = np.log(2.0 * np.pi)\n        return 0.5 * torch.sum(\n            logtwopi + self.logvar + torch.pow(sample - self.mean, 2) / self.var,\n            dim=dims)\n    def mode(self):\n        return self.mean\n</code></pre>"},{"location":"book/chapter7_diffusion/ldm_handson/#313-losses","title":"3.1.3 Losses","text":"<p>Details of the loss</p> LPIPSWithDiscriminator<pre><code>import torch\nimport torch.nn as nn\n\nfrom taming.modules.losses.vqperceptual import *\nclass LPIPSWithDiscriminator(nn.Module):\n    def __init__(self, disc_start, logvar_init=0.0, kl_weight=1.0, pixelloss_weight=1.0,\n                 disc_num_layers=3, disc_in_channels=3, disc_factor=1.0, disc_weight=1.0,\n                 perceptual_weight=1.0, use_actnorm=False, disc_conditional=False,\n                 disc_loss=\"hinge\"):\n\n        super().__init__()\n        assert disc_loss in [\"hinge\", \"vanilla\"]\n        self.kl_weight = kl_weight\n        self.pixel_weight = pixelloss_weight\n        self.perceptual_loss = LPIPS().eval()\n        # LPIPS\uff08Learned Perceptual Image Patch Similarity\uff09\u80fd\u591f\u6355\u6349\u56fe\u50cf\u4e4b# \u95f4\u66f4\u9ad8\u5c42\u6b21\u7684\u76f8\u4f3c\u6027\u3002\u5f53 perceptual_weight \u5927\u4e8e 0 \u65f6\uff0c\u4f1a\u5c06\u8be5\u635f\u5931\u4e0e # L1 \u50cf\u7d20\u635f\u5931\u76f8\u52a0\uff0c\u4ece\u800c\u83b7\u5f97\u66f4\u7b26\u5408\u4eba\u773c\u611f\u77e5\u7684\u91cd\u5efa\u6548\u679c\u3002\n        self.perceptual_weight = perceptual_weight\n        # output log variance\n        self.logvar = nn.Parameter(torch.ones(size=()) * logvar_init)\n        # self.logvar \u662f\u4e00\u4e2a\u53ef\u5b66\u4e60\u7684\u6807\u91cf\u53c2\u6570\uff0c\u7528\u4e8e\u5bf9\u91cd\u5efa\u635f\u5931\u8fdb\u884c\u7f29\u653e\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u6211\u4eec\u5c06\u91cd\u5efa\u8bef\u5dee\u9664\u4ee5 $\\exp(\\text{logvar})$\uff0c\n        # \u518d\u52a0\u4e0a logvar\uff0c\u8fd9\u6837\u53ef\u4ee5\u52a8\u6001\u5e73\u8861\u91cd\u5efa\u635f\u5931\u7684\u5c3a\u5ea6\uff0c\u540c\u65f6\u5728\u8bad\u7ec3\u4e2d\u8ba9\u6a21\u578b\u5b66\u4e60\u4e00\u4e2a\u5408\u9002\u7684\u6743\u91cd\u3002\n        self.discriminator = NLayerDiscriminator(input_nc=disc_in_channels,\n                                                 n_layers=disc_num_layers,\n                                                 use_actnorm=use_actnorm\n                                                 ).apply(weights_init)\n        # \u5224\u522b\u5668\u4f7f\u7528 NLayerDiscriminator \u6784\u5efa\uff0c\u652f\u6301\u591a\u5c42\u7ed3\u6784\uff0c\u540c\u65f6\u53ef\u4ee5\u901a\u8fc7 use_actnorm \u9009\u62e9\u662f\u5426\u4f7f\u7528\u6fc0\u6d3b\u5f52\u4e00\u5316\u3002\n\n        self.discriminator_iter_start = disc_start\n        # discriminator_iter_start \u7528\u6765\u8bbe\u7f6e\u5728\u8bad\u7ec3\u7684\u54ea\u4e2a\u6b65\u9aa4\u5f00\u59cb\u5f15\u5165\u5224\u522b\u5668\u7684\u635f\u5931\uff0c\u8fd9\u6837\u53ef\u4ee5\u5148\u8ba9\u751f\u6210\u5668\u5b66\u5230\u8f83\u4e3a\u7a33\u5b9a\u7684\u91cd\u5efa\uff0c\u518d\u52a0\u5165\u5bf9\u6297\u8bad\u7ec3\u3002\n\n        self.disc_loss = hinge_d_loss if disc_loss == \"hinge\" else vanilla_d_loss\n        # disc_conditional \u53c2\u6570\u7528\u4e8e\u5224\u65ad\u662f\u5426\u4e3a\u6761\u4ef6\u5224\u522b\u5668\uff0c\u5373\u5728\u8f93\u5165\u56fe\u50cf\u7684\u57fa\u7840\u4e0a\u662f\u5426\u8fd8\u9700\u8981\u989d\u5916\u7684\u6761\u4ef6\u4fe1\u606f\uff08\u5982\u7c7b\u522b\u3001\u8bed\u4e49\u4fe1\u606f\u7b49\uff09\u3002\n        # disc_loss \u6839\u636e\u4f20\u5165\u7684\u53c2\u6570\u9009\u62e9 hinge \u635f\u5931\u6216\u8005 vanilla \u635f\u5931\u3002\n        self.disc_factor = disc_factor\n        # disc_factor \u548c discriminator_weight \u7528\u4e8e\u5bf9\u5224\u522b\u5668\u76f8\u5173\u635f\u5931\u8fdb\u884c\u52a0\u6743\uff0c\u4f7f\u5f97 GAN \u90e8\u5206\u7684\u635f\u5931\u4e0d\u4f1a\u76f4\u63a5\u4e3b\u5bfc\u6574\u4e2a\u635f\u5931\u51fd\u6570\u3002\n\n        self.discriminator_weight = disc_weight\n        self.disc_conditional = disc_conditional\n\n    def calculate_adaptive_weight(self, nll_loss, g_loss, last_layer=None):\n        \"\"\"\n        \u5728\u751f\u6210\u5668\u90e8\u5206\uff0c\u6211\u4eec\u5e0c\u671b\u540c\u65f6\u4f18\u5316\u91cd\u5efa\uff08NLL\uff09\u548c\u751f\u6210\u5668\u5bf9\u6297\u635f\u5931\uff08g_loss\uff09\uff0c\u800c\u4e8c\u8005\u7684\u5c3a\u5ea6\u53ef\u80fd\u76f8\u5dee\u8f83\u5927\u3002\u4e3a\u6b64\uff0c\u4ee3\u7801\u4e2d\u5f15\u5165\u4e86\u81ea\u9002\u5e94\u6743\u91cd\u8ba1\u7b97\n        \"\"\"\n\n        if last_layer is not None:\n            nll_grads = torch.autograd.grad(nll_loss, last_layer, retain_graph=True)[0]\n            g_grads = torch.autograd.grad(g_loss, last_layer, retain_graph=True)[0]\n        else:\n            nll_grads = torch.autograd.grad(nll_loss, self.last_layer[0], retain_graph=True)[0]\n            g_grads = torch.autograd.grad(g_loss, self.last_layer[0], retain_graph=True)[0]\n\n        d_weight = torch.norm(nll_grads) / (torch.norm(g_grads) + 1e-4)\n        d_weight = torch.clamp(d_weight, 0.0, 1e4).detach()\n        d_weight = d_weight * self.discriminator_weight\n        return d_weight\n\n    def forward(self, inputs, reconstructions, posteriors, optimizer_idx,\n                global_step, last_layer=None, cond=None, split=\"train\",\n                weights=None):\n        rec_loss = torch.abs(inputs.contiguous() - reconstructions.contiguous())\n        if self.perceptual_weight &gt; 0:\n            p_loss = self.perceptual_loss(inputs.contiguous(), reconstructions.contiguous())\n            rec_loss = rec_loss + self.perceptual_weight * p_loss\n\n        nll_loss = rec_loss / torch.exp(self.logvar) + self.logvar\n        weighted_nll_loss = nll_loss\n        if weights is not None:\n            weighted_nll_loss = weights*nll_loss\n        weighted_nll_loss = torch.sum(weighted_nll_loss) / weighted_nll_loss.shape[0]\n        nll_loss = torch.sum(nll_loss) / nll_loss.shape[0]\n        kl_loss = posteriors.kl()\n        kl_loss = torch.sum(kl_loss) / kl_loss.shape[0]\n\n        # now the GAN part\n        if optimizer_idx == 0:\n            # generator update\n            if cond is None:\n                assert not self.disc_conditional\n                logits_fake = self.discriminator(reconstructions.contiguous())\n            else:\n                assert self.disc_conditional\n                logits_fake = self.discriminator(torch.cat((reconstructions.contiguous(), cond), dim=1))\n            g_loss = -torch.mean(logits_fake)\n\n            if self.disc_factor &gt; 0.0:\n                try:\n                    d_weight = self.calculate_adaptive_weight(nll_loss, g_loss, last_layer=last_layer)\n                except RuntimeError:\n                    assert not self.training\n                    d_weight = torch.tensor(0.0)\n            else:\n                d_weight = torch.tensor(0.0)\n\n            disc_factor = adopt_weight(self.disc_factor, global_step, threshold=self.discriminator_iter_start)\n            loss = weighted_nll_loss + self.kl_weight * kl_loss + d_weight * disc_factor * g_loss\n\n            log = {\"{}/total_loss\".format(split): loss.clone().detach().mean(), \"{}/logvar\".format(split): self.logvar.detach(),\n                   \"{}/kl_loss\".format(split): kl_loss.detach().mean(), \"{}/nll_loss\".format(split): nll_loss.detach().mean(),\n                   \"{}/rec_loss\".format(split): rec_loss.detach().mean(),\n                   \"{}/d_weight\".format(split): d_weight.detach(),\n                   \"{}/disc_factor\".format(split): torch.tensor(disc_factor),\n                   \"{}/g_loss\".format(split): g_loss.detach().mean(),\n                   }\n            return loss, log\n\n        if optimizer_idx == 1:\n            # second pass for discriminator update\n            if cond is None:\n                logits_real = self.discriminator(inputs.contiguous().detach())\n                logits_fake = self.discriminator(reconstructions.contiguous().detach())\n            else:\n                logits_real = self.discriminator(torch.cat((inputs.contiguous().detach(), cond), dim=1))\n                logits_fake = self.discriminator(torch.cat((reconstructions.contiguous().detach(), cond), dim=1))\n\n            disc_factor = adopt_weight(self.disc_factor, global_step, threshold=self.discriminator_iter_start)\n            d_loss = disc_factor * self.disc_loss(logits_real, logits_fake)\n\n            log = {\"{}/disc_loss\".format(split): d_loss.clone().detach().mean(),\n                   \"{}/logits_real\".format(split): logits_real.detach().mean(),\n                   \"{}/logits_fake\".format(split): logits_fake.detach().mean()\n                   }\n            return d_loss, log\n</code></pre> <p>The default config for loss is</p> <pre><code>params:\n    disc_start: 50001\n    kl_weight: 0.000001\n    disc_weight: 0.5\n</code></pre> <p>Here <code>adopt_weight</code> is defined as</p> <pre><code>def adopt_weight(weight, global_step, threshold=0, value=0.):\n    if global_step &lt; threshold:\n        weight = value\n    return weight\n</code></pre> <p>which control in which step, we introduce the GAN loss.</p>"},{"location":"book/chapter7_diffusion/ldm_handson/#3131-adaptive-weights-for-reconstruction-loss-and-gan-loss","title":"3.1.3.1 Adaptive weights for reconstruction loss and gan loss","text":"<p>We can express <code>calculate_adaptive_weight</code>  using the following formula</p> <ol> <li>assume the gradient of last layer from the NLL loss\uff1a</li> </ol> \\[ \\nabla_{\\text{nll}} = \\nabla_{\\theta_{\\text{last}}} \\mathcal{L}_{\\text{nll}} \\] <p>and the gradient of the last layer from the GAN loss\uff1a</p> \\[ \\nabla_{g} = \\nabla_{\\theta_{\\text{last}}} \\mathcal{L}_{g} \\] <ol> <li>Adptive weights</li> </ol> \\[ w_{\\text{adaptive}} = \\text{clip}\\!\\left(\\frac{\\|\\nabla_{\\text{nll}}\\|}{\\|\\nabla_{g}\\| + \\epsilon}, \\, 0, \\, 10^4\\right) \\] <ol> <li>Finally adding the weights \\(w_{\\text{disc}}\\)\uff1a</li> </ol> \\[ d_{\\text{weight}} = w_{\\text{adaptive}} \\times w_{\\text{disc}} \\] <p>It assumes that the norm of the gradient of the GAN should be equal to that of the reconstruction loss, make them in same level. Of course, finnaly, it will multiply another weights to control the importance of the GAN loss compared with other loss</p>"},{"location":"book/chapter7_diffusion/ldm_handson/#3132-forward","title":"3.1.3.2 Forward","text":"<p>The forward part is splited by the optimizer index, when <code>optimizer_idx==0</code>, it optimized the VAE, when <code>optimizer_idx==1</code>, it optimized the GAN</p>"},{"location":"book/chapter7_diffusion/ldm_handson/#31321-optimization-of-vae","title":"3.1.3.2.1 Optimization of VAE","text":"<p>It also splited into three parts</p> <ol> <li>reconstruction loss     It used the \\(L_1\\) loss for reconstruction loss. If the <code>perceptual_weight&gt;0</code>, it also combines with the <code>perceptual_loss</code>, which is usually a loss to constrained the feature map distances between the generation and input via a pretrained CNN feature extraction like \"VGG\"</li> </ol> <pre><code>rec_loss = torch.abs(inputs.contiguous() - reconstructions.contiguous())\n# \u5982\u679c\u8bbe\u7f6e\u4e86\u611f\u77e5\u635f\u5931\u6743\u91cd\uff0c\u5219\u8ba1\u7b97 LPIPS \u611f\u77e5\u635f\u5931\u5e76\u53e0\u52a0\nif self.perceptual_weight &gt; 0:\n    p_loss = self.perceptual_loss(inputs.contiguous(), reconstructions.contiguous())\n    rec_loss = rec_loss + self.perceptual_weight * p_loss\n    # NLL \u635f\u5931\uff1a\u5c06\u91cd\u5efa\u635f\u5931\u7ecf\u8fc7\u52a8\u6001\u7f29\u653e\uff08\u901a\u8fc7 logvar\uff09\u540e\u8ba1\u7b97\u5f97\u5230\nnll_loss = rec_loss / torch.exp(self.logvar) + self.logvar\nweighted_nll_loss = nll_loss\nif weights is not None:\n    weighted_nll_loss = weights * nll_loss\nweighted_nll_loss = torch.sum(weighted_nll_loss) / weighted_nll_loss.shape[0]\nnll_loss = torch.sum(nll_loss) / nll_loss.shape[0]\n</code></pre> <ol> <li> <p>KL Divergence    posteriors.kl() the KL divence between the posteriors and the Gaussian distribution \\(U(0,1)\\). It is defined in the Gaissian Sampler <code>DiagonalGaussianDistribution</code>.  It it is a deterministic sampling, this loss returns <code>0</code>.</p> </li> <li> <p>Gan Loss     Since here it aimed to train the generator (VAE), we dont have the real part for adversary loss. If it is a conditional GAN, then put the conditional information into the input, which is a quite standard adversary loss.</p> <pre><code>if cond is None:\n    assert not self.disc_conditional\n    logits_fake = self.discriminator(reconstructions.contiguous())\nelse:\n    assert self.disc_conditional\n    logits_fake = self.discriminator(torch.cat((reconstructions.contiguous(), cond), dim=1))\ng_loss = -torch.mean(logits_fake)\n</code></pre> </li> </ol>"},{"location":"book/chapter7_diffusion/ldm_handson/#31322-optimization-of-gan","title":"3.1.3.2.2 Optimization of GAN","text":"<pre><code>if optimizer_idx == 1:\n    # \u5bf9\u5224\u522b\u5668\u800c\u8a00\uff0c\u9700\u8981\u5206\u522b\u8ba1\u7b97\u771f\u5b9e\u56fe\u50cf\u548c\u751f\u6210\u56fe\u50cf\u7684 logits\n    if cond is None:\n        logits_real = self.discriminator(inputs.contiguous().detach())\n        logits_fake = self.discriminator(reconstructions.contiguous().detach())\n    else:\n        logits_real = self.discriminator(torch.cat((inputs.contiguous().detach(), cond), dim=1))\n        logits_fake = self.discriminator(torch.cat((reconstructions.contiguous().detach(), cond), dim=1))\n\n    # \u540c\u6837\u91c7\u7528 adopt_weight \u63a7\u5236\u5224\u522b\u5668\u635f\u5931\u7684\u5f15\u5165\u65f6\u673a\n    disc_factor = adopt_weight(self.disc_factor, global_step, threshold=self.discriminator_iter_start)\n    # \u5224\u522b\u5668\u635f\u5931\u6839\u636e\u9009\u7528\u7684 hinge \u6216 vanilla \u635f\u5931\u51fd\u6570\u8fdb\u884c\u8ba1\u7b97\n    d_loss = disc_factor * self.disc_loss(logits_real, logits_fake)\n\n    log = {\"{}/disc_loss\".format(split): d_loss.clone().detach().mean(),\n           \"{}/logits_real\".format(split): logits_real.detach().mean(),\n           \"{}/logits_fake\".format(split): logits_fake.detach().mean()\n           }\n    return d_loss, log\n</code></pre> <p>To optimize the GAN, we only need the fake/real images. Also, add the condition into the <code>discriminator</code> when it is a conditional GAN.</p> <pre><code>def hinge_d_loss(logits_real, logits_fake):\n    loss_real = torch.mean(F.relu(1. - logits_real))\n    loss_fake = torch.mean(F.relu(1. + logits_fake))\n    d_loss = 0.5 * (loss_real + loss_fake)\n    return d_loss\n\n\ndef vanilla_d_loss(logits_real, logits_fake):\n    d_loss = 0.5 * (\n        torch.mean(torch.nn.functional.softplus(-logits_real)) +\n        torch.mean(torch.nn.functional.softplus(logits_fake)))\n    return d_loss\n</code></pre> <p>use hinge or vanilla loss by the parameter Below are the mathematical formulas for the two loss functions as implemented in the code:</p>"},{"location":"book/chapter7_diffusion/ldm_handson/#31323-hinge-loss","title":"3.1.3.2.3 Hinge Loss","text":"<p>Given the discriminator outputs for real samples, \\( D(x) \\), and for generated samples, \\( D(\\tilde{x}) \\), the hinge loss for the discriminator is defined as:</p> \\[ \\mathcal{L}_D^{\\text{hinge}} = \\frac{1}{2} \\left( \\mathbb{E}_{x \\sim p_{\\text{data}}}\\left[\\max\\left(0,\\, 1 - D(x)\\right)\\right] + \\mathbb{E}_{\\tilde{x} \\sim p_G}\\left[\\max\\left(0,\\, 1 + D(\\tilde{x})\\right)\\right] \\right) \\] <ul> <li>\\(\\max(0,\\, 1 - D(x))\\) computes the loss for real samples.</li> <li>\\(\\max(0,\\, 1 + D(\\tilde{x}))\\) computes the loss for generated (fake) samples.</li> </ul>"},{"location":"book/chapter7_diffusion/ldm_handson/#31324-vanilla-loss","title":"3.1.3.2.4 Vanilla Loss","text":"<p>For the vanilla loss, we use the softplus function, defined as:</p> \\[ \\text{softplus}(x) = \\ln(1 + e^x) \\] <p>Then the vanilla loss for the discriminator is given by:</p> \\[ \\mathcal{L}_D^{\\text{vanilla}} = \\frac{1}{2} \\left( \\mathbb{E}_{x \\sim p_{\\text{data}}}\\left[\\ln\\left(1 + e^{-D(x)}\\right)\\right] + \\mathbb{E}_{\\tilde{x} \\sim p_G}\\left[\\ln\\left(1 + e^{D(\\tilde{x})}\\right)\\right] \\right) \\] <p>These formulas correspond exactly to the implementation in the code:</p> <ul> <li>For the hinge loss, the code computes \\(\\text{loss\\_real} = \\text{mean}(\\text{ReLU}(1 - \\text{logits\\_real}))\\) and \\(\\text{loss\\_fake} = \\text{mean}(\\text{ReLU}(1 + \\text{logits\\_fake}))\\), then takes their average.</li> <li>For the vanilla loss, the code computes \\(\\text{mean}(\\text{softplus}(-\\text{logits\\_real}))\\) and \\(\\text{mean}(\\text{softplus}(\\text{logits\\_fake}))\\) and averages them. Here we plot the curve of the above two types of losses for intuitive comparison.</li> </ul> <p></p>"},{"location":"book/chapter7_diffusion/ldm_handson/#314-summary","title":"3.1.4 Summary","text":"<p>Based on the above analysis, we can see that the loss is basically a normal <code>VAE loss</code> +  <code>GAN loss</code> + <code>Perceptural Loss</code>.</p>"},{"location":"book/chapter7_diffusion/ldm_handson/#32-ddpm","title":"3.2 DDPM","text":"<p>Train latent diffusion</p> <pre><code>CUDA_VISIBLE_DEVICES=&lt;GPU_ID&gt; python main.py --base configs/latent-diffusion/&lt;config_spec&gt;.yaml -t --gpus 0,\n</code></pre> <p>Let's study the codes step by step. The code is in <code>ldm/models/diffusion/ddpm.py</code> in github: CompVis/latent-diffusion</p>"},{"location":"book/chapter7_diffusion/ldm_handson/#321-ddpm-class","title":"3.2.1 DDPM Class","text":""},{"location":"book/chapter7_diffusion/ldm_handson/#3211-__init__","title":"3.2.1.1 <code>__init__</code>","text":"init<pre><code>class DDPM(pl.LightningModule):\n    # classic DDPM with Gaussian diffusion, in image space\n    def __init__(self,\n                 unet_config,\n                 timesteps=1000,\n                 beta_schedule=\"linear\",\n                 loss_type=\"l2\",\n                 ckpt_path=None,\n                 ignore_keys=[],\n                 load_only_unet=False,\n                 monitor=\"val/loss\",\n                 use_ema=True,\n                 first_stage_key=\"image\",\n                 image_size=256,\n                 channels=3,\n                 log_every_t=100,\n                 clip_denoised=True,\n                 linear_start=1e-4,\n                 linear_end=2e-2,\n                 cosine_s=8e-3,\n                 given_betas=None,\n                 original_elbo_weight=0.,\n                 v_posterior=0.,  # weight for choosing posterior variance as sigma = (1-v) * beta_tilde + v * beta\n                 l_simple_weight=1.,\n                 conditioning_key=None,\n                 parameterization=\"eps\",  # all assuming fixed variance schedules\n                 scheduler_config=None,\n                 use_positional_encodings=False,\n                 learn_logvar=False,\n                 logvar_init=0.,\n                 ):\n        super().__init__()\n        assert parameterization in [\"eps\", \"x0\"], 'currently only supporting \"eps\" and \"x0\"'\n        self.parameterization = parameterization\n        print(f\"{self.__class__.__name__}: Running in {self.parameterization}-prediction mode\")\n        self.cond_stage_model = None\n        self.clip_denoised = clip_denoised\n        self.log_every_t = log_every_t\n        self.first_stage_key = first_stage_key\n        self.image_size = image_size  # try conv?\n        self.channels = channels\n        self.use_positional_encodings = use_positional_encodings\n        self.model = DiffusionWrapper(unet_config, conditioning_key)\n        count_params(self.model, verbose=True)\n        self.use_ema = use_ema\n        if self.use_ema:\n            self.model_ema = LitEma(self.model)\n            print(f\"Keeping EMAs of {len(list(self.model_ema.buffers()))}.\")\n\n        self.use_scheduler = scheduler_config is not None\n        if self.use_scheduler:\n            self.scheduler_config = scheduler_config\n\n        self.v_posterior = v_posterior\n        self.original_elbo_weight = original_elbo_weight\n        self.l_simple_weight = l_simple_weight\n\n        if monitor is not None:\n            self.monitor = monitor\n        if ckpt_path is not None:\n            self.init_from_ckpt(ckpt_path, ignore_keys=ignore_keys, only_model=load_only_unet)\n\n        self.register_schedule(given_betas=given_betas, beta_schedule=beta_schedule, timesteps=timesteps,\n                               linear_start=linear_start, linear_end=linear_end, cosine_s=cosine_s)\n\n        self.loss_type = loss_type\n\n        self.learn_logvar = learn_logvar\n        self.logvar = torch.full(fill_value=logvar_init, size=(self.num_timesteps,))\n        if self.learn_logvar:\n            self.logvar = nn.Parameter(self.logvar, requires_grad=True)\n</code></pre> <p>The DDPM class is herited from the <code>pl.LightningModule</code>, includes the forward, reversem training and sampling processes.</p> <p>In the init part,</p> <ul> <li><code>timesteps=1000</code> is the diffusion steps, usually be 1000,</li> <li><code>beta_schedule='linear'</code> is the noise scheduler that controls \\(\\beta_t\\)</li> <li><code>parameterization=\"eps\"</code> is the training target, 'eps' means network predicted the noise, <code>x0</code> means predict the denoied image</li> <li><code>use_ema=True</code> means the expotentinoal moving average to stabalize the training. <code>LitEma(self.model)</code> defines the ema model</li> <li><code>logvar_init=0</code>: the initial value of log var in the traiing. Can be choose to learn or use fixed value.</li> <li><code>self.model = DiffusionWrapper(unet_config, conditioning_key)</code> defines the U-Net used in the diffusion proces</li> </ul>"},{"location":"book/chapter7_diffusion/ldm_handson/#3212-register_schedule","title":"3.2.1.2 <code>register_schedule</code>","text":"register_schedule<pre><code>    def register_schedule(self, given_betas=None, beta_schedule=\"linear\", timesteps=1000,\n                          linear_start=1e-4, linear_end=2e-2, cosine_s=8e-3):\n        if exists(given_betas):\n            betas = given_betas\n        else:\n            betas = make_beta_schedule(beta_schedule, timesteps, linear_start=linear_start, linear_end=linear_end,\n                                       cosine_s=cosine_s)\n        alphas = 1. - betas\n        alphas_cumprod = np.cumprod(alphas, axis=0)\n        alphas_cumprod_prev = np.append(1., alphas_cumprod[:-1])\n\n        timesteps, = betas.shape\n        self.num_timesteps = int(timesteps)\n        self.linear_start = linear_start\n        self.linear_end = linear_end\n        assert alphas_cumprod.shape[0] == self.num_timesteps, 'alphas have to be defined for each timestep'\n\n        to_torch = partial(torch.tensor, dtype=torch.float32)\n\n        self.register_buffer('betas', to_torch(betas))\n        self.register_buffer('alphas_cumprod', to_torch(alphas_cumprod))\n        self.register_buffer('alphas_cumprod_prev', to_torch(alphas_cumprod_prev))\n\n        # calculations for diffusion q(x_t | x_{t-1}) and others\n        self.register_buffer('sqrt_alphas_cumprod', to_torch(np.sqrt(alphas_cumprod)))\n        self.register_buffer('sqrt_one_minus_alphas_cumprod', to_torch(np.sqrt(1. - alphas_cumprod)))\n        self.register_buffer('log_one_minus_alphas_cumprod', to_torch(np.log(1. - alphas_cumprod)))\n        self.register_buffer('sqrt_recip_alphas_cumprod', to_torch(np.sqrt(1. / alphas_cumprod)))\n        self.register_buffer('sqrt_recipm1_alphas_cumprod', to_torch(np.sqrt(1. / alphas_cumprod - 1)))\n\n        # calculations for posterior q(x_{t-1} | x_t, x_0)\n        posterior_variance = (1 - self.v_posterior) * betas * (1. - alphas_cumprod_prev) / (\n                    1. - alphas_cumprod) + self.v_posterior * betas\n        # above: equal to 1. / (1. / (1. - alpha_cumprod_tm1) + alpha_t / beta_t)\n        self.register_buffer('posterior_variance', to_torch(posterior_variance))\n        # below: log calculation clipped because the posterior variance is 0 at the beginning of the diffusion chain\n        self.register_buffer('posterior_log_variance_clipped', to_torch(np.log(np.maximum(posterior_variance, 1e-20))))\n        self.register_buffer('posterior_mean_coef1', to_torch(\n            betas * np.sqrt(alphas_cumprod_prev) / (1. - alphas_cumprod)))\n        self.register_buffer('posterior_mean_coef2', to_torch(\n            (1. - alphas_cumprod_prev) * np.sqrt(alphas) / (1. - alphas_cumprod)))\n\n        if self.parameterization == \"eps\":\n            lvlb_weights = self.betas ** 2 / (\n                        2 * self.posterior_variance * to_torch(alphas) * (1 - self.alphas_cumprod))\n        elif self.parameterization == \"x0\":\n            lvlb_weights = 0.5 * np.sqrt(torch.Tensor(alphas_cumprod)) / (2. * 1 - torch.Tensor(alphas_cumprod))\n        else:\n            raise NotImplementedError(\"mu not supported\")\n        # TODO how to choose this term\n        lvlb_weights[0] = lvlb_weights[1]\n        self.register_buffer('lvlb_weights', lvlb_weights, persistent=False)\n        assert not torch.isnan(self.lvlb_weights).all()\n</code></pre> <p><code>register_schedule</code> is mainly used tp calculate the noise scheduler, including the  \\(\\beta_t\\) (noise), \\(\\alpha_t\\) (original image info)\u3001 accumulated \\(\\alpha_t\\), (\\(\\bar{\\alpha}_t\\)), and mean and variance of posterior distribution \\(q(x_{t-1} | x_t, x_0)\\).</p> <p>\\(\\beta_t\\)</p> <ul> <li>Linear:</li> </ul> <p>$$   \\beta_t = \\text{linear_start} + t \\cdot \\frac{\\text{linear_end} - \\text{linear_start}}{\\text{timesteps} - 1}   $$</p> <p>Here  <code>linear_start = 1e-4</code>\uff0c<code>linear_end = 2e-2</code>\uff0cnoise is increasing w.r.t \\(t\\).</p> <ul> <li>Cosine:</li> </ul> <p>$$   \\beta_t = 1 - \\frac{\\cos\\left(\\frac{t / T + s}{1 + s} \\cdot \\frac{\\pi}{2} \\right)^2}{\\cos\\left(\\frac{s}{1+s} \\cdot \\frac{\\pi}{2}\\right)^2}   $$</p> <pre><code>`s = 8e-3` controls the initial noise\n</code></pre> <p>\\(\\alpha_t\\) and  \\(\\bar{\\alpha}_t\\)</p> <ul> <li>\\(\\alpha_t\\):</li> </ul> <p>$$   \\alpha_t = 1 - \\beta_t   $$</p> <ul> <li>\\(\\bar{\\alpha}_t\\) (product of previous \\(t\\) steps):</li> </ul> <p>$$   \\bar{\\alpha}t = \\prod \\alpha_i   $$}^{t</p> <pre><code>$\\bar{\\alpha}_t$ represents the aspect of original info is left from $x_0$ to $x_t$\n</code></pre> <p>\\(q(x_{t-1} | x_t, x_0)\\)</p> <ul> <li>mean \\(\\mu_t\\):</li> </ul> <p>$$   \\mu_t = \\frac{\\sqrt{\\bar{\\alpha}{t-1}} \\beta_t}{1 - \\bar{\\alpha}_t} x_0 + \\frac{\\sqrt{\\alpha_t} (1 - \\bar{\\alpha} x_t   $$})}{1 - \\bar{\\alpha}_t</p> <ul> <li>varience \\(\\sigma_t^2\\):</li> </ul> <p>$$   \\sigma_t^2 = (1 - v) \\cdot \\frac{\\beta_t (1 - \\bar{\\alpha}_{t-1})}{1 - \\bar{\\alpha}_t} + v \\cdot \\beta_t   $$</p> <p><code>v</code>\uff08<code>v_posterior</code>) determines the calculatetion of the variance, default <code>v=0</code>\u3002</p> <p>According to the 'make_beta_schedule' formula</p> <pre><code>betas = make_beta_schedule(beta_schedule, timesteps, linear_start=linear_start, linear_end=linear_end, cosine_s=cosine_s)\nalphas = 1. - betas\nalphas_cumprod = np.cumprod(alphas, axis=0)\nalphas_cumprod_prev = np.append(1., alphas_cumprod[:-1])\n</code></pre> <ul> <li>Here <code>betas</code>  is  \\(\\beta_t\\)\uff0c<code>alphas</code> is \\(\\alpha_t\\)\uff0c<code>alphas_cumprod</code> is \\(\\bar{\\alpha}_t\\).</li> </ul> <p>Here is uses the <code>make_beta_schedule</code> functoin, which is</p> <p>The function <code>make_beta_schedule</code> is designed to generate the noise schedule \\(\\beta_t\\) used in the diffusion process. Different scheduling methods impact the convergence and final image quality of the diffusion model.</p> <p>Input Parameters</p> <ul> <li><code>schedule</code>: Specifies the method for computing \\(\\beta_t\\).</li> <li><code>n_timestep</code>: Total number of diffusion steps <code>T</code>, typically 1000.</li> <li><code>linear_start</code> &amp; <code>linear_end</code>:</li> <li>Linear schedule: \\(\\beta_t\\) gradually increases from <code>linear_start</code> to <code>linear_end</code>.</li> <li>Square root schedule: \\(\\beta_t\\) increases based on a square root transformation.</li> <li><code>cosine_s=8e-3</code>:</li> <li> <p>Used in cosine schedule, typically for Stable Diffusion, improving stability.</p> </li> <li> <p>1. Linear Schedule</p> <pre><code>if schedule == \"linear\":\n    betas = (\n        torch.linspace(linear_start ** 0.5, linear_end ** 0.5, n_timestep, dtype=torch.float64) ** 2\n    )\n</code></pre> <p>Mathematical Formula:</p> <p>$$  \\beta_t = \\left( \\sqrt{\\text{linear_start}} + \\frac{t}{T} \\left( \\sqrt{\\text{linear_end}} - \\sqrt{\\text{linear_start}} \\right) \\right)^2  $$</p> <p>First take the square root, then apply linear interpolation, and finally square the values. This ensures a smooth increase in \\(\\beta_t\\).</p> </li> <li> <p>2. Cosine Schedule</p> <pre><code>elif schedule == \"cosine\":\n    timesteps = (\n        torch.arange(n_timestep + 1, dtype=torch.float64) / n_timestep + cosine_s\n    )\n    alphas = timesteps / (1 + cosine_s) * np.pi / 2\n    alphas = torch.cos(alphas).pow(2)\n    alphas = alphas / alphas[0]\n    betas = 1 - alphas[1:] / alphas[:-1]\n    betas = np.clip(betas, a_min=0, a_max=0.999)\n</code></pre> <p>Mathematical Formula:</p> <p>$$   \\alpha_t = \\cos^2 \\left( \\frac{t/T + s}{1 + s} \\cdot \\frac{\\pi}{2} \\right) $$   - <code>s</code> controls the initial noise strength.   - \\(\\alpha_t\\) is normalized so that \\(\\alpha_0 = 1\\).   - \\(\\beta_t = 1 - \\frac{\\alpha_{t+1}}{\\alpha_t}\\) ensures \\(\\beta_t\\) is computed correctly.</p> <ul> <li>Key Features:</li> <li>Cosine scheduling increases slowly at first and then rapidly towards the end.</li> <li>This better matches human perception of noise and improves detail generation.</li> </ul> </li> <li> <p>3. Square Root Linear Schedule</p> <pre><code>elif schedule == \"sqrt_linear\":\n    betas = torch.linspace(linear_start, linear_end, n_timestep, dtype=torch.float64)\n</code></pre> <p>Mathematical Formula: $$  \\beta_t = \\text{linear_start} + \\frac{t}{T} \\left( \\text{linear_end} - \\text{linear_start} \\right) $$ \\(\\beta_t\\) increases uniformly over time.</p> </li> <li> <p>4. Square Root Schedule</p> <pre><code>elif schedule == \"sqrt\":\n    betas = torch.linspace(linear_start, linear_end, n_timestep, dtype=torch.float64) ** 0.5\n</code></pre> <p>Mathematical Formula:</p> \\[ \\beta_t = \\left( \\text{linear\\_start} + \\frac{t}{T} \\left( \\text{linear\\_end} - \\text{linear\\_start} \\right) \\right)^{0.5} \\] <p>Takes the square root to achieve a smoother increase in \\(\\beta_t\\).</p> </li> </ul> <p>Comparison of Different \\(\\beta_t\\) Schedules</p> Schedule Type Formula Usage Linear \\( \\beta_t = \\left( \\sqrt{\\text{start}} + \\frac{t}{T} \\left( \\sqrt{\\text{end}} - \\sqrt{\\text{start}} \\right) \\right)^2 \\) Standard DDPM, suitable for most tasks Cosine \\( \\alpha_t = \\cos^2 \\left( \\frac{t/T + s}{1 + s} \\cdot \\frac{\\pi}{2} \\right) \\) Stable Diffusion, improves image quality Sqrt Linear \\( \\beta_t = \\text{start} + \\frac{t}{T} \\left( \\text{end} - \\text{start} \\right) \\) Used for denoising tasks Sqrt \\( \\beta_t = \\left( \\text{start} + \\frac{t}{T} \\left( \\text{end} - \\text{start} \\right) \\right)^{0.5} \\) Smooth increase, useful for video tasks <p></p> <p>The choice of schedule impacts model convergence, image quality, and noise control. Experiments are often necessary to determine the most suitable \\(\\beta_t\\) scheduling method.</p> <p>And calculated the posterior distribution\uff1a</p> <pre><code>posterior_variance = (1 - self.v_posterior) * betas * (1. - alphas_cumprod_prev) / (\n                1. - alphas_cumprod) + self.v_posterior * betas\n</code></pre> <p>Here <code>posterior_variance</code> is \\(\\sigma_t^2\\)</p> <p>Mean parameters</p> <pre><code>self.register_buffer('posterior_mean_coef1', to_torch(\n    betas * np.sqrt(alphas_cumprod_prev) / (1. - alphas_cumprod)))\nself.register_buffer('posterior_mean_coef2', to_torch(\n    (1. - alphas_cumprod_prev) * np.sqrt(alphas) / (1. - alphas_cumprod)))\n</code></pre> <p>Which is the two coes of the \\(\\mu_t\\)</p>"},{"location":"book/chapter7_diffusion/ldm_handson/#3213-training-step","title":"3.2.1.3 training step","text":"<pre><code>def q_sample(self, x_start, t, noise=None):\n    noise = default(noise, lambda: torch.randn_like(x_start))\n    return (extract_into_tensor(self.sqrt_alphas_cumprod, t, x_start.shape) * x_start +\n                extract_into_tensor(self.sqrt_one_minus_alphas_cumprod, t, x_start.shape) * noise)\n\ndef forward(self, x, *args, **kwargs):\n    # input image shape is: [b, c, h, w]\n    t = torch.randint(0, self.num_timesteps, (x.shape[0],), device=self.device).long()\n    # random pick a time step t, as the argument of the model\n    return self.p_losses(x, t, *args, **kwargs)\n\ndef p_losses(self, x_start, t, noise=None):\n    noise = default(noise, lambda: torch.randn_like(x_start))\n    x_noisy = self.q_sample(x_start=x_start, t=t, noise=noise)\n    model_out = self.model(x_noisy, t)\n\n    loss_dict = {}\n    if self.parameterization == \"eps\":\n        target = noise\n    elif self.parameterization == \"x0\":\n        target = x_start\n    else:\n        raise NotImplementedError(f\"Paramterization {self.parameterization} not yet supported\")\n\n    loss = self.get_loss(model_out, target, mean=False).mean(dim=[1, 2, 3])\n\n    log_prefix = 'train' if self.training else 'val'\n\n    loss_dict.update({f'{log_prefix}/loss_simple': loss.mean()})\n    loss_simple = loss.mean() * self.l_simple_weight\n\n    loss_vlb = (self.lvlb_weights[t] * loss).mean()\n    loss_dict.update({f'{log_prefix}/loss_vlb': loss_vlb})\n\n    loss = loss_simple + self.original_elbo_weight * loss_vlb\n\n    loss_dict.update({f'{log_prefix}/loss': loss})\n\n    return loss, loss_dict\n</code></pre> <p>Let's recall the forward process of ddpm</p> \\[ x_t = \\sqrt{1-\\beta_t}\\, x_{t-1} + \\sqrt{\\beta_t}\\, \\epsilon_t,\\quad \\epsilon_t \\sim \\mathcal{N}(0,I) \\] <p>\\(x_0\\) is the noiseless image. The diffusion process (adding noise) is definedin the <code>q_sample</code> method, which is exactly</p> <p>\u5728 DDPM\uff08Denoising Diffusion Probabilistic Models\uff09\u4e2d\uff0c\u52a0\u566a\u58f0\u7684\u8fc7\u7a0b\uff08forward diffusion process\uff09\u53ef\u4ee5\u63cf\u8ff0\u4e3a\u4e00\u4e2a\u9010\u6b65\u52a0\u5165\u566a\u58f0\u7684\u9a6c\u5c14\u53ef\u592b\u94fe\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u6bcf\u4e00\u6b65\u7684\u566a\u58f0\u6dfb\u52a0\u516c\u5f0f\u4e3a\uff1a</p> \\[ x_t = \\sqrt{1-\\beta_t}\\, x_{t-1} + \\sqrt{\\beta_t}\\, \\epsilon_t,\\quad \\epsilon_t \\sim \\mathcal{N}(0,I) \\] <p>with</p> \\[ \\bar{\\alpha}_t = \\prod_{s=1}^{t} (1-\\beta_s) \\] <p>Theoretically,</p> \\[ x_t = \\sqrt{\\bar{\\alpha}_t}\\, x_0 + \\sqrt{1-\\bar{\\alpha}_t}\\, \\epsilon \\] <p>And in the code  <code>q_sample</code>,</p> <ul> <li><code>self.sqrt_alphas_cumprod</code> \\(\\leftrightarrow\\) \\(\\sqrt{\\bar{\\alpha}_t}\\) (product of square root of \\(\\prod_{s=1}^{t} (1-\\beta_s)\\)\uff09\uff0c</li> <li><code>self.sqrt_one_minus_alphas_cumprod</code> \\(\\leftrightarrow\\) \\(\\sqrt{1-\\bar{\\alpha}_t}\\)\uff0c</li> </ul> <p>There are two types of target, one is <code>x_0</code>, one is <code>eps</code>, corresponds to the noiseless image and the noise. We usually used the noise prediction. The loss is then used \\(L_1\\) or \\(L_2\\).</p> <p>The loss typically is quite simple, but it gots another re-weighted copy which is</p> <p>This code snippet is part of the loss computation in a diffusion model when the model is parameterized to predict the noise (often referred to as \"eps\" parameterization). Here\u2019s what it does: weights help balance the contribution of each term.</p> <pre><code>...\nif self.parameterization == \"eps\":\n    lvlb_weights = self.betas ** 2 / (\n        2 * self.posterior_variance * to_torch(alphas) * (1 - self.alphas_cumprod))\n\u00b7\u00b7\u00b7\ndef p_losses(self, x_start, t, noise=None):\n    ...\n    loss_vlb = (self.lvlb_weights[t] * loss).mean()\n    loss_dict.update({f'{log_prefix}/loss_vlb': loss_vlb})\n\n    loss = loss_simple + self.original_elbo_weight * loss_vlb\n    ...\n</code></pre> <p>Accounting for the Noise Schedule and Posterior Variance:</p> <ul> <li><code>self.betas</code> represents the noise schedule parameters at each timestep.</li> <li><code>self.posterior_variance</code> is the variance of the reverse (posterior) process \\( q(x_{t-1}\\mid x_t, x_0) \\).</li> <li><code>alphas</code> (converted to a torch tensor) and <code>self.alphas_cumprod</code> (the cumulative product of \\( 1-\\beta_t \\)) are used to capture how the signal decays over time.</li> </ul> <p>The formula</p> <p>$$    \\text{lvlb_weights} = \\frac{\\beta_t^2}{2 \\cdot \\text{posterior_variance} \\cdot \\alpha_t \\cdot (1 - \\text{alphas_cumprod}_t)}    $$    adjusts the loss term based on these factors, ensuring that the loss is appropriately scaled at each timestep.</p> <p>Usage in the Loss Function:    When the model predicts \\(\\epsilon\\) (the noise added to \\( x_0 \\)), the training loss often reduces to a weighted mean squared error (MSE) between the predicted and actual noise. The <code>lvlb_weights</code> are used to weight this error term, so that the model\u2019s learning objective better approximates the true variational lower bound of the data likelihood. We can visualize the curve of te weights according to \\(t\\), to see whether weights are focused on.</p> <p></p> <p>This seems that the weights are more focused on the \\(t\\) close to zero, which means the model focus more on the denosing steps that is close to the noiseless images.</p> <p>So far, we have understand the ddpm process. Let's go further on the latent ddpm process</p>"},{"location":"book/chapter7_diffusion/ldm_handson/#322-sampling","title":"3.2.2 Sampling","text":"<pre><code>    def q_mean_variance(self, x_start, t):\n        \"\"\"\n        Get the distribution q(x_t | x_0).\n        :param x_start: the [N x C x ...] tensor of noiseless inputs.\n        :param t: the number of diffusion steps (minus 1). Here, 0 means one step.\n        :return: A tuple (mean, variance, log_variance), all of x_start's shape.\n        \"\"\"\n        mean = (extract_into_tensor(self.sqrt_alphas_cumprod, t, x_start.shape) * x_start)\n        variance = extract_into_tensor(1.0 - self.alphas_cumprod, t, x_start.shape)\n        log_variance = extract_into_tensor(self.log_one_minus_alphas_cumprod, t, x_start.shape)\n        return mean, variance, log_variance\n\n    def predict_start_from_noise(self, x_t, t, noise):\n        return (\n                extract_into_tensor(self.sqrt_recip_alphas_cumprod, t, x_t.shape) * x_t -\n                extract_into_tensor(self.sqrt_recipm1_alphas_cumprod, t, x_t.shape) * noise\n        )\n\n    def q_posterior(self, x_start, x_t, t):\n        posterior_mean = (\n                extract_into_tensor(self.posterior_mean_coef1, t, x_t.shape) * x_start +\n                extract_into_tensor(self.posterior_mean_coef2, t, x_t.shape) * x_t\n        )\n        posterior_variance = extract_into_tensor(self.posterior_variance, t, x_t.shape)\n        posterior_log_variance_clipped = extract_into_tensor(self.posterior_log_variance_clipped, t, x_t.shape)\n        return posterior_mean, posterior_variance, posterior_log_variance_clipped\n\n    def p_mean_variance(self, x, t, clip_denoised: bool):\n        model_out = self.model(x, t)\n        if self.parameterization == \"eps\":\n            x_recon = self.predict_start_from_noise(x, t=t, noise=model_out)\n        elif self.parameterization == \"x0\":\n            x_recon = model_out\n        if clip_denoised:\n            x_recon.clamp_(-1., 1.)\n\n        model_mean, posterior_variance, posterior_log_variance = self.q_posterior(x_start=x_recon, x_t=x, t=t)\n        return model_mean, posterior_variance, posterior_log_variance\n\n    @torch.no_grad()\n    def p_sample(self, x, t, clip_denoised=True, repeat_noise=False):\n        b, *_, device = *x.shape, x.device\n        model_mean, _, model_log_variance = self.p_mean_variance(x=x, t=t, clip_denoised=clip_denoised)\n        noise = noise_like(x.shape, device, repeat_noise)\n        # no noise when t == 0\n        nonzero_mask = (1 - (t == 0).float()).reshape(b, *((1,) * (len(x.shape) - 1)))\n        return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise\n\n    @torch.no_grad()\n    def p_sample_loop(self, shape, return_intermediates=False):\n        device = self.betas.device\n        b = shape[0]\n        img = torch.randn(shape, device=device)\n        intermediates = [img]\n        for i in tqdm(reversed(range(0, self.num_timesteps)), desc='Sampling t', total=self.num_timesteps):\n            img = self.p_sample(img, torch.full((b,), i, device=device, dtype=torch.long),\n                                clip_denoised=self.clip_denoised)\n            if i % self.log_every_t == 0 or i == self.num_timesteps - 1:\n                intermediates.append(img)\n        if return_intermediates:\n            return img, intermediates\n        return img\n\n    @torch.no_grad()\n    def sample(self, batch_size=16, return_intermediates=False):\n        image_size = self.image_size\n        channels = self.channels\n        return self.p_sample_loop((batch_size, channels, image_size, image_size),\n                                  return_intermediates=return_intermediates)\n</code></pre> <p>We give the following explanation for the DDPM sampling steps and corresponds it to the original DDPM reverse process</p> <ul> <li>\\(x_0\\) Estimation:   $$   x_0 = \\frac{1}{\\sqrt{\\bar{\\alpha}_t}}\\, x_t - \\sqrt{\\frac{1}{\\bar{\\alpha}_t} - 1}\\, \\epsilon   $$</li> </ul> <p>\u2194 <code>predict_start_from_noise</code>   (Coefficients: <code>sqrt_recip_alphas_cumprod</code> and <code>sqrt_recipm1_alphas_cumprod</code>)</p> <ul> <li> <p>Posterior Mean Calculation:   $$   \\mu_{\\text{posterior}}(x_t, x_0) = \\frac{\\sqrt{\\bar{\\alpha}{t-1}}\\, \\beta_t}{1-\\bar{\\alpha}_t}\\, x_0 + \\frac{\\sqrt{\\alpha_t}\\,(1-\\bar{\\alpha}\\, x_t   $$   \u2194 })}{1-\\bar{\\alpha}_t<code>q_posterior</code>   (Coefficients: <code>posterior_mean_coef1</code> and <code>posterior_mean_coef2</code>)</p> </li> <li> <p>Reverse Process Sampling:   $$   x_{t-1} = \\mu_\\theta(x_t,t) + \\sigma_t\\, z,\\quad z \\sim \\mathcal{N}(0,I)   $$</p> </li> </ul> <p>\u2194 <code>p_sample</code>   (Mean from <code>p_mean_variance</code> and variance computed via</p> <p>\\(\\(e^{0.5 \\times \\text{model-log-variance}}\\)\\)</p> <ul> <li>Forward Process Sampling:   $$   x_t = \\sqrt{\\bar{\\alpha}_t}\\, x_0 + \\sqrt{1-\\bar{\\alpha}_t}\\, \\epsilon   $$   \u2194 <code>q_sample</code>   (Coefficients: <code>sqrt_alphas_cumprod</code> and <code>sqrt_one_minus_alphas_cumprod</code>)</li> </ul> <p>Need to mention that, every time, it predicted a \\(x_0\\) and then calculate \\(x_{t-1}\\) according to the forward process.</p>"},{"location":"book/chapter7_diffusion/ldm_handson/#33-latent-dm","title":"3.3 Latent DM","text":"<p>In this section, we can just compare the differences between the LDM ad DDPM.</p> <p>First, in the init stage, it has extra</p> <pre><code>        self.instantiate_first_stage(first_stage_config)\n</code></pre> <p>to initialize the auto encoder which map the original image to the latent space.</p> <p>In summary, the loss are exactly the same as that of DDPM. The differences comes from the forward step, which</p> <p>If do not considet the condition, the main difference is</p> <p>The LDM will first convert image to latent space by the pretrained VAE</p> <pre><code>encoder_posterior = self.encode_first_stage(x)\nz = self.get_first_stage_encoding(encoder_posterior).detach()\n</code></pre> <p>All the rest is same.</p> <p>The codes got a lot of lines dealing with the conditioning including <code>get_input</code>, <code>apply_model</code></p>"},{"location":"book/chapter7_diffusion/ldm_handson/#331-conditional-latent-dm","title":"3.3.1 Conditional Latent DM","text":"<p>Next, we focus on how the latent DM put the condition into the network. The training is not guided on the conditioning, it just puts the condition information into the betwork for conditional generation in a implicite architecture.</p> <p>The diffusion model accepts three different types of conditions</p> DiffusionWrapper<pre><code>    def forward(self, x, t, c_concat: list = None, c_crossattn: list = None):\n        if self.conditioning_key is None:\n            out = self.diffusion_model(x, t)\n        elif self.conditioning_key == 'concat':\n            xc = torch.cat([x] + c_concat, dim=1)\n            out = self.diffusion_model(xc, t)\n        elif self.conditioning_key == 'crossattn':\n            cc = torch.cat(c_crossattn, 1)\n            out = self.diffusion_model(x, t, context=cc)\n        elif self.conditioning_key == 'hybrid':\n            xc = torch.cat([x] + c_concat, dim=1)\n            cc = torch.cat(c_crossattn, 1)\n            out = self.diffusion_model(xc, t, context=cc)\n        elif self.conditioning_key == 'adm':\n            cc = c_crossattn[0]\n            out = self.diffusion_model(x, t, y=cc)\n        else:\n            raise NotImplementedError()\n\n        return out\n</code></pre> <p>The conditioning_key have \"hybrid\", \"concat\", \"crossattn\", \"adm\" types.</p> <ul> <li>Concat   In the \"Concat\" format, the condition information is concated in to the original input, which require the same shape with the input \\(x\\). It can handles the conditions like</li> <li>segmentation map</li> <li>edge map</li> <li>depthmap</li> <li> <p>any spacial condition with the same shape</p> </li> <li> <p>CrossAttention     In this type, the condition should be a sequence of shape [B,L,D]. Which usually handles for conditions</p> </li> <li>texts (ex. from the clip model)</li> <li>class embeddings</li> <li> <p>any conditions in sequence format</p> <p>These infomation will be fed into the attention block in the UNet via cross attention</p> </li> <li> <p>ADM     The condition shape if of [B,D] which is a single token embedding. Can handle conditions like     The information will be assigned to class label \\(y\\).     In the network, the class label condition is added into the time step condition</p> <pre><code>        t_emb = timestep_embedding(timesteps, self.model_channels, repeat_only=False)\n    emb = self.time_embed(t_emb)\n\n    if self.num_classes is not None:\n        assert y.shape == (x.shape[0],)\n        emb = emb + self.label_emb(y)\n</code></pre> </li> <li> <p>classfier guided generation</p> </li> <li>Hybrid     Which combines different types of conditions together</li> </ul>"},{"location":"book/chapter7_diffusion/ldm_handson/#332-sampling-with-ddpm-class","title":"3.3.2 Sampling with DDPM class","text":"<p>This is exactly the same as that of DDPM sampling except with handling with different conditions</p>"},{"location":"book/chapter7_diffusion/ldm_handson/#34-unet","title":"3.4 UNet","text":"SpatialTransformerBasic Transfomer BlockCross Attention <pre><code>Input x [B, C, H, W]\n    \u2502\n    \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502                     \u2502\n    \u2193                     \u2502\nLayerNorm (self.norm)     \u2502\n    \u2502                     \u2502\n    \u2193                     \u2502\nProjection (self.proj_in) \u2502\n[B, C', H, W]             \u2502\n    \u2502                     \u2502\n    \u2193                     \u2502\nReshape (rearrange)       \u2502\n[B, (H\u00d7W), C']            \u2502\n    \u2502                     \u2502\n    \u2193                     \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510       \u2502\n\u2502Transformer Block\u2502       \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502       \u2502\n\u2502  \u2502Self-Attn\u2502    \u2502       \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502       \u2502\n\u2502      \u2502          \u2502       \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502       \u2502\n\u2502  \u2502Cross-Att\u2502\u2190\u2500\u2500\u253c\u2500\u2500\u2500\u2500context\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502       \u2502\n\u2502      \u2502          \u2502       \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502       \u2502\n\u2502  \u2502   FF    \u2502    \u2502       \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518       \u2502\n    \u2502                     \u2502\n    \u2193                     \u2502\nReshape (rearrange)       \u2502\n[B, C', H, W]             \u2502\n    \u2502                     \u2502\n    \u2193                     \u2502\nProjection (self.proj_out)\u2502\n[B, C, H, W]              \u2502\n    \u2502                     \u2502\n    \u2193                     \u2502\n    +\u2190\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n    \u2502\nOutput\n[B, C, H, W]\n</code></pre> <pre><code>Input x\n\u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2193             \u2502\nLayerNorm1    \u2502\n\u2502             \u2502\n\u2193             \u2502\nSelf-Attention\u2502\n(attn1)       \u2502\n\u2502             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2192 + \u2500\u2500\u2500\u2500\u2518\n        \u2502\n        \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2193              \u2502\n    LayerNorm2         \u2502\n        \u2502              \u2502\n        \u2193              \u2502\n    Cross-Attention    \u2502\n    (attn2)            \u2502\n       \u2502               \u2502\n       \u2514\u2500\u2500\u2500\u2500\u2500\u2192 + \u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                \u2502\n                \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                \u2193              \u2502\n                LayerNorm3     \u2502\n                \u2502              \u2502\n                \u2193              \u2502\n            Feed-Forward       \u2502\n                (ff)           \u2502\n                \u2502              \u2502\n                \u2514\u2500\u2500\u2500\u2500\u2192 + \u2500\u2500\u2500\u2500\u2518\n                        \u2502\n                        \u2193\n                    Output\n</code></pre> <pre><code>Input x             Context\n[b, n, dim]       [b, m, dim]\n    \u2502                  \u2502\n    \u2193                  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\nto_q Linear          \u2193             \u2193\n    \u2502             to_k Linear    to_v Linear\n    \u2193                  \u2502             \u2502\n[b, n, h*d]    [b, m, h*d]    [b, m, h*d]\n    \u2502                  \u2502             \u2502\n    \u2193                  \u2193             \u2193\nReshape to heads  Reshape to heads   Reshape\n[b*h, n, d]      [b*h, m, d]    [b*h, m, d]\n    \u2502                  \u2502             \u2502\n    \u2502                  \u2502             \u2502\n    \u2514\u2500\u2500\u2192 Q\u00b7K^T * scale \u2190\u2500\u2518           \u2502\n        [b*h, n, m]                  \u2502\n            \u2502                        \u2502\n            \u2193                        \u2502\n        softmax(dim=-1)              \u2502\n        [b*h, n, m]                  \u2502\n            \u2502                        \u2502\n            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2192 \u00b7 V \u2190\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                    \u2502\n                    \u2193\n                [b*h, n, d]\n                    \u2502\n                    \u2193\n            Reshape to batch\n            [b, n, h*d]\n                    \u2502\n                    \u2193\n            Linear Output\n                    \u2502\n                    \u2193\n            [b, n, query_dim]\n</code></pre> <p>Based on the above basic block, the overall structure is </p>"},{"location":"book/chapter7_diffusion/ldm_handson/#35-ddim-sampling","title":"3.5 DDIM sampling","text":"<pre><code>\"\"\"SAMPLING ONLY.\"\"\"\n\nimport torch\nimport numpy as np\nfrom tqdm import tqdm\nfrom functools import partial\n\nfrom ldm.modules.diffusionmodules.util import make_ddim_sampling_parameters, make_ddim_timesteps, noise_like\n\n\nclass DDIMSampler(object):\n    def __init__(self, model, schedule=\"linear\", **kwargs):\n        super().__init__()\n        self.model = model\n        self.ddpm_num_timesteps = model.num_timesteps\n        self.schedule = schedule\n\n    def register_buffer(self, name, attr):\n        if type(attr) == torch.Tensor:\n            if attr.device != torch.device(\"cuda\"):\n                attr = attr.to(torch.device(\"cuda\"))\n        setattr(self, name, attr)\n\n    def make_schedule(self, ddim_num_steps, ddim_discretize=\"uniform\", ddim_eta=0., verbose=True):\n        self.ddim_timesteps = make_ddim_timesteps(ddim_discr_method=ddim_discretize, num_ddim_timesteps=ddim_num_steps,\n                                                  num_ddpm_timesteps=self.ddpm_num_timesteps,verbose=verbose)\n        alphas_cumprod = self.model.alphas_cumprod\n        assert alphas_cumprod.shape[0] == self.ddpm_num_timesteps, 'alphas have to be defined for each timestep'\n        to_torch = lambda x: x.clone().detach().to(torch.float32).to(self.model.device)\n\n        self.register_buffer('betas', to_torch(self.model.betas))\n        self.register_buffer('alphas_cumprod', to_torch(alphas_cumprod))\n        self.register_buffer('alphas_cumprod_prev', to_torch(self.model.alphas_cumprod_prev))\n\n        # calculations for diffusion q(x_t | x_{t-1}) and others\n        self.register_buffer('sqrt_alphas_cumprod', to_torch(np.sqrt(alphas_cumprod.cpu())))\n        self.register_buffer('sqrt_one_minus_alphas_cumprod', to_torch(np.sqrt(1. - alphas_cumprod.cpu())))\n        self.register_buffer('log_one_minus_alphas_cumprod', to_torch(np.log(1. - alphas_cumprod.cpu())))\n        self.register_buffer('sqrt_recip_alphas_cumprod', to_torch(np.sqrt(1. / alphas_cumprod.cpu())))\n        self.register_buffer('sqrt_recipm1_alphas_cumprod', to_torch(np.sqrt(1. / alphas_cumprod.cpu() - 1)))\n\n        # ddim sampling parameters\n        ddim_sigmas, ddim_alphas, ddim_alphas_prev = make_ddim_sampling_parameters(alphacums=alphas_cumprod.cpu(),\n                                                                                   ddim_timesteps=self.ddim_timesteps,\n                                                                                   eta=ddim_eta,verbose=verbose)\n        self.register_buffer('ddim_sigmas', ddim_sigmas)\n        self.register_buffer('ddim_alphas', ddim_alphas)\n        self.register_buffer('ddim_alphas_prev', ddim_alphas_prev)\n        self.register_buffer('ddim_sqrt_one_minus_alphas', np.sqrt(1. - ddim_alphas))\n        sigmas_for_original_sampling_steps = ddim_eta * torch.sqrt(\n            (1 - self.alphas_cumprod_prev) / (1 - self.alphas_cumprod) * (\n                        1 - self.alphas_cumprod / self.alphas_cumprod_prev))\n        self.register_buffer('ddim_sigmas_for_original_num_steps', sigmas_for_original_sampling_steps)\n\n    @torch.no_grad()\n    def sample(self,\n               S,\n               batch_size,\n               shape,\n               conditioning=None,\n               callback=None,\n               normals_sequence=None,\n               img_callback=None,\n               quantize_x0=False,\n               eta=0.,\n               mask=None,\n               x0=None,\n               temperature=1.,\n               noise_dropout=0.,\n               score_corrector=None,\n               corrector_kwargs=None,\n               verbose=True,\n               x_T=None,\n               log_every_t=100,\n               unconditional_guidance_scale=1.,\n               unconditional_conditioning=None,\n               # this has to come in the same format as the conditioning, # e.g. as encoded tokens, ...\n               **kwargs\n               ):\n        if conditioning is not None:\n            if isinstance(conditioning, dict):\n                cbs = conditioning[list(conditioning.keys())[0]].shape[0]\n                if cbs != batch_size:\n                    print(f\"Warning: Got {cbs} conditionings but batch-size is {batch_size}\")\n            else:\n                if conditioning.shape[0] != batch_size:\n                    print(f\"Warning: Got {conditioning.shape[0]} conditionings but batch-size is {batch_size}\")\n\n        self.make_schedule(ddim_num_steps=S, ddim_eta=eta, verbose=verbose)\n        # sampling\n        C, H, W = shape\n        size = (batch_size, C, H, W)\n        print(f'Data shape for DDIM sampling is {size}, eta {eta}')\n\n        samples, intermediates = self.ddim_sampling(conditioning, size,\n                                                    callback=callback,\n                                                    img_callback=img_callback,\n                                                    quantize_denoised=quantize_x0,\n                                                    mask=mask, x0=x0,\n                                                    ddim_use_original_steps=False,\n                                                    noise_dropout=noise_dropout,\n                                                    temperature=temperature,\n                                                    score_corrector=score_corrector,\n                                                    corrector_kwargs=corrector_kwargs,\n                                                    x_T=x_T,\n                                                    log_every_t=log_every_t,\n                                                    unconditional_guidance_scale=unconditional_guidance_scale,\n                                                    unconditional_conditioning=unconditional_conditioning,\n                                                    )\n        return samples, intermediates\n\n    @torch.no_grad()\n    def ddim_sampling(self, cond, shape,\n                      x_T=None, ddim_use_original_steps=False,\n                      callback=None, timesteps=None, quantize_denoised=False,\n                      mask=None, x0=None, img_callback=None, log_every_t=100,\n                      temperature=1., noise_dropout=0., score_corrector=None, corrector_kwargs=None,\n                      unconditional_guidance_scale=1., unconditional_conditioning=None,):\n        device = self.model.betas.device\n        b = shape[0]\n        if x_T is None:\n            img = torch.randn(shape, device=device)\n        else:\n            img = x_T\n\n        if timesteps is None:\n            timesteps = self.ddpm_num_timesteps if ddim_use_original_steps else self.ddim_timesteps\n        elif timesteps is not None and not ddim_use_original_steps:\n            subset_end = int(min(timesteps / self.ddim_timesteps.shape[0], 1) * self.ddim_timesteps.shape[0]) - 1\n            timesteps = self.ddim_timesteps[:subset_end]\n\n        intermediates = {'x_inter': [img], 'pred_x0': [img]}\n        time_range = reversed(range(0,timesteps)) if ddim_use_original_steps else np.flip(timesteps)\n        total_steps = timesteps if ddim_use_original_steps else timesteps.shape[0]\n        print(f\"Running DDIM Sampling with {total_steps} timesteps\")\n\n        iterator = tqdm(time_range, desc='DDIM Sampler', total=total_steps)\n\n        for i, step in enumerate(iterator):\n            index = total_steps - i - 1\n            ts = torch.full((b,), step, device=device, dtype=torch.long)\n\n            if mask is not None:\n                assert x0 is not None\n                img_orig = self.model.q_sample(x0, ts)  # TODO: deterministic forward pass?\n                img = img_orig * mask + (1. - mask) * img\n\n            outs = self.p_sample_ddim(img, cond, ts, index=index, use_original_steps=ddim_use_original_steps,\n                                      quantize_denoised=quantize_denoised, temperature=temperature,\n                                      noise_dropout=noise_dropout, score_corrector=score_corrector,\n                                      corrector_kwargs=corrector_kwargs,\n                                      unconditional_guidance_scale=unconditional_guidance_scale,\n                                      unconditional_conditioning=unconditional_conditioning)\n            img, pred_x0 = outs\n            if callback: callback(i)\n            if img_callback: img_callback(pred_x0, i)\n\n            if index % log_every_t == 0 or index == total_steps - 1:\n                intermediates['x_inter'].append(img)\n                intermediates['pred_x0'].append(pred_x0)\n\n        return img, intermediates\n\n    @torch.no_grad()\n    def p_sample_ddim(self, x, c, t, index, repeat_noise=False, use_original_steps=False, quantize_denoised=False,\n                      temperature=1., noise_dropout=0., score_corrector=None, corrector_kwargs=None,\n                      unconditional_guidance_scale=1., unconditional_conditioning=None):\n        b, *_, device = *x.shape, x.device\n\n        if unconditional_conditioning is None or unconditional_guidance_scale == 1.:\n            e_t = self.model.apply_model(x, t, c)\n        else:\n            x_in = torch.cat([x] * 2)\n            t_in = torch.cat([t] * 2)\n            c_in = torch.cat([unconditional_conditioning, c])\n            e_t_uncond, e_t = self.model.apply_model(x_in, t_in, c_in).chunk(2)\n            e_t = e_t_uncond + unconditional_guidance_scale * (e_t - e_t_uncond)\n\n        if score_corrector is not None:\n            assert self.model.parameterization == \"eps\"\n            e_t = score_corrector.modify_score(self.model, e_t, x, t, c, **corrector_kwargs)\n\n        alphas = self.model.alphas_cumprod if use_original_steps else self.ddim_alphas\n        alphas_prev = self.model.alphas_cumprod_prev if use_original_steps else self.ddim_alphas_prev\n        sqrt_one_minus_alphas = self.model.sqrt_one_minus_alphas_cumprod if use_original_steps else self.ddim_sqrt_one_minus_alphas\n        sigmas = self.model.ddim_sigmas_for_original_num_steps if use_original_steps else self.ddim_sigmas\n        # select parameters corresponding to the currently considered timestep\n        a_t = torch.full((b, 1, 1, 1), alphas[index], device=device)\n        a_prev = torch.full((b, 1, 1, 1), alphas_prev[index], device=device)\n        sigma_t = torch.full((b, 1, 1, 1), sigmas[index], device=device)\n        sqrt_one_minus_at = torch.full((b, 1, 1, 1), sqrt_one_minus_alphas[index],device=device)\n\n        # current prediction for x_0\n        pred_x0 = (x - sqrt_one_minus_at * e_t) / a_t.sqrt()\n        if quantize_denoised:\n            pred_x0, _, *_ = self.model.first_stage_model.quantize(pred_x0)\n        # direction pointing to x_t\n        dir_xt = (1. - a_prev - sigma_t**2).sqrt() * e_t\n        noise = sigma_t * noise_like(x.shape, device, repeat_noise) * temperature\n        if noise_dropout &gt; 0.:\n            noise = torch.nn.functional.dropout(noise, p=noise_dropout)\n        x_prev = a_prev.sqrt() * pred_x0 + dir_xt + noise\n        return x_prev, pred_x0\n</code></pre> <p>In DDIM (Denoising Diffusion Implicit Models), the reverse (denoising) step from \\(x_t\\) to \\(x_{t-1}\\) is given by:</p> <ol> <li>Predicting \\(x_0\\):</li> </ol> <p>$$    \\hat{x}0 = \\frac{x_t - \\sqrt{1-\\bar{\\alpha}_t}\\,\\epsilon\\theta(x_t,t)}{\\sqrt{\\bar{\\alpha}_t}},    $$</p> <p>where:    - \\(x_t\\) is the current noisy image.    - \\(\\epsilon_\\theta(x_t,t)\\) is the model\u2019s predicted noise.    - \\(\\bar{\\alpha}_t\\) is the cumulative product of the \\(\\alpha\\) values up to time \\(t\\).</p> <ol> <li>Computing the DDIM Update:</li> </ol> <p>$$    x_{t-1} = \\sqrt{\\bar{\\alpha}{t-1}}\\,\\hat{x}_0 + \\sqrt{1-\\bar{\\alpha}(0,I),    $$} - \\sigma_t^2}\\,\\epsilon_\\theta(x_t,t) + \\sigma_t\\,z,\\quad z\\sim\\mathcal{N</p> <p>where:    - \\(\\sqrt{\\bar{\\alpha}_{t-1}}\\) scales the predicted \\(x_0\\).    - \\(\\sqrt{1-\\bar{\\alpha}_{t-1} - \\sigma_t^2}\\) scales the noise prediction.    - \\(\\sigma_t\\) (controlled via the parameter \\(\\eta\\)) governs the stochasticity; if \\(\\sigma_t=0\\) (i.e. \\(\\eta=0\\)), the process is deterministic.    - \\(z\\) is standard Gaussian noise.</p> <p>The code implements this DDIM denoising process primarily in the function <code>p_sample_ddim</code>. Let\u2019s break down the correspondence:</p> <ol> <li> <p>Prediction of \\(x_0\\):</p> </li> <li> <p>Theoretical Formula:      $$      \\hat{x}0 = \\frac{x_t - \\sqrt{1-\\bar{\\alpha}_t}\\,\\epsilon\\theta(x_t,t)}{\\sqrt{\\bar{\\alpha}_t}}      $$</p> </li> <li> <p>Code:</p> <pre><code>pred_x0 = (x - sqrt_one_minus_at * e_t) / a_t.sqrt()\n</code></pre> <ul> <li>Here, <code>x</code> represents \\(x_t\\).</li> <li><code>e_t</code> is the model\u2019s noise prediction \\(\\epsilon_\\theta(x,t)\\).</li> <li><code>a_t</code> holds the value of \\(\\bar{\\alpha}_t\\) (so that <code>a_t.sqrt()</code> is \\(\\sqrt{\\bar{\\alpha}_t}\\)).</li> <li><code>sqrt_one_minus_at</code> represents \\(\\sqrt{1-\\bar{\\alpha}_t}\\).</li> </ul> </li> <li> <p>Computing the Direction Term:</p> </li> <li> <p>Theoretical Term: \\(\\sqrt{1-\\bar{\\alpha}_{t-1} - \\sigma_t^2}\\,\\epsilon_\\theta(x_t,t)\\)</p> </li> <li> <p>Code:</p> <pre><code>dir_xt = (1. - a_prev - sigma_t**2).sqrt() * e_t\n</code></pre> <ul> <li><code>a_prev</code> corresponds to \\(\\bar{\\alpha}_{t-1}\\) (so that <code>a_prev.sqrt()</code> is \\(\\sqrt{\\bar{\\alpha}_{t-1}}\\)).</li> <li><code>sigma_t</code> is the standard deviation \\(\\sigma_t\\) at time \\(t\\).</li> <li>This computes the directional component by scaling the predicted noise \\(e_t\\).</li> </ul> </li> <li> <p>Adding the Noise Term and Forming \\(x_{t-1}\\):</p> </li> <li> <p>Theoretical Formula:      $$      x_{t-1} = \\sqrt{\\bar{\\alpha}{t-1}}\\,\\hat{x}_0 + \\sqrt{1-\\bar{\\alpha}\\,\\epsilon_\\theta(x_t,t) + \\sigma_t\\,z      $$} - \\sigma_t^2</p> </li> <li> <p>Code:</p> <pre><code>noise = sigma_t * noise_like(x.shape, device, repeat_noise) * temperature\nx_prev = a_prev.sqrt() * pred_x0 + dir_xt + noise\n</code></pre> <ul> <li><code>a_prev.sqrt() * pred_x0</code> implements the \\(\\sqrt{\\bar{\\alpha}_{t-1}}\\,\\hat{x}_0\\) term.</li> <li><code>dir_xt</code> is the directional term.</li> <li>The variable <code>noise</code> represents \\(\\sigma_t\\,z\\), where <code>noise_like(...)</code> samples from a standard Gaussian distribution.</li> <li>The <code>temperature</code> parameter can further modulate the noise level.</li> </ul> </li> <li> <p>Handling Conditioning and Guidance (Optional):</p> </li> <li> <p>The code also includes conditional sampling and guidance:</p> <pre><code>if unconditional_conditioning is None or unconditional_guidance_scale == 1.:\n    e_t = self.model.apply_model(x, t, c)\nelse:\n    x_in = torch.cat([x] * 2)\n    t_in = torch.cat([t] * 2)\n    c_in = torch.cat([unconditional_conditioning, c])\n    e_t_uncond, e_t = self.model.apply_model(x_in, t_in, c_in).chunk(2)\n    e_t = e_t_uncond + unconditional_guidance_scale * (e_t - e_t_uncond)\n</code></pre> <ul> <li>This branch adjusts the noise prediction \\(e_t\\) to steer the generation process in conditional settings. Although not part of the base DDIM equations, it is a common extension for improving sample quality.</li> </ul> </li> <li> <p>DDIM Timesteps and Schedule:</p> </li> <li> <p>The function <code>make_schedule</code> precomputes the necessary parameters (such as <code>ddim_alphas</code>, <code>ddim_alphas_prev</code>, <code>ddim_sigmas</code>, etc.) based on the chosen DDIM discretization schedule.</p> </li> <li>These parameters represent the cumulative products \\(\\bar{\\alpha}_t\\) and their variants, ensuring that the updates in <code>p_sample_ddim</code> use the correct coefficients at each timestep.</li> </ol> <p>In summary</p> <ul> <li>Prediction of \\(x_0\\):   The code computes   $$   \\hat{x}0 = \\frac{x_t - \\sqrt{1-\\bar{\\alpha}_t}\\,\\epsilon\\theta(x_t,t)}{\\sqrt{\\bar{\\alpha}_t}}   $$   via</li> </ul> <pre><code>pred_x0 = (x - sqrt_one_minus_at * e_t) / a_t.sqrt()\n</code></pre> <ul> <li>Directional Component and Noise Addition:   The update for \\(x_{t-1}\\) is given by   $$   x_{t-1} = \\sqrt{\\bar{\\alpha}{t-1}}\\,\\hat{x}_0 + \\sqrt{1-\\bar{\\alpha}\\,\\epsilon_\\theta(x_t,t) + \\sigma_t\\,z,   $$   which is implemented as:} - \\sigma_t^2</li> </ul> <pre><code>dir_xt = (1. - a_prev - sigma_t**2).sqrt() * e_t\nnoise = sigma_t * noise_like(x.shape, device, repeat_noise) * temperature\nx_prev = a_prev.sqrt() * pred_x0 + dir_xt + noise\n</code></pre> <ul> <li> <p>Control of Stochasticity:   The parameter \\(\\eta\\) (used when creating <code>ddim_sigmas</code>) controls \\(\\sigma_t\\). When \\(\\eta=0\\), \\(\\sigma_t=0\\) and the process is deterministic.</p> </li> <li> <p>Additional Conditioning:   The code includes mechanisms for conditional generation and classifier-free guidance, which modify the noise prediction before performing the update.</p> </li> </ul> <p>This detailed comparison shows how the DDIM denoising process in the code mirrors the theoretical formulas, translating the mathematical update steps into practical sampling operations.</p>"},{"location":"book/chapter7_diffusion/probability_flow_ode/","title":"Understanding Probability Flow ODE: Converting SDEs into Deterministic Sampling","text":""},{"location":"book/chapter7_diffusion/probability_flow_ode/#1-introduction","title":"1. Introduction","text":"<p>Score-based generative models (SBMs) and diffusion models rely on stochastic differential equations (SDEs)  to model data distributions. However, while SDEs introduce randomness in sample trajectories, they can be converted into an equivalent ordinary differential equation (ODE)  that retains the same probability density evolution. This ODE, known as the Probability Flow ODE , enables deterministic sampling  while preserving the learned data distribution. This post will:</p> <ul> <li> <p>Explain how SDE-based models generate samples</p> </li> <li> <p>Derive Probability Flow ODE from Fokker-Planck theory</p> </li> <li> <p>Provide an intuitive understanding of why this works</p> </li> <li> <p>Give a Python implementation for deterministic sampling</p> </li> </ul>"},{"location":"book/chapter7_diffusion/probability_flow_ode/#2-what-is-an-sde-based-generative-model","title":"2. What is an SDE-Based Generative Model?","text":"<p>A stochastic differential equation (SDE)  is used to describe how data evolves over time:</p> \\[  dx = f(x, t) dt + g(t) dW \\] <p>where:</p> <ul> <li> <p>\\(f(x, t)\\) is the drift term  (deterministic evolution).</p> </li> <li> <p>\\(g(t) dW\\) is the diffusion term  (random noise from a Wiener process \\(dW\\)).</p> </li> <li> <p>\\(p_t(x)\\) is the time-dependent probability density  of \\(x_t\\). Since SDEs include random noise , different samples follow different trajectories even if they start at the same initial condition.</p> </li> </ul>"},{"location":"book/chapter7_diffusion/probability_flow_ode/#3-the-fokker-planck-equation","title":"3. The Fokker-Planck Equation","text":"<p>The Key to Probability Density EvolutionAlthough each sample follows a random trajectory , the probability density function \\(p_t(x)\\)  follows a deterministic evolution governed by the Fokker-Planck equation (FPE) : $$  \\frac{\\partial p_t(x)}{\\partial t} = -\\nabla \\cdot (f(x, t) p_t(x)) + \\frac{1}{2} g^2(t) \\nabla^2 p_t(x) $$</p> <ul> <li> <p>The first term \\(-\\nabla \\cdot (f(x, t) p_t(x))\\) describes the effect of the drift term \\(f(x, t)\\) on the probability density.</p> </li> <li> <p>The second term \\(\\frac{1}{2} g^2(t) \\nabla^2 p_t(x)\\) captures how diffusion smooths out the density over time. Even though each particle moves randomly, the overall probability distribution \\(p_t(x)\\) evolves in a deterministic  manner.</p> </li> </ul>"},{"location":"book/chapter7_diffusion/probability_flow_ode/#4-how-can-we-convert-an-sde-into-an-ode","title":"4. How Can We Convert an SDE into an ODE?","text":"<p>Since the probability density \\(p_t(x)\\) follows a deterministic  equation (FPE), there should exist a corresponding deterministic process  that moves samples in a way that preserves the same \\(p_t(x)\\).</p> <p>This motivates the idea of a Probability Flow ODE :</p> \\[  dx = v(x, t) dt \\] <p>where \\(v(x, t)\\) is a velocity field ensuring that the samples evolve according to the same probability density as the SDE, which is</p> \\[ dx = \\left[ f(x, t) - \\frac{1}{2} g^2(t) s_t(x) \\right] dt \\] <p>where \\(s_t(x) = \\nabla_x \\log p_t(x)\\) is the score function  (gradient of the log density).</p> <p>Proof: Convert SDE to Probability Flow ODE</p> <p>Using the continuity equation  from fluid mechanics, the deterministic probability flow should satisfy:</p> \\[ \\frac{\\partial p_t(x)}{\\partial t} = -\\nabla \\cdot (v(x, t) p_t(x)) \\] <p>For this to be equivalent to the Fokker-Planck equation , we set:</p> \\[ -\\nabla \\cdot (v(x, t) p_t(x)) = -\\nabla \\cdot (f(x, t) p_t(x)) + \\frac{1}{2} g^2(t) \\nabla^2 p_t(x) \\] <p>Rearranging:</p> \\[ v(x, t) p_t(x) = f(x, t) p_t(x) - \\frac{1}{2} g^2(t) \\nabla p_t(x) \\] <p>Dividing by \\(p_t(x)\\) (assuming \\(p_t(x) &gt; 0\\)):</p> \\[ v(x, t) = f(x, t) - \\frac{1}{2} g^2(t) \\frac{\\nabla p_t(x)}{p_t(x)} \\] <p>Since the score function  is:</p> \\[ s_t(x) = \\nabla_x \\log p_t(x) = \\frac{\\nabla_x p_t(x)}{p_t(x)} \\] <p>we obtain the Probability Flow ODE :</p> \\[ dx = \\left[ f(x, t) - \\frac{1}{2} g^2(t) s_t(x) \\right] dt \\] <p>Thus, we have converted the original SDE into an equivalent deterministic ODE that preserves the same probability density evolution!</p>"},{"location":"book/chapter7_diffusion/probability_flow_ode/#5-intuition-why-does-this-work","title":"5. Intuition: Why Does This Work?","text":"<ul> <li> <p>SDE  = Particles move randomly, but their overall density evolves deterministically.</p> </li> <li> <p>ODE  = Particles move deterministically in a way that ensures the density evolves the same way.</p> </li> </ul> <p>Thus, we can replace SDE sampling with Probability Flow ODE sampling  without changing the generated distribution!</p>"},{"location":"book/chapter7_diffusion/probability_flow_ode/#6-implementing-probability-flow-ode-sampling","title":"6. Implementing Probability Flow ODE Sampling","text":"<p>We can implement Probability Flow ODE sampling using an ODE solver  like <code>torchdiffeq.odeint</code>:</p> <pre><code>import torch\nfrom torchdiffeq import odeint\n\ndef probability_flow_ode(x, t, score_model):\n    score = score_model(x, t)  # Compute score function s_t(x)\n    drift = f(x, t) - 0.5 * g(t)**2 * score\n    return drift\n\n# Solve the ODE to generate samples\nx_generated = odeint(probability_flow_ode, x_init, t_space)\n</code></pre> <ul> <li>Key difference from SDE sampling :</li> <li> <p>No randomness \u2192 Every run gives identical outputs.</p> </li> <li> <p>Faster sampling \u2192 Fewer steps needed than stochastic diffusion.</p> </li> </ul>"},{"location":"book/chapter7_diffusion/probability_flow_ode/#7-existence-condition-and-uniqueness-condition","title":"7. Existence Condition and Uniqueness Condition","text":"<p>Existence Conditions</p> <p>For \\(v(x, t)\\) to exist , the following conditions must hold:</p> Condition Explanation \\(p_t(x)\\) is continuously differentiable (\\(p_t(x) \\in C^1\\)) Ensures that \\(\\nabla_x p_t(x)\\) and \\(\\nabla_x \\log p_t(x)\\) are well-defined. \\(p_t(x) &gt; 0\\) for all \\(x\\) Avoids division by zero in the score function \\(s_t(x) = \\nabla_x \\log p_t(x)\\). Drift term \\(f(x, t)\\) is well-defined Ensures the continuity equation has a meaningful solution. \\(p_t(x)\\) evolves deterministically under Fokker-Planck equation The probability density function should not be singular. \\(g(t) &gt; 0\\) (Non-degenerate diffusion) If \\(g(t) = 0\\), then the SDE is already deterministic and trivially satisfies an ODE. <p>Uniqueness Conditions</p> Condition Explanation \\(p_t(x)\\) is log-concave (\\(\\nabla^2 \\log p_t(x) \\preceq 0\\)) Ensures the score function \\(s_t(x) = \\nabla_x \\log p_t(x)\\) is unique and stable. No divergence-free component in \\(v(x, t)\\) If an alternative field \\(v'(x,t)=v(x,t)+v_{div-free}\u200b(x,t)\\) exists, \\(v(x, t)\\) is not unique. \\(p_t(x)\\) is strictly positive and smooth Avoids singularities and undefined score function regions. Drift term \\(f(x, t)\\) is uniquely defined Ensures a single solution to the continuity equation."},{"location":"book/chapter7_diffusion/probability_flow_ode/#8-experiment","title":"8. Experiment","text":""},{"location":"book/chapter7_diffusion/probability_flow_ode/#81-target-distribution","title":"8.1 Target Distribution","text":"<p>The Funnel distribution is defined as follows:</p> <ul> <li>\\( v \\sim \\mathcal{N}(0, 3^2) \\)</li> <li>\\( x \\mid v \\sim \\mathcal{N}\\bigl(0, \\exp(v)\\bigr) \\)</li> </ul> <p>Thus, the joint density is given by:</p> \\[ p(x,v) = \\frac{1}{3\\sqrt{2\\pi}} \\exp\\left(-\\frac{v^2}{18}\\right) \\cdot \\frac{1}{\\sqrt{2\\pi\\,\\exp(v)}} \\exp\\left(-\\frac{x^2}{2\\exp(v)}\\right) \\] <p></p> <pre><code>import torch\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.datasets import make_swiss_roll\ndef sample_funnel_data(num_samples=10000):\n    \"\"\"\n    \u4ece\u7b80\u5316 2D funnel \u5206\u5e03\u4e2d\u91c7\u6837:\n    z ~ N(0, 1)\n    x ~ N(0, exp(z))\n    \u8fd4\u56de shape: (num_samples, 2)\n    \"\"\"\n    z = torch.randn(num_samples)*0.8\n    x = torch.randn(num_samples) * torch.exp(z )/5  # exp(z/2) \u7684\u65b9\u5dee = exp(z)\n    data = torch.stack([x,z], dim=1)  # shape [num_samples, 2]\n    return data\n</code></pre>"},{"location":"book/chapter7_diffusion/probability_flow_ode/#82-sampling-formula","title":"8.2 sampling formula","text":"<p>Below are the expressions for the original distribution, the Langevin (diffusion) process, the DDPM reverse diffusion SDE, and the corresponding probability flow ODE for DDPM sampling.</p>"},{"location":"book/chapter7_diffusion/probability_flow_ode/#821-langevin-diffusion-expression","title":"8.2.1 Langevin Diffusion Expression","text":"<p>In overdamped Langevin dynamics, the update rule for a state \\( z = (x,v) \\) is:</p> \\[ z_{t+1} = z_t + \\epsilon\\,\\nabla_z \\log p(z_t) + \\sqrt{2\\epsilon}\\,\\xi_t,\\quad \\xi_t \\sim \\mathcal{N}(0, I) \\] <p>This iterative update gradually moves samples toward the target distribution \\( p(x,v) \\).</p>"},{"location":"book/chapter7_diffusion/probability_flow_ode/#822-ddpm-reverse-diffusion-sde","title":"8.2.2 DDPM Reverse Diffusion SDE","text":"<p>For a variance-preserving (VP) forward SDE defined as</p> \\[ dx = -\\frac{1}{2}\\beta(t)x\\,dt + \\sqrt{\\beta(t)}\\,dW_t, \\] <p>the reverse-time SDE used for sampling (starting from pure Gaussian noise at \\( t=1 \\)) is:</p> \\[ dx = \\left[-\\frac{1}{2}\\beta(t)x - \\beta(t)\\nabla_x\\log p_t(x)\\right]\\,dt + \\sqrt{\\beta(t)}\\,d\\bar{W}_t. \\] <p>Here, \\( \\nabla_x\\log p_t(x) \\) is the score function at time \\( t \\).</p>"},{"location":"book/chapter7_diffusion/probability_flow_ode/#823-ddpm-probability-flow-ode","title":"8.2.3 DDPM Probability Flow ODE","text":"<p>The deterministic probability flow ODE corresponding to the DDPM SDE is given by:</p> \\[ dx = \\left[-\\frac{1}{2}\\beta(t)x - \\frac{1}{2}\\beta(t)\\nabla_x\\log p_t(x)\\right]\\,dt. \\] <p>Solving this ODE from \\( t=1 \\) (Gaussian noise) to \\( t=0 \\) yields samples that follow the target distribution.</p> <p>These expressions form the basis for diffusion-based generative modeling\u2014from the formulation of the target distribution to sampling via both stochastic reverse diffusion and its deterministic ODE counterpart.</p>"},{"location":"book/chapter7_diffusion/probability_flow_ode/#83-results-on-different-sampling-methods","title":"8.3 Results on different sampling methods","text":""},{"location":"book/chapter7_diffusion/probability_flow_ode/#831-vp-sde","title":"8.3.1 VP-SDE","text":""},{"location":"book/chapter7_diffusion/probability_flow_ode/#8311-sampling-annimation","title":"8.3.1.1 Sampling Annimation","text":"Langervin Dynamic VP-SDE VP-SDE FLow ODE DDPM"},{"location":"book/chapter7_diffusion/probability_flow_ode/#8312-codes","title":"8.3.1.2 Codes","text":"ddpmVP-SDE trainingVP-SDE samplingVP-SDE FLOW ODE samplingLangervin Dynamic samplingmake annimation ddpm training and sampling<pre><code>import torch\nimport torch.nn as nn\nclass DiffusionBlock(nn.Module):\n    def **init**(self, nunits):\n        super(DiffusionBlock, self).**init**()\n        self.linear = nn.Linear(nunits, nunits)\n    def forward(self, x: torch.Tensor):\n        x = self.linear(x)\n        x = nn.functional.relu(x)\n        return x\nclass DiffusionModel(nn.Module):\n    def **init**(self, nfeatures: int, nblocks: int = 2, nunits: int = 64):\n        super(DiffusionModel, self).**init**()\n        self.inblock = nn.Linear(nfeatures+1, nunits)\n        self.midblocks = nn.ModuleList([DiffusionBlock(nunits) for _ in range(nblocks)])\n        self.outblock = nn.Linear(nunits, nfeatures)\n    def forward(self, x: torch.Tensor, t: torch.Tensor) -&gt; torch.Tensor:\n        val = torch.hstack([x, t])  # Add t to inputs\n        val = self.inblock(val)\n        for midblock in self.midblocks:\n            val = midblock(val)\n        val = self.outblock(val)\n        return val\nmodel = DiffusionModel(nfeatures=2, nblocks=4)\ndevice = \"cuda\"\nmodel = model.to(device)\nimport torch.optim as optim\nnepochs = 100\nbatch_size = 2048\nloss_fn = nn.MSELoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\nscheduler = optim.lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=0.01, total_iters=nepochs)\nfor epoch in range(nepochs):\n    epoch_loss = steps = 0\n    for i in range(0, len(X), batch_size):\n        Xbatch = X[i:i+batch_size]\n        timesteps = torch.randint(0, diffusion_steps, size=[len(Xbatch), 1])\n        noised, eps = noise(Xbatch, timesteps)\n        predicted_noise = model(noised.to(device), timesteps.to(device))\n        loss = loss_fn(predicted_noise, eps.to(device))\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        epoch_loss += loss\n        steps += 1\n    print(f\"Epoch {epoch} loss = {epoch_loss / steps}\")\ndef sample_ddpm(model, nsamples, nfeatures):\n    \"\"\"Sampler following the Denoising Diffusion Probabilistic Models method by Ho et al (Algorithm 2)\"\"\"\n    with torch.no_grad():\n        x = torch.randn(size=(nsamples, nfeatures)).to(device)\n        xt = [x]\n        for t in range(diffusion_steps-1, 0, -1):\n            predicted_noise = model(x, torch.full([nsamples, 1], t).to(device))\n            # See DDPM paper between equations 11 and 12\n            x = 1 / (alphas[t] ** 0.5) * (x - (1 - alphas[t]) / ((1-baralphas[t]) ** 0.5) * predicted_noise)\n            if t &gt; 1:\n                # See DDPM paper section 3.2.\n                # Choosing the variance through beta_t is optimal for x_0 a normal distribution\n                variance = betas[t]\n                std = variance ** (0.5)\n                x += std * torch.randn(size=(nsamples, nfeatures)).to(device)\n            xt += [x]\n        return x, xt\n</code></pre> VP-SDE training<pre><code>import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\n# Function to generate funnel data\ndef sample_funnel_data(num_samples=10000):\n    z = torch.randn(num_samples) * 0.8\n    x = torch.randn(num_samples) * torch.exp(z) / 5\n    return torch.stack([x, z], dim=1)\nclass ScoreModel(nn.Module):\n    def __init__(self, hidden_dims=[128, 256, 128], embed_dim=64):\n        super().__init__()\n        # \u65f6\u95f4\u5d4c\u5165\u5c42\n        self.embed = nn.Sequential(\n            nn.Linear(1, embed_dim),\n            nn.SiLU(),\n            nn.Linear(embed_dim, embed_dim)\n        )\n        # \u4e3b\u5e72\u7f51\u7edc\n        self.net = nn.ModuleList()\n        input_dim = 2  # \u8f93\u5165\u7ef4\u5ea6\n        for h_dim in hidden_dims:\n            self.net.append(nn.Sequential(\n                nn.Linear(input_dim + embed_dim, h_dim),\n                nn.SiLU()))\n            input_dim = h_dim\n        self.out = nn.Linear(input_dim, 2)  # \u8f93\u51fa\u566a\u58f0\u9884\u6d4b\n\n    def forward(self, x, t):\n        t_embed = self.embed(t)\n        for layer in self.net:\n            x = layer(torch.cat([x, t_embed], dim=1))\n        return self.out(x)\n# \u8bad\u7ec3\u53c2\u6570\nbeta_min, beta_max = 0.1, 20.0\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n# device ='cpu'\nmodel = ScoreModel().to(device)\noptimizer = optim.Adam(model.parameters(), lr=3e-4)\n# \u51c6\u5907\u6570\u636e\ndata = sample_funnel_data(100000)\ndataset = TensorDataset(data)\ndataloader = DataLoader(dataset, batch_size=512, shuffle=True)\nfrom tqdm import tqdm\n# \u8bad\u7ec3\u5faa\u73af\nfor epoch in tqdm(range(200)):\n    total_loss = 0.0\n    for batch, in dataloader:\n        x0 = batch.to(device)\n        batch_size = x0.size(0)\n        # \u91c7\u6837\u65f6\u95f4\u548c\u566a\u58f0\n        t = torch.rand(batch_size, 1, device=device)\n        epsilon = torch.randn_like(x0, device=device)\n        # \u8ba1\u7b97 \u03b1(t) \u548c \u03c3(t)\n        integral = beta_min * t + 0.5 * (beta_max - beta_min) * t**2\n        alpha = torch.exp(-integral)\n        sigma = torch.sqrt(1.0 - alpha)\n        # \u6270\u52a8\u6570\u636e\n        x_t = torch.sqrt(alpha) * x0 + torch.sqrt(1.0 - alpha) * epsilon\n        # \u9884\u6d4b\u566a\u58f0\n        score_pred = model(x_t, t)\n        # \u8ba1\u7b97\u52a0\u6743\u635f\u5931\n        # beta_t = beta_min + (beta_max - beta_min) * t\n        # print((1-alpha))\n        loss = torch.mean( (score_pred - epsilon)**2) # predict is the score\n        # \u53cd\u5411\u4f20\u64ad\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item() * batch_size\n    if (epoch+1) % 20 == 0:\n        print(f\"Epoch {epoch+1}, Loss: {total_loss/len(data):.5f}\")\n</code></pre> VP SDE sampling<pre><code>import torch\nimport numpy as np\nimport math\nimport matplotlib.pyplot as plt\ndef vp_sde_sample(model,x_T, timesteps, beta_min=0.1, beta_max=20.0, save_trajectory=True):\n    \"\"\"\n    Implements the reverse sampling process for VP-SDE using Euler-Maruyama method.\n    Args:\n        x_T: Final noisy sample (torch.Tensor) of shape (N, D)\n        timesteps: Number of diffusion steps (int)\n        beta_min: Minimum beta value (float)\n        beta_max: Maximum beta value (float)\n        save_trajectory: Whether to save and return the sampling trajectory (bool)\n    Returns:\n        x_0: Recovered data sample (torch.Tensor)\n        trajectory: List of intermediate states (if save_trajectory=True)\n    \"\"\"\n    dt = 1.0 / timesteps  # Time step for numerical integration\n    x_t = x_T.clone()\n    trajectory = [x_t.clone().cpu().numpy()] if save_trajectory else None\n    model  = model.eval()\n    for t_index in reversed(range(1,timesteps)):\n        t = t_index * dt\n        print(\"t\",t, end=\"\\r\")\n        # \u8ba1\u7b97 \u03b1(t) \u548c \u03c3(t)\n        integral = beta_min * t + 0.5 * (beta_max - beta_min) * t**2\n        integral = torch.Tensor([integral])\n        alpha = torch.exp(-integral)\n        beta_t = beta_min +  (beta_max - beta_min) * t\n        beta_t = torch.Tensor([beta_t])\n        with torch.no_grad():\n            t_input = torch.Tensor([t]*len(x_t)).to(device).unsqueeze(-1)\n            # print('x_t',x_t.shape, t_input.shape)\n            noise_pred = model(x_t.to(device),t_input)\n            if  not torch.isfinite(noise_pred).all():\n                print('score_function got nan',score_function,t_index)\n                raise\n            score_function = - noise_pred.cpu() / torch.sqrt(1-alpha)\n        s_theta  = score_function.cpu()\n        # Reverse SDE Euler-Maruyama step\n        x_t = x_t +1/2 * beta_t *( x_t +2* s_theta)* dt # dritf term\n        x_t += torch.sqrt(beta_t) * torch.randn_like(x_t) * math.sqrt(dt) # diffusion term\n        if  not torch.isfinite(x_t).all():\n            print(\"xt got infinite\", t_index, x_t[:2],torch.sqrt(1-alpha))\n        if save_trajectory:\n            trajectory.append(x_t.clone().cpu().numpy())\n    return x_t, trajectory if save_trajectory else None\n# Set parameters\ntimesteps = 1500\nnum_samples = 20000\ndim = 2  # 2D distribution for visualization\nx_T = torch.randn(num_samples, dim)  # Sample from Gaussian prior (standard normal)\n# Perform VP-SDE sampling\nx_0, trajectory = vp_sde_sample(model, x_T, timesteps)\n# Convert trajectory to numpy for plotting\ntrajectory_np = np.array(trajectory)  # Shape: (timesteps, num_samples, dim)\n# Plot final distribution shape\nplt.figure(figsize=(6, 6))\nplt.scatter(x_0[:, 0].numpy(), x_0[:, 1].numpy(), alpha=0.5, s=10)\nplt.title(\"Final Sampled Distribution from VP-SDE\")\nplt.xlabel(\"X-axis\")\nplt.ylabel(\"Y-axis\")\nplt.axis(\"equal\")\nplt.show()\n</code></pre> VP-SDE FLOW ODE sampling<pre><code>import torch\nimport numpy as np\nimport math\nimport matplotlib.pyplot as plt\ndef vp_ode_sample(model,x_T, timesteps, beta_min=0.1, beta_max=20.0, save_trajectory=True):\n    \"\"\"\n    Implements the reverse sampling process for VP-SDE using Euler-Maruyama method.\n    Args:\n        x_T: Final noisy sample (torch.Tensor) of shape (N, D)\n        timesteps: Number of diffusion steps (int)\n        beta_min: Minimum beta value (float)\n        beta_max: Maximum beta value (float)\n        save_trajectory: Whether to save and return the sampling trajectory (bool)\n    Returns:\n        x_0: Recovered data sample (torch.Tensor)\n        trajectory: List of intermediate states (if save_trajectory=True)\n    \"\"\"\n    dt = 1.0 / timesteps  # Time step for numerical integration\n    x_t = x_T.clone()\n    trajectory = [x_t.clone().cpu().numpy()] if save_trajectory else None\n    model  = model.eval()\n    for t_index in reversed(range(1,timesteps)):\n        t = t_index *dt\n        print(\"t\",t, end=\"\\r\")\n        # \u8ba1\u7b97 \u03b1(t) \u548c \u03c3(t)\n        integral = beta_min* t + 0.5 *(beta_max - beta_min)* t**2\n        integral = torch.Tensor([integral])\n        alpha = torch.exp(-integral)\n        beta_t = beta_min +  (beta_max - beta_min) *t\n        beta_t = torch.Tensor([beta_t])\n        with torch.no_grad():\n            t_input = torch.Tensor([t]*len(x_t)).to(device).unsqueeze(-1)\n            # print('x_t',x_t.shape, t_input.shape)\n            noise_pred = model(x_t.to(device),t_input)\n            if  not torch.isfinite(noise_pred).all():\n                print('score_function got nan',score_function,t_index)\n                raise\n            score_function = - noise_pred.cpu() / torch.sqrt(1-alpha)\n        s_theta  = score_function.cpu()\n        # Reverse SDE Euler-Maruyama step\n        # x_t = x_t +1/2 * beta_t *( x_t +2* s_theta)* dt # dritf term\n        # x_t += torch.sqrt(beta_t)* torch.randn_like(x_t) *math.sqrt(dt) # diffusion term\n        x_t = x_t +1/2* beta_t *( x_t + s_theta)* dt\n        if  not torch.isfinite(x_t).all():\n            print(\"xt got infinite\", t_index, x_t[:2],torch.sqrt(1-alpha))\n        if save_trajectory:\n            trajectory.append(x_t.clone().cpu().numpy())\n    return x_t, trajectory if save_trajectory else None\n# Set parameters\ntimesteps = 1500\nnum_samples = 20000\ndim = 2  # 2D distribution for visualization\nx_T = torch.randn(num_samples, dim)  # Sample from Gaussian prior (standard normal)\n# Perform VP-SDE sampling\nx_0, trajectory = vp_ode_sample(model, x_T, timesteps)\n# Convert trajectory to numpy for plotting\ntrajectory_np = np.array(trajectory)  # Shape: (timesteps, num_samples, dim)\n# Plot final distribution shape\nplt.figure(figsize=(6, 6))\nplt.scatter(x_0[:, 0].numpy(), x_0[:, 1].numpy(), alpha=0.5, s=10)\nplt.title(\"Final Sampled Distribution from VP-SDE\")\nplt.xlabel(\"X-axis\")\nplt.ylabel(\"Y-axis\")\nplt.axis(\"equal\")\nplt.show()\n</code></pre> Langervin Dynamic sampling<pre><code>    import torch\n    import matplotlib.pyplot as plt\n    def funnel_score(x, z):\n        \"\"\"Compute the score function (gradient of log-density) of the funnel distribution.\"\"\"\n        score_x = -x / torch.exp(z)\n        score_z = -z + 0.5 * x**2 * torch.exp(-z)\n        return torch.stack([score_x, score_z], dim=1)\n    def langevin_sampling_funnel(num_samples=10000, lr=0.001, num_steps=1500, noise_scale=0.001):\n        \"\"\"Sample from the funnel distribution using Langevin dynamics.\"\"\"\n        # Initialize samples from a normal distribution\n        samples = torch.randn(num_samples, 2)\n        trajectory = [samples.clone()]  # Store trajectory\n        for _ in range(num_steps):\n            x, z = samples[:, 0], samples[:, 1]\n            score = funnel_score(x, z)\n            samples = samples + lr * score + math.sqrt(2*noise_scale) * torch.randn_like(samples)\n            trajectory.append(samples.clone())  # Store trajectory step\n        return samples, trajectory\n    # Sample using Langevin dynamics\n    samples, trajectory = langevin_sampling_funnel()\n    # Convert trajectory to numpy for visualization\n    trajectory_np = [step.numpy() for step in trajectory]\n    # Plot final distribution\n    plt.figure(figsize=(6, 6))\n    plt.scatter(samples[:, 0], samples[:, 1], alpha=0.5, s=0.1)\n    plt.title(\"Final Sampled Distribution from VP-SDE\")\n    plt.xlabel(\"X-axis\")\n    plt.ylabel(\"Y-axis\")\n    plt.axis(\"equal\")\n    plt.show()\n</code></pre> <pre><code>from matplotlib.animation import FuncAnimation, PillowWriter\ndef make_animation(trajectory, filename=\"sampling.gif\"):\n    \"\"\"\n    Given a list of [N x 2] arrays (trajectory), create and save an animation.\n    \"\"\"\n    trajectory = [x.cpu() for x in trajectory]\n    fig, ax = plt.subplots(figsize=(5, 5))\n    scat = ax.scatter(trajectory[0][:, 0], trajectory[0][:, 1], alpha=0.5, color='red',s=0.2)\n    ax.set_xlim(-6, 6)\n    ax.set_ylim(-6, 6)\n    ax.axis(\"off\")\n    ax.set_aspect('equal')\n    time_text = ax.text(0.02, 0.02, '', transform=ax.transAxes, fontsize=12)\n    def update(frame):\n        data = trajectory[frame]\n        scat.set_offsets(data)\n        time_text.set_text(f\"Step {frame}/{len(trajectory)-1}\")\n        return scat, time_text\n    ani = FuncAnimation(fig, update, frames=len(trajectory), interval=1)\n    writer = PillowWriter(fps=40)\n    ani.save(filename, writer=writer)\n    plt.close()\n...\nmake_animation(trajectory_np, filename=img_file)\n</code></pre>"},{"location":"book/chapter7_diffusion/probability_flow_ode/#832-ve-sde","title":"8.3.2 VE-SDE","text":"<p>Let's experiment with VE-SDE. First, just recall the formulas to understand the dynamics:</p> <ul> <li>Forward Process (SDE)</li> </ul> \\[ dx = \\sqrt{\\frac{d[\\sigma^2(t)]}{dt}} dw \\] <ul> <li>Noise Schedule</li> </ul> \\[ \\sigma_t = \\sigma_{\\text{min}} \\left(\\frac{\\sigma_{\\text{max}}}{\\sigma_{\\text{min}}} \\right)^t \\] <ul> <li>Sampling from Noisy Distribution</li> </ul> \\[ x_t = x_0 + \\sigma_t \\epsilon, \\quad \\epsilon \\sim \\mathcal{N}(0, I) \\] <ul> <li>Reverse Process (SDE)</li> </ul> \\[ dx = - \\left(\\frac{d[\\sigma^2(t)]}{dt} \\right) \\nabla_x \\log p_t(x) dt + \\sqrt{\\frac{d[\\sigma^2(t)]}{dt}} dw \\] <ul> <li>derivateve of \\(\\sigma(t)\\)</li> </ul> \\[ \\frac{d \\sigma^2(t)}{dt} = \\sigma_{\\text{min}}^2 \\left(\\frac{\\sigma_{\\text{max}}^2}{\\sigma_{\\text{min}}^2} \\right)^t \\log \\left(\\frac{\\sigma_{\\text{max}}^2}{\\sigma_{\\text{min}}^2} \\right) \\] <ul> <li>Flow ODE (Deterministic Approximation)</li> </ul> \\[ dx = -\\frac{1}{2}\\left(\\frac{d[\\sigma^2(t)]}{dt} \\right) \\nabla_x \\log p_t(x) dt \\] <ul> <li>Reverse Sampling</li> </ul> \\[ x_{t-1} = x_t + \\left(\\frac{d[\\sigma^2(t)]}{dt} \\right) s_{\\theta}(x, t) dt \\] <ul> <li>Score Function</li> </ul> \\[ s_{\\theta}(x, t) = -\\frac{\\epsilon}{\\sigma_t} \\] <ul> <li>Loss Function (Score Matching)</li> </ul> \\[ \\mathbb{E}_{t, x_0, \\epsilon} \\left[ \\lambda_t \\left\\| s_{\\theta}(x_t, t) + \\frac{\\epsilon}{\\sigma_t} \\right\\|^2 \\right] \\]"},{"location":"book/chapter7_diffusion/probability_flow_ode/#8321-sampling-results","title":"8.3.2.1 Sampling Results","text":"<p>docs/images/ve_ode.gif</p> ve-sde ve-sde flow ODE DP-SDE flow ODE DDPM"},{"location":"book/chapter7_diffusion/probability_flow_ode/#9-conclusion","title":"9. Conclusion","text":"<ul> <li> <p>Every SDE can be converted into a Probability Flow ODE.</p> </li> <li> <p>The deterministic ODE preserves the same probability density as the SDE.</p> </li> <li> <p>Probability Flow ODE allows for efficient, repeatable sampling.</p> </li> <li> <p>ODE solvers can be used instead of SDE solvers for generative modeling. By leveraging Probability Flow ODE, we gain a powerful tool for deterministic yet efficient sampling in deep generative models . \ud83d\ude80</p> </li> </ul>"},{"location":"book/chapter7_diffusion/probability_flow_ode/#10-further-reading","title":"10. Further Reading","text":"<ul> <li> <p>Song et al., \"Score-Based Generative Modeling through Stochastic Differential Equations,\" NeurIPS 2021</p> </li> <li> <p>Chen et al., \"Neural ODEs,\" NeurIPS 2018</p> </li> <li> <p>Fluid mechanics: Continuity equation and probability flow</p> </li> <li> <p>\"The Probability Flow ODE is Provably Fast\" Authors: Sitan Chen, Sinho Chewi, Holden Lee, Yuanzhi Li, Jianfeng Lu, Adil Salim Summary: This paper provides the first polynomial-time convergence guarantees for the probability flow ODE implementation in score-based generative modeling. The authors develop novel techniques to study deterministic dynamics without contractivity. Link: arXiv:2305.11798</p> </li> <li> <p>\"Convergence Analysis of Probability Flow ODE for Score-based Generative Models\" Authors: Daniel Zhengyu Huang, Jiaoyang Huang, Zhengjiang Lin Summary: This work studies the convergence properties of deterministic samplers based on probability flow ODEs, providing theoretical bounds on the total variation between the target and generated distributions. Link: arXiv:2404.09730 2. Practical Implementations and Tutorials:</p> </li> <li> <p>\"On the Probability Flow ODE of Langevin Dynamics\" Author: Mingxuan Yi Summary: This blog post offers a numerical approach using PyTorch to simulate the probability flow ODE of Langevin dynamics, providing insights into practical implementation. Link: Mingxuan Yi's Blog</p> </li> <li> <p>\"Generative Modeling by Estimating Gradients of the Data Distribution\" Author: Yang Song Summary: This post discusses learning score functions (gradients of log probability density functions) on noise-perturbed data distributions and generating samples with Langevin-type sampling. Link: Yang Song's Blog 3. Advanced Topics and Related Methods:</p> </li> <li> <p>\"An Introduction to Flow Matching\" Authors: Cambridge Machine Learning Group Summary: This blog post introduces Flow Matching, a generative modeling paradigm combining aspects from Continuous Normalizing Flows and Diffusion Models, offering a unique perspective on generative modeling. Link: Cambridge MLG Blog</p> </li> <li> <p>\"Flow Matching: Matching Flows Instead of Scores\" Author: Jakub M. Tomczak Summary: This article presents a different perspective on generative models with ODEs, discussing Continuous Normalizing Flows and Probability Flow ODEs. Link: Jakub M. Tomczak's Blog</p> </li> </ul>"},{"location":"book/chapter7_diffusion/score_based_sde/","title":"Score-Based SDEs","text":""},{"location":"book/chapter7_diffusion/score_based_sde/#1-introduction","title":"1. Introduction","text":"<p>Score-based Stochastic Differential Equations (SDEs) provide a continuous-time framework for diffusion models. They define a forward diffusion process (adding noise) and a reverse process (denoising) using score functions.</p> <p>In this guide, we will:</p> <ul> <li>Explain different SDE designs including VPSDE, VESDE, and Sub-VPSDE.</li> <li>Show how to construct \\( x_t \\) given \\( x_0 \\).</li> <li>Derive conditional SDE score functions.</li> <li>Implement training, reverse sampling, and probability flow ODE sampling.</li> </ul>"},{"location":"book/chapter7_diffusion/score_based_sde/#2-forward-process-adding-noise","title":"2. Forward Process (Adding Noise)","text":"<p>In Score-based SDEs, the forward process gradually adds noise to data:</p> \\[ dx = f(x, t) dt + g(t) dw \\] <p>where:</p> <ul> <li>\\( f(x, t) \\) is the drift term (controls decay).</li> <li>\\( g(t) \\) is the diffusion term (controls noise strength).</li> <li>\\( dw \\) is the Wiener process (random noise).</li> </ul> <p>At time \\( t \\), the noisy version of \\( x_0 \\) is denoted as \\( x_t \\).</p>"},{"location":"book/chapter7_diffusion/score_based_sde/#3-constructing-x_t-from-x_0","title":"3. Constructing \\( x_t \\) from \\( x_0 \\)","text":"<p>For any SDE, we can write the transition distribution \\( p_t(x_t | x_0) \\) as:</p> \\[ p_t(x_t | x_0) = \\mathcal{N}(\\mu_t(x_0), \\Sigma_t) \\] <p>where:</p> <ul> <li>\\( \\mu_t(x_0) \\) is the mean (drifted input).</li> <li>\\( \\Sigma_t \\) is the variance (accumulated noise).</li> </ul>"},{"location":"book/chapter7_diffusion/score_based_sde/#31-vpsde-variance-preserving-sde","title":"3.1 VPSDE (Variance Preserving SDE)","text":"\\[ dx = -\\frac{1}{2} \\beta(t) x dt + \\sqrt{\\beta(t)} dw \\] <p>Solution:</p> \\[ x_t = x_0 e^{-\\frac{1}{2} \\int_0^t \\beta(s) ds} + \\sqrt{1 - e^{-\\int_0^t \\beta(s) ds}} \\epsilon, \\quad \\epsilon \\sim \\mathcal{N}(0, I) \\]"},{"location":"book/chapter7_diffusion/score_based_sde/#32-vesde-variance-exploding-sde","title":"3.2 VESDE (Variance Exploding SDE)","text":"\\[ dx = \\sigma(t) dw \\] <p>Solution:</p> \\[ x_t = x_0 + \\sqrt{\\int_0^t \\sigma^2(s) ds} \\epsilon, \\quad \\epsilon \\sim \\mathcal{N}(0, I) \\]"},{"location":"book/chapter7_diffusion/score_based_sde/#33-sub-vpsde","title":"3.3 Sub-VPSDE","text":"<p>Sub-VPSDE is a modification of VPSDE that controls the noise level more finely:</p> \\[ dx = -\\frac{1}{2} \\beta(t) x dt + \\sqrt{\\beta(t) (1 - e^{-2 \\int_0^t \\beta(s) ds})} dw \\] <p>Solution:</p> \\[ x_t = x_0 e^{-\\frac{1}{2} \\int_0^t \\beta(s) ds} + \\sqrt{(1 - e^{-\\int_0^t \\beta(s) ds})} \\epsilon, \\quad \\epsilon \\sim \\mathcal{N}(0, I) \\] <ul> <li>This keeps the noise level lower than VPSDE, helping preserve some structure in the data.</li> </ul>"},{"location":"book/chapter7_diffusion/score_based_sde/#4-conditional-score-function","title":"4. Conditional Score Function","text":"<p>The score function is:</p> \\[ \\nabla_x \\log p_t(x_t | x_0) = -\\Sigma_t^{-1} (x_t - \\mu_t(x_0)) \\]"},{"location":"book/chapter7_diffusion/score_based_sde/#41-for-vpsde","title":"4.1 For VPSDE:","text":"\\[ \\nabla_x \\log p_t(x_t | x_0) = -\\frac{x_t - x_0 e^{-\\frac{1}{2} \\int_0^t \\beta(s) ds}}{(1 - e^{-\\int_0^t \\beta(s) ds})} \\]"},{"location":"book/chapter7_diffusion/score_based_sde/#42-for-vesde","title":"4.2 For VESDE:","text":"\\[ \\nabla_x \\log p_t(x_t | x_0) = -\\frac{x_t - x_0}{\\int_0^t \\sigma^2(s) ds} \\]"},{"location":"book/chapter7_diffusion/score_based_sde/#43-for-sub-vpsde","title":"4.3 For Sub-VPSDE:","text":"\\[ \\nabla_x \\log p_t(x_t | x_0) = -\\frac{x_t - x_0 e^{-\\frac{1}{2} \\int_0^t \\beta(s) ds}}{(1 - e^{-\\int_0^t \\beta(s) ds})} \\] <ul> <li>The score function is similar to VPSDE but adapted to Sub-VPSDE's noise control.</li> </ul>"},{"location":"book/chapter7_diffusion/score_based_sde/#5-training-loss-score-matching","title":"5. Training Loss (Score Matching)","text":"<p>We train a score network \\( s_\\theta(x, t) \\) to approximate the true score function:</p> \\[ s_\\theta(x, t) \\approx \\nabla_x \\log p_t(x) \\] <p>The training loss is:</p> \\[ \\mathcal{L}(\\theta) = \\mathbb{E}_{t, x_0, \\epsilon} \\left[ \\lambda(t) \\| s_\\theta(x_t, t) - \\nabla_x \\log p_t(x_t | x_0) \\|^2 \\right] \\] <p>where \\( \\lambda(t) \\) is a weighting function.</p>"},{"location":"book/chapter7_diffusion/score_based_sde/#51-code-for-constructing-x_t-and-training","title":"5.1 Code for Constructing \\( x_t \\) and Training","text":"<pre><code>import torch\nimport torch.nn as nn\nimport torch.optim as optim\n\n# Define the score network\nclass ScoreNetwork(nn.Module):\n    def __init__(self, input_dim):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(input_dim, 128), nn.ReLU(),\n            nn.Linear(128, 128), nn.ReLU(),\n            nn.Linear(128, input_dim)\n        )\n\n    def forward(self, x, t):\n        return self.net(x)\n\n# Construct x_t for Sub-VPSDE\ndef sample_xt_sub_vpsde(x0, t):\n    beta_int = torch.exp(-0.5 * beta_t(t))\n    noise = torch.randn_like(x0)\n    return beta_int * x0 + torch.sqrt((1 - beta_int**2)) * noise, noise\n\n# Define loss function\ndef score_matching_loss(model, x0):\n    t = torch.rand((x0.shape[0], 1))  # Random time\n    xt, noise = sample_xt_sub_vpsde(x0, t)\n    score = model(xt, t)\n    return ((score + noise)**2).mean()\n\n# Training loop\nmodel = ScoreNetwork(input_dim=2)\noptimizer = optim.Adam(model.parameters(), lr=1e-3)\n\nfor step in range(10000):\n    x0 = torch.randn((128, 2))  # Sample data\n    loss = score_matching_loss(model, x0)\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n    if step % 1000 == 0:\n        print(f\"Step {step}, Loss: {loss.item()}\")\n</code></pre>"},{"location":"book/chapter7_diffusion/score_based_sde/#6-reverse-sampling","title":"6. Reverse Sampling","text":"<p>Once trained, we use reverse SDE:</p> \\[ dx = \\left[f(x, t) - g(t)^2 s_\\theta(x, t) \\right] dt + g(t) d\\bar{w} \\]"},{"location":"book/chapter7_diffusion/score_based_sde/#61-sampling-code-euler-maruyama","title":"6.1 Sampling Code (Euler-Maruyama)","text":"<pre><code>def reverse_sde(model, xT, steps=1000):\n    dt = -1.0 / steps\n    x = xT\n    for i in range(steps):\n        t = torch.ones_like(x[:, :1]) * (1.0 - i / steps)\n        drift = -0.5 * beta_t(t) * x - beta_t(t) * model(x, t)\n        diffusion = torch.sqrt(beta_t(t)) * torch.randn_like(x)\n        x = x + drift * dt + diffusion * torch.sqrt(-dt)\n    return x\n</code></pre>"},{"location":"book/chapter7_diffusion/score_based_sde/#7-score-function","title":"7. Score function","text":"<p>Understanding Score Functions and Gaussian Transition Probabilities in Score-Based SDE Models</p>"},{"location":"book/chapter7_diffusion/score_based_sde/#71-the-forward-sde-and-its-score-function","title":"7.1 The Forward SDE and Its Score Function","text":"<p>A generalized SDE is often written as:</p> \\[ dx = f(x,t)\\,dt + g(x,t)\\,dw, \\] <p>where \\(w\\) is a standard Brownian motion and \\(p_t(x)\\) is the marginal density at time \\(t\\). The score function is defined as the gradient of the log probability density:</p> \\[ s(x,t) = \\nabla_x \\log p_t(x) = \\frac{\\nabla_x p_t(x)}{p_t(x)}. \\] <p>In practice, a neural network \\(s_\\theta(x,t)\\) approximates this score function to guide the reverse diffusion process in generative models.</p>"},{"location":"book/chapter7_diffusion/score_based_sde/#72-deriving-the-score-function-under-gaussian-transition-assumptions","title":"7.2 Deriving the Score Function under Gaussian Transition Assumptions","text":"<p>Assume that the transition probability from an initial state \\(x_0\\) to \\(x\\) at time \\(t\\) is Gaussian:</p> \\[ p_{t|0}(x \\mid x_0) = \\frac{1}{\\sqrt{2\\pi\\,\\sigma_t^2}} \\exp\\left(-\\frac{\\left(x - m(x_0,t)\\right)^2}{2\\sigma_t^2}\\right). \\] <p>Given an initial density \\(p_0(x_0)\\), the marginal density is</p> \\[ p_t(x) = \\int p_{t|0}(x \\mid x_0) \\, p_0(x_0) \\, dx_0. \\]"},{"location":"book/chapter7_diffusion/score_based_sde/#721-marginal-score-function","title":"7.2.1 Marginal Score Function","text":"<p>Differentiating \\(p_t(x)\\) with respect to \\(x\\) and using properties of the Gaussian yields</p> \\[ \\nabla_x p_t(x) = -\\frac{1}{\\sigma_t^2}\\int \\bigl(x - m(x_0,t)\\bigr)\\, p_{t|0}(x \\mid x_0)\\, p_0(x_0) \\, dx_0. \\] <p>Recognizing the conditional expectation</p> \\[ \\mathbb{E}[m(x_0,t) \\mid x] = \\frac{\\int m(x_0,t) \\, p_{t|0}(x \\mid x_0)\\, p_0(x_0) \\, dx_0}{p_t(x)}, \\] <p>the marginal score function becomes</p> \\[ s(x,t) = \\nabla_x \\log p_t(x) = -\\frac{x - \\mathbb{E}[m(x_0,t) \\mid x]}{\\sigma_t^2}. \\] <p>A notable special case is when \\(m(x_0,t) = x_0\\), which leads to the well-known Tweedie's formula:</p> \\[ s(x,t) = -\\frac{x - \\mathbb{E}[x_0 \\mid x]}{\\sigma_t^2}. \\]"},{"location":"book/chapter7_diffusion/score_based_sde/#722-conditional-score-function","title":"7.2.2 Conditional Score Function","text":"<p>In many scenarios, it is useful to consider the score function for the conditional probability \\(p_{t|0}(x \\mid x_0)\\) directly. We define the conditional score function as:</p> \\[ s(x,t\\mid x_0) = \\nabla_x \\log p_{t|0}(x \\mid x_0). \\] <p>Since the conditional density is Gaussian,</p> \\[ p_{t|0}(x \\mid x_0) = \\frac{1}{\\sqrt{2\\pi\\,\\sigma_t^2}} \\exp\\left(-\\frac{\\left(x - m(x_0,t)\\right)^2}{2\\sigma_t^2}\\right), \\] <p>its log-density is</p> \\[ \\log p_{t|0}(x \\mid x_0) = -\\frac{1}{2}\\log(2\\pi\\,\\sigma_t^2) - \\frac{\\left(x - m(x_0,t)\\right)^2}{2\\sigma_t^2}. \\] <p>Taking the gradient with respect to \\(x\\) yields</p> \\[ s(x,t\\mid x_0) = \\nabla_x \\log p_{t|0}(x \\mid x_0) = -\\frac{x - m(x_0,t)}{\\sigma_t^2}. \\] <p>This expression explicitly quantifies how the log-probability of \\(x\\) given \\(x_0\\) changes with \\(x\\) under the Gaussian assumption.</p>"},{"location":"book/chapter7_diffusion/score_based_sde/#73-conditions-for-gaussian-transition-probabilities-from-the-fokkerplanck-perspective","title":"7.3 Conditions for Gaussian Transition Probabilities from the Fokker\u2013Planck Perspective","text":"<p>The evolution of the probability density \\(p(x,t)\\) is governed by the Fokker\u2013Planck equation:</p> \\[ \\frac{\\partial p(x,t)}{\\partial t} = -\\frac{\\partial}{\\partial x}\\Bigl(f(x,t)\\,p(x,t)\\Bigr) + \\frac{1}{2}\\frac{\\partial^2}{\\partial x^2}\\Bigl(g(x,t)^2\\,p(x,t)\\Bigr). \\] <p>For the Gaussian form of \\(p(x,t)\\) to be preserved over time, the following conditions are necessary:</p> <ol> <li>Linear (or Affine) Drift:    The drift function must be linear in \\(x\\):</li> </ol> <p>$$    f(x,t) = A(t)x + b(t),    $$</p> <p>where \\(A(t)\\) is a matrix (or scalar) and \\(b(t)\\) is a bias term. This ensures that applying the drift to a Gaussian density results in another Gaussian (or an affine-transformed Gaussian).</p> <ol> <li>State-Independent Diffusion:    The diffusion function must be independent of \\(x\\):</li> </ol> <p>$$    g(x,t) = g(t).    $$</p> <p>When the noise is additive (i.e., \\(g(x,t)\\) does not depend on \\(x\\)), the diffusion term in the Fokker\u2013Planck equation preserves the quadratic form in \\(x\\) and, therefore, the Gaussian shape of the density.</p> <p>For example, the Ornstein\u2013Uhlenbeck process</p> \\[ dx = -\\lambda x\\,dt + \\sigma\\,dw, \\] <p>satisfies these conditions, resulting in a Gaussian transition probability.</p>"},{"location":"book/chapter7_diffusion/score_based_sde/#74-relationship-between-the-state-transition-matrix-psit-and-at","title":"7.4 Relationship Between the State Transition Matrix \\(\\Psi(t)\\) and \\(A(t)\\)","text":"<p>For linear systems, the state transition matrix \\(\\Psi(t)\\) (often denoted as \\(\\Phi(t)\\) in some literature) is defined as the solution to the differential equation</p> \\[ \\frac{d}{dt}\\Psi(t) = A(t)\\,\\Psi(t), \\quad \\Psi(0)=I, \\] <p>where \\(I\\) is the identity matrix. This matrix propagates the initial state \\(x_0\\) to the state at time \\(t\\) through the relation:</p> \\[ x(t) = \\Psi(t)x_0 + \\int_0^t \\Psi(t,s)\\,b(s)\\,ds + \\int_0^t \\Psi(t,s)\\,g(s)\\,dw(s). \\]"},{"location":"book/chapter7_diffusion/score_based_sde/#741-closed-forms-expression-for-psit","title":"7.4.1 Closed-Forms Expression for \\(\\Psi(t)\\)","text":"<p>Since the ODE for \\(\\Psi(t)\\) is linear, it is often possible to obtain a closed-form expression for \\(\\Psi(t)\\) under certain conditions. For example, if \\(A(t)\\) is time-invariant, i.e., \\(A(t) = A\\) for all \\(t\\), then the solution is given by the matrix exponential:</p> \\[ \\Psi(t) = e^{At}. \\] <p>Even if \\(A(t)\\) is time-dependent, if it commutes with itself at different times (i.e., \\([A(t_1), A(t_2)] = 0\\) for all \\(t_1, t_2\\)), the closed-form solution can be written as:</p> \\[ \\Psi(t) = \\exp\\left(\\int_0^t A(s)\\,ds\\right). \\] <p>In cases where \\(A(t)\\) does not commute at different times, the closed-form expression might not be available, and one must resort to numerical integration or approximation methods.</p>"},{"location":"book/chapter7_diffusion/score_based_sde/#75-explicit-expression-for-the-conditional-score-function","title":"7.5 Explicit Expression for the Conditional Score Function","text":"<p>Under the assumptions that the drift is linear and the diffusion is state-independent, the SDE becomes</p> \\[ dx = \\bigl(A(t)x + b(t)\\bigr)dt + g(t)\\,dw. \\] <p>Its solution can be written as:</p> \\[ x(t) = \\Psi(t)x_0 + \\mu(t) + \\int_0^t \\Psi(t,s) g(s)\\, dw(s), \\] <p>where:</p> <ul> <li>\\(\\Psi(t)\\) is the state transition matrix defined above,</li> <li>\\(\\mu(t) = \\int_0^t \\Psi(t,s)\\,b(s)\\, ds\\),</li> <li>The noise integral is Gaussian with covariance</li> </ul> <p>$$   \\Sigma(t) = \\int_0^t \\Psi(t,s)\\,g(s)<sup>2\\,\\Psi(t,s)</sup>\\top ds.   $$</p> <p>Thus, the conditional (or transition) probability is given by</p> \\[ p_{t|0}(x \\mid x_0) = \\mathcal{N}\\Bigl(x; \\Psi(t)x_0 + \\mu(t),\\, \\Sigma(t)\\Bigr). \\] <p>Assuming the initial distribution \\(p_0(x_0)\\) is also Gaussian, the marginal distribution \\(p_t(x)\\) remains Gaussian:</p> \\[ p_t(x) = \\mathcal{N}\\Bigl(x; m(t),\\, \\Sigma(t)\\Bigr), \\] <p>with mean</p> \\[ m(t) = \\Psi(t)m_0 + \\mu(t), \\] <p>where \\(m_0\\) is the mean of \\(p_0(x_0)\\).</p> <p>The marginal score function is computed as the gradient of the log density of a Gaussian:</p> \\[ s(x,t) = \\nabla_x \\log p_t(x) = -\\Sigma(t)^{-1}\\bigl(x - m(t)\\bigr). \\] <p>Recall that the conditional score function for \\(p_{t|0}(x \\mid x_0)\\) is</p> \\[ s(x,t\\mid x_0) = \\nabla_x \\log p_{t|0}(x \\mid x_0). \\] <p>Given the Gaussian form of \\(p_{t|0}(x \\mid x_0)\\), we obtain</p> \\[ s(x,t\\mid x_0) = -\\frac{x - (\\Psi(t)x_0 + \\mu(t))}{\\sigma_t^2}, \\] <p>where, in this context, \\(\\sigma_t^2\\) relates to the covariance \\(\\Sigma(t)\\) (or is a scalar if the state is one-dimensional). This expression quantifies how the log-probability of \\(x\\) given \\(x_0\\) changes with \\(x\\) under the Gaussian assumption.</p>"},{"location":"book/chapter7_diffusion/score_based_sde/#76-example-non-gaussian-transition-probability","title":"7.6 Example: Non-Gaussian Transition Probability","text":"<p>When the conditions for Gaussian transitions are not met, the SDE may yield a non-Gaussian transition probability. A classic example is geometric Brownian motion, where the SDE is given by</p> \\[ dx = \\mu x\\,dt + \\sigma x\\,dw. \\] <p>Here, both the drift \\(f(x,t) = \\mu x\\) and the diffusion \\(g(x,t)=\\sigma x\\) depend linearly on \\(x\\). Although the drift is linear, the diffusion is state-dependent (multiplicative noise). The solution to this SDE is</p> \\[ x(t)= x_0\\,\\exp\\Bigl\\{\\left(\\mu - \\frac{1}{2}\\sigma^2\\right)t + \\sigma w_t\\Bigr\\}, \\] <p>and the resulting distribution of \\(x(t)\\) is log-normal, not Gaussian. This deviation occurs because the multiplicative nature of the noise distorts the Gaussian structure through a nonlinear transformation, resulting in a distribution with asymmetry (skewness) and a long tail.</p>"},{"location":"book/chapter7_diffusion/score_based_sde/#77-when-the-score-function-is-fracx-x_0sigma_t2","title":"7.7 When the score function is \\(-\\frac{x-x_0}{\\sigma_t^2}\\)","text":"<p>When we say that the conditional mean is preserved, we mean that for a sample starting at \\(x_0\\), the mean of the transition density remains \\(m(x_0,t)=x_0\\) for all \\(t\\). In terms of the SDE,</p> <p>this property requires that the drift term does not \u201cpush\u201d the process away from its initial value in expectation. Here are several common cases with specific forms for \\(f(x,t)\\):</p>"},{"location":"book/chapter7_diffusion/score_based_sde/#771-zero-drift","title":"7.7.1 Zero Drift","text":"<p>The simplest case is when there is no drift at all. That is, set</p> \\[ f(x,t) = 0. \\] <p>Then the SDE becomes a pure diffusion process</p> \\[ dx = g(t)\\,dw, \\] <p>and since there is no deterministic shift, we have</p> \\[ E[x(t) \\mid x_0] = x_0. \\]"},{"location":"book/chapter7_diffusion/score_based_sde/#772-centered-linear-drift","title":"7.7.2 Centered Linear Drift","text":"<p>Another case is to use a drift that is linear and \u201ccentered\u201d at the initial condition. For the conditional process (i.e. given \\(x(0)=x_0\\)), one can choose a drift of the form</p> \\[ f(x,t) = -a(t)\\bigl(x - x_0\\bigr), \\] <p>where \\(a(t)\\) is a nonnegative function (or a positive function) of time. To see why this preserves the conditional mean, define</p> \\[ y(t)=x(t)-x_0. \\] <p>Then the SDE for \\(y(t)\\) becomes</p> \\[ dy = -a(t)y\\,dt + g(t)\\,dw, \\] <p>with initial condition \\(y(0)=0\\). Since the drift term in \\(y(t)\\) is proportional to \\(y\\) and \\(y(0)=0\\), it follows by uniqueness and linearity of expectation that</p> \\[ E[y(t)] = 0, \\] <p>which implies</p> \\[ E[x(t) \\mid x_0] = x_0. \\]"},{"location":"book/chapter7_diffusion/score_based_sde/#773-symmetric-odd-drift-functions-around-x_0","title":"7.7.3 Symmetric (Odd) Drift Functions Around \\(x_0\\)","text":"<p>More generally, any drift function that satisfies</p> \\[ f(x_0,t)=0 \\quad \\text{and} \\quad f(x_0+\\delta,t)=-f(x_0-\\delta,t) \\] <p>for all small \\(\\delta\\) and for all \\(t\\) will not induce a bias in the conditional mean. For example, one might choose</p> \\[ f(x,t) = -a(t)\\,\\tanh\\bigl(x - x_0\\bigr), \\] <p>where \\(\\tanh\\) is an odd function. Near \\(x=x_0\\) (where \\(\\tanh(z) \\approx z\\) for small \\(z\\)), this behaves similarly to the linear case, ensuring that \\(f(x_0,t)=0\\) and that the \u201cpush\u201d is symmetric about \\(x_0\\). Hence, the conditional mean remains unchanged.</p> <p>In summary, the conditional mean \\(m(x_0,t)=x_0\\) is preserved if the drift \\(f(x,t)\\) is chosen such that it does not introduce a net shift away from the initial condition \\(x_0\\). Common choices include:</p> <ul> <li>Zero drift: \\(f(x,t)=0\\).</li> <li>Centered linear drift: \\(f(x,t) = -a(t)(x-x_0)\\).</li> <li>Symmetric (odd) drift: For instance, \\(f(x,t) = -a(t)\\,\\tanh(x-x_0)\\).</li> </ul>"},{"location":"book/chapter7_diffusion/score_based_sde/#774-vp-vesub-ve-sdes","title":"7.7.4 VP, VE,sub-VE SDEs","text":"<p>Below are the answers regarding the three SDE types and their conditional score functions:</p>"},{"location":"book/chapter7_diffusion/score_based_sde/#7741-vp-sde-variance-preserving-sde","title":"7.7.4.1 VP SDE (Variance Preserving SDE)","text":"<p>Definition: The VP SDE is typically defined as</p> \\[ dx = -\\frac{1}{2}\\beta(t)x\\,dt + \\sqrt{\\beta(t)}\\,dw. \\] <p>Mean Behavior: Its solution is</p> \\[ x(t) = e^{-\\frac{1}{2}\\int_0^t \\beta(s)\\,ds}\\,x_0 + \\sqrt{1-e^{-\\int_0^t \\beta(s)\\,ds}}\\,z, \\] <p>where \\(z\\sim\\mathcal{N}(0,I)\\). Therefore, the conditional mean is</p> \\[ m(x_0,t) = e^{-\\frac{1}{2}\\int_0^t \\beta(s)\\,ds}\\,x_0, \\] <p>which is not equal to \\(x_0\\) unless \\(x_0=0\\) or \\(\\beta(t)\\) is zero. Hence, VP SDE does not preserve the mean.</p> <p>Conditional Score Function: Since the conditional distribution is</p> \\[ p_{t|0}(x\\mid x_0)=\\mathcal{N}\\Bigl(x;\\, e^{-\\frac{1}{2}\\int_0^t \\beta(s)\\,ds}\\,x_0,\\; 1-e^{-\\int_0^t \\beta(s)\\,ds}\\Bigr), \\] <p>its conditional score function is</p> \\[ s(x,t\\mid x_0) = \\nabla_x \\log p_{t|0}(x\\mid x_0) = -\\frac{x - e^{-\\frac{1}{2}\\int_0^t \\beta(s)\\,ds}\\,x_0}{\\,1-e^{-\\int_0^t \\beta(s)\\,ds}\\,}. \\]"},{"location":"book/chapter7_diffusion/score_based_sde/#7742-ve-sde-variance-exploding-sde","title":"7.7.4.2 VE SDE (Variance Exploding SDE)","text":"<p>Definition: The VE SDE is usually written as</p> \\[ dx = \\sqrt{\\frac{d\\sigma^2(t)}{dt}}\\,dw. \\] <p>Mean Behavior: Because there is no drift term, the solution is</p> \\[ x(t) = x_0 + \\sigma(t)\\,z, \\] <p>with \\(z\\sim\\mathcal{N}(0,I)\\). Thus, the conditional mean is</p> \\[ m(x_0,t)= x_0, \\] <p>i.e. the mean is preserved.</p> <p>Conditional Score Function: Since</p> \\[ p_{t|0}(x\\mid x_0)=\\mathcal{N}\\Bigl(x;\\, x_0,\\; \\sigma^2(t)\\Bigr), \\] <p>the conditional score function becomes</p> \\[ s(x,t\\mid x_0) = -\\frac{x-x_0}{\\sigma^2(t)}. \\]"},{"location":"book/chapter7_diffusion/score_based_sde/#7743-sub-vp-sde-sub-variance-preserving-sde","title":"7.7.4.3 sub-VP SDE (Sub-Variance Preserving SDE)","text":"<p>Definition and Mean Behavior: The sub-VP SDE is designed as a reparameterization of the VP SDE to cancel the exponential decay factor in the mean. By construction, its dynamics are modified so that the conditional mean is preserved:</p> \\[ m(x_0,t)= x_0. \\] <p>Although several equivalent formulations exist, a common interpretation is that the reparameterized process has a conditional distribution</p> \\[ p_{t|0}(x\\mid x_0)=\\mathcal{N}\\Bigl(x;\\, x_0,\\; \\tilde{\\sigma}^2(t)\\Bigr), \\] <p>with a suitably defined variance schedule \\(\\tilde{\\sigma}^2(t)\\).</p> <p>Conditional Score Function: Then the conditional score function for the sub-VP SDE is</p> \\[ s(x,t\\mid x_0) = -\\frac{x-x_0}{\\tilde{\\sigma}^2(t)}. \\]"},{"location":"book/chapter7_diffusion/score_based_sde/#78-summary","title":"7.8 Summary","text":"<ul> <li>VP SDE:</li> <li>Mean: \\(m(x_0,t)= e^{-\\frac{1}{2}\\int_0^t \\beta(s)\\,ds}\\,x_0\\) (not preserved)</li> <li>Conditional Score:</li> </ul> \\[ s(x,t\\mid x_0) = -\\frac{x - e^{-\\frac{1}{2}\\int_0^t \\beta(s)\\,ds}\\,x_0}{\\,1-e^{-\\int_0^t \\beta(s)\\,ds}\\,}. \\] <ul> <li>VE SDE:</li> <li>Mean: \\(m(x_0,t)= x_0\\) (preserved)</li> <li>Conditional Score:</li> </ul> \\[ s(x,t\\mid x_0) = -\\frac{x-x_0}{\\sigma^2(t)}. \\] <ul> <li>sub-VP SDE:</li> <li>Mean: \\(m(x_0,t)= x_0\\) (by design)</li> <li>Conditional Score:</li> </ul> \\[ s(x,t\\mid x_0) = -\\frac{x-x_0}{\\tilde{\\sigma}^2(t)}. \\]"},{"location":"book/chapter7_diffusion/score_based_sde/#79-conclusion","title":"7.9 Conclusion","text":"<p>To summarize:</p> <ul> <li>Score Functions:</li> <li>The marginal score function is defined as \\(\\nabla_x \\log p_t(x)\\). Under Gaussian assumptions, we derived</li> </ul> \\[ s(x,t) = -\\frac{x - \\mathbb{E}[m(x_0,t) \\mid x]}{\\sigma_t^2} \\quad \\text{or} \\quad s(x,t) = -\\Sigma(t)^{-1}\\bigl(x - m(t)\\bigr). \\] <ul> <li>The conditional score function for the transition density \\(p_{t|0}(x \\mid x_0)\\) is</li> </ul> \\[ s(x,t\\mid x_0) = -\\frac{x - m(x_0,t)}{\\sigma_t^2}, \\] <pre><code>and under linear drift and state-independent diffusion, this becomes\n</code></pre> \\[ s(x,t\\mid x_0) = -\\frac{x - (\\Psi(t)x_0 + \\mu(t))}{\\sigma_t^2}. \\] <ul> <li> <p>Gaussian Transition Probabilities:   The transition probability remains Gaussian if the drift is linear (or affine), \\(f(x,t)=A(t)x+b(t)\\), and the diffusion is state-independent, \\(g(x,t)=g(t)\\).</p> </li> <li> <p>State Transition Matrix \\(\\Psi(t)\\) and \\(A(t)\\): \\(\\Psi(t)\\) satisfies</p> </li> </ul> <p>$$   \\frac{d}{dt}\\Psi(t) = A(t)\\,\\Psi(t) \\quad \\text{with} \\quad \\Psi(0)=I.   $$</p> <p>When \\(A(t)\\) is time-invariant, \\(\\Psi(t) = e^{At}\\). More generally, if \\(A(t)\\) commutes with itself at different times, then</p> <p>$$   \\Psi(t) = \\exp\\left(\\int_0^t A(s)\\,ds\\right),   $$</p> <p>providing a closed-form expression for the state transition matrix.</p> <ul> <li>Non-Gaussian Example:   When \\(g(x,t)\\) depends on \\(x\\), as in geometric Brownian motion (\\(dx=\\mu x\\,dt + \\sigma x\\,dw\\)), the resulting transition probability becomes log-normal rather than Gaussian.</li> </ul>"},{"location":"book/chapter7_diffusion/score_based_sde/#8-extenstion-types-of-score-based-sde","title":"8. Extenstion Types of Score Based SDE","text":"<p>Beyond VPSDE, VESDE, and Sub-VPSDE, there are several other types of Score-based SDEs that modify the drift and diffusion terms to improve generation quality, stability, or computational efficiency.</p> <p>Here are some additional Score-based SDEs:</p>"},{"location":"book/chapter7_diffusion/score_based_sde/#81-critically-damped-langevin-diffusion-cld-sde","title":"8.1 Critically Damped Langevin Diffusion (CLD-SDE)","text":"<p>This method introduces momentum variables to improve sampling efficiency. Unlike VPSDE/VESDE, which use only position updates, CLD-SDE includes velocity to achieve faster convergence.</p>"},{"location":"book/chapter7_diffusion/score_based_sde/#811-sde-formulation","title":"8.1.1 SDE Formulation","text":"\\[ \\begin{cases} dx &amp;= v dt \\\\ dv &amp;= -\\gamma v dt - \\lambda^2 x dt + \\sigma dw \\end{cases} \\] <p>where:</p> <ul> <li>\\( x \\) is the position.</li> <li>\\( v \\) is the velocity.</li> <li>\\( \\gamma \\) is the friction coefficient (controls how fast momentum dissipates).</li> <li>\\( \\lambda \\) is the spring constant (pulls data towards the center).</li> <li> <p>\\( \\sigma \\) is the noise strength.</p> </li> <li> <p>score function</p> </li> </ul> \\[ \\nabla_{v_t} \\log p(v_t | x_t) = -\\frac{v_t + \\lambda^2 x_t}{\\sigma^2} \\] <ul> <li>training loss</li> </ul> \\[|| \\nabla_{v_t} \\log p(v_t | x_t) - s_\\theta(x,v)||^2\\] <ul> <li>initial condition</li> <li>\\(v=0\\)</li> <li>\\(x \\sim p_{data}(x)\\)</li> <li>training data construction</li> <li>use the SDE discrete formula to estimate \\(x_t, v_t\\) and calculate the score function accordingly</li> </ul>"},{"location":"book/chapter7_diffusion/score_based_sde/#812-key-features","title":"8.1.2 Key Features","text":"<ul> <li>Faster sampling: Uses both position and momentum to traverse the data manifold efficiently.</li> <li>Inspired by Langevin dynamics, used in Hamiltonian Monte Carlo (HMC).</li> </ul>"},{"location":"book/chapter7_diffusion/score_based_sde/#82-rectified-flow-sde","title":"8.2 Rectified Flow SDE","text":"<p>Instead of traditional diffusion, Rectified Flow SDE designs a flow field where trajectories follow a straight-line path from data to noise.</p>"},{"location":"book/chapter7_diffusion/score_based_sde/#821-sde-formulation","title":"8.2.1 SDE Formulation","text":"\\[ dx = (x_T - x) dt + g(t) dw \\] <p>where:</p> <ul> <li>\\( x_T \\) is the terminal (noise) state.</li> <li>\\( g(t) \\) controls the noise schedule.</li> </ul>"},{"location":"book/chapter7_diffusion/score_based_sde/#822-key-features","title":"8.2.2 Key Features","text":"<ul> <li>Deterministic reverse process: Paths are approximately straight, reducing error in reverse sampling.</li> <li>Faster convergence: Uses ODE-based sampling efficiently.</li> </ul>"},{"location":"book/chapter7_diffusion/score_based_sde/#823-training-details","title":"8.2.3 Training Details","text":"<ul> <li>Loss: MSE loss on score function</li> <li>data construction</li> </ul> \\[x_t =(1-t) x_0 + t x_T\\] <ul> <li>score function</li> </ul> \\[\\nabla_x \\log p_t (x_t|x_0) = - \\frac{x_t - x_0}{\\sigma_t}\\]"},{"location":"book/chapter7_diffusion/score_based_sde/#824-formula-for-sigma_t","title":"8.2.4 Formula for \\( \\sigma_t \\)","text":"<p>The variance of the noise term in the Rectified Flow SDE can be written as:</p> \\[ \\sigma_t^2 = \\int_0^t g(s)^2 ds \\] <p>The function \\( g(t) \\) is designed to minimize unnecessary randomness, leading to more deterministic trajectories.</p> <p>A common choice for \\( g(t) \\) is:</p> \\[ g(t) = \\sigma_0 \\sqrt{1 - t} \\] <p>where \\( \\sigma_0 \\) is a constant that determines the initial noise scale.</p> <p>Thus, the variance accumulates as:</p> \\[ \\sigma_t^2 = \\int_0^t \\sigma_0^2 (1 - s) ds = \\sigma_0^2 \\left( t - \\frac{t^2}{2} \\right) \\] <p>which gives:</p> \\[ \\sigma_t = \\sigma_0 \\sqrt{t - \\frac{t^2}{2}} \\] <p>This ensures that noise starts large at \\( t=0 \\) and gradually decreases to zero as \\( t \\to 1 \\), making the flow almost deterministic near the final state.</p> <p>Using the definition:</p> \\[ \\nabla_x \\log p_t(x_t | x_0) = -\\frac{x_t - x_0}{\\sigma_t^2} \\] <p>we get:</p> \\[ \\nabla_x \\log p_t(x_t | x_0) = -\\frac{x_t - x_0}{\\sigma_0^2 (t - \\frac{t^2}{2})} \\] <p>which reduces to:</p> \\[ \\nabla_x \\log p_t(x_t | x_0) = -\\frac{x_t - x_0}{\\sigma_0^2 t (1 - \\frac{t}{2})} \\] <ul> <li>Noise scaling function:</li> </ul> \\[ g(t) = \\sigma_0 \\sqrt{1 - t} \\] <ul> <li>Variance accumulation:</li> </ul> \\[ \\sigma_t^2 = \\sigma_0^2 (t - \\frac{t^2}{2}) \\] <ul> <li>Score function:</li> </ul> \\[ \\nabla_x \\log p_t(x_t | x_0) = -\\frac{x_t - x_0}{\\sigma_0^2 t (1 - \\frac{t}{2})} \\]"},{"location":"book/chapter7_diffusion/score_based_sde/#83-continuous-time-normalizing-flows-ctnf-sde","title":"8.3 Continuous-Time Normalizing Flows (CTNF-SDE)","text":"<p>Continuous-Time Normalizing Flows (CTNF) combine normalizing flows with stochastic differential equations (SDEs). Unlike traditional diffusion models, CTNF explicitly models the log-likelihood of the data, making it a likelihood-based generative model.</p>"},{"location":"book/chapter7_diffusion/score_based_sde/#831-sde-formulation","title":"8.3.1 SDE Formulation","text":"<p>The CTNF-SDE is defined as:</p> \\[ dx = f(x, t) dt + g(x, t) dw \\] <p>where:</p> <ul> <li>\\( f(x, t) \\) is a learnable drift function.</li> <li>\\( g(x, t) \\) is a learnable diffusion function.</li> <li>\\( dw \\) is a Wiener process (Brownian motion).</li> <li>The drift \\( f(x, t) \\) and diffusion \\( g(x, t) \\) are parameterized using neural networks.</li> </ul> <p>This SDE can be interpreted as a normalizing flow in continuous time, where we transform a simple base distribution (e.g., Gaussian) into the data distribution.</p>"},{"location":"book/chapter7_diffusion/score_based_sde/#832-variance-function-sigma_t","title":"8.3.2 Variance Function \\( \\sigma_t \\)","text":"<p>For CTNF, the variance function is learned rather than fixed. It follows:</p> \\[ \\sigma_t^2 = \\int_0^t g(x, s)^2 ds \\] <p>This means:</p> <ul> <li>\\( \\sigma_t \\) is data-dependent.</li> <li>The noise schedule adapts based on the dataset.</li> </ul>"},{"location":"book/chapter7_diffusion/score_based_sde/#833-score-function","title":"8.3.3 Score Function","text":"<p>The score function is derived as:</p> \\[ \\nabla_x \\log p_t(x_t | x_0) = -\\frac{x_t - \\mu_t}{\\sigma_t^2} \\] <p>where:</p> <ul> <li>\\( \\mu_t \\) and \\( \\sigma_t^2 \\) are estimated using the learned drift and diffusion functions.</li> </ul> <p>Since \\( g(x, t) \\) is learned, the score function is not fixed like in traditional diffusion models.</p>"},{"location":"book/chapter7_diffusion/score_based_sde/#834-training-loss","title":"8.3.4 Training Loss","text":"<p>CTNF optimizes a log-likelihood loss based on the probability flow ODE:</p> \\[ \\mathcal{L}(\\theta) = \\mathbb{E}_{x_t} \\left[ -\\log p_t(x_t) \\right] \\] <p>Alternatively, we can use score matching:</p> \\[ \\mathbb{E}_{x_t} \\left[ || \\nabla_x \\log p_t(x_t | x_0) - s_\\theta(x, t) ||^2 \\right] \\]"},{"location":"book/chapter7_diffusion/score_based_sde/#835-initial-condition","title":"8.3.5 Initial Condition","text":"<ul> <li>\\( x \\sim p_{data}(x) \\) (samples from the data distribution).</li> </ul>"},{"location":"book/chapter7_diffusion/score_based_sde/#84-training-data-construction","title":"8.4 Training Data Construction","text":"<p>Since \\( x_t \\) does not have an analytical solution, we must numerically estimate it:</p> <ul> <li>Use SDE discretization:</li> </ul> <p>$$   x_{t+\\Delta t} = x_t + f(x_t, t) \\Delta t + g(x_t, t) \\sqrt{\\Delta t} \\eta_t, \\quad \\eta_t \\sim \\mathcal{N}(0, I)   $$</p> <ul> <li>Compute the score function numerically.</li> </ul>"},{"location":"book/chapter7_diffusion/score_based_sde/#841-summary","title":"8.4.1 Summary","text":"Property CTNF-SDE Equation \\( dx = f(x, t) dt + g(x, t) dw \\) \\( \\sigma_t \\) \\( \\sigma_t^2 = \\int_0^t g(x, s)^2 ds \\) Score Function \\( \\nabla_x \\log p_t(x_t\\| x_0) = -\\frac{x_t - \\mu_t}{\\sigma_t^2} \\) Training Loss \\( -\\mathbb{E}_{x_t} \\log p_t(x_t) \\) or score matching Training Data Construction SDE discretization"},{"location":"book/chapter7_diffusion/score_based_sde/#85-score-based-sdes-with-adaptive-noise-an-sde","title":"8.5 Score-Based SDEs with Adaptive Noise (AN-SDE)","text":"<p>Instead of fixing a noise schedule, Adaptive Noise SDE dynamically adjusts \\( g(t) \\) based on data properties.</p> \\[ dx = f(x, t) dt + \\sigma(x, t) dw \\] <p>where:</p> <ul> <li>\\( \\sigma(x, t) \\) is data-dependent noise.</li> </ul>"},{"location":"book/chapter7_diffusion/score_based_sde/#86-key-features","title":"8.6 Key Features","text":"<ul> <li>Adapts to dataset complexity (e.g., higher noise for high-frequency details).</li> <li>Better preservation of structure in images and 3D modeling.</li> </ul>"},{"location":"book/chapter7_diffusion/score_based_sde/#9-6-fractional-brownian-motion-sde-fbm-sde","title":"9. 6. Fractional Brownian Motion SDE (FBM-SDE)","text":"<p>Instead of using standard Brownian motion, FBM-SDE incorporates long-range dependencies.</p> \\[ dx = -\\alpha x dt + g(t) dB^H_t \\] <p>where:</p> <ul> <li>\\( B^H_t \\) is a fractional Brownian motion with Hurst parameter \\( H \\).</li> <li>\\( H \\) controls memory effects (larger \\( H \\) \u2192 more persistent motion).</li> </ul>"},{"location":"book/chapter7_diffusion/score_based_sde/#91-key-features","title":"9.1 Key Features","text":"<ul> <li>Models long-range dependencies (useful in speech, financial modeling).</li> <li>Better generation for sequential data.</li> </ul>"},{"location":"book/chapter7_diffusion/score_based_sde/#10-7-hybrid-sde-ode-models","title":"10. 7. Hybrid SDE-ODE Models","text":"<p>Some models combine SDE and ODE approaches to get the best of both:</p> \\[ \\begin{cases} dx = f(x, t) dt + g(t) dw  &amp;\\text{for } t &lt; T_1\\\\ dx = f(x, t) dt  &amp;\\text{for } t \\geq T_1 \\end{cases} \\] <p>where:</p> <ul> <li>The system follows an SDE initially (better exploration).</li> <li>The system switches to an ODE at a later stage (better precision).</li> </ul>"},{"location":"book/chapter7_diffusion/score_based_sde/#101-key-features","title":"10.1 Key Features","text":"<ul> <li>Combines SDE exploration with ODE stability.</li> <li>More efficient sampling compared to full SDE models.</li> </ul>"},{"location":"book/chapter7_diffusion/score_based_sde/#11-8-summary-of-score-based-sdes","title":"11. 8. Summary of Score-Based SDEs","text":"SDE Type Equation Key Features VPSDE \\( dx = -\\frac{1}{2} \\beta(t) x dt + \\sqrt{\\beta(t)} dw \\) Standard variance-preserving diffusion VESDE \\( dx = \\sigma(t) dw \\) Large-scale noise growth (variance exploding) Sub-VPSDE \\( dx = -\\frac{1}{2} \\beta(t) x dt + \\sqrt{\\beta(t)(1 - e^{-2\\int_0^t \\beta(s) ds})} dw \\) Controlled noise decay CLD-SDE \\( dx = v dt, \\quad dv = -\\gamma v dt - \\lambda^2 x dt + \\sigma dw \\) Faster convergence with momentum Rectified Flow SDE \\( dx = (x_T - x) dt + g(t) dw \\) Near-deterministic straight-line flow CTNF-SDE \\( dx = f(x, t) dt + g(x, t) dw \\) Normalizing flows + diffusion Generalized SDE \\( dx = -f(x, t) dt + g(t) dw \\) Customizable drift and noise schedules AN-SDE \\( dx = f(x, t) dt + \\sigma(x, t) dw \\) Adaptive noise for structured data FBM-SDE \\( dx = -\\alpha x dt + g(t) dB^H_t \\) Models long-range dependencies Hybrid SDE-ODE \\( dx = f(x, t) dt + g(t) dw \\) for early \\( t \\), \\( dx = f(x, t) dt \\) later Mixes SDE and ODE for stability"},{"location":"book/chapter7_diffusion/score_based_sde/#12-conclusion","title":"12. Conclusion","text":"<p>While VPSDE and VESDE are the most widely used Score-based SDEs, many variations introduce optimizations for different tasks.</p> <ul> <li>Momentum-based SDEs (CLD-SDE) \u2192 Faster sampling.</li> <li>Straight-line diffusion (Rectified Flow) \u2192 Better sample paths.</li> <li>Hybrid SDE-ODE models \u2192 Efficient sampling.</li> <li>Adaptive SDEs (AN-SDE) \u2192 Noise adjustment based on data.</li> </ul> <p>Score Based SDE vs SDE diffusion</p> <p>SDE Diffusion (Stochastic Differential Equation-based diffusion models) and Score-based SDE (Score-based Stochastic Differential Equations) are closely related in the field of generative models, but they are not completely equivalent. Most SDE Diffusion models involve the estimation of score functions and therefore fall under the category of Score-based SDE. However, there are still some SDE Diffusion models that do not directly rely on the estimation of score functions.</p> <p>For example, the Fractional SDE-Net is a generative model for time series data with long-term dependencies. This model is based on fractional Brownian motion and captures the long-range dependency characteristics in time series by introducing fractional-order stochastic differential equations. In this approach, the model focuses on simulating the temporal dependency structure of the data rather than directly estimating the score function of the data distribution.</p> <p>Additionally, the Diffusion-Model-Assisted Supervised Learning method uses diffusion models to generate labeled data to assist in density estimation tasks in supervised learning. This method directly approximates the score function in the reverse-time SDE through a training-free score estimation method, thereby improving sampling efficiency and model performance. Although this method involves the estimation of score functions, its primary goal is to generate auxiliary data through diffusion models to enhance the supervised learning process.</p> <p>In summary, while most SDE Diffusion models fall under the category of Score-based SDE, there are still some models, such as the Fractional SDE-Net and Diffusion-Model-Assisted Supervised Learning method, that focus on other aspects, such as modeling temporal dependency structures or assisting supervised learning, without directly relying on score function estimation.</p>"},{"location":"book/chapter9_flow_matching/affine_conditional_flows/","title":"Affine conditional flows","text":"<p>Note</p> <p>Please refere the article in flow matching theory for the general formula of flow matching and its optimization target. In this article, we will introduce the family of affine conditional flows from general to specific.</p>"},{"location":"book/chapter9_flow_matching/affine_conditional_flows/#1-gaussian-path","title":"1. Gaussian Path","text":""},{"location":"book/chapter9_flow_matching/flow_matching_theory/","title":"Flow Matching Theorem","text":"<p>[toc]</p> <p>Note</p> <p>In this article, we establish the theroy foundation of the flow matching method</p> <p>Please read the section introduction for common knowledges of the flow matching and standard notations</p>"},{"location":"book/chapter9_flow_matching/flow_matching_theory/#1-formula-of-flow-matching","title":"1. Formula of flow matching","text":"<p>Suppose \\(v(x,t)\\) is the velocity field from push the probability \\(p\\) to \\(q\\). Our aim is to estimate the delocity field</p> <p>Flow Matching Loss</p> <p>The flow matching loss is defined as</p> <p>$$   \\begin{equation}   L_{F M}=E_{t,X_t\\sim p_t} ||v(x,t) - v_\\theta(x,t)||^2   \\end{equation}   $$</p> <p>Here \\(||\\) could be any distance metric besides the normal mean square error.</p> <p>For simplicity, we denote the \\(\\pi_{0,1}(X_0,X_1)\\) be the joint distribution of the data coupling</p> \\[(X_0,X_1)\\sim \\pi_{0,1}(X_0,X_1)\\] <p>Although, the common used distirbution of \\(X_0\\) is the Gaussian noise, we just consider the general distribution in this section.</p>"},{"location":"book/chapter9_flow_matching/flow_matching_theory/#11-conditional-probability-path","title":"1.1 Conditional probability path","text":"<p>Let \\(p_{t|1}(x|x_1)\\) be the consitional probability path.</p> <p>Then the marginal probability path (responde to the joint distribution \\(\\pi_{0,1}\\)) \\(p_t\\)</p> \\[\\tag{1}p_t(x) = \\int p_{t|1}(x|x_1) q(x_1)d x_1.\\] <p>and \\(p_t\\) satisfied the boundary condition</p> \\[p_0 = p, \\qquad p_1 = q\\] <p>which required the conditional probability path satisfy</p> \\[ p_{0|1}(x|x_1) = \\pi_{0|1}(x|x_1), and \\; p_{1|1} (x|x_1) = \\delta_{x_1}(x) \\] <p>where \\(\\delta_{x_1}\\) is the delta measure centered at \\(x_1\\).</p> <p>If we consider the independent data coupling, then</p> \\[\\pi_{0|1}(x_0|x_1) = \\pi_{0,1}(x_0,x_1)/q(x_1)\\] <p>The constrains becomes \\(p_{0|1}(x|x_1) = p(x)\\).</p> <p>The second condition could also be written as</p> \\[\\int p_{t|1}(x|y) f(y) d y \\rightarrow f(x)\\] <p>as \\(t\\rightarrow 1\\) for any continuous function \\(f\\) since \\(\\delta\\) has no density function.</p>"},{"location":"book/chapter9_flow_matching/flow_matching_theory/#12-conditional-velocity-field","title":"1.2 Conditional Velocity Field","text":"<p>Let \\(u_t(\\cdot|x_1)\\) generates \\(p_{t|1}(\\cdot | x_1)\\)</p> <p>Thus we have</p> \\[\\tag{2}u_t(x) = \\int u_t(x|x_1) p_{x_1|x} d x_1\\] <p>This can be viewed as a weighted average of the conditional velocities or it can be regared as the conditional expectation</p> \\[u_t(x) = \\mathbf{E}[u_t(X_t|X_1)|X_t=x]\\] <p>Expectation of conditional velocity</p> <p>Given any Random Variable \\(Z\\), \\(p_Z\\) has bounded support,</p> <p>\\(\\(p_{t|Z}(x|z)\\in C^1([0,1]\\times R^d)\\)\\)</p> <p>\\(\\(u_t(x|z) \\in C^1([0,1]\\times R^d,R^d), p_t(x)&gt;0 \\; \\forall x \\in R^d, t\\in[0,1)\\)\\)</p> <p>If \\(u_t(x|z)\\) is conditional integrable and generates the conditional probability path \\(p_t(\\cdot|z)\\), then the marginal velocity field \\(u_t\\) generates the marginal probability path \\(p_t\\) for all \\(t\\in [0,1)\\)</p> Expectation of conditional velocity <p>Step 1: Differentiating $ p_t(x) $   By the law of total probability:</p> <p>$$   p_t(x) = \\int p_{t|Z}(x|z) p_Z(z) dz.   $$</p> <p>Differentiating both sides:</p> <p>$$   \\frac{d}{dt} p_t(x) = \\int \\frac{d}{dt} p_{t|Z}(x|z) p_Z(z) dz.   $$</p> <p>Since $ u_t(x|z) $ generates $ p_{t|Z}(x|z) $, we have:</p> <p>$$   \\frac{d}{dt} p_{t|Z}(x|z) = -\\nabla_x \\cdot [ u_t(x|z) p_{t|Z}(x|z) ].   $$</p> <p>Thus,</p> <p>$$   \\frac{d}{dt} p_t(x) = -\\int \\nabla_x \\cdot\\left[ u_t(x|z) p_{t|Z}(x|z) \\right] p_Z(z) dz.   $$</p> <p>Using the Leibniz rule to move differentiation outside the integral:</p> <p>$$   \\frac{d}{dt} p_t(x) = -\\nabla_x \\cdot \\int u_t(x|z) p_{t|Z}(x|z) p_Z(z) dz.   $$</p> <p>Step 2: Expressing $ u_t(x) $ Using Bayes' Formula   From Bayes' rule:</p> <p>$$   p_{t|Z}(x|z) p_Z(z) = p_{Z|t}(z|x) p_t(x),   $$</p> <p>we substitute:</p> <p>$$   \\frac{d}{dt} p_t(x) = -\\nabla_x \\cdot \\int u_t(x|z) p_{Z|t}(z|x) p_t(x) dz.   $$</p> <p>Since the definition of $ u_t(x) $ is:</p> <p>$$   u_t(x) = \\int u_t(x|z) p_{Z|t}(z|x) dz,   $$</p> <p>Contitional Flow Matching</p> <p>Define the conditional flow matching loss as   $$   L_{CF M}(\\theta) = E_{t,z,x_t\\sim p_{t|Z}(\\cdot | Z)} || u_t(x_t|Z)-v_\\theta(x_t,t)||^2   $$</p> <p>Equivalent of gradient of FM and CFM loss</p> <p>The gradients of the Flow Matching loss and the Conditional Flow Matching loss coincide. In particular, the minimizer of the Conditional Flow Matching loss is the marginal velocity.</p> <p>$$   \\begin{equation}   \\nabla_\\theta L_{F M}(\\theta)  = \\nabla_\\theta L_{CF M}(\\theta)   \\end{equation}   $$</p> Proof <p>To prove that the gradients of the Flow Matching (FM) loss and the Conditional Flow Matching (CFM) loss coincide, i.e.,</p> <p>Take the gradient</p> <p>$$   \\begin{equation}   \\nabla L_{F M}  = \\nabla E_{t, X_t}[||v(x,t) - v_\\theta(x,t)||^2]    = E_{t, X_t} (v_\\theta - v)\\nabla v_\\theta   \\end{equation}   $$</p> <p>Use the expectation formula of conditional velocity field</p> <p>$$   \\begin{equation}         \\nabla L_{F M} =E_{t,X_t} (v_\\theta - E_{Z\\sim p_{Z|t}(\\cdot|X_t)}[v_t(X_t|Z)])\\nabla v_\\theta = E_{t,X_t,Z\\sim p_{Z|t}(\\cdot|X_t) } (v_\\theta - v_t(x_t|Z))\\nabla v_\\theta   \\end{equation}   $$</p> <p>By chain rule,</p> <p>$$   \\nabla L_{F M} = = E_{t,X_t,Z\\sim p_{Z|t}(\\cdot|X_t) }[ \\nabla (||v_t(x_t|Z) - v_\\theta||^2)]   $$</p> <p>Change the order of expectation and gradient we hvae</p> <p>$$   \\nabla L_{F M}  =  \\nabla  E_{t,X_t,Z\\sim p_{Z|t}(\\cdot|X_t) }[||v_t(x_t|Z) - v_\\theta||^2]   $$</p> <p>By the Bayes's rule,</p> <p>$$p_{Z|t}(Z|X_t) p(X_t) = p_{t|Z}(X_t|z) $$</p> <p>we have</p> <p>$$ E_{X_t,Z\\sim p_{Z|t}(\\cdot|X_t) } \\cdots  = \\int p(X_t)p_{Z|t}(\\cdot|X_t) \\cdots dx_t dz $$</p> <p>which equals</p> <p>$$ E_{X,x_t\\sim p_{t|Z}(X_t|z) } \\cdots  = \\int p(z)p_{t|Z}(x_t|z) \\cdots dx_t dz $$</p> <p>Hence</p> <p>$$   \\begin{equation}   \\nabla L_{F M} = \\nabla E_{t,z,x_t\\sim p_{t|Z}(x_t|z)} [ ||v_t(x_t|Z) - v_\\theta||^2]   \\end{equation}   $$</p> <p>Different conditioning choices Z exist but are essentially all equivalent.</p> <p></p> <p>Main options include fixing target samples \\(Z = X_1\\), source samples \\(Z = X_0\\), or two-sided \\(Z = (X_0, X_1)\\).</p>"},{"location":"book/chapter9_flow_matching/introduction/","title":"Introduction to Flow Matching","text":"<p>The goal of the generative model is sampling from a real data distribution \\(p_{data}(x)\\). However, it's not possible to unkow the density function of \\(p_{data}(x)\\).</p> <ul> <li> <p>If we know the density function \\(p_{data}(x)\\) or the score function of \\(p_{data}(x)\\), we can use the sampling algorithm to generate samples from \\(p_{data}(x)\\) like the Langevin Dynamics as described in the engery based function.</p> </li> <li> <p>If we say, approximate the original density function is not easy, we can work around this problem by building a path from the original data distribution to a easy distribution. Then we can sample from the easy distribution and follow the path to sample the original data distribution. Like the diffusion process, either DDPM or SDE based model, we build a path that the original data distribution is gradually transformed to a standard normal distribution. The path is called the probability path.</p> </li> </ul> <p>By building the probability path, there are two main streams:</p> <ul> <li>random walk on the probability path</li> <li>deterministic flow on the probability path</li> </ul> <p>While the first one is similar to the motion of particales in the heat diffusion phenomino. The partical is random walk has high probability to low temparature area. But the density function (heat) is changed over time deterministically and finally reach the uniform distribution.</p> <p>The second one is similar to the motion of the particles in the water flow. The flow is driven by a force and particle is moved deterministically.</p> <p>Mathematical, the first one can be written as</p> \\[ \\tag{1} \\boxed{ dx \\;=\\;f(x,t)\\;dt \\;+\\; g(t)\\,d\\overline{W}_t, } \\] <p>where \\(f\\) is the drift term and \\(g\\) is the diffusion term. See more in the diffusion chapter if reader is not clear about this process.</p> <p>The second one can be written as</p> \\[ \\tag{2} \\boxed{ dx \\;=\\;v(x,t)\\;dt, } \\] <p>In either case, the probability path is deterministic, they can be described by the following ODE, respectively.</p> \\[ \\tag{3}  \\frac{d\\, p_t(x)}{dt}  = -\\nabla \\cdot (p_t(x) f(x, t)) + \\frac{1}{2} g^2(t) \\nabla^2 p_t(x) \\] \\[ \\tag{4}  \\frac{d\\,p_t(x)}{dt}  = -\\nabla \\cdot (p_t(x) v(x, t)) \\] <p>Correspondingly, the score function (see chapter energey based model for the score function explanation) can be written as</p> \\[ \\tag{5}  \\frac{d}{dt} \\log p_t(x) = -\\nabla \\cdot f(x, t) - f(x, t) \\cdot \\nabla \\log p_t(x) + \\frac{1}{2} g^2(t) \\frac{\\nabla^2 p_t(x)}{p_t(x)} \\] \\[ \\tag{6}  \\frac{d}{dt} \\log p_t(x) = -\\nabla \\cdot v(x, t) - v(x, t) \\cdot \\nabla \\log p_t(x) \\] <p>Refer the chapter diffusion for explanation of the equation (1), (3), and (5). Dont be afraid if not understand formula (2), (4) and (6). We will describe in the following contents.</p> <p>Here we just indicate that the two different density map path both has a deterministic change with respect to time \\(t\\).</p> <p>Let's consider the deterministic flow and forget about the above formulas.</p> <p>Just like the diffusion model, we can build a path from the easy distribution to the data destribution that we are interested. But unlike the diffusion, the path of the element moving is deterministic. If we can build this path, then we can sample from the easy distribution and follow the path to sample from the data distribution. That is the main idea of the flow generative models.</p> <p>Mathematically, suppose we have the two distribution \\(p_{easy}(x)\\) and \\(p_{data}(x)\\). Generally, we denote them as \\(p\\) and \\(q\\) for the source and target distribution and \\(X_0\\sim p\\) and \\(X_1\\sim q\\) are two random variables, \\(x_0\\) and \\(x_1\\) are two samples from \\(p\\) and \\(q\\) respectively.</p> <p>Suppose \\(\\psi(x,t)=\\psi_t(x)\\) is the moving path of the samples from \\(p\\) to \\(q\\) at any time \\(t\\) such that it starts from \\(X_0\\sim p\\) and ends at \\(X_1\\sim q\\), i.e.,</p> \\[ \\psi(X_0,t=0) = X_0\\sim p, \\; \\psi(X_0,t=1) = X_1\\sim q. \\] <p>Naturally, for any \\(t\\), there will be a density \\(p_t(x)\\), where</p> \\[\\psi(X_0,t)\\sim p_t(x)\\] <p></p> <p>The problem is how to find the moving path \\(\\psi(x,t)\\) based on what we have is \\(p\\) and \\(q\\). Can we estimate \\(\\psi(x,t)\\) directly? This seems to have no help compared to estimating \\(\\psi(x,1)\\) directly and has no help from the flow that from easy to complex distribution.</p> <p>If we can't estimate \\(\\psi(x,t)\\) directly, what else we can do. One way is to estimate the velocity field \\(v(x,t)\\) by the definition</p> \\[\\frac{d \\psi(x,t)}{dt} = v(\\psi(x,t),t)\\] <p>Which sometimes noted as \\(\\frac{dx}{dt} = v(x,t)\\).</p> <p>Due to the continuity equation (probability conservation), we have the relationship between \\(p_t\\) and \\(v(x,t)\\)</p> \\[ \\tag{7} \\frac{d p_t(x)}{dt} = -\\nabla \\cdot\\big[ v(x,t) p_t(x)\\big] \\] <p>If we can estimate the velocity field, then we sample the data from \\(q\\) and follow the velocity field to sample the data from \\(p\\) by solving the ODE.</p> <p>Although we haven't known how to build a path from \\(p\\) to \\(q\\), just assume we have a path. Let's see how to model it.</p> <p>Let's say \\(v_\\theta(x,t)\\) is the estimated velocity field from the network with parameters \\(\\theta\\). Then how to find the loss function?</p> <p>Generative Flow model</p> <p>A generative flow model is to find a flow \\(\\psi(x,t)\\) such that</p> \\[X_1 = \\psi(X_0,t=1)\\sim q\\] <p>There are two main ways to find the loss function:</p> <ol> <li>Maximal log likelihood (MLL)</li> <li>Score matching (regression of velocity field)</li> </ol> <p>In the MML sense, we have the loss</p> \\[ \\max_\\theta \\log p_\\theta(x) = \\log p(x(0)) -\\max \\int_{0}^{T} \\operatorname{Tr}\\Bigl(\\frac{\\partial v(x(t),t)}{\\partial x(t)}\\Bigr) dt, \\] <p>which is exactly the continuous normalization flow method, see chapter \"normalize flow\" for more details.</p> <p>In the score matching sense, we have the loss</p> \\[  \\mathcal{L}_{\\text{FM}} = \\mathbb{E}_{t\\sim \\mathcal{U}(0,T),\\, x\\sim p_t(x)} \\Bigl[\\, \\|v_\\theta(x,t) - v^*(x,t)\\|^2 \\Bigr]. \\] <p>Which requires us to know the exact velocity field \\(v^*(x,t)\\) at any time \\(t\\) and position \\(x\\).</p> <p>Flow Matching</p> <p>Let \\(\\{p_t(x)\\}_{t\\in[0,T]}\\) be a family of distributions interpolating between a base distribution \\(p_0(x)\\) and a target distribution \\(p_T(x)\\). Suppose there exists an ideal, time-dependent velocity field \\(v(x,t)\\) that satisfies the continuity equation</p> \\[ \\frac{\\partial p_t(x)}{\\partial t} + \\nabla \\cdot \\Bigl(p_t(x) \\, v(x,t)\\Bigr) = 0. \\] <p>Flow Matching trains a neural network \\(v_\\theta(x,t)\\) to approximate \\(v(x,t)\\) by minimizing the distance:</p> \\[ \\mathcal{L}(\\theta) = \\mathbb{E}_{t\\sim \\mathcal{U}(0,T),\\, x\\sim p_t(x)} D(v_\\theta(x,t), v(x,t)) \\] <p>where \\(D\\) is the metric (distance function) of the distance between \\(v_\\theta(x,t)\\) and \\(v(x,t)\\) and is usually chosen as the mean squared error (MSE).</p> <p>Once trained, the learned velocity field defines a deterministic flow via the ODE</p> \\[ \\frac{dx(t)}{dt} = v_\\theta(x(t),t), \\quad x(0) \\sim p_0(x), \\] <p>which, upon integration from \\(t=0\\) to \\(t=T\\), transports samples from the base distribution \\(p_0(x)\\) to approximate the target distribution \\(p_T(x)\\).</p> <p>Now we have defined what is the flow matching method. One thing that is not solved yet is</p> <ol> <li>How to build a path from \\(p\\) to \\(q\\)?</li> <li>How to know the ground truth of the velocity field \\(v(x,t)\\)?</li> </ol> <p>The first problem seems easy. For example, we can build</p> \\[X_t = tX_1 + (1-t)X_0\\] <p>This is a well-defined probability path transit from \\(X_0\\) to \\(X_1\\) gradually. Of course, there are many different constructions of the probability path.</p> <p>Just take this probability path as an example, and see how to can find the ground truth of the velocity field \\(v(x,t)\\).</p> <p>Although we know the probability path, but for each particle, how they are moved is not easy to understand.</p> <p>As we do usually, we can do it from simple to complex.</p> <p>First, let's assume that \\(X_1\\) contains only single particle \\(x_1\\), then the path of each particle in \\(X_0\\) is easy to know.</p> \\[\\psi(x,t) = t x_1 + (1-t) x, \\quad \\forall x \\in X_0,\\quad t\\in [0,1]\\] <p>as shown in the figure below.</p> <p></p> <p>We have</p> \\[v(x,t) = x_1 - x\\quad \\forall x \\in X_0,\\quad t\\in[0,1]\\] <p>Thus we have the loss</p> \\[ L_\\theta = \\mathbb{E}_{t\\sim \\mathcal{U}(0,T),\\, x_0\\sim p_0(x)} ||v_\\theta(x,t) - (x_1-x_0)|| \\] <p>It is too hard for us to find the ground truth of the velocity field \\(v(x,t)\\). We introduce the conditional velocity field \\(v(x|x_1,t)\\) by condition \\(X_1 = x_1\\).</p> <p>And we have the  conditional flow matching loss</p> \\[ L_{\\text{CMF}}(\\theta) = \\mathbb{E}_{t, X_0, X_1} ||v_\\theta(x,t) - (x_1-x_0)|| \\] <p>That is the target of the conditional flow matching. One may be confused why this conditional flow matching is equivalent to the original flow matching, we will give further explanation in the next sections.</p> <p>By the above explanation, we can have a simple training script for the flow matching</p> <pre><code>import torch\nfrom torch import nn, Tensor\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import make_moons\n\nclass Flow(nn.Module):\n    def __init__(self, dim: int = 2, h: int = 64):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(dim + 1, h), nn.ELU(),\n            nn.Linear(h, h), nn.ELU(),\n            nn.Linear(h, h), nn.ELU(),\n            nn.Linear(h, dim))\n\n    def forward(self, x_t: Tensor, t: Tensor) -&gt; Tensor:\n        return self.net(torch.cat((t, x_t), -1))\n\n    def step(self, x_t: Tensor, t_start: Tensor, t_end: Tensor) -&gt; Tensor:\n        t_start = t_start.view(1, 1).expand(x_t.shape[0], 1)\n        # For simplicity, using midpoint ODE solver in this example\n        return x_t + (t_end - t_start) * self(x_t + self(x_t, t_start) * (t_end - t_start) / 2,\n        t_start + (t_end - t_start) / 2)\n\n# training\nflow = Flow()\noptimizer = torch.optim.Adam(flow.parameters(), 1e-2)\nloss_fn = nn.MSELoss()\nfrom tqdm import  tqdm\nfor _ in tqdm(range(20000)):\n    x_1 = Tensor(make_moons(256, noise=0.05)[0])\n    x_0 = torch.randn_like(x_1)\n    t = torch.rand(len(x_1), 1)\n    x_t = (1 - t) * x_0 + t * x_1\n    dx_t = x_1 - x_0\n    optimizer.zero_grad()\n    loss_fn(flow(x_t, t), dx_t).backward()\n    optimizer.step()\n\n# sampling\nx = torch.randn(3000, 2)\nn_steps = 8\nfig, axes = plt.subplots(1, n_steps + 1, figsize=(32, 4), sharex=True, sharey=True)\ntime_steps = torch.linspace(0, 1.0, n_steps + 1)\n\naxes[0].scatter(x.detach()[:, 0], x.detach()[:, 1], s=10)\naxes[0].set_title(f't = {time_steps[0]:.2f}')\naxes[0].set_xlim(-3.0, 3.0)\naxes[0].set_ylim(-3.0, 3.0)\n\nfor i in range(n_steps):\n    x = flow.step(x, time_steps[i], time_steps[i + 1])\n    axes[i + 1].scatter(x.detach()[:, 0], x.detach()[:, 1], s=10)\n    axes[i + 1].set_title(f't = {time_steps[i + 1]:.2f}')\n\nplt.tight_layout()\nplt.show()\n</code></pre> <p>The density distribution changes</p> <p></p>"},{"location":"book/chapter9_flow_matching/probability_with_velocity_field/","title":"Relationship bettween probability path, flow, and velocity field","text":"<p>[TOC] In this article, we illustrate the relationship between the probability density path and the continuity equation.</p>"},{"location":"book/chapter9_flow_matching/probability_with_velocity_field/#1-what-is-probability-path","title":"1. What is probability path","text":"<p>A probability path is a path that the probability density function is gradually transformed from one distribution to another.</p> <p>In the flow model, we also have the probability path. Suppose \\(X_t = \\psi(X_0,t)\\), and \\(X_t\\sim p_t\\), the \\(p_t\\) defines a probability path from \\(X_0\\sim p\\) to \\(X_1\\sim q\\).</p> <p>Recall the push forward function in the normalize flow method,</p> \\[  p_x(\\mathbf{x}) = p_z(f^{-1}(\\mathbf{x})) \\left| \\det J_{f^{-1}}(\\mathbf{x}) \\right| \\] <p>where \\(f\\) is the flow function that maps from \\(z\\) to \\(x\\) and \\(f^{-1}\\) is its inverse.</p> <p>Denote</p> \\[\\psi_{\\#}P_z = p_x(\\mathbf{X})\\] <p>Thus we have</p> \\[ p_{t}(x)   = \\psi_{\\#} p(x) \\] <p>We say \\(v(x,t)\\) generates the probability path from \\(x_0\\sim p\\) to \\(x_1\\sim q\\) if</p> \\[\\tag{1} X_t = \\psi(X_0,t)\\sim p_t \\; \\forall t\\in [0,1)\\]"},{"location":"book/chapter9_flow_matching/probability_with_velocity_field/#2-velocity-field","title":"2. Velocity Field","text":"<p>Given the definition of \\(\\psi(x,t)\\), we have the velocity field \\(v(x,t)\\)</p> \\[\\tag{2}\\frac{\\text{d} \\psi(x,t)}{\\text{d} t} = v(\\psi(x,t),t)\\] <p>Flow Existence</p> <p>ODE (2) has a unique solution in \\(C^r (\\Omega,R^d)\\) diffeomorphism if \\(u\\) is \\(C^r([0,1]\\times R^d, R^d)\\)</p> Solution Existence <p>Proof omitted. It is easy to prove by constructing the integral function.</p>"},{"location":"book/chapter9_flow_matching/probability_with_velocity_field/#3-continuity-equation","title":"3. Continuity Equation","text":"<p>Continuity equation establishes the relation ship between probability path and velocity fields which is come from the mass conversation.</p> <p>Continuity Equation</p> <p>Let \\(p_t\\) be a probability path and \\(v(x,t)\\) be a vector field. The continuity equation states that the probability density function \\(p(x)\\) satisfies</p> \\[\\frac{d p_t(x)}{dt} = -\\nabla \\cdot\\big[ v(x,t) p_t(x)\\big]\\] Continuity Equation <p>Here's a concise proof using \\(\\rho \\cdot \\mathbf{v}\\) directly:</p> <ol> <li> <p>Probability Conservation: For a probability density \\(\\rho(\\mathbf{x}, t)\\), the total probability in any volume \\(V\\) is $$ P_V(t) = \\int_V \\rho(\\mathbf{x}, t)\\, d\\mathbf{x}. $$ Conservation of probability means that any change in \\(P_V(t)\\) comes solely from the flow of probability across the boundary \\(\\partial V\\).</p> </li> <li> <p>Expressing the Rate of Change: If probability moves with a velocity field \\(\\mathbf{v}(\\mathbf{x}, t)\\), then the probability flux (flow per unit area) is \\(\\rho(\\mathbf{x}, t)\\mathbf{v}(\\mathbf{x}, t)\\). Thus, the rate at which probability leaves the volume \\(V\\) is $$ \\frac{d}{dt}P_V(t) = -\\int_{\\partial V} \\rho(\\mathbf{x}, t) \\,\\mathbf{v}(\\mathbf{x}, t)\\cdot d\\mathbf{S}, $$ where \\(d\\mathbf{S}\\) is the outward-pointing surface element.</p> </li> <li> <p>Applying the Divergence Theorem: The divergence theorem converts the surface integral to a volume integral: $$ \\int_{\\partial V} \\rho \\,\\mathbf{v}\\cdot d\\mathbf{S} = \\int_V \\nabla \\cdot (\\rho\\, \\mathbf{v})\\, d\\mathbf{x}. $$ Thus, we have $$ \\frac{d}{dt}P_V(t) = -\\int_V \\nabla \\cdot (\\rho\\, \\mathbf{v})\\, d\\mathbf{x}. $$</p> </li> <li> <p>Equating the Two Expressions: On the one hand, directly differentiating \\(P_V(t)\\) gives $$ \\frac{d}{dt}P_V(t) = \\int_V \\frac{\\partial \\rho}{\\partial t}\\, d\\mathbf{x}. $$ Equating the two expressions: $$ \\int_V \\frac{\\partial \\rho}{\\partial t}\\, d\\mathbf{x} = -\\int_V \\nabla \\cdot (\\rho\\, \\mathbf{v})\\, d\\mathbf{x}. $$</p> </li> <li> <p>Local Form of the Continuity Equation: Since the volume \\(V\\) is arbitrary, the integrands must be equal at every point: $$ \\frac{\\partial \\rho}{\\partial t} + \\nabla \\cdot (\\rho\\, \\mathbf{v}) = 0. $$ This is the continuity equation expressed directly in terms of \\(\\rho\\) and \\(\\mathbf{v}\\).</p> </li> </ol> <p>Uniquness of \\(p_t\\)</p> <p>Given the continuity equation and \\(v(x,t)\\), there must exist a unique solution \\(p_t\\) which is the probability path generated by \\(v(x,t)\\).</p> <p>Below is a simpler proof based on an energy estimate (using the \\(L^2\\) norm) and Gronwall\u2019s inequality. We assume that \\(r(t,x)\\) is sufficiently smooth and decays at infinity so that all integrations by parts are justified, and that \\(v(x,t)\\) is locally Lipschitz with bounded divergence.</p> Uniqueness of the solution <p>Equivalence of probability path and velocity field</p> <p>Let \\(p_t\\) be a probability path and \\(v(x,t)\\) a locally Lipchitz integrable vector field, then the following are equivalent</p> <ol> <li> <p>Cotinuity Equation holds for \\(t\\in[0,1)]\\)</p> </li> <li> <p>\\(v(x,t)\\) generates \\(p_t\\)</p> </li> </ol> velocity generated probability path"},{"location":"book/chapter9_flow_matching/probability_with_velocity_field/#the-setting","title":"The Setting","text":"<p>let \\(p_t\\) and \\(q_t\\) both satisfied the continuity equation with same initial condition. Let \\(r(t,x) = p_t(x) - q_t(x)\\). Then \\(r(t,x)\\) satisfy</p> \\[ \\partial_t r(t,x) = -\\nabla\\cdot\\big(r(t,x)\\,v(x,t)\\big), \\quad r(0,x) = 0. \\] <p>It is enough to show that  \\(r(t,x)\\equiv 0\\) for all \\(t\\ge0\\).</p>"},{"location":"book/chapter9_flow_matching/probability_with_velocity_field/#step-1-multiply-by-r-and-integrate","title":"Step 1. Multiply by \\(r\\) and Integrate","text":"<p>Multiply the equation by \\(r(t,x)\\) and integrate over \\(\\mathbb{R}^d\\):</p> \\[ \\int_{\\mathbb{R}^d} r\\,\\partial_t r\\,dx = -\\int_{\\mathbb{R}^d} r\\,\\nabla\\cdot\\big(r\\,v\\big)\\,dx. \\]"},{"location":"book/chapter9_flow_matching/probability_with_velocity_field/#step-2-rewrite-the-left-hand-side","title":"Step 2. Rewrite the Left-Hand Side","text":"<p>Notice that $$ \\int_{\\mathbb{R}^d} r\\,\\partial_t r\\,dx = \\frac{1}{2}\\frac{d}{dt}\\int_{\\mathbb{R}^d} r^2\\,dx. $$</p>"},{"location":"book/chapter9_flow_matching/probability_with_velocity_field/#step-3-rewrite-the-right-hand-side-by-expanding-the-divergence","title":"Step 3. Rewrite the Right-Hand Side by Expanding the Divergence","text":"<p>Expand the divergence: $$ \\nabla\\cdot\\big(r\\,v\\big) = v\\cdot\\nabla r + r\\,\\nabla\\cdot v. $$ Thus, $$ -\\int r\\,\\nabla\\cdot\\big(r\\,v\\big)\\,dx = -\\int r\\,(v\\cdot\\nabla r)\\,dx - \\int r^2\\,\\nabla\\cdot v\\,dx. $$</p>"},{"location":"book/chapter9_flow_matching/probability_with_velocity_field/#step-4-handle-the-first-term-on-the-right","title":"Step 4. Handle the First Term on the Right","text":"<p>Consider the term $$ -\\int r\\,(v\\cdot\\nabla r)\\,dx. $$ Notice that $$ -\\int r\\,(v\\cdot\\nabla r)\\,dx = -\\frac{1}{2}\\int v\\cdot \\nabla (r^2)\\,dx. $$ Integrate by parts (using that \\(r\\) decays sufficiently at infinity so that the boundary term vanishes): $$ -\\frac{1}{2}\\int v\\cdot \\nabla (r^2)\\,dx = \\frac{1}{2}\\int r^2\\,\\nabla\\cdot v\\,dx. $$</p>"},{"location":"book/chapter9_flow_matching/probability_with_velocity_field/#step-5-combine-the-terms","title":"Step 5. Combine the Terms","text":"<p>The two terms on the right-hand side become: $$ -\\frac{1}{2}\\int r^2\\,\\nabla\\cdot v\\,dx - \\int r^2\\,\\nabla\\cdot v\\,dx = -\\frac{1}{2}\\int r^2\\,\\nabla\\cdot v\\,dx. $$ Thus, we obtain $$ \\frac{1}{2}\\frac{d}{dt}\\int r^2\\,dx = -\\frac{1}{2}\\int r^2\\,\\nabla\\cdot v\\,dx. $$ Multiplying both sides by 2 yields $$ \\frac{d}{dt}\\int r^2\\,dx = -\\int r^2\\,\\nabla\\cdot v\\,dx. $$</p>"},{"location":"book/chapter9_flow_matching/probability_with_velocity_field/#step-6-use-boundedness-of-nablacdot-v-and-apply-gronwalls-inequality","title":"Step 6. Use Boundedness of \\(\\nabla\\cdot v\\) and Apply Gronwall\u2019s Inequality","text":"<p>Assume that the divergence of \\(v\\) is bounded in absolute value; that is, there exists a constant \\(M\\) such that $$ \\bigl|\\nabla\\cdot v(x,t)\\bigr| \\le M \\quad \\text{for all } x,t. $$ Then, $$ \\frac{d}{dt}\\int r^2\\,dx \\le M \\int r^2\\,dx. $$ Let $$ E(t) = \\int_{\\mathbb{R}^d} r(t,x)^2\\,dx. $$ We then have $$ \\frac{d}{dt}E(t) \\le M\\, E(t). $$ Since \\(r(0,x)=0\\), it follows that \\(E(0)=0\\).</p> <p>By Gronwall\u2019s inequality, we obtain $$ E(t) \\le E(0) e^{Mt} = 0. $$ Thus, for all \\(t\\ge0\\), $$ \\int_{\\mathbb{R}^d} r(t,x)^2\\,dx = 0. $$ Since the \\(L^2\\) norm of \\(r(t,\\cdot)\\) is zero, we conclude that $$ r(t,x) = 0 \\quad \\text{for almost every } x \\text{ and for all } t\\ge0. $$</p>"},{"location":"book/chapter9_flow_matching/probability_with_velocity_field/#1-flow-map","title":"1. Flow Map","text":"<p>Let \\(v: \\mathbb{R}^d \\times [0,T] \\to \\mathbb{R}^d\\) be a smooth (or Lipschitz) velocity field. Define the flow map \\(X(t,x)\\) as the unique solution of the ordinary differential equation (ODE)</p> \\[ \\begin{cases} \\displaystyle \\frac{d}{dt} X(t,x) = v\\big(X(t,x),t\\big),\\$1mm] X(0,x) = x. \\end{cases} \\] <p>Under these conditions, for each fixed \\(t\\), the map \\(X(t,\\cdot): \\mathbb{R}^d \\to \\mathbb{R}^d\\) is a diffeomorphism.</p>"},{"location":"book/chapter9_flow_matching/probability_with_velocity_field/#2-pushforward-of-measures","title":"2 Pushforward of Measures","text":"<p>Given a probability measure \\(p_0\\) (absolutely continuous with respect to the Lebesgue measure, with density \\(p_0(x)\\)), the pushforward of \\(p_0\\) under \\(X(t,\\cdot)\\) is defined by</p> \\[ p_t = \\bigl(X(t,\\cdot)\\bigr)_\\# p_0, \\] <p>which means that for any measurable set \\(A \\subset \\mathbb{R}^d\\),</p> \\[ p_t(A) = p_0\\Bigl(X(t,\\cdot)^{-1}(A)\\Bigr). \\] <p>If \\(X(t,\\cdot)\\) is a diffeomorphism, the density \\(p_t(x)\\) is given by the change of variables formula: $$ p_t(x) = \\frac{p_0(y)}{\\bigl|\\det\\bigl(D_yX(t,y)\\bigr)\\bigr|},\\quad\\text{with } x=X(t,y). $$</p>"},{"location":"book/chapter9_flow_matching/probability_with_velocity_field/#3-weak-formulation-of-the-continuity-equation","title":"3. Weak Formulation of the Continuity Equation","text":"<p>and integrating over \\(\\mathbb{R}^d\\) yields: $$ \\int_{\\mathbb{R}^d} \\partial_t p_t(x) \\, f(x) \\,dx + \\int_{\\mathbb{R}^d} \\nabla\\cdot\\big(v(x,t)p_t(x)\\big)\\, f(x) \\,dx = 0. $$</p> <p>Applying integration by parts (using the compact support of \\(f\\)) to the second term gives</p> \\[ \\int_{\\mathbb{R}^d} \\nabla\\cdot\\big(v(x,t)p_t(x)\\big)\\, f(x) \\,dx = - \\int_{\\mathbb{R}^d} v(x,t)p_t(x)\\cdot\\nabla f(x)\\,dx. \\] <p>Thus, the weak formulation becomes: for all \\(f\\in C_c^\\infty(\\mathbb{R}^d)\\),</p> \\[ \\frac{d}{dt}\\int_{\\mathbb{R}^d} p_t(x)\\, f(x)\\, dx = \\int_{\\mathbb{R}^d} v(x,t)p_t(x)\\cdot\\nabla f(x)\\, dx. \\] <p>We denote the pairing by \\(\\langle p_t, f\\rangle\\), so that</p> \\[ \\frac{d}{dt}\\langle p_t, f\\rangle = \\langle p_t, v(\\cdot,t)\\cdot\\nabla f \\rangle. \\]"},{"location":"book/chapter9_flow_matching/probability_with_velocity_field/#4-pushforward-density-satisfies-the-weak-formulation","title":"4. Pushforward Density Satisfies the Weak Formulation","text":"<p>Define the candidate solution by the pushforward:</p> \\[ \\tilde{p}_t = \\bigl(X(t,\\cdot)\\bigr)_\\# p_0. \\] <p>For any test function \\(f\\in C_c^\\infty(\\mathbb{R}^d)\\), by the definition of pushforward we have</p> \\[ \\int_{\\mathbb{R}^d} f(x)\\,\\tilde{p}_t(x)\\,dx = \\int_{\\mathbb{R}^d} f\\bigl(X(t,x)\\bigr)\\,p_0(x)\\,dx. \\] <p>Differentiate with respect to \\(t\\) and apply the chain rule:</p> \\[ \\frac{d}{dt} f\\bigl(X(t,x)\\bigr) = \\nabla f\\bigl(X(t,x)\\bigr) \\cdot \\frac{d}{dt} X(t,x) = \\nabla f\\bigl(X(t,x)\\bigr)\\cdot v\\bigl(X(t,x),t\\bigr). \\] <p>Thus,</p> \\[ \\frac{d}{dt}\\int f(x)\\,\\tilde{p}_t(x)\\,dx = \\int_{\\mathbb{R}^d} \\nabla f\\bigl(X(t,x)\\bigr)\\cdot v\\bigl(X(t,x),t\\bigr)\\, p_0(x)\\,dx. \\] <p>Changing variables using \\(y = X(t,x)\\) (with the corresponding Jacobian) yields</p> \\[ \\frac{d}{dt}\\int f(x)\\,\\tilde{p}_t(x)\\,dx = \\int_{\\mathbb{R}^d} \\nabla f(y)\\cdot v(y,t)\\, \\tilde{p}_t(y)\\,dy. \\] <p>This is exactly the weak formulation of the continuity equation:</p> \\[ \\frac{d}{dt}\\langle \\tilde{p}_t, f\\rangle = \\langle \\tilde{p}_t, v(\\cdot,t)\\cdot\\nabla f \\rangle. \\] <p>Assuming the continuity equation has a unique solution (under suitable regularity conditions on \\(v\\) and \\(p_t\\)), and noting that both \\(p_t\\) and \\(\\tilde{p}_t\\) satisfy the weak formulation with the same initial condition \\(p_0\\), we conclude that $$ p_t = \\tilde{p}_t \\quad \\text{for all } t\\in[0,T]. $$ That is, the evolution of the probability density under the velocity field \\(v(x,t)\\) is exactly given by the pushforward of \\(p_0\\) under the flow \\(X(t,\\cdot)\\).</p>"},{"location":"book/chapter9_flow_matching/probability_with_velocity_field/#4-log-likelihood-path","title":"4. Log Likelihood path","text":""},{"location":"book/chapter9_flow_matching/probability_with_velocity_field/#41-1-introduction","title":"4.1 1. Introduction","text":"<p>One of the advantages of using normalizing flows as generative models is that they allow the computation of exact likelihoods \\(\\log p_1(x)\\) for any $ x \\in \\mathbb{R}^d $. This is made possible by the Continuity Equation, leading to the Instantaneous Change of Variables formulation.</p> <p>The governing ordinary differential equation (ODE) for the change in log-likelihood along a trajectory \\(\\psi_t(x)\\) is given by:</p> \\[ \\frac{d}{dt} \\log p (\\psi_t (x),t) = - \\nabla \\cdot u_t (\\psi_t (x)). \\]"},{"location":"book/chapter9_flow_matching/probability_with_velocity_field/#42-2-derivation","title":"4.2 2. Derivation","text":"<p>Let \\(p_t = p(x,t)\\) incase confusino about the partial derivative and derivateive.</p>"},{"location":"book/chapter9_flow_matching/probability_with_velocity_field/#421-step-1-the-continuity-equation","title":"4.2.1 Step 1: The Continuity Equation","text":"<p>The probability density function $ p_t(x) $ evolves over time according to the Continuity Equation:</p> \\[ \\frac{\\partial p(x,t)}{\\partial t} + \\nabla \\cdot (p_t(x) u_t(x)) = 0. \\] <p>Expanding the divergence term using the product rule:</p> \\[ \\nabla \\cdot (p_t(x) u_t(x)) = (\\nabla p_t(x)) \\cdot u_t(x) + p_t(x) (\\nabla \\cdot u_t(x)). \\] <p>Substituting this into the Continuity Equation:</p> \\[ \\frac{\\partial p_t(x)}{\\partial t} + (\\nabla p_t(x)) \\cdot u_t(x) + p_t(x) (\\nabla \\cdot u_t(x)) = 0. \\]"},{"location":"book/chapter9_flow_matching/probability_with_velocity_field/#422-step-2-expressing-in-terms-of-log-probability","title":"4.2.2 Step 2: Expressing in Terms of Log Probability","text":"<p>Define the log-probability function:</p> \\[ \\log p_t(x). \\] <p>Taking the total derivative along the flow:</p> \\[ \\frac{d}{dt} p_t(\\psi_t(x)) = \\frac{\\partial p_t}{\\partial t} + (\\nabla p_t) \\cdot \\frac{d \\psi_t}{dt}. \\] <p>Since $ x = \\psi_t(x) $ follows the deterministic transport equation:</p> \\[ \\frac{d \\psi_t}{dt} = u_t(\\psi_t(x)), \\] <p>substituting gives:</p> \\[ \\frac{d}{dt} p_t(\\psi_t(x)) = \\frac{\\partial p_t}{\\partial t} + (\\nabla p_t) \\cdot u_t. \\] <p>Dividing by $ p_t(x) $ and substituting the continuity equation:</p> \\[ \\frac{d}{dt} \\log p_t(\\psi_t(x)) = - \\nabla \\cdot u_t(x). \\]"},{"location":"book/chapter9_flow_matching/probability_with_velocity_field/#43-3-hutchinsons-trace-estimator-for-efficient-computation","title":"4.3 3. Hutchinson\u2019s Trace Estimator for Efficient Computation","text":"<p>Directly computing $ \\nabla \\cdot u_t(x) $, which requires evaluating the trace of the Jacobian matrix, is expensive for large dimensions. Hutchinson\u2019s trace estimator provides an efficient approximation:</p> \\[ \\nabla \\cdot u_t(x) = \\mathbb{E}_Z \\left[ Z^T \\partial_x u_t(x) Z \\right], \\] <p>where $ Z \\sim \\mathcal{N}(0, I) $. Plugging this into the integral form of log-likelihood evolution:</p> \\[ \\log p_1 (\\psi_1 (x)) = \\log p_0 (\\psi_0 (x)) - \\mathbb{E}_Z \\int_0^1 \\text{tr} \\left[ Z^T \\partial_x u_t (\\psi_t (x)) Z \\right] dt. \\] <p>This allows efficient computation using vector-Jacobian products (VJP) in autodiff frameworks.</p>"}]}